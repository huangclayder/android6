From c6155e78c45f639f066c8bd6b2ea09d2097488f5 Mon Sep 17 00:00:00 2001
From: Xiaowen Liu <xiaowen.liu@freescale.com>
Date: Thu, 19 Nov 2015 12:15:41 -0500
Subject: [PATCH 607/635] MA-7121 enable camera hal v3 interface.

Implement Camera HAL v3 inteface.
CameraHal class which contains all module state that isn't specific
to an individual camera device.
Stream class represents input/output stream from framework.
Camera class decribes camera device static parameters and provides interface
to framework. It also has its own DeviceStream.
DeviceStream class which represents camera device stream flow maintain
device stream state and operate on device stream interaction.
The specific camera sensor has its own specific static parameters.
OvStream and UvcStream inheriting from DeviceStream operate on devices
stream interaction according their specific interface.

Signed-off-by: Xiaowen Liu <xiaowen.liu@freescale.com>
---
 Android.mk                          |   2 +-
 mx6/libcamera/Android.mk            |   2 +-
 mx6/libcamera3/Android.mk           |  77 ++++
 mx6/libcamera3/Camera.cpp           | 785 +++++++++++++++++++++++++++++++++
 mx6/libcamera3/Camera.h             | 126 ++++++
 mx6/libcamera3/CameraHAL.cpp        | 337 +++++++++++++++
 mx6/libcamera3/CameraHAL.h          |  57 +++
 mx6/libcamera3/CameraUtils.cpp      | 340 +++++++++++++++
 mx6/libcamera3/CameraUtils.h        | 198 +++++++++
 mx6/libcamera3/DeviceStream.cpp     | 415 ++++++++++++++++++
 mx6/libcamera3/DeviceStream.h       | 140 ++++++
 mx6/libcamera3/JpegBuilder.cpp      | 677 +++++++++++++++++++++++++++++
 mx6/libcamera3/JpegBuilder.h        | 191 ++++++++
 mx6/libcamera3/MessageQueue.cpp     | 140 ++++++
 mx6/libcamera3/MessageQueue.h       | 100 +++++
 mx6/libcamera3/Metadata.cpp         | 613 ++++++++++++++++++++++++++
 mx6/libcamera3/Metadata.h           |  77 ++++
 mx6/libcamera3/NV12_resize.c        | 303 +++++++++++++
 mx6/libcamera3/NV12_resize.h        | 148 +++++++
 mx6/libcamera3/Ov5640Csi.cpp        | 177 ++++++++
 mx6/libcamera3/Ov5640Csi.h          |  34 ++
 mx6/libcamera3/Ov5640Mipi.cpp       | 170 ++++++++
 mx6/libcamera3/Ov5640Mipi.h         |  34 ++
 mx6/libcamera3/Ov5642Csi.cpp        | 173 ++++++++
 mx6/libcamera3/Ov5642Csi.h          |  35 ++
 mx6/libcamera3/OvStream.cpp         | 362 ++++++++++++++++
 mx6/libcamera3/OvStream.h           |  49 +++
 mx6/libcamera3/Stream.cpp           | 515 ++++++++++++++++++++++
 mx6/libcamera3/Stream.h             | 107 +++++
 mx6/libcamera3/UvcDevice.cpp        | 153 +++++++
 mx6/libcamera3/UvcDevice.h          |  34 ++
 mx6/libcamera3/UvcStream.cpp        | 328 ++++++++++++++
 mx6/libcamera3/UvcStream.h          |  51 +++
 mx6/libcamera3/VendorTags.cpp       | 182 ++++++++
 mx6/libcamera3/VendorTags.h         |  73 ++++
 mx6/libcamera3/YuvToJpegEncoder.cpp | 839 ++++++++++++++++++++++++++++++++++++
 mx6/libcamera3/YuvToJpegEncoder.h   | 151 +++++++
 37 files changed, 8193 insertions(+), 2 deletions(-)
 create mode 100644 mx6/libcamera3/Android.mk
 create mode 100644 mx6/libcamera3/Camera.cpp
 create mode 100644 mx6/libcamera3/Camera.h
 create mode 100644 mx6/libcamera3/CameraHAL.cpp
 create mode 100644 mx6/libcamera3/CameraHAL.h
 create mode 100644 mx6/libcamera3/CameraUtils.cpp
 create mode 100644 mx6/libcamera3/CameraUtils.h
 create mode 100644 mx6/libcamera3/DeviceStream.cpp
 create mode 100644 mx6/libcamera3/DeviceStream.h
 create mode 100644 mx6/libcamera3/JpegBuilder.cpp
 create mode 100644 mx6/libcamera3/JpegBuilder.h
 create mode 100644 mx6/libcamera3/MessageQueue.cpp
 create mode 100644 mx6/libcamera3/MessageQueue.h
 create mode 100644 mx6/libcamera3/Metadata.cpp
 create mode 100644 mx6/libcamera3/Metadata.h
 create mode 100644 mx6/libcamera3/NV12_resize.c
 create mode 100644 mx6/libcamera3/NV12_resize.h
 create mode 100644 mx6/libcamera3/Ov5640Csi.cpp
 create mode 100644 mx6/libcamera3/Ov5640Csi.h
 create mode 100644 mx6/libcamera3/Ov5640Mipi.cpp
 create mode 100644 mx6/libcamera3/Ov5640Mipi.h
 create mode 100644 mx6/libcamera3/Ov5642Csi.cpp
 create mode 100644 mx6/libcamera3/Ov5642Csi.h
 create mode 100644 mx6/libcamera3/OvStream.cpp
 create mode 100644 mx6/libcamera3/OvStream.h
 create mode 100644 mx6/libcamera3/Stream.cpp
 create mode 100644 mx6/libcamera3/Stream.h
 create mode 100644 mx6/libcamera3/UvcDevice.cpp
 create mode 100644 mx6/libcamera3/UvcDevice.h
 create mode 100644 mx6/libcamera3/UvcStream.cpp
 create mode 100644 mx6/libcamera3/UvcStream.h
 create mode 100644 mx6/libcamera3/VendorTags.cpp
 create mode 100644 mx6/libcamera3/VendorTags.h
 create mode 100644 mx6/libcamera3/YuvToJpegEncoder.cpp
 create mode 100644 mx6/libcamera3/YuvToJpegEncoder.h

diff --git a/Android.mk b/Android.mk
index e416238..28d6209 100644
--- a/Android.mk
+++ b/Android.mk
@@ -1,6 +1,6 @@
 imx_dirs := libsensors libgps lights wlan libbt-ath3k \
             alsa libsensors_sensorhub mx6/libgralloc_wrapper \
-            mx6/hwcomposer mx6/power mx6/libcamera mx6/libcamera2 \
+            mx6/hwcomposer mx6/power mx6/libcamera mx6/libcamera3 \
             mx7/gralloc mx7/hwcomposer \
 
 include $(call all-named-subdir-makefiles,$(imx_dirs))
diff --git a/mx6/libcamera/Android.mk b/mx6/libcamera/Android.mk
index 30403ea..3110052 100644
--- a/mx6/libcamera/Android.mk
+++ b/mx6/libcamera/Android.mk
@@ -15,7 +15,7 @@
 LOCAL_PATH:= $(call my-dir)
 
 ifeq ($(BOARD_HAVE_IMX_CAMERA),true)
-ifneq ($(IMX_CAMERA_HAL_V2),true)
+ifeq ($(IMX_CAMERA_HAL_V1),true)
 include $(CLEAR_VARS)
 
 LOCAL_SRC_FILES:=    \
diff --git a/mx6/libcamera3/Android.mk b/mx6/libcamera3/Android.mk
new file mode 100644
index 0000000..d561faa
--- /dev/null
+++ b/mx6/libcamera3/Android.mk
@@ -0,0 +1,77 @@
+# Copyright (C) 2012 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+LOCAL_PATH := $(call my-dir)
+
+ifeq ($(BOARD_HAVE_IMX_CAMERA),true)
+ifeq ($(IMX_CAMERA_HAL_V3),true)
+
+include $(CLEAR_VARS)
+
+LOCAL_MODULE := camera.$(TARGET_BOARD_PLATFORM)
+LOCAL_MODULE_RELATIVE_PATH := hw
+
+LOCAL_C_INCLUDES += \
+    system/core/include \
+    system/media/camera/include \
+    external/jpeg \
+    external/jhead \
+    device/fsl-proprietary/include \
+    external/fsl_vpu_omx/OpenMAXIL/src/component/vpu_wrapper \
+    external/fsl_imx_omx/OpenMAXIL/src/component/vpu_wrapper \
+    hardware/imx/mx6/libgralloc_wrapper \
+    system/core/libion/include
+
+LOCAL_SRC_FILES := \
+    CameraHAL.cpp \
+    Camera.cpp \
+    Metadata.cpp \
+    Stream.cpp \
+    VendorTags.cpp \
+    CameraUtils.cpp \
+    MessageQueue.cpp \
+    DeviceStream.cpp \
+    JpegBuilder.cpp \
+    Ov5640Csi.cpp \
+    Ov5640Mipi.cpp \
+    Ov5642Csi.cpp \
+    YuvToJpegEncoder.cpp \
+    NV12_resize.c \
+    OvStream.cpp \
+    UvcStream.cpp \
+    UvcDevice.cpp
+
+LOCAL_SHARED_LIBRARIES := \
+    libcamera_metadata \
+    libcutils \
+    liblog \
+    libsync \
+    libutils \
+    libc \
+    libjpeg \
+    libjhead \
+    libion \
+    libg2d \
+    libbinder \
+    lib_vpu_wrapper \
+    libcamera_client
+
+LOCAL_CFLAGS += -Wall -Wextra -fvisibility=hidden
+
+LOCAL_MODULE_TAGS := optional
+
+include $(BUILD_SHARED_LIBRARY)
+
+endif
+endif
diff --git a/mx6/libcamera3/Camera.cpp b/mx6/libcamera3/Camera.cpp
new file mode 100644
index 0000000..c827bd3
--- /dev/null
+++ b/mx6/libcamera3/Camera.cpp
@@ -0,0 +1,785 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <cstdlib>
+#include <stdio.h>
+#include <linux/videodev2.h>
+#include <hardware/camera3.h>
+#include <sync/sync.h>
+#include <system/camera_metadata.h>
+#include <system/graphics.h>
+#include <utils/Mutex.h>
+#include <sys/stat.h>
+#include "CameraHAL.h"
+#include "Metadata.h"
+#include "Stream.h"
+
+//#define LOG_NDEBUG 0
+#include <cutils/log.h>
+
+#include "Camera.h"
+#include "CameraUtils.h"
+#include "Ov5640Mipi.h"
+#include "Ov5640Csi.h"
+#include "Ov5642Csi.h"
+#include "UvcDevice.h"
+#include "OvStream.h"
+#include "UvcStream.h"
+
+#define CAMERA_SYNC_TIMEOUT 5000 // in msecs
+
+
+extern "C" {
+// Shim passed to the framework to close an opened device.
+static int32_t close_device(hw_device_t* dev)
+{
+    camera3_device_t* cam_dev = reinterpret_cast<camera3_device_t*>(dev);
+    Camera* cam = static_cast<Camera*>(cam_dev->priv);
+    return cam->closeDev();
+}
+} // extern "C"
+
+android::Mutex Camera::sStaticInfoLock(android::Mutex::PRIVATE);
+
+Camera* Camera::createCamera(int32_t id, char* name, int32_t facing,
+                             int32_t orientation, char* path)
+{
+    Camera* device = NULL;
+    sp<DeviceStream> devStream = NULL;
+
+    android::Mutex::Autolock al(sStaticInfoLock);
+
+    if (strstr(name, OV5640MIPI_SENSOR_NAME)) {
+        ALOGI("create id:%d ov5640 mipi device", id);
+        device = new Ov5640Mipi(id, facing, orientation, path);
+        devStream = new OvStream(device);
+    }
+    else if (strstr(name, OV5642CSI_SENSOR_NAME)) {
+        ALOGI("create id:%d ov5642 csi device", id);
+        device = new Ov5642Csi(id, facing, orientation, path);
+        devStream = new OvStream(device);
+    }
+    else if (strstr(name, OV5640CSI_SENSOR_NAME)) {
+        ALOGI("create id:%d ov5640 csi device", id);
+        device = new Ov5640Csi(id, facing, orientation, path);
+        devStream = new OvStream(device);
+    }
+    else if (strstr(name, UVC_SENSOR_NAME)) {
+        ALOGI("create id:%d usb camera device", id);
+        device = new UvcDevice(id, facing, orientation, path);
+        devStream = new UvcStream(device, path);
+    }
+    else {
+        ALOGE("doesn't support camera id:%d %s", id, name);
+    }
+
+    if (device != NULL) {
+        device->setDeviceStream(devStream);
+    }
+
+    return device;
+}
+
+Camera::Camera(int32_t id, int32_t facing, int32_t orientation, char* path)
+  : mId(id),
+    mStaticInfo(NULL),
+    mBusy(false),
+    mCallbackOps(NULL),
+    mStreams(NULL),
+    mNumStreams(0)
+{
+    ALOGI("%s:%d: new camera device", __func__, mId);
+    android::Mutex::Autolock al(mDeviceLock);
+
+    camera_info::facing = facing;
+    camera_info::orientation = orientation;
+    strncpy(SensorData::mDevPath, path, CAMAERA_FILENAME_LENGTH);
+
+    memset(&mDevice, 0, sizeof(mDevice));
+    mDevice.common.tag    = HARDWARE_DEVICE_TAG;
+    mDevice.common.version = CAMERA_DEVICE_API_VERSION_3_0;
+    mDevice.common.close  = close_device;
+    mDevice.ops           = const_cast<camera3_device_ops_t*>(&sOps);
+    mDevice.priv          = this;
+}
+
+Camera::~Camera()
+{
+    android::Mutex::Autolock al(mDeviceLock);
+    if (mStaticInfo != NULL) {
+        free_camera_metadata(mStaticInfo);
+    }
+
+    if (mDeviceStream != NULL) {
+        mDeviceStream.clear();
+    }
+}
+
+void Camera::setPreviewPixelFormat()
+{
+    mPreviewPixelFormat = getMatchFormat(mVpuSupportFmt,
+                          MAX_VPU_SUPPORT_FORMAT,
+                          mAvailableFormats, MAX_SENSOR_FORMAT);
+}
+
+void Camera::setPicturePixelFormat()
+{
+    mPicturePixelFormat = getMatchFormat(mPictureSupportFmt,
+                            MAX_PICTURE_SUPPORT_FORMAT,
+                            mAvailableFormats, MAX_SENSOR_FORMAT);
+}
+
+int32_t Camera::setDeviceStream(sp<DeviceStream>& stream)
+{
+    android::Mutex::Autolock al(mDeviceLock);
+    mDeviceStream = stream;
+    return 0;
+}
+
+int32_t Camera::openDev(const hw_module_t *module, hw_device_t **device)
+{
+    ALOGI("%s:%d: Opening camera device", __func__, mId);
+    android::Mutex::Autolock al(mDeviceLock);
+
+    if (mBusy) {
+        ALOGE("%s:%d: Error! Camera device already opened", __func__, mId);
+        return -EBUSY;
+    }
+
+    // open camera dev nodes, etc
+    int32_t ret = mDeviceStream->openDev(mDevPath);
+    if (ret != 0) {
+        ALOGE("can not open camera devpath:%s", mDevPath);
+        return BAD_VALUE;
+    }
+
+    mBusy = true;
+    mDevice.common.module = const_cast<hw_module_t*>(module);
+    *device = &mDevice.common;
+    return 0;
+}
+
+int32_t Camera::getInfo(struct camera_info *info)
+{
+    android::Mutex::Autolock al(mDeviceLock);
+
+    info->facing = camera_info::facing;
+    info->orientation = camera_info::orientation;
+    info->device_version = mDevice.common.version;
+    if (mStaticInfo == NULL) {
+        int32_t ret = initSensorStaticData();
+        if (ret != 0) {
+            ALOGE("%s initSensorStaticData failed");
+            return ret;
+        }
+        setPreviewPixelFormat();
+        setPicturePixelFormat();
+        mStaticInfo = Metadata::createStaticInfo(*this);
+    }
+    info->static_camera_characteristics = mStaticInfo;
+    return 0;
+}
+
+int32_t Camera::closeDev()
+{
+    ALOGI("%s:%d: Closing camera device", __func__, mId);
+    android::Mutex::Autolock al(mDeviceLock);
+
+    if (!mBusy) {
+        ALOGE("%s:%d: Error! Camera device not open", __func__, mId);
+        return -EINVAL;
+    }
+
+    // close camera dev nodes, etc
+    mDeviceStream->closeDev();
+
+    mBusy = false;
+    return 0;
+}
+
+int32_t Camera::initializeDev(const camera3_callback_ops_t *callback_ops)
+{
+    int32_t res;
+
+    ALOGV("%s:%d: callback_ops=%p", __func__, mId, callback_ops);
+    {
+        android::Mutex::Autolock al(mDeviceLock);
+        mCallbackOps = callback_ops;
+    }
+    // per-device specific initialization
+    res = initDevice();
+    if (res != 0) {
+        ALOGE("%s:%d: Failed to initialize device!", __func__, mId);
+        return res;
+    }
+    return 0;
+}
+
+int32_t Camera::configureStreams(camera3_stream_configuration_t *stream_config)
+{
+    camera3_stream_t *astream;
+    sp<Stream> *newStreams = NULL;
+
+    ALOGV("%s:%d: stream_config=%p", __func__, mId, stream_config);
+    android::Mutex::Autolock al(mDeviceLock);
+
+    if (stream_config == NULL) {
+        ALOGE("%s:%d: NULL stream configuration array", __func__, mId);
+        return -EINVAL;
+    }
+    if (stream_config->num_streams == 0) {
+        ALOGE("%s:%d: Empty stream configuration array", __func__, mId);
+        return -EINVAL;
+    }
+
+    // Create new stream array
+    newStreams = new sp<Stream>[stream_config->num_streams];
+    ALOGV("%s:%d: Number of Streams: %d", __func__, mId,
+            stream_config->num_streams);
+
+    // Mark all current streams unused for now
+    for (int32_t i = 0; i < mNumStreams; i++)
+        mStreams[i]->setReuse(false);
+    // Fill new stream array with reused streams and new streams
+    for (uint32_t i = 0; i < stream_config->num_streams; i++) {
+        astream = stream_config->streams[i];
+        if (astream->max_buffers > 0) {
+            ALOGV("%s:%d: Reusing stream %d", __func__, mId, i);
+            newStreams[i] = reuseStream(astream);
+        } else {
+            ALOGV("%s:%d: Creating new stream %d", __func__, mId, i);
+            newStreams[i] = new Stream(mId, astream, this);
+        }
+
+        if (newStreams[i] == NULL) {
+            ALOGE("%s:%d: Error processing stream %d", __func__, mId, i);
+            goto err_out;
+        }
+        astream->priv = newStreams[i].get();
+    }
+
+    // Verify the set of streams in aggregate
+    if (!isValidStreamSet(newStreams, stream_config->num_streams)) {
+        ALOGE("%s:%d: Invalid stream set", __func__, mId);
+        goto err_out;
+    }
+
+    // Destroy all old streams and replace stream array with new one
+    destroyStreams(mStreams, mNumStreams);
+    mStreams = newStreams;
+    mNumStreams = stream_config->num_streams;
+
+    // Clear out last seen settings metadata
+    mSettings.clear();
+    return 0;
+
+err_out:
+    // Clean up temporary streams, preserve existing mStreams/mNumStreams
+    destroyStreams(newStreams, stream_config->num_streams);
+    return -EINVAL;
+}
+
+void Camera::destroyStreams(sp<Stream> *streams, int32_t count)
+{
+    if (streams == NULL)
+        return;
+    for (int32_t i = 0; i < count; i++) {
+        // Only destroy streams that weren't reused
+        if (streams[i] != NULL)
+            streams[i].clear();
+    }
+    delete [] streams;
+}
+
+sp<Stream> Camera::reuseStream(camera3_stream_t *astream)
+{
+    sp<Stream> priv = reinterpret_cast<Stream*>(astream->priv);
+    // Verify the re-used stream's parameters match
+    if (!priv->isValidReuseStream(mId, astream)) {
+        ALOGE("%s:%d: Mismatched parameter in reused stream", __func__, mId);
+        return NULL;
+    }
+    // Mark stream to be reused
+    priv->setReuse(true);
+    return priv;
+}
+
+bool Camera::isValidStreamSet(sp<Stream> *streams, int32_t count)
+{
+    int32_t inputs = 0;
+    int32_t outputs = 0;
+
+    if (streams == NULL) {
+        ALOGE("%s:%d: NULL stream configuration streams", __func__, mId);
+        return false;
+    }
+    if (count == 0) {
+        ALOGE("%s:%d: Zero count stream configuration streams", __func__, mId);
+        return false;
+    }
+    // Validate there is at most one input stream and at least one output stream
+    for (int32_t i = 0; i < count; i++) {
+        // A stream may be both input and output (bidirectional)
+        if (streams[i]->isInputType())
+            inputs++;
+        if (streams[i]->isOutputType())
+            outputs++;
+    }
+    ALOGV("%s:%d: Configuring %d output streams and %d input streams",
+            __func__, mId, outputs, inputs);
+    if (outputs < 1) {
+        ALOGE("%s:%d: Stream config must have >= 1 output", __func__, mId);
+        return false;
+    }
+    if (inputs > 1) {
+        ALOGE("%s:%d: Stream config must have <= 1 input", __func__, mId);
+        return false;
+    }
+    // TODO: check for correct number of Bayer/YUV/JPEG/Encoder streams
+    return true;
+}
+
+int32_t Camera::registerStreamBuffers(const camera3_stream_buffer_set_t *buf_set)
+{
+    ALOGV("%s:%d: buffer_set=%p", __func__, mId, buf_set);
+    if (buf_set == NULL) {
+        ALOGE("%s:%d: NULL buffer set", __func__, mId);
+        return -EINVAL;
+    }
+    if (buf_set->stream == NULL) {
+        ALOGE("%s:%d: NULL stream handle", __func__, mId);
+        return -EINVAL;
+    }
+    return 0;
+}
+
+bool Camera::isValidTemplateType(int32_t type)
+{
+    return type >= CAMERA3_TEMPLATE_PREVIEW && type < CAMERA3_TEMPLATE_COUNT;
+}
+
+const camera_metadata_t* Camera::constructDefaultRequestSettings(int32_t type)
+{
+    ALOGI("%s:%d: type=%d", __func__, mId, type);
+
+    android::Mutex::Autolock al(mDeviceLock);
+    if (!isValidTemplateType(type)) {
+        ALOGE("%s:%d: Invalid template request type: %d", __func__, mId, type);
+        return NULL;
+    }
+    return mTemplates[type]->get();
+}
+
+int32_t Camera::processCaptureRequest(camera3_capture_request_t *request)
+{
+    if (request == NULL) {
+        ALOGE("%s:%d: NULL request recieved", __func__, mId);
+        return -EINVAL;
+    }
+
+    ALOGV("%s:%d: Request Frame:%d Settings:%p", __func__, mId,
+            request->frame_number, request->settings);
+
+    {
+        android::Mutex::Autolock al(mDeviceLock);
+        // NULL indicates use last settings
+        if (request->settings == NULL) {
+            if (mSettings == NULL || mSettings->isEmpty()) {
+                ALOGE("%s:%d: NULL settings without previous set Frame:%d Req:%p",
+                        __func__, mId, request->frame_number, request);
+                return -EINVAL;
+            }
+        } else {
+            mSettings = new Metadata(request->settings);
+        }
+    }
+
+    if (request->input_buffer != NULL) {
+        ALOGV("%s:%d: Reprocessing input buffer %p", __func__, mId,
+                request->input_buffer);
+
+        if (!isValidReprocessSettings(request->settings)) {
+            ALOGE("%s:%d: Invalid settings for reprocess request: %p",
+                    __func__, mId, request->settings);
+            return -EINVAL;
+        }
+    } else {
+        ALOGV("%s:%d: Capturing new frame.", __func__, mId);
+
+        if (!isValidCaptureSettings(request->settings)) {
+            ALOGE("%s:%d: Invalid settings for capture request: %p",
+                    __func__, mId, request->settings);
+            return -EINVAL;
+        }
+    }
+
+    if (request->num_output_buffers <= 0) {
+        ALOGE("%s:%d: Invalid number of output buffers: %d", __func__, mId,
+                request->num_output_buffers);
+        return -EINVAL;
+    }
+
+    // set preview/still capture stream.
+    sp<Stream> preview = NULL, stillcap = NULL;
+    sp<Metadata> meta = NULL;
+    sp<DeviceStream> devStream = NULL;
+    camera3_callback_ops* callback = NULL;
+    {
+        android::Mutex::Autolock al(mDeviceLock);
+        for (int32_t i = 0; i < mNumStreams; i++) {
+            sp<Stream>& stream = mStreams[i];
+            if (stream->isPreview()) {
+                preview = stream;
+            }
+            if (stream->isJpeg()) {
+                stillcap = stream;
+            }
+        }
+
+        meta = mSettings;
+        devStream = mDeviceStream;
+        callback = (camera3_callback_ops*)mCallbackOps;
+    }
+    sp<CaptureRequest> capture = new CaptureRequest();
+
+    // configure DeviceStream according to request type.
+    if (request->settings != NULL) {
+        if (meta->getRequestType() == TYPE_STILLCAP) {
+            if (stillcap == NULL) {
+                ALOGE("still capture intent but without jpeg stream");
+                stillcap = preview;
+            }
+            devStream->configure(stillcap);
+        }
+        else {
+            devStream->configure(preview);
+        }
+    }
+
+    capture->init(request, callback, meta);
+
+    return devStream->requestCapture(capture);
+
+err_out:
+    // TODO: this should probably be a total device failure; transient for now
+    return -EINVAL;
+}
+
+bool Camera::isValidReprocessSettings(const camera_metadata_t* /*settings*/)
+{
+    // TODO: reject settings that cannot be reprocessed
+    // input buffers unimplemented, use this to reject reprocessing requests
+    ALOGE("%s:%d: Input buffer reprocessing not implemented", __func__, mId);
+    return false;
+}
+
+//do advanced character set.
+int32_t Camera::processSettings(sp<Metadata> settings, uint32_t frame)
+{
+    if (settings == NULL || settings->isEmpty()) {
+        ALOGE("invalid settings");
+        return 0;
+    }
+
+    int64_t timestamp = 0;
+    struct timespec ts;
+    clock_gettime(CLOCK_BOOTTIME, &ts);
+    timestamp = ts.tv_sec * 1000000000ULL + ts.tv_nsec;
+    settings->addInt64(ANDROID_SENSOR_TIMESTAMP, 1, &timestamp);
+
+    uint8_t aeState = ANDROID_CONTROL_AE_STATE_INACTIVE;
+    settings->addUInt8(ANDROID_CONTROL_AE_STATE, 1, &aeState);
+
+    uint8_t afState = ANDROID_CONTROL_AF_STATE_INACTIVE;
+    settings->addUInt8(ANDROID_CONTROL_AF_STATE, 1, &afState);
+
+    uint8_t awbState = ANDROID_CONTROL_AWB_STATE_INACTIVE;
+    settings->addUInt8(ANDROID_CONTROL_AWB_STATE, 1, &awbState);
+
+    int32_t triggerId = 0;
+    camera_metadata_entry_t entry = settings->find(ANDROID_CONTROL_AF_TRIGGER_ID);
+    if (entry.count > 0) {
+        triggerId = entry.data.i32[0];
+    }
+
+    settings->addInt32(ANDROID_CONTROL_AF_TRIGGER_ID, 1, &triggerId);
+    settings->addInt32(ANDROID_CONTROL_AE_PRECAPTURE_ID, 1, &triggerId);
+
+    notifyShutter(frame, timestamp);
+
+    return 0;
+}
+
+void Camera::notifyShutter(uint32_t frame_number, uint64_t timestamp)
+{
+    int32_t res;
+    struct timespec ts;
+
+    // If timestamp is 0, get timestamp from right now instead
+    if (timestamp == 0) {
+        ALOGW("%s:%d: No timestamp provided, using CLOCK_BOOTTIME",
+                __func__, mId);
+        res = clock_gettime(CLOCK_BOOTTIME, &ts);
+        if (res == 0) {
+            timestamp = ts.tv_sec * 1000000000ULL + ts.tv_nsec;
+        } else {
+            ALOGE("%s:%d: No timestamp and failed to get CLOCK_BOOTTIME %s(%d)",
+                    __func__, mId, strerror(errno), errno);
+        }
+    }
+    camera3_notify_msg_t m;
+    memset(&m, 0, sizeof(m));
+    m.type = CAMERA3_MSG_SHUTTER;
+    m.message.shutter.frame_number = frame_number;
+    m.message.shutter.timestamp = timestamp;
+    mCallbackOps->notify(mCallbackOps, &m);
+}
+
+void Camera::dumpDev(int32_t fd)
+{
+    ALOGV("%s:%d: Dumping to fd %d", __func__, mId, fd);
+    android::Mutex::Autolock al(mDeviceLock);
+
+    dprintf(fd, "Camera ID: %d (Busy: %d)\n", mId, mBusy);
+
+    // TODO: dump all settings
+    dprintf(fd, "Most Recent Settings: (%p)\n", mSettings.get());
+
+    dprintf(fd, "Number of streams: %d\n", mNumStreams);
+    for (int32_t i = 0; i < mNumStreams; i++) {
+        dprintf(fd, "Stream %d/%d:\n", i, mNumStreams);
+        mStreams[i]->dump(fd);
+    }
+}
+
+const char* Camera::templateToString(int32_t type)
+{
+    switch (type) {
+    case CAMERA3_TEMPLATE_PREVIEW:
+        return "CAMERA3_TEMPLATE_PREVIEW";
+    case CAMERA3_TEMPLATE_STILL_CAPTURE:
+        return "CAMERA3_TEMPLATE_STILL_CAPTURE";
+    case CAMERA3_TEMPLATE_VIDEO_RECORD:
+        return "CAMERA3_TEMPLATE_VIDEO_RECORD";
+    case CAMERA3_TEMPLATE_VIDEO_SNAPSHOT:
+        return "CAMERA3_TEMPLATE_VIDEO_SNAPSHOT";
+    case CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG:
+        return "CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG";
+    }
+    // TODO: support vendor templates
+    return "Invalid template type!";
+}
+
+int32_t Camera::setTemplate(int32_t type, camera_metadata_t *settings)
+{
+    android::Mutex::Autolock al(mDeviceLock);
+
+    if (!isValidTemplateType(type)) {
+        ALOGE("%s:%d: Invalid template request type: %d", __func__, mId, type);
+        return -EINVAL;
+    }
+
+    if (mTemplates[type] != NULL && !mTemplates[type]->isEmpty()) {
+        ALOGI("%s:%d: Setting already constructed template type %s(%d)",
+                __func__, mId, templateToString(type), type);
+        return 0;
+    }
+
+    // Make a durable copy of the underlying metadata
+    mTemplates[type] = new Metadata(settings);
+    if (mTemplates[type]->isEmpty()) {
+        ALOGE("%s:%d: Failed to clone metadata %p for template type %s(%d)",
+                __func__, mId, settings, templateToString(type), type);
+        return -EINVAL;
+    }
+    return 0;
+}
+
+int32_t Camera::initDevice()
+{
+    int32_t res;
+
+    // Use base settings to create all other templates and set them
+    res = setPreviewTemplate();
+    if (res)
+        return res;
+    res = setStillTemplate();
+    if (res)
+        return res;
+    res = setRecordTemplate();
+    if (res)
+        return res;
+    res = setSnapshotTemplate();
+    if (res)
+        return res;
+    res = setZslTemplate();
+    if (res)
+        return res;
+
+    return 0;
+}
+
+int32_t Camera::setPreviewTemplate()
+{
+    Metadata base;
+    // Create standard settings templates from copies of base metadata
+    // TODO: use vendor tags in base metadata
+    Metadata::createSettingTemplate(base, *this, CAMERA3_TEMPLATE_PREVIEW);
+
+    // Setup default preview controls
+    int32_t res = base.add1UInt8(ANDROID_CONTROL_CAPTURE_INTENT,
+                            ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW);
+
+    if (res)
+        return res;
+    // TODO: set fast auto-focus, auto-whitebalance, auto-exposure, auto flash
+    return setTemplate(CAMERA3_TEMPLATE_PREVIEW, base.get());
+}
+
+int32_t Camera::setStillTemplate()
+{
+    Metadata base;
+    // Create standard settings templates from copies of base metadata
+    // TODO: use vendor tags in base metadata
+    Metadata::createSettingTemplate(base, *this, CAMERA3_TEMPLATE_STILL_CAPTURE);
+
+    int32_t res = base.add1UInt8(ANDROID_CONTROL_CAPTURE_INTENT,
+                            ANDROID_CONTROL_CAPTURE_INTENT_STILL_CAPTURE);
+    // Setup default still capture controls
+    if (res)
+        return res;
+    // TODO: set fast auto-focus, auto-whitebalance, auto-exposure, auto flash
+    return setTemplate(CAMERA3_TEMPLATE_STILL_CAPTURE, base.get());
+}
+
+int32_t Camera::setRecordTemplate()
+{
+    Metadata base;
+    // Create standard settings templates from copies of base metadata
+    // TODO: use vendor tags in base metadata
+    Metadata::createSettingTemplate(base, *this, CAMERA3_TEMPLATE_VIDEO_RECORD);
+
+    int32_t res = base.add1UInt8(ANDROID_CONTROL_CAPTURE_INTENT,
+                            ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_RECORD);
+    // Setup default video record controls
+    if (res)
+        return res;
+    // TODO: set slow auto-focus, auto-whitebalance, auto-exposure, flash off
+    return setTemplate(CAMERA3_TEMPLATE_VIDEO_RECORD, base.get());
+}
+
+int32_t Camera::setSnapshotTemplate()
+{
+    Metadata base;
+    // Create standard settings templates from copies of base metadata
+    // TODO: use vendor tags in base metadata
+    Metadata::createSettingTemplate(base, *this, CAMERA3_TEMPLATE_VIDEO_SNAPSHOT);
+
+    int32_t res = base.add1UInt8(ANDROID_CONTROL_CAPTURE_INTENT,
+                            ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT);
+    // Setup default video snapshot controls
+    if (res)
+        return res;
+    // TODO: set slow auto-focus, auto-whitebalance, auto-exposure, flash off
+    return setTemplate(CAMERA3_TEMPLATE_VIDEO_SNAPSHOT, base.get());
+}
+
+int32_t Camera::setZslTemplate()
+{
+    Metadata base;
+    // Create standard settings templates from copies of base metadata
+    // TODO: use vendor tags in base metadata
+    Metadata::createSettingTemplate(base, *this, CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG);
+
+    int32_t res = base.add1UInt8(ANDROID_CONTROL_CAPTURE_INTENT,
+                            ANDROID_CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG);
+    // Setup default zero shutter lag controls
+    if (res)
+        return res;
+    // TODO: set reprocessing parameters for zsl input queue
+    return setTemplate(CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG, base.get());
+}
+
+bool Camera::isValidCaptureSettings(const camera_metadata_t* settings)
+{
+    // TODO: reject settings that cannot be captured
+    return true;
+}
+
+//---------------------------------------------------------
+extern "C" {
+// Get handle to camera from device priv data
+static Camera *camdev_to_camera(const camera3_device_t *dev)
+{
+    return reinterpret_cast<Camera*>(dev->priv);
+}
+
+static int32_t initialize(const camera3_device_t *dev,
+        const camera3_callback_ops_t *callback_ops)
+{
+    return camdev_to_camera(dev)->initializeDev(callback_ops);
+}
+
+static int32_t configure_streams(const camera3_device_t *dev,
+        camera3_stream_configuration_t *stream_list)
+{
+    return camdev_to_camera(dev)->configureStreams(stream_list);
+}
+
+static int32_t register_stream_buffers(const camera3_device_t *dev,
+        const camera3_stream_buffer_set_t *buffer_set)
+{
+    return camdev_to_camera(dev)->registerStreamBuffers(buffer_set);
+}
+
+static const camera_metadata_t *construct_default_request_settings(
+        const camera3_device_t *dev, int32_t type)
+{
+    return camdev_to_camera(dev)->constructDefaultRequestSettings(type);
+}
+
+static int32_t process_capture_request(const camera3_device_t *dev,
+        camera3_capture_request_t *request)
+{
+    return camdev_to_camera(dev)->processCaptureRequest(request);
+}
+
+static void dump(const camera3_device_t *dev, int32_t fd)
+{
+    camdev_to_camera(dev)->dumpDev(fd);
+}
+
+static int32_t flush(const camera3_device_t*)
+{
+    ALOGE("%s: unimplemented.", __func__);
+    return -1;
+}
+
+} // extern "C"
+
+const camera3_device_ops_t Camera::sOps = {
+    .initialize = initialize,
+    .configure_streams = configure_streams,
+    .register_stream_buffers = register_stream_buffers,
+    .construct_default_request_settings
+        = construct_default_request_settings,
+    .process_capture_request = process_capture_request,
+    .get_metadata_vendor_tag_ops = NULL,
+    .dump = dump,
+    .flush = flush,
+    .reserved = {0},
+};
+
diff --git a/mx6/libcamera3/Camera.h b/mx6/libcamera3/Camera.h
new file mode 100644
index 0000000..572eda4
--- /dev/null
+++ b/mx6/libcamera3/Camera.h
@@ -0,0 +1,126 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _CAMERA_H_
+#define _CAMERA_H_
+
+#include <hardware/hardware.h>
+#include <hardware/camera3.h>
+#include <utils/Mutex.h>
+#include "Metadata.h"
+#include "Stream.h"
+#include "CameraUtils.h"
+
+class DeviceStream;
+// Camera represents a physical camera on a device.
+// This is constructed when the HAL module is loaded, one per physical camera.
+// It is opened by the framework, and must be closed before it can be opened
+// again.
+// This is an abstract class, containing all logic and data shared between all
+// camera devices (front, back, etc) and common to the ISP.
+class Camera : public camera_info, public SensorData
+{
+public:
+    // id is used to distinguish cameras. 0 <= id < NUM_CAMERAS.
+    // module is a handle to the HAL module, used when the device is opened.
+    Camera(int32_t id, int32_t facing, int32_t orientation, char* path);
+    virtual ~Camera();
+
+    static Camera* createCamera(int32_t id, char* name, int32_t facing,
+                                int32_t orientation, char* path);
+    int32_t setDeviceStream(sp<DeviceStream>& stream);
+    // do advanced character set.
+    int32_t processSettings(sp<Metadata> settings, uint32_t frame);
+    // Common Camera Device Operations (see <hardware/camera_common.h>)
+    int32_t openDev(const hw_module_t *module, hw_device_t **device);
+    int32_t getInfo(struct camera_info *info);
+    int32_t closeDev();
+
+    // Camera v3 Device Operations (see <hardware/camera3.h>)
+    int32_t initializeDev(const camera3_callback_ops_t *callback_ops);
+    int32_t configureStreams(camera3_stream_configuration_t *stream_list);
+    int32_t registerStreamBuffers(const camera3_stream_buffer_set_t *buf_set);
+    const camera_metadata_t *constructDefaultRequestSettings(int32_t type);
+    int32_t processCaptureRequest(camera3_capture_request_t *request);
+    void dumpDev(int32_t fd);
+
+protected:
+    // Initialize static camera characteristics for individual device
+    virtual status_t initSensorStaticData() = 0;
+
+    virtual void setPreviewPixelFormat();
+    virtual void setPicturePixelFormat();
+
+    // Verify settings are valid for a capture
+    virtual bool isValidCaptureSettings(const camera_metadata_t *);
+    // Separate initialization method for individual devices when opened
+    virtual int32_t initDevice();
+    // Accessor used by initDevice() to set the templates' metadata
+    int32_t setTemplate(int32_t type, camera_metadata_t *static_info);
+    // Prettyprint32_t template names
+    const char* templateToString(int32_t type);
+
+    // Initialize each template metadata controls
+    int32_t setPreviewTemplate();
+    int32_t setStillTemplate();
+    int32_t setRecordTemplate();
+    int32_t setSnapshotTemplate();
+    int32_t setZslTemplate();
+
+private:
+    // Camera device handle returned to framework for use
+    camera3_device_t mDevice;
+    // Reuse a stream already created by this device
+    sp<Stream> reuseStream(camera3_stream_t *astream);
+    // Destroy all streams in a stream array, and the array itself
+    void destroyStreams(sp<Stream> *array, int32_t count);
+    // Verify a set of streams is valid in aggregate
+    bool isValidStreamSet(sp<Stream> *array, int32_t count);
+    // Verify settings are valid for reprocessing an input buffer
+    bool isValidReprocessSettings(const camera_metadata_t *settings);
+    // Send a shutter notify message with start of exposure time
+    void notifyShutter(uint32_t frame_number, uint64_t timestamp);
+    // Is type a valid template type (and valid index int32_to mTemplates)
+    bool isValidTemplateType(int32_t type);
+
+    // Identifier used by framework to distinguish cameras
+    const int32_t mId;
+    // camera_metadata structure containing static characteristics
+    camera_metadata_t *mStaticInfo;
+    // Busy flag indicates camera is in use
+    bool mBusy;
+    // Camera device operations handle shared by all devices
+    const static camera3_device_ops_t sOps;
+    // Methods used to call back into the framework
+    const camera3_callback_ops_t *mCallbackOps;
+    // Lock protecting the Camera object for modifications
+    android::Mutex mDeviceLock;
+    // Lock protecting only static camera characteristics, which may
+    // be accessed without the camera device open
+    static android::Mutex sStaticInfoLock;
+    // Array of handles to streams currently in use by the device
+    sp<Stream> *mStreams;
+    // Number of streams in mStreams
+    int32_t mNumStreams;
+    // Static array of standard camera settings templates
+    sp<Metadata> mTemplates[CAMERA3_TEMPLATE_COUNT];
+    // Most recent request settings seen, memoized to be reused
+    sp<Metadata> mSettings;
+
+    sp<DeviceStream> mDeviceStream;
+};
+
+#endif // CAMERA_H_
diff --git a/mx6/libcamera3/CameraHAL.cpp b/mx6/libcamera3/CameraHAL.cpp
new file mode 100644
index 0000000..379b12c
--- /dev/null
+++ b/mx6/libcamera3/CameraHAL.cpp
@@ -0,0 +1,337 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <cstdlib>
+#include <stdint.h>
+#include <sys/types.h>
+#include <hardware/camera_common.h>
+#include <hardware/hardware.h>
+#include <sys/stat.h>
+#include <linux/videodev2.h>
+#include <dirent.h>
+#include "VendorTags.h"
+
+//#define LOG_NDEBUG 0
+#include <cutils/log.h>
+
+#define ATRACE_TAG (ATRACE_TAG_CAMERA | ATRACE_TAG_HAL)
+#include <cutils/trace.h>
+
+#include "CameraHAL.h"
+
+/* Hardware limitation on I.MX6DQ platform
+ * VPU only support NV12&I420 format.
+ * IPU doesn't support NV21 format.
+ * But android framework requires NV21&YV12 format support.
+ * YV12&I420 Y/UV stride doesn't match between android framework and IPU/GPU.
+     ** Android YV12&I420 define:
+     * - a horizontal stride multiple of 16 pixels
+     * - a vertical stride equal to the height
+     * - y_size = stride * height
+     * - c_stride = ALIGN(stride/2, 16)
+     *
+     ** GPU YV12&I420 limitation:
+     * - GPU limit Y stride to be 32 alignment, and UV stride 16 alignment.
+     *
+     ** IPU hardware YV12&I420 limitation:
+     * - IPU limit the Y stride to be 2x of the UV stride alignment.
+     ** IPU driver YV12&I420 define:
+     * - y_stride = width
+     * - uv_stride = y_stride / 2;
+ * So there is work around to treat the format on I.MX6DQ platform:
+ * Change format NV21&YV12 to NV12&I420 in Camera framework.
+ * The NV21 format required by CTS is treated as NV12.
+ * YUV alignment required by CTS doesn't match on I.MX6DQ platform.
+ */
+
+/*
+ * This file serves as the entry point to the HAL.  It contains the module
+ * structure and functions used by the framework to load and interface to this
+ * HAL, as well as the handles to the individual camera devices.
+ */
+
+// Default Camera HAL has 2 cameras, front and rear.
+static CameraHAL gCameraHAL;
+// Handle containing vendor tag functionality
+static VendorTags gVendorTags;
+
+CameraHAL::CameraHAL()
+  : mNumberOfCameras(0),
+    mCallbacks(NULL)
+{
+    // Allocate camera array and instantiate camera devices
+    mCameras = new Camera*[MAX_CAMERAS];
+
+    // Rear camera
+    mCameras[0] = createCamera(0, true);
+    if (mCameras[0] != NULL) {
+        mNumberOfCameras++;
+        // Front camera
+        mCameras[1] = createCamera(1, false);
+        if (mCameras[1] != NULL) {
+            mNumberOfCameras++;
+        }
+    }
+}
+
+CameraHAL::~CameraHAL()
+{
+    for (int32_t i = 0; i < mNumberOfCameras; i++) {
+        delete mCameras[i];
+    }
+    delete [] mCameras;
+}
+
+int CameraHAL::getNumberOfCameras()
+{
+    ALOGV("%s: %d", __func__, mNumberOfCameras);
+    return mNumberOfCameras;
+}
+
+int CameraHAL::getCameraInfo(int id, struct camera_info* info)
+{
+    ALOGV("%s: camera id %d: info=%p", __func__, id, info);
+    if (id < 0 || id >= mNumberOfCameras) {
+        ALOGE("%s: Invalid camera id %d", __func__, id);
+        return -ENODEV;
+    }
+    // TODO: return device-specific static metadata
+    return mCameras[id]->getInfo(info);
+}
+
+int CameraHAL::setCallbacks(const camera_module_callbacks_t *callbacks)
+{
+    ALOGV("%s : callbacks=%p", __func__, callbacks);
+    mCallbacks = callbacks;
+    return 0;
+}
+
+int CameraHAL::openDev(const hw_module_t* mod, const char* name, hw_device_t** dev)
+{
+    int id;
+    char *nameEnd;
+
+    ALOGV("%s: module=%p, name=%s, device=%p", __func__, mod, name, dev);
+    if (*name == '\0') {
+        ALOGE("%s: Invalid camera id name is NULL", __func__);
+        return -EINVAL;
+    }
+    id = strtol(name, &nameEnd, 10);
+    if (*nameEnd != '\0') {
+        ALOGE("%s: Invalid camera id name %s", __func__, name);
+        return -EINVAL;
+    } else if (id < 0 || id >= mNumberOfCameras) {
+        ALOGE("%s: Invalid camera id %d", __func__, id);
+        return -ENODEV;
+    }
+    return mCameras[id]->openDev(mod, dev);
+}
+
+Camera* CameraHAL::createCamera(int32_t id, bool isRear)
+{
+    char camera_name[CAMERA_SENSOR_LENGTH], camera_prop[PROPERTY_VALUE_MAX];
+    char orientStr[CAMERA_SENSOR_LENGTH], orient_prop[PROPERTY_VALUE_MAX];
+    char devPath[CAMAERA_FILENAME_LENGTH];
+    int32_t facing, orientation;
+    bool found = false;
+
+    if (isRear) {
+        snprintf(camera_prop, PROPERTY_VALUE_MAX, "%s_%s", "back", FACE_CAMERA_NAME);
+        snprintf(orient_prop, PROPERTY_VALUE_MAX, "%s_%s", "back", FACE_CAMERA_ORIENT);
+        property_get(camera_prop, camera_name, OV5640MIPI_SENSOR_NAME);
+        facing = CAMERA_FACING_BACK;
+    }
+    else {
+        snprintf(camera_prop, PROPERTY_VALUE_MAX, "%s_%s", "front", FACE_CAMERA_NAME);
+        snprintf(orient_prop, PROPERTY_VALUE_MAX, "%s_%s", "front", FACE_CAMERA_ORIENT);
+        property_get(camera_prop, camera_name, OV5640CSI_SENSOR_NAME);
+        facing = CAMERA_FACING_FRONT;
+    }
+    property_get(orient_prop, orientStr, "0");
+    orientation = atoi(orientStr);
+
+    char *pCameraName = strtok(camera_name, ",");
+    while (pCameraName != NULL) {
+        ALOGI("Checking the camera %s", pCameraName);
+        if (getDevPath(pCameraName, devPath, CAMAERA_FILENAME_LENGTH) == -1) {
+            pCameraName = strtok(NULL, ",");
+            continue;
+        }
+        ALOGI("Camera ID %d: name %s, Facing %d, orientation %d, dev path %s",
+              id, pCameraName, facing, orientation,
+              devPath);
+        found = true;
+        break;
+    }
+
+    if (!found) {
+        ALOGE("can't find camera id %d, name %s", id, camera_name);
+        return NULL;
+    }
+
+    return Camera::createCamera(id, pCameraName, facing, orientation, devPath);
+}
+
+int32_t CameraHAL::getDevPath(const char* pName, char* pDevPath, uint32_t pathLen)
+{
+    int  retCode = -1;
+    int  fd      = 0;
+    char dev_node[CAMAERA_FILENAME_LENGTH];
+    DIR *v4l_dir = NULL;
+    struct dirent *dir_entry;
+    struct v4l2_capability v4l2_cap;
+    struct v4l2_dbg_chip_ident vid_chip;
+
+    v4l_dir = opendir("/sys/class/video4linux");
+    if (v4l_dir) {
+        while ((dir_entry = readdir(v4l_dir))) {
+            memset((void *)dev_node, 0, CAMAERA_FILENAME_LENGTH);
+            if (strncmp(dir_entry->d_name, "video", 5))
+                continue;
+            sprintf(dev_node, "/dev/%s", dir_entry->d_name);
+            if ((fd = open(dev_node, O_RDWR, O_NONBLOCK)) < 0)
+                continue;
+            if (ioctl(fd, VIDIOC_QUERYCAP, &v4l2_cap) < 0) {
+                close(fd);
+                fd = 0;
+                continue;
+            } else if (v4l2_cap.capabilities & V4L2_CAP_VIDEO_CAPTURE) {
+                if (ioctl(fd, VIDIOC_DBG_G_CHIP_IDENT, &vid_chip) < 0) {
+                    if(strstr((const char*)v4l2_cap.driver, pName)) {
+                       if (pathLen > strlen(dev_node)) {
+                            strcpy(pDevPath, dev_node);
+                            ALOGI("Get sensor %s's dev path %s, card %s, driver %s",
+                                  pName,
+                                  pDevPath,
+                                  (const char*)v4l2_cap.card,
+                                  (const char*)v4l2_cap.driver);
+                            retCode = 0;
+                        }
+                        close(fd);
+                        fd = 0;
+                        break;
+                    }
+                    close(fd);
+                    fd = 0;
+                    continue;
+                }
+                if (strstr(vid_chip.match.name, pName)) {
+                    // fsl csi/mipi camera name and path match
+                    if (pathLen > strlen(dev_node)) {
+                        strcpy(pDevPath, dev_node);
+                        ALOGI("Get sensor %s's dev path %s",
+                              pName,
+                              pDevPath);
+                        retCode = 0;
+                    }
+                    close(fd);
+                    fd = 0;
+                    break;
+                }
+            }
+            close(fd);
+            fd = 0;
+        }
+        closedir(v4l_dir);
+    }
+
+    return retCode;
+}
+
+extern "C" {
+
+static int get_number_of_cameras()
+{
+    return gCameraHAL.getNumberOfCameras();
+}
+
+static int get_camera_info(int id, struct camera_info* info)
+{
+    return gCameraHAL.getCameraInfo(id, info);
+}
+
+static int set_callbacks(const camera_module_callbacks_t *callbacks)
+{
+    return gCameraHAL.setCallbacks(callbacks);
+}
+
+static int get_tag_count(const vendor_tag_ops_t* ops)
+{
+    return gVendorTags.getTagCount(ops);
+}
+
+static void get_all_tags(const vendor_tag_ops_t* ops, uint32_t* tag_array)
+{
+    gVendorTags.getAllTags(ops, tag_array);
+}
+
+static const char* get_section_name(const vendor_tag_ops_t* ops, uint32_t tag)
+{
+    return gVendorTags.getSectionName(ops, tag);
+}
+
+static const char* get_tag_name(const vendor_tag_ops_t* ops, uint32_t tag)
+{
+    return gVendorTags.getTagName(ops, tag);
+}
+
+static int get_tag_type(const vendor_tag_ops_t* ops, uint32_t tag)
+{
+    return gVendorTags.getTagType(ops, tag);
+}
+
+static void get_vendor_tag_ops(vendor_tag_ops_t* ops)
+{
+    ALOGV("%s : ops=%p", __func__, ops);
+    ops->get_tag_count      = get_tag_count;
+    ops->get_all_tags       = get_all_tags;
+    ops->get_section_name   = get_section_name;
+    ops->get_tag_name       = get_tag_name;
+    ops->get_tag_type       = get_tag_type;
+}
+
+static int open_dev(const hw_module_t* mod, const char* name, hw_device_t** dev)
+{
+    return gCameraHAL.openDev(mod, name, dev);
+}
+
+static hw_module_methods_t gCameraModuleMethods = {
+    open : open_dev
+};
+
+camera_module_t HAL_MODULE_INFO_SYM __attribute__ ((visibility("default"))) = {
+    common : {
+        tag                : HARDWARE_MODULE_TAG,
+        module_api_version : CAMERA_MODULE_API_VERSION_2_2,
+        hal_api_version    : HARDWARE_HAL_API_VERSION,
+        id                 : CAMERA_HARDWARE_MODULE_ID,
+        name               : "Default Camera HAL",
+        author             : "The Android Open Source Project",
+        methods            : &gCameraModuleMethods,
+        dso                : NULL,
+        reserved           : {0},
+    },
+    get_number_of_cameras : get_number_of_cameras,
+    get_camera_info       : get_camera_info,
+    set_callbacks         : set_callbacks,
+    get_vendor_tag_ops    : get_vendor_tag_ops,
+    open_legacy           : NULL,
+    set_torch_mode        : NULL,
+    init                  : NULL,
+    reserved              : {0},
+};
+} // extern "C"
+
diff --git a/mx6/libcamera3/CameraHAL.h b/mx6/libcamera3/CameraHAL.h
new file mode 100644
index 0000000..eb1a323
--- /dev/null
+++ b/mx6/libcamera3/CameraHAL.h
@@ -0,0 +1,57 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef CAMERA_HAL_H_
+#define CAMERA_HAL_H_
+
+#include <cutils/bitops.h>
+#include <hardware/hardware.h>
+#include <hardware/camera_common.h>
+#include <system/camera_vendor_tags.h>
+#include "Camera.h"
+#include "VendorTags.h"
+
+// CameraHAL contains all module state that isn't specific to an individual
+// camera device.
+class CameraHAL
+{
+public:
+    CameraHAL();
+    ~CameraHAL();
+
+    // Camera Module Interface (see <hardware/camera_common.h>)
+    int getNumberOfCameras();
+    int getCameraInfo(int camera_id, struct camera_info *info);
+    int setCallbacks(const camera_module_callbacks_t *callbacks);
+    void getVendorTagOps(vendor_tag_ops_t* ops);
+
+    // Hardware Module Interface (see <hardware/hardware.h>)
+    int openDev(const hw_module_t* mod, const char* name, hw_device_t** dev);
+
+private:
+    Camera* createCamera(int32_t id, bool isRear);
+    int32_t getDevPath(const char* pName, char* pDevPath, uint32_t pathLen);
+
+private:
+    // Number of cameras
+    int32_t mNumberOfCameras;
+    // Callback handle
+    const camera_module_callbacks_t *mCallbacks;
+    // Array of camera devices, contains mNumberOfCameras device pointers
+    Camera **mCameras;
+};
+
+#endif // CAMERA_HAL_H_
diff --git a/mx6/libcamera3/CameraUtils.cpp b/mx6/libcamera3/CameraUtils.cpp
new file mode 100644
index 0000000..e4822ab
--- /dev/null
+++ b/mx6/libcamera3/CameraUtils.cpp
@@ -0,0 +1,340 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "CameraUtils.h"
+#include <linux/videodev2.h>
+#include "Metadata.h"
+#include "Stream.h"
+
+using namespace android;
+
+int convertPixelFormatToV4L2Format(PixelFormat format, bool invert)
+{
+    int nFormat = 0;
+
+    switch (format) {
+        case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+        case HAL_PIXEL_FORMAT_YCrCb_420_SP:
+            // IPU doesn't support NV21, so treat this two format as the same.
+            nFormat = v4l2_fourcc('N', 'V', '1', '2');
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_420_P:
+            if (!invert) {
+                nFormat = v4l2_fourcc('Y', 'U', '1', '2');
+            }
+            else {
+                nFormat = v4l2_fourcc('Y', 'V', '1', '2');
+            }
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_422_I:
+            nFormat = v4l2_fourcc('Y', 'U', 'Y', 'V');
+            break;
+
+        default:
+            ALOGE("Error: format:0x%x not supported!", format);
+            break;
+    }
+    ALOGV("v4l2 format: %c%c%c%c", nFormat&0xFF, (nFormat>>8)&0xFF,
+                            (nFormat>>16)&0xFF, (nFormat>>24)&0xFF);
+    return nFormat;
+}
+
+StreamBuffer::StreamBuffer()
+{
+}
+
+StreamBuffer::~StreamBuffer()
+{
+}
+
+void StreamBuffer::initialize(buffer_handle_t* buf_h)
+{
+    if (buf_h == NULL) {
+        return;
+    }
+
+    private_handle_t *handle = (private_handle_t *)(*buf_h);
+    mBufHandle = buf_h;
+    mVirtAddr  = (void *)handle->base;
+    mPhyAddr   = handle->phys;
+    mSize      = handle->size;
+}
+
+//--------------------CaptureRequest----------------------
+CaptureRequest::CaptureRequest()
+    : mOutBuffersNumber(0)
+{
+    for (uint32_t i = 0; i < MAX_STREAM_BUFFERS; i++) {
+        mOutBuffers[i] = NULL;
+    }
+}
+
+CaptureRequest::~CaptureRequest()
+{
+    if (mOutBuffers == NULL) {
+        return;
+    }
+
+    for (uint32_t i = 0; i < mOutBuffersNumber; i++) {
+        if (mOutBuffers[i] != NULL)
+            delete mOutBuffers[i];
+    }
+}
+
+void CaptureRequest::init(camera3_capture_request* request,
+              camera3_callback_ops* callback,
+              sp<Metadata> settings)
+{
+    mFrameNumber = request->frame_number;
+    mSettings = settings;
+    mOutBuffersNumber = request->num_output_buffers;
+    mRequest = request;
+    mCallbackOps = callback;
+
+    ALOGV("CaptureRequest fm:%d, bn:%d", mFrameNumber, mOutBuffersNumber);
+    for (uint32_t i = 0; i < request->num_output_buffers; i++) {
+        mOutBuffers[i] = new StreamBuffer();
+        mOutBuffers[i]->mStream = reinterpret_cast<Stream*>(
+                            request->output_buffers[i].stream->priv);
+        mOutBuffers[i]->mAcquireFence = request->output_buffers[i].acquire_fence;
+        mOutBuffers[i]->initialize(request->output_buffers[i].buffer);
+    }
+}
+
+int32_t CaptureRequest::onCaptureDone(StreamBuffer* buffer)
+{
+    if (buffer == NULL || buffer->mBufHandle == NULL || mCallbackOps == NULL) {
+        return 0;
+    }
+
+    camera3_stream_buffer_t cameraBuffer;
+    cameraBuffer.stream = buffer->mStream->stream();
+    cameraBuffer.buffer = buffer->mBufHandle;
+    cameraBuffer.status = CAMERA3_BUFFER_STATUS_OK;
+    cameraBuffer.acquire_fence = -1;
+    cameraBuffer.release_fence = -1;
+
+    camera3_capture_result_t result;
+    memset(&result, 0, sizeof(result));
+    result.frame_number = mFrameNumber;
+    result.result = NULL;
+    result.num_output_buffers = 1;
+    result.output_buffers = &cameraBuffer;
+
+    ALOGV("onCaptureDone fm:%d", mFrameNumber);
+    mCallbackOps->process_capture_result(mCallbackOps, &result);
+    return 0;
+}
+
+int32_t CaptureRequest::onSettingsDone(sp<Metadata> meta)
+{
+    if (meta == NULL || (meta->get() == NULL) || mCallbackOps == NULL) {
+        return 0;
+    }
+
+    camera_metadata_entry_t entry = meta->find(ANDROID_SENSOR_TIMESTAMP);
+    if (entry.count <= 0) {
+        ALOGW("invalid meta data");
+        return 0;
+    }
+
+    camera3_capture_result_t result;
+    memset(&result, 0, sizeof(result));
+    result.frame_number = mFrameNumber;
+    result.result = meta->get();
+    result.num_output_buffers = 0;
+    result.output_buffers = NULL;
+
+    ALOGV("onSettingsDone fm:%d", mFrameNumber);
+    mCallbackOps->process_capture_result(mCallbackOps, &result);
+    return 0;
+}
+
+//------------------SensorData------------------------
+SensorData::SensorData()
+{
+    mVpuSupportFmt[0] = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    mVpuSupportFmt[1] = HAL_PIXEL_FORMAT_YCbCr_420_P;
+
+    mPictureSupportFmt[0] = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    mPictureSupportFmt[1] = HAL_PIXEL_FORMAT_YCbCr_422_I;
+
+    memset(mSensorFormats, 0, sizeof(mSensorFormats));
+    memset(mAvailableFormats, 0, sizeof(mAvailableFormats));
+
+    memset(mPreviewResolutions, 0, sizeof(mPreviewResolutions));
+    memset(mPictureResolutions, 0, sizeof(mPictureResolutions));
+}
+
+SensorData::~SensorData()
+{
+}
+
+int32_t SensorData::getSensorFormat(int32_t availFormat)
+{
+    for (int32_t i=0; i<mSensorFormatCount; i++) {
+        if (availFormat == mSensorFormats[i]) {
+            return availFormat;
+        }
+    }
+
+    // return the first sensor format by default.
+    return mSensorFormats[0];
+}
+
+int32_t SensorData::changeSensorFormats(int *src, int *dst, int len)
+{
+    if (src == NULL || dst == NULL || len == 0) {
+        ALOGE("%s invalid parameters", __func__);
+        return 0;
+    }
+
+    int32_t k = 0;
+    for (int32_t i=0; i<len && i<MAX_SENSOR_FORMAT; i++) {
+        switch (src[i]) {
+            case v4l2_fourcc('N', 'V', '1', '2'):
+                dst[k++] = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+                break;
+
+            case v4l2_fourcc('Y', 'V', '1', '2'):
+                dst[k++] = HAL_PIXEL_FORMAT_YCbCr_420_P;
+                break;
+
+            case v4l2_fourcc('Y', 'U', 'Y', 'V'):
+                dst[k++] = HAL_PIXEL_FORMAT_YCbCr_422_I;
+                break;
+
+            case v4l2_fourcc('B', 'L', 'O', 'B'):
+                dst[k++] = HAL_PIXEL_FORMAT_BLOB;
+                break;
+
+            case v4l2_fourcc('R', 'A', 'W', 'S'):
+                dst[k++] = HAL_PIXEL_FORMAT_RAW16;
+                break;
+
+            default:
+                ALOGE("Error: format:%c%c%c%c not supported!", src[i]&0xFF,
+                      (src[i]>>8)&0xFF, (src[i]>>16)&0xFF, (src[i]>>24)&0xFF);
+                break;
+        }
+    }
+
+    return k;
+}
+
+int SensorData::getCaptureMode(int width, int height)
+{
+    int capturemode = 0;
+
+    if ((width == 640) && (height == 480)) {
+        capturemode = 0;
+    }
+    else if ((width == 320) && (height == 240)) {
+        capturemode = 1;
+    }
+    else if ((width == 720) && (height == 480)) {
+        capturemode = 2;
+    }
+    else if ((width == 720) && (height == 576)) {
+        capturemode = 3;
+    }
+    else if ((width == 1280) && (height == 720)) {
+        capturemode = 4;
+    }
+    else if ((width == 1920) && (height == 1080)) {
+        capturemode = 5;
+    }
+    else if ((width == 2592) && (height == 1944)) {
+        capturemode = 6;
+    }
+    else if ((width == 176) && (height == 144)) {
+        capturemode = 7;
+    }
+    else if ((width == 1024) && (height == 768)) {
+        capturemode = 8;
+    }
+    else {
+        ALOGE("width:%d height:%d is not supported.", width, height);
+    }
+    return capturemode;
+}
+
+status_t SensorData::adjustPreviewResolutions()
+{
+    int xTmp, yTmp, xMax, yMax, idx;
+    idx = 0;
+    xTmp = xMax = mPreviewResolutions[0];
+    yTmp = yMax = mPreviewResolutions[1];
+    for (int i=0; i<MAX_RESOLUTION_SIZE; i+=2) {
+        if (mPreviewResolutions[i] > xMax) {
+            xMax = mPreviewResolutions[i];
+            yMax = mPreviewResolutions[i+1];
+            idx = i;
+        }
+    }
+
+    mPreviewResolutions[0] = xMax;
+    mPreviewResolutions[1] = yMax;
+    mPreviewResolutions[idx] = xTmp;
+    mPreviewResolutions[idx+1] = yTmp;
+
+    return 0;
+}
+
+status_t SensorData::setMaxPictureResolutions()
+{
+    int xMax, yMax;
+    xMax = mPictureResolutions[0];
+    yMax = mPictureResolutions[1];
+
+    for (int i=0; i<MAX_RESOLUTION_SIZE; i+=2) {
+        if (mPictureResolutions[i] > xMax || mPictureResolutions[i+1] > yMax) {
+            xMax = mPictureResolutions[i];
+            yMax = mPictureResolutions[i+1];
+        }
+    }
+
+    mMaxWidth = xMax;
+    mMaxHeight = yMax;
+
+    return 0;
+}
+
+PixelFormat SensorData::getMatchFormat(int *sfmt, int  slen,
+                                         int *dfmt, int  dlen)
+{
+    if ((sfmt == NULL) || (slen == 0) || (dfmt == NULL) || (dlen == 0)) {
+        ALOGE("getMatchFormat invalid parameters");
+        return 0;
+    }
+
+    PixelFormat matchFormat = 0;
+    bool live = true;
+    for (int i = 0; i < slen && live; i++) {
+        for (int j = 0; j < dlen; j++) {
+            if (sfmt[i] == dfmt[j]) {
+                matchFormat = dfmt[j];
+                live        = false;
+                break;
+            }
+        }
+    }
+
+    return matchFormat;
+}
+
diff --git a/mx6/libcamera3/CameraUtils.h b/mx6/libcamera3/CameraUtils.h
new file mode 100644
index 0000000..58a7dc5
--- /dev/null
+++ b/mx6/libcamera3/CameraUtils.h
@@ -0,0 +1,198 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _CAMERA_UTILS_H
+#define _CAMERA_UTILS_H
+
+#undef LOG_TAG
+#define LOG_TAG "FslCameraHAL"
+#include <utils/Log.h>
+
+#include <string.h>
+#include <unistd.h>
+#include <time.h>
+#include <dlfcn.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <linux/time.h>
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include <utils/threads.h>
+#include <utils/RefBase.h>
+#include <binder/MemoryBase.h>
+#include <binder/MemoryHeapBase.h>
+#include <camera/CameraParameters.h>
+#include <utils/Vector.h>
+#include <utils/KeyedVector.h>
+#include <cutils/properties.h>
+#include <hardware_legacy/power.h>
+#include <ui/PixelFormat.h>
+#include <hardware/camera3.h>
+#include "gralloc_priv.h"
+
+#define MAX_CAMERAS 2
+
+#define FACE_CAMERA_NAME "camera_name"
+#define FACE_CAMERA_ORIENT "camera_orient"
+#define DEFAULT_ERROR_NAME '0'
+#define DEFAULT_ERROR_NAME_str "0"
+
+#define UVC_SENSOR_NAME "uvc"
+#define OV5640MIPI_SENSOR_NAME "ov5640_mipi"
+#define OV5642CSI_SENSOR_NAME "ov5642_camera"
+#define OV5640CSI_SENSOR_NAME "ov5640_camera"
+#define ADV7180_TVIN_NAME "adv7180_decoder"
+
+#define CAMAERA_FILENAME_LENGTH 256
+#define CAMERA_SENSOR_LENGTH    92
+#define CAMERA_FORMAT_LENGTH    32
+#define CAMER_PARAM_BUFFER_SIZE 512
+#define PARAMS_DELIMITER ","
+
+#define MAX_RESOLUTION_SIZE   64
+#define MAX_FPS_RANGE   4
+#define MAX_SENSOR_FORMAT 20
+
+#define MAX_VPU_SUPPORT_FORMAT 2
+#define MAX_PICTURE_SUPPORT_FORMAT 2
+
+#define CAMERA_SYNC_TIMEOUT 5000 // in msecs
+#define MAX_STREAM_BUFFERS 32
+
+#define CAMERA_GRALLOC_USAGE_JPEG GRALLOC_USAGE_HW_TEXTURE | \
+    GRALLOC_USAGE_HW_RENDER |                           \
+    GRALLOC_USAGE_SW_READ_RARELY |                      \
+    GRALLOC_USAGE_SW_WRITE_NEVER
+
+#define CAMERA_GRALLOC_USAGE GRALLOC_USAGE_HW_TEXTURE | \
+    GRALLOC_USAGE_HW_RENDER |                           \
+    GRALLOC_USAGE_SW_READ_RARELY |                      \
+    GRALLOC_USAGE_SW_WRITE_NEVER |                      \
+    GRALLOC_USAGE_FORCE_CONTIGUOUS
+
+#define NUM_PREVIEW_BUFFER      2
+#define NUM_CAPTURE_BUFFER      1
+
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof(a[0]))
+
+using namespace android;
+
+int convertPixelFormatToV4L2Format(PixelFormat format, bool invert=false);
+
+class Metadata;
+class Stream;
+class StreamBuffer
+{
+public:
+    StreamBuffer();
+    ~StreamBuffer();
+    void initialize(buffer_handle_t* buf_h);
+    // buffer width, height, format is in Stream.
+    sp<Stream> mStream;
+    int32_t mAcquireFence;
+
+    buffer_handle_t* mBufHandle;
+    void*   mVirtAddr;
+    int32_t mPhyAddr;
+    size_t  mSize;
+    int32_t mFd;
+};
+
+enum RequestType {
+    TYPE_PREVIEW = 1,
+    TYPE_SNAPSHOT = 2,
+    TYPE_STILLCAP = 3
+};
+
+class CaptureRequest : public LightRefBase<CaptureRequest>
+{
+public:
+    CaptureRequest();
+    ~CaptureRequest();
+
+    void init(camera3_capture_request* request, camera3_callback_ops* callback,
+              sp<Metadata> settings);
+    int32_t onCaptureDone(StreamBuffer* buffer);
+    int32_t onSettingsDone(sp<Metadata> meta);
+
+public:
+    uint32_t mFrameNumber;
+    sp<Metadata> mSettings;
+    uint32_t mOutBuffersNumber;
+    StreamBuffer* mOutBuffers[MAX_STREAM_BUFFERS];
+
+    camera3_capture_request* mRequest;
+    camera3_callback_ops *mCallbackOps;
+};
+
+class SensorData
+{
+public:
+    SensorData();
+    virtual ~SensorData();
+
+    int getCaptureMode(int width, int height);
+
+    PixelFormat getPreviewPixelFormat() {
+        return mPreviewPixelFormat;
+    }
+
+    PixelFormat getPicturePixelFormat() {
+        return mPicturePixelFormat;
+    }
+
+    PixelFormat getMatchFormat(int *sfmt, int  slen,
+                               int *dfmt, int  dlen);
+
+    int32_t getSensorFormat(int32_t availFormat);
+
+protected:
+    int32_t changeSensorFormats(int *src, int *dst, int len);
+    status_t adjustPreviewResolutions();
+    status_t setMaxPictureResolutions();
+
+public:
+    int mPreviewResolutions[MAX_RESOLUTION_SIZE];
+    int mPreviewResolutionCount;
+    int mPictureResolutions[MAX_RESOLUTION_SIZE];
+    int mPictureResolutionCount;
+    int mAvailableFormats[MAX_SENSOR_FORMAT];
+    int mAvailableFormatCount;
+    nsecs_t mMinFrameDuration;
+    nsecs_t mMaxFrameDuration;
+    int mTargetFpsRange[MAX_FPS_RANGE];
+    int mMaxWidth;
+    int mMaxHeight;
+    float mPhysicalWidth;
+    float mPhysicalHeight;
+    float mFocalLength;
+
+    // preview and picture format.
+    PixelFormat mPicturePixelFormat;
+    PixelFormat mPreviewPixelFormat;
+
+    // vpu and capture limitation.
+    int mVpuSupportFmt[MAX_VPU_SUPPORT_FORMAT];
+    int mPictureSupportFmt[MAX_PICTURE_SUPPORT_FORMAT];
+
+    int mSensorFormats[MAX_SENSOR_FORMAT];
+    int mSensorFormatCount;
+    char mDevPath[CAMAERA_FILENAME_LENGTH];
+};
+
+#endif
diff --git a/mx6/libcamera3/DeviceStream.cpp b/mx6/libcamera3/DeviceStream.cpp
new file mode 100644
index 0000000..ed522ea
--- /dev/null
+++ b/mx6/libcamera3/DeviceStream.cpp
@@ -0,0 +1,415 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "DeviceStream.h"
+
+using namespace android;
+
+DeviceStream::DeviceStream(Camera* device)
+    : Stream(device), mState(STATE_INVALID),
+      mChanged(false), mDev(-1),
+      mAllocatedBuffers(0)
+{
+    g2dHandle = NULL;
+    mMessageThread = new MessageThread(this);
+}
+
+DeviceStream::~DeviceStream()
+{
+    mMessageQueue.postMessage(new CMessage(MSG_EXIT, 1), 1);
+    mMessageThread->requestExit();
+    mMessageThread->join();
+}
+
+int32_t DeviceStream::openDev(const char* name)
+{
+    ALOGI("%s", __func__);
+    if (name == NULL) {
+        ALOGE("invalid dev name");
+        return BAD_VALUE;
+    }
+
+    Mutex::Autolock lock(mLock);
+
+    mDev = open(name, O_RDWR);
+    if (mDev <= 0) {
+        ALOGE("%s can not open camera devpath:%s", __func__, name);
+        return BAD_VALUE;
+    }
+
+    return 0;
+}
+
+int32_t DeviceStream::configure(sp<Stream> stream)
+{
+    ALOGV("%s", __func__);
+    if ((stream->width() == 0) || (stream->height() == 0)
+         || (stream->format() == 0)) {
+        ALOGE("%s: invalid stream parameters", __func__);
+        return BAD_VALUE;
+    }
+
+    int32_t sensorFormat = mCamera->getSensorFormat(stream->format());
+
+    Mutex::Autolock lock(mLock);
+    // when width&height&format are same, keep it to reduce start/stop time.
+    if ((mWidth == stream->width()) && (mHeight == stream->height())
+         && (mFormat == sensorFormat)) {
+        return 0;
+    }
+
+    mWidth  = stream->width();
+    mHeight = stream->height();
+    mFormat = sensorFormat;
+    mNumBuffers = stream->bufferNum();
+    mChanged = true;
+
+    ALOGI("%s: w:%d, h:%d, sensor format:0x%x, stream format:0x%x, num:%d",
+           __func__, mWidth, mHeight, mFormat, stream->format(), mNumBuffers);
+    mMessageQueue.clearMessages();
+    mMessageQueue.postMessage(new CMessage(MSG_CONFIG, 0), 0);
+
+    return 0;
+}
+
+int32_t DeviceStream::handleConfigureLocked()
+{
+    int32_t ret   = 0;
+    ALOGV("%s", __func__);
+
+    // add start state to go into config state.
+    // so, only call config to do stop automically.
+    if (mState == STATE_START) {
+        ret = handleStopLocked(false);
+        if (ret < 0) {
+            ALOGE("please stop firstly before configure");
+            return ret;
+        }
+    }
+
+    // only invalid&stop&config state can go into config state.
+    if ((mState != STATE_INVALID) && (mState != STATE_STOP) &&
+        (mState != STATE_CONFIG)) {
+        ALOGE("invalid state:0x%x go into config state", mState);
+        return 0;
+    }
+
+    ret = onDeviceConfigureLocked();
+    if (ret != 0) {
+        ALOGE("%s onDeviceConfigure failed", __func__);
+        return ret;
+    }
+
+    mState = STATE_CONFIG;
+
+    return 0;
+}
+
+int32_t DeviceStream::handleStartLocked(bool force)
+{
+    int32_t ret = 0;
+    ALOGV("%s", __func__);
+
+    // only config&stop state can go into start state.
+    if ((mState != STATE_CONFIG) && (mState != STATE_STOP)) {
+        ALOGE("invalid state:0x%x go into start state", mState);
+        return 0;
+    }
+
+    if (mChanged || force) {
+        mChanged = false;
+        if (allocateBuffersLocked() != 0) {
+            ALOGE("%s allocateBuffersLocked failed", __func__);
+            return -1;
+        }
+    }
+
+    ret = onDeviceStartLocked();
+    if (ret != 0) {
+        ALOGE("%s onDeviceStart failed", __func__);
+        return ret;
+    }
+
+    mState = STATE_START;
+
+    return 0;
+}
+
+int32_t DeviceStream::closeDev()
+{
+    ALOGI("%s", __func__);
+    Mutex::Autolock lock(mLock);
+
+    if (mMessageThread->isRunning()) {
+        mMessageQueue.postMessage(new CMessage(MSG_CLOSE, 0), 1);
+    }
+    else {
+        ALOGI("%s thread is exit", __func__);
+        if (mDev > 0) {
+            close(mDev);
+            mDev = -1;
+        }
+    }
+
+    return 0;
+}
+
+int32_t DeviceStream::handleStopLocked(bool force)
+{
+    int32_t ret = 0;
+    ALOGV("%s", __func__);
+
+    // only start can go into stop state.
+    if (mState != STATE_START) {
+        ALOGI("state:0x%x can't go into stop state", mState);
+        return 0;
+    }
+
+    if (force || mChanged) {
+        ret = freeBuffersLocked();
+        if (ret != 0) {
+            ALOGE("%s freeBuffersLocked failed", __func__);
+            return -1;
+        }
+    }
+
+    ret = onDeviceStopLocked();
+    if (ret < 0) {
+        ALOGE("StopStreaming: Unable to stop capture: %s", strerror(errno));
+        return ret;
+    }
+
+    mState = STATE_STOP;
+    if (force) {
+        // clear request messages.
+        mMessageQueue.clearMessages();
+        // clear capture request.
+        mRequests.clear();
+        // to do configure agian.
+        mWidth = 0;
+    }
+
+    return ret;
+}
+
+int32_t DeviceStream::requestCapture(sp<CaptureRequest> req)
+{
+    Mutex::Autolock lock(mLock);
+
+    mRequests.push_back(req);
+
+    mMessageQueue.postMessage(new CMessage(MSG_FRAME, 0));
+
+    return 0;
+}
+
+StreamBuffer* DeviceStream::acquireFrameLocked()
+{
+    int32_t index = onFrameAcquireLocked();
+    if (index >= MAX_STREAM_BUFFERS || index < 0) {
+        ALOGE("%s: invalid index %d", __func__, index);
+        return NULL;
+    }
+
+    return mBuffers[index];
+}
+
+int32_t DeviceStream::getBufferIndexLocked(StreamBuffer& buf)
+{
+    for (uint32_t i=0; i<mNumBuffers; i++) {
+        if (mBuffers[i]->mPhyAddr == buf.mPhyAddr) {
+            return i;
+        }
+    }
+
+    return -1;
+}
+
+int32_t DeviceStream::returnFrameLocked(StreamBuffer& buf)
+{
+    ALOGV("%s", __func__);
+    int32_t i = getBufferIndexLocked(buf);
+    if (i < 0 || i >= MAX_STREAM_BUFFERS) {
+        return BAD_VALUE;
+    }
+
+    return onFrameReturnLocked(i, buf);
+}
+
+int32_t DeviceStream::handleCaptureFrame()
+{
+    int32_t ret = 0;
+    ALOGV("%s", __func__);
+
+    List< sp<CaptureRequest> >::iterator cur;
+    sp<CaptureRequest> req = NULL;
+    StreamBuffer *buf = NULL;
+    {
+        Mutex::Autolock lock(mLock);
+        if (mRequests.empty()) {
+            return 0;
+        }
+
+        cur = mRequests.begin();
+        req = *cur;
+    }
+    //advanced character.
+    ret = processCaptureSettings(req);
+    if (ret != 0) {
+        Mutex::Autolock lock(mLock);
+        mRequests.erase(cur);
+        ALOGE("processSettings failed");
+        return 0;
+    }
+
+    {
+        Mutex::Autolock lock(mLock);
+        buf = acquireFrameLocked();
+        if (buf == NULL) {
+            ALOGE("acquireFrameLocked failed");
+            return 0;
+        }
+    }
+
+    ret = processCaptureRequest(*buf, req);
+    if (ret != 0) {
+        Mutex::Autolock lock(mLock);
+        returnFrameLocked(*buf);
+        ALOGE("processRequest failed");
+        return 0;
+    }
+
+    Mutex::Autolock lock(mLock);
+    mRequests.erase(cur);
+    returnFrameLocked(*buf);
+
+    return 0;
+}
+
+int32_t DeviceStream::processCaptureRequest(StreamBuffer& src,
+                         sp<CaptureRequest> req)
+{
+    int32_t ret = 0;
+    ALOGV("%s", __func__);
+    for (uint32_t i=0; i<req->mOutBuffersNumber; i++) {
+        StreamBuffer* out = req->mOutBuffers[i];
+        sp<Stream>& stream = out->mStream;
+        // stream to process buffer.
+        stream->setCurrentBuffer(out);
+        stream->processCaptureBuffer(src, req->mSettings);
+        stream->setCurrentBuffer(NULL);
+        ret = req->onCaptureDone(out);
+        if (ret != 0) {
+            return ret;
+        }
+    }
+
+    return ret;
+}
+
+// process advanced character.
+int32_t DeviceStream::processCaptureSettings(sp<CaptureRequest> req)
+{
+    ALOGV("%s", __func__);
+    sp<Metadata> meta = req->mSettings;
+    if (meta == NULL || meta->get() == NULL) {
+        ALOGI("invalid meta data");
+        return 0;
+    }
+    // device to do advanced character set.
+    int32_t ret = mCamera->processSettings(meta, req->mFrameNumber);
+    if (ret != 0) {
+        ALOGI("mCamera->processSettings failed");
+        return ret;
+    }
+
+    ret = req->onSettingsDone(meta);
+    if (ret != 0) {
+        ALOGI("onSettingsDone failed");
+        return ret;
+    }
+
+    if (req->mOutBuffersNumber == 0) {
+        ALOGI("num_output_buffers less than 0");
+        ret = 1;
+    }
+
+    return ret;
+}
+
+int32_t DeviceStream::handleMessage()
+{
+    int32_t ret = 0;
+
+    sp<CMessage> msg = mMessageQueue.waitMessage();
+    if (msg == 0) {
+        ALOGE("get invalid message");
+        return -1;
+    }
+
+    switch (msg->what) {
+        case MSG_CONFIG: {
+            Mutex::Autolock lock(mLock);
+            ret = handleConfigureLocked();
+        }
+        break;
+
+        case MSG_CLOSE: {
+            Mutex::Autolock lock(mLock);
+            ret = handleStopLocked(true);
+            if (mDev > 0) {
+                close(mDev);
+                mDev = -1;
+            }
+        }
+        break;
+
+        case MSG_FRAME: {
+            Mutex::Autolock lock(mLock);
+            // to start device automically.
+            if (mState != STATE_START) {
+                ALOGV("state:0x%x when handle frame message", mState);
+                ret = handleStartLocked(false);
+                if (ret != 0) {
+                    ALOGE("%s handleStartLocked failed", __func__);
+                    return ret;
+                }
+            }
+
+        }
+        ret = handleCaptureFrame();
+        break;
+
+        case MSG_EXIT: {
+            Mutex::Autolock lock(mLock);
+            ALOGI("capture thread exit...");
+            if (mState == STATE_START) {
+                handleStopLocked(true);
+            }
+
+            ret = -1;
+        }
+        break;
+
+        default: {
+            ALOGE("%s invalid message what:%d", __func__, msg->what);
+        }
+        break;
+    }
+
+    return ret;
+}
+
diff --git a/mx6/libcamera3/DeviceStream.h b/mx6/libcamera3/DeviceStream.h
new file mode 100644
index 0000000..1f4d934
--- /dev/null
+++ b/mx6/libcamera3/DeviceStream.h
@@ -0,0 +1,140 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _DEVICE_STREAM_H
+#define _DEVICE_STREAM_H
+
+#include <utils/threads.h>
+#include "MessageQueue.h"
+#include "CameraUtils.h"
+#include "Stream.h"
+#include "Camera.h"
+
+using namespace android;
+
+class Camera;
+
+class DeviceStream : public Stream
+{
+public:
+    DeviceStream(Camera* device);
+    virtual ~DeviceStream();
+
+    // configure device stream.
+    int32_t configure(sp<Stream> stream);
+    //send capture request for stream.
+    int32_t requestCapture(sp<CaptureRequest> req);
+
+    // open/close device stream.
+    int32_t openDev(const char* name);
+    int32_t closeDev();
+
+    virtual void* getG2dHandle() {return g2dHandle;}
+
+private:
+    // message type.
+    static const int32_t MSG_CONFIG = 0x100;
+    static const int32_t MSG_FRAME = 0x103;
+    static const int32_t MSG_CLOSE = 0x104;
+    static const int32_t MSG_EXIT  = 0x105;
+
+    // device stream state.
+    static const int32_t STATE_INVALID = 0x201;
+    static const int32_t STATE_CONFIG = 0x202;
+    static const int32_t STATE_START = 0x203;
+    static const int32_t STATE_STOP  = 0x204;
+
+protected:
+    // handle configure message internally.
+    int32_t handleConfigureLocked();
+    virtual int32_t onDeviceConfigureLocked() = 0;
+    // handle start message internally.
+    int32_t handleStartLocked(bool force);
+    virtual int32_t onDeviceStartLocked() = 0;
+    // handle stop message internally.
+    int32_t handleStopLocked(bool force);
+    virtual int32_t onDeviceStopLocked() = 0;
+    // handle frame message internally.
+    int32_t handleCaptureFrame();
+
+    // process capture request with lock.
+    int32_t processCaptureRequest(StreamBuffer& src, sp<CaptureRequest> req);
+    // process capture advanced settings with lock.
+    int32_t processCaptureSettings(sp<CaptureRequest> req);
+    // get buffer from V4L2.
+    StreamBuffer* acquireFrameLocked();
+    virtual int32_t onFrameAcquireLocked() = 0;
+    // put buffer back to V4L2.
+    int32_t returnFrameLocked(StreamBuffer& buf);
+    virtual int32_t onFrameReturnLocked(int32_t index, StreamBuffer& buf) = 0;
+    // get buffer index.
+    int32_t getBufferIndexLocked(StreamBuffer& buf);
+
+    // allocate buffers.
+    virtual int32_t allocateBuffersLocked() = 0;
+    // free buffers.
+    virtual int32_t freeBuffersLocked() = 0;
+
+    int32_t handleMessage();
+
+private:
+    class MessageThread : public Thread
+    {
+    public:
+        MessageThread(DeviceStream *device)
+            : Thread(false), mStream(device)
+            {}
+
+        virtual void onFirstRef() {
+            run("MessageThread", PRIORITY_URGENT_DISPLAY);
+        }
+
+        virtual status_t readyToRun() {
+            g2d_open(&mStream->g2dHandle);
+            return 0;
+        }
+
+        virtual bool threadLoop() {
+            int ret = mStream->handleMessage();
+            if (ret != 0) {
+                ALOGI("%s exit...", __func__);
+                g2d_close(mStream->g2dHandle);
+                return false;
+            }
+
+            // loop until we need to quit
+            return true;
+        }
+
+    private:
+        sp<DeviceStream> mStream;
+    };
+
+protected:
+    CMessageQueue mMessageQueue;
+    sp<MessageThread> mMessageThread;
+    int32_t mState;
+
+    List< sp<CaptureRequest> > mRequests;
+    int32_t mChanged;
+
+    // camera dev node.
+    int32_t mDev;
+    void *g2dHandle;
+    uint32_t mAllocatedBuffers;
+};
+
+#endif
diff --git a/mx6/libcamera3/JpegBuilder.cpp b/mx6/libcamera3/JpegBuilder.cpp
new file mode 100644
index 0000000..54735ad
--- /dev/null
+++ b/mx6/libcamera3/JpegBuilder.cpp
@@ -0,0 +1,677 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "CameraHAL"
+
+#include <stdlib.h>
+#include <unistd.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <stdio.h>
+#include <errno.h>
+#include <math.h>
+
+#include "JpegBuilder.h"
+#include "Metadata.h"
+#include "Stream.h"
+
+extern "C" {
+    #include "jpeglib.h"
+    #include "jerror.h"
+}
+
+namespace android {
+struct string_pair {
+    const char *string1;
+    const char *string2;
+};
+
+static string_pair degress_to_exif_lut[] = {
+    // degrees, exif_orientation
+    { "0",   "1"     },
+    { "90",  "6"     },
+    { "180", "3"     },
+    { "270", "8"     },
+};
+
+/* public static functions */
+const char * JpegBuilder::degreesToExifOrientation(const char *degrees) {
+    for (unsigned int i = 0; i < ARRAY_SIZE(degress_to_exif_lut); i++) {
+        if (!strcmp(degrees, degress_to_exif_lut[i].string1)) {
+            return degress_to_exif_lut[i].string2;
+        }
+    }
+    return NULL;
+}
+
+void JpegBuilder::stringToRational(const char   *str,
+                                   unsigned int *num,
+                                   unsigned int *den) {
+    int   len;
+    char *tempVal = NULL;
+
+    if (str != NULL) {
+        len     = strlen(str);
+        tempVal = (char *)malloc(sizeof(char) * (len + 1));
+    }
+
+    if (tempVal != NULL) {
+        // convert the decimal string into a rational
+        size_t den_len;
+        char  *ctx;
+        unsigned int numerator   = 0;
+        unsigned int denominator = 0;
+        char *temp               = NULL;
+
+        memset(tempVal, '\0', len + 1);
+        strncpy(tempVal, str, len);
+        temp = strtok_r(tempVal, ".", &ctx);
+
+        if (temp != NULL)
+            numerator = atoi(temp);
+
+        if (!numerator)
+            numerator = 1;
+
+        temp = strtok_r(NULL, ".", &ctx);
+        if (temp != NULL) {
+            den_len = strlen(temp);
+            if (HUGE_VAL == den_len) {
+                den_len = 0;
+            }
+
+            denominator = static_cast<unsigned int>(pow(10, den_len));
+            numerator   = numerator * denominator + atoi(temp);
+        }
+        else {
+            denominator = 1;
+        }
+
+        free(tempVal);
+
+        *num = numerator;
+        *den = denominator;
+    }
+}
+
+bool JpegBuilder::isAsciiTag(const char *tag) {
+    // TODO(XXX): Add tags as necessary
+    return (strcmp(tag, TAG_GPS_PROCESSING_METHOD) == 0);
+}
+
+void JpegBuilder::insertExifToJpeg(unsigned char *jpeg,
+                                   size_t         jpeg_size) {
+    ReadMode_t read_mode = (ReadMode_t)(READ_METADATA | READ_IMAGE);
+
+    ResetJpgfile();
+    if (ReadJpegSectionsFromBuffer(jpeg, jpeg_size, read_mode)) {
+        jpeg_opened = true;
+        create_EXIF(table, exif_tag_count, gps_tag_count, has_datetime_tag);
+    }
+}
+
+status_t JpegBuilder::insertExifThumbnailImage(const char *thumb,
+                                               int         len) {
+    status_t ret = NO_ERROR;
+
+    if ((len > 0) && jpeg_opened) {
+        ret = ReplaceThumbnailFromBuffer(thumb, len);
+        ALOGI("insertExifThumbnailImage. ReplaceThumbnail(). ret=%d", ret);
+    }
+
+    return ret;
+}
+
+void JpegBuilder::saveJpeg(unsigned char *jpeg,
+                           size_t         jpeg_size) {
+    if (jpeg_opened) {
+        WriteJpegToBuffer(jpeg, jpeg_size);
+        DiscardData();
+        jpeg_opened = false;
+    }
+}
+
+status_t JpegBuilder::insertElement(const char *tag,
+                                    const char *value) {
+    int value_length = 0;
+    status_t ret     = NO_ERROR;
+
+    if (!value || !tag) {
+        return -EINVAL;
+    }
+
+    if (position >= MAX_EXIF_TAGS_SUPPORTED) {
+        ALOGE("Max number of EXIF elements already inserted");
+        return NO_MEMORY;
+    }
+
+    if (isAsciiTag(tag)) {
+        value_length = sizeof(ExifAsciiPrefix) +
+                       strlen(value + sizeof(ExifAsciiPrefix));
+    }
+    else {
+        value_length = strlen(value);
+    }
+
+    if (IsGpsTag(tag)) {
+        table[position].GpsTag = TRUE;
+        table[position].Tag    = GpsTagNameToValue(tag);
+        gps_tag_count++;
+    }
+    else {
+        table[position].GpsTag = FALSE;
+        table[position].Tag    = TagNameToValue(tag);
+        exif_tag_count++;
+
+        if (strcmp(tag, TAG_DATETIME) == 0) {
+            has_datetime_tag = true;
+        }
+    }
+
+    table[position].DataLength = 0;
+    table[position].Value      = (char *)malloc(sizeof(char) * (value_length + 1));
+
+    if (table[position].Value) {
+        memcpy(table[position].Value, value, value_length + 1);
+        table[position].DataLength = value_length + 1;
+    }
+
+    position++;
+    return ret;
+}
+
+JpegBuilder::JpegBuilder()
+    : gps_tag_count(0), exif_tag_count(0), position(0),
+      jpeg_opened(false), has_datetime_tag(false)
+{
+    reset();
+}
+
+void JpegBuilder::reset()
+{
+    gps_tag_count    = 0;
+    exif_tag_count   = 0;
+    position         = 0;
+    jpeg_opened      = false;
+    has_datetime_tag = false;
+    mMainInput       = NULL;
+    mThumbnailInput  = NULL;
+    mCancelEncoding  = false;
+    memset(&mEXIFData, 0, sizeof(mEXIFData));
+    memset(&table, 0, sizeof(table));
+}
+
+JpegBuilder::~JpegBuilder()
+{
+    int num_elements = gps_tag_count + exif_tag_count;
+
+    for (int i = 0; i < num_elements; i++) {
+        if (table[i].Value) {
+            free(table[i].Value);
+        }
+    }
+
+    if (jpeg_opened) {
+        DiscardData();
+    }
+}
+
+status_t JpegBuilder::prepareImage(const StreamBuffer *streamBuf)
+{
+    status_t ret = NO_ERROR;
+    int eError   = 0;
+    struct timeval sTv;
+    struct tm     *pTime;
+
+    if (streamBuf == NULL || streamBuf->mStream == NULL) {
+        ALOGE("%s invalid stream buffer", __func__);
+        return 0;
+    }
+
+    const sp<Stream>& stream = streamBuf->mStream;
+
+    if ((NO_ERROR == ret) && (mEXIFData.mModelValid)) {
+        ret = insertElement(TAG_MODEL, EXIF_MODEL);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mMakeValid)) {
+        ret = insertElement(TAG_MAKE, EXIF_MAKENOTE);
+    }
+
+    float focalLength;
+    ret = mMeta->getFocalLength(focalLength);
+    if ((NO_ERROR == ret)) {
+        char str[16];  // 14 should be enough. We overestimate to be safe.
+        snprintf(str, sizeof(str), "%g", focalLength);
+        unsigned int numerator = 0, denominator = 0;
+        JpegBuilder::stringToRational(str, &numerator, &denominator);
+        if (numerator || denominator) {
+            char temp_value[256]; // arbitrarily long string
+            snprintf(temp_value,
+                     sizeof(temp_value) / sizeof(char),
+                     "%u/%u", numerator, denominator);
+            ret = insertElement(TAG_FOCALLENGTH, temp_value);
+        }
+    }
+
+    if ((NO_ERROR == ret)) {
+        int status = gettimeofday(&sTv, NULL);
+        pTime = localtime(&sTv.tv_sec);
+        char temp_value[EXIF_DATE_TIME_SIZE + 1];
+        if ((0 == status) && (NULL != pTime)) {
+            snprintf(temp_value, EXIF_DATE_TIME_SIZE,
+                     "%04d:%02d:%02d %02d:%02d:%02d",
+                     pTime->tm_year + 1900,
+                     pTime->tm_mon + 1,
+                     pTime->tm_mday,
+                     pTime->tm_hour,
+                     pTime->tm_min,
+                     pTime->tm_sec);
+
+            ret = insertElement(TAG_DATETIME, temp_value);
+        }
+    }
+
+    int width, height;
+    width = stream->width();
+    height = stream->height();
+    if ((NO_ERROR == ret)) {
+        char temp_value[5];
+        snprintf(temp_value, sizeof(temp_value) / sizeof(char), "%lu",
+                 (unsigned long)width);
+        ret = insertElement(TAG_IMAGE_WIDTH, temp_value);
+    }
+
+    if ((NO_ERROR == ret)) {
+        char temp_value[5];
+        snprintf(temp_value, sizeof(temp_value) / sizeof(char), "%lu",
+                 (unsigned long)height);
+        ret = insertElement(TAG_IMAGE_LENGTH, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLatValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d/%d,%d/%d,%d/%d",
+                 abs(mEXIFData.mGPSData.mLatDeg), 1,
+                 abs(mEXIFData.mGPSData.mLatMin), 1,
+                 abs(mEXIFData.mGPSData.mLatSec),
+                 abs(mEXIFData.mGPSData.mLatSecDiv));
+        ret = insertElement(TAG_GPS_LAT, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLatValid)) {
+        ret = insertElement(TAG_GPS_LAT_REF, mEXIFData.mGPSData.mLatRef);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLongValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d/%d,%d/%d,%d/%d",
+                 abs(mEXIFData.mGPSData.mLongDeg), 1,
+                 abs(mEXIFData.mGPSData.mLongMin), 1,
+                 abs(mEXIFData.mGPSData.mLongSec),
+                 abs(mEXIFData.mGPSData.mLongSecDiv));
+        ret = insertElement(TAG_GPS_LONG, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLongValid)) {
+        ret = insertElement(TAG_GPS_LONG_REF, mEXIFData.mGPSData.mLongRef);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mAltitudeValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d/%d",
+                 abs(mEXIFData.mGPSData.mAltitude), 1);
+        ret = insertElement(TAG_GPS_ALT, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mAltitudeValid)) {
+        char temp_value[5];
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d", mEXIFData.mGPSData.mAltitudeRef);
+        ret = insertElement(TAG_GPS_ALT_REF, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mMapDatumValid)) {
+        ret = insertElement(TAG_GPS_MAP_DATUM, mEXIFData.mGPSData.mMapDatum);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mProcMethodValid)) {
+        char temp_value[GPS_PROCESSING_SIZE];
+        memcpy(temp_value, ExifAsciiPrefix, sizeof(ExifAsciiPrefix));
+        memcpy(temp_value + sizeof(ExifAsciiPrefix),
+               mEXIFData.mGPSData.mProcMethod,
+               (GPS_PROCESSING_SIZE - sizeof(ExifAsciiPrefix)));
+        ret = insertElement(TAG_GPS_PROCESSING_METHOD, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mVersionIdValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d,%d,%d,%d",
+                 mEXIFData.mGPSData.mVersionId[0],
+                 mEXIFData.mGPSData.mVersionId[1],
+                 mEXIFData.mGPSData.mVersionId[2],
+                 mEXIFData.mGPSData.mVersionId[3]);
+        ret = insertElement(TAG_GPS_VERSION_ID, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mTimeStampValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d/%d,%d/%d,%d/%d",
+                 mEXIFData.mGPSData.mTimeStampHour, 1,
+                 mEXIFData.mGPSData.mTimeStampMin, 1,
+                 mEXIFData.mGPSData.mTimeStampSec, 1);
+        ret = insertElement(TAG_GPS_TIMESTAMP, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mDatestampValid)) {
+        ret = insertElement(TAG_GPS_DATESTAMP, mEXIFData.mGPSData.mDatestamp);
+    }
+
+    int32_t jpegRotation;
+    ret = mMeta->getJpegRotation(jpegRotation);
+    if (NO_ERROR == ret) {
+        char str[16];
+        snprintf(str, sizeof(str), "%d", jpegRotation);
+        const char *exif_orient =
+            JpegBuilder::degreesToExifOrientation(str);
+
+        if (exif_orient) {
+            ret = insertElement(TAG_ORIENTATION, exif_orient);
+        }
+    }
+
+    return ret;
+}
+
+void JpegBuilder::setMetadata(sp<Metadata> meta)
+{
+    mMeta = meta;
+    if (mMeta == NULL) {
+        ALOGV("%s invalid meta param", __func__);
+        return;
+    }
+
+    status_t ret = NO_ERROR;
+
+    double gpsCoordinates[3];
+    ret = mMeta->getGpsCoordinates(gpsCoordinates, 3);
+    if (ret == 0) {
+        double gpsPos = gpsCoordinates[0];
+        if (convertGPSCoord(gpsPos,
+                            mEXIFData.mGPSData.mLatDeg,
+                            mEXIFData.mGPSData.mLatMin,
+                            mEXIFData.mGPSData.mLatSec,
+                            mEXIFData.mGPSData.mLatSecDiv) == NO_ERROR) {
+            if (0 < gpsPos) {
+                strncpy(mEXIFData.mGPSData.mLatRef, GPS_NORTH_REF, GPS_REF_SIZE);
+            }
+            else {
+                strncpy(mEXIFData.mGPSData.mLatRef, GPS_SOUTH_REF, GPS_REF_SIZE);
+            }
+
+            mEXIFData.mGPSData.mLatValid = true;
+        }
+        else {
+            mEXIFData.mGPSData.mLatValid = false;
+        }
+
+        gpsPos = gpsCoordinates[1];
+        if (convertGPSCoord(gpsPos,
+                            mEXIFData.mGPSData.mLongDeg,
+                            mEXIFData.mGPSData.mLongMin,
+                            mEXIFData.mGPSData.mLongSec,
+                            mEXIFData.mGPSData.mLongSecDiv) == NO_ERROR) {
+            if (0 < gpsPos) {
+                strncpy(mEXIFData.mGPSData.mLongRef, GPS_EAST_REF, GPS_REF_SIZE);
+            }
+            else {
+                strncpy(mEXIFData.mGPSData.mLongRef, GPS_WEST_REF, GPS_REF_SIZE);
+            }
+
+            mEXIFData.mGPSData.mLongValid = true;
+        }
+        else {
+            mEXIFData.mGPSData.mLongValid = false;
+        }
+
+        gpsPos = gpsCoordinates[2];
+        mEXIFData.mGPSData.mAltitude = floor(fabs(gpsPos));
+        if (gpsPos < 0) {
+            mEXIFData.mGPSData.mAltitudeRef = 1;
+        }
+        else {
+            mEXIFData.mGPSData.mAltitudeRef = 0;
+        }
+        mEXIFData.mGPSData.mAltitudeValid = true;
+    }
+    else {
+        mEXIFData.mGPSData.mLatValid = false;
+        mEXIFData.mGPSData.mLongValid = false;
+        mEXIFData.mGPSData.mAltitudeValid = false;
+    }
+
+    int64_t gpsTimestamp;
+    ret = mMeta->getGpsTimeStamp(gpsTimestamp);
+    if (ret == 0) {
+        struct tm *timeinfo = gmtime((time_t *)&(gpsTimestamp));
+        if (NULL != timeinfo) {
+            mEXIFData.mGPSData.mTimeStampHour  = timeinfo->tm_hour;
+            mEXIFData.mGPSData.mTimeStampMin   = timeinfo->tm_min;
+            mEXIFData.mGPSData.mTimeStampSec   = timeinfo->tm_sec;
+            mEXIFData.mGPSData.mTimeStampValid = true;
+        }
+        else {
+            mEXIFData.mGPSData.mTimeStampValid = false;
+        }
+
+        long gpsDatestamp = gpsTimestamp;
+        timeinfo = gmtime((time_t *)&(gpsDatestamp));
+        if (NULL != timeinfo) {
+            strftime(mEXIFData.mGPSData.mDatestamp,
+                     GPS_DATESTAMP_SIZE,
+                     "%Y:%m:%d",
+                     timeinfo);
+            mEXIFData.mGPSData.mDatestampValid = true;
+        }
+        else {
+            mEXIFData.mGPSData.mDatestampValid = false;
+        }
+    }
+    else {
+        mEXIFData.mGPSData.mTimeStampValid = false;
+        mEXIFData.mGPSData.mDatestampValid = false;
+    }
+
+    uint8_t gpsProcessingMethod[GPS_PROCESSING_SIZE];
+    ret = mMeta->getGpsProcessingMethod(gpsProcessingMethod, GPS_PROCESSING_SIZE);
+    if (ret == 0) {
+        memset(mEXIFData.mGPSData.mProcMethod, 0, GPS_PROCESSING_SIZE);
+        strcpy(mEXIFData.mGPSData.mProcMethod, (const char*)gpsProcessingMethod);
+        mEXIFData.mGPSData.mProcMethodValid = true;
+    }
+    else {
+        mEXIFData.mGPSData.mProcMethodValid = false;
+    }
+
+    mEXIFData.mGPSData.mMapDatumValid  = false;
+    mEXIFData.mGPSData.mVersionIdValid = false;
+    mEXIFData.mModelValid              = true;
+    mEXIFData.mMakeValid               = true;
+}
+
+status_t JpegBuilder::encodeImage(JpegParams *mainJpeg,
+                                  JpegParams *thumbNail)
+{
+    status_t ret = NO_ERROR;
+
+    mMainInput      = mainJpeg;
+    mThumbnailInput = thumbNail;
+    if (thumbNail) {
+        ret = encodeJpeg(thumbNail);
+    }
+
+    if (ret != NO_ERROR) {
+        ALOGE("%s encodeJpeg failed", __FUNCTION__);
+        return ret;
+    }
+
+    return encodeJpeg(mainJpeg);
+}
+
+status_t JpegBuilder::encodeJpeg(JpegParams *input)
+{
+    PixelFormat format = input->format;
+    YuvToJpegEncoder *encoder = YuvToJpegEncoder::create(format);
+
+    if (encoder == NULL) {
+        ALOGE("%s YuvToJpegEncoder::create failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    int res = 0;
+    res = encoder->encode(input->src,
+                          input->srcPhy,
+                          input->in_width,
+                          input->in_height,
+                          input->quality,
+                          input->dst,
+                          input->dst_size,
+                          input->out_width,
+                          input->out_height);
+
+    delete encoder;
+    if (res) {
+        input->jpeg_size = res;
+        return NO_ERROR;
+    }
+    else {
+        return BAD_VALUE;
+    }
+}
+
+size_t JpegBuilder::getImageSize()
+{
+    size_t jpeg_size, image_size;
+    Section_t *exif_section = NULL;
+
+    jpeg_size = mMainInput->jpeg_size;
+
+    exif_section = FindSection(M_EXIF);
+    if (exif_section != NULL) {
+        image_size = jpeg_size + exif_section->Size;
+    }
+    else {
+        image_size = jpeg_size;
+    }
+    return image_size;
+}
+
+status_t JpegBuilder::buildImage(const StreamBuffer *streamBuf)
+{
+    size_t   jpeg_size;
+    uint8_t *src  = NULL;
+
+    if (!streamBuf || !mMainInput || !streamBuf->mVirtAddr) {
+        ALOGE("%s invalid param", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    jpeg_size = mMainInput->jpeg_size;
+    src       = mMainInput->src;
+
+    if (mMainInput->dst && (jpeg_size > 0)) {
+        if (position > 0) {
+            Section_t *exif_section = NULL;
+
+            insertExifToJpeg((unsigned char *)mMainInput->dst, jpeg_size);
+
+            if (mThumbnailInput) {
+                insertExifThumbnailImage((const char *)mThumbnailInput->dst,
+                                         (int)mThumbnailInput->jpeg_size);
+            }
+
+            exif_section = FindSection(M_EXIF);
+            if (exif_section) {
+                size_t imageSize = jpeg_size + exif_section->Size;
+                if (streamBuf->mSize < imageSize) {
+                    ALOGE("%s buf size %d small than %d", __FUNCTION__,
+                                    streamBuf->mSize, imageSize);
+                    return BAD_VALUE;
+                }
+
+                saveJpeg((unsigned char *)streamBuf->mVirtAddr,
+                         jpeg_size + exif_section->Size + 2);
+            }
+        } else {
+            size_t imageSize = jpeg_size;
+            if (streamBuf->mSize < imageSize) {
+                ALOGE("%s buf size %d small than %d", __FUNCTION__,
+                                    streamBuf->mSize, imageSize);
+                return BAD_VALUE;
+            }
+            memcpy(streamBuf->mVirtAddr, mMainInput->dst, jpeg_size);
+        }
+    }
+
+    return NO_ERROR;
+}
+
+status_t JpegBuilder::convertGPSCoord(double coord,
+                                      int  & deg,
+                                      int  & min,
+                                      int  & sec,
+                                      int  & secDivisor)
+{
+    double tmp;
+
+    if (coord == 0) {
+        ALOGE("Invalid GPS coordinate");
+
+        return -EINVAL;
+    }
+
+    deg        = (int)floor(fabs(coord));
+    tmp        = (fabs(coord) - floor(fabs(coord))) * GPS_MIN_DIV;
+    min        = (int)floor(tmp);
+    tmp        = (tmp - floor(tmp)) * (GPS_SEC_DIV * GPS_SEC_ACCURACY);
+    sec        = (int)floor(tmp);
+    secDivisor = GPS_SEC_ACCURACY;
+
+    if (sec >= (GPS_SEC_DIV * GPS_SEC_ACCURACY)) {
+        sec  = 0;
+        min += 1;
+    }
+
+    if (min >= 60) {
+        min  = 0;
+        deg += 1;
+    }
+
+    return NO_ERROR;
+}
+};
diff --git a/mx6/libcamera3/JpegBuilder.h b/mx6/libcamera3/JpegBuilder.h
new file mode 100644
index 0000000..edf3d46
--- /dev/null
+++ b/mx6/libcamera3/JpegBuilder.h
@@ -0,0 +1,191 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _JPEG_BUILDER_H_
+#define _JPEG_BUILDER_H_
+
+#include "CameraUtils.h"
+#include <utils/RefBase.h>
+#include "YuvToJpegEncoder.h"
+
+extern "C" {
+#include "jhead.h"
+}
+
+namespace android {
+#define EXIF_MAKENOTE "fsl_makernote"
+#define EXIF_MODEL    "fsl_model"
+
+#define MAX_EXIF_TAGS_SUPPORTED 30
+
+static const char TAG_MODEL[]                 = "Model";
+static const char TAG_MAKE[]                  = "Make";
+static const char TAG_FOCALLENGTH[]           = "FocalLength";
+static const char TAG_DATETIME[]              = "DateTime";
+static const char TAG_IMAGE_WIDTH[]           = "ImageWidth";
+static const char TAG_IMAGE_LENGTH[]          = "ImageLength";
+static const char TAG_GPS_LAT[]               = "GPSLatitude";
+static const char TAG_GPS_LAT_REF[]           = "GPSLatitudeRef";
+static const char TAG_GPS_LONG[]              = "GPSLongitude";
+static const char TAG_GPS_LONG_REF[]          = "GPSLongitudeRef";
+static const char TAG_GPS_ALT[]               = "GPSAltitude";
+static const char TAG_GPS_ALT_REF[]           = "GPSAltitudeRef";
+static const char TAG_GPS_MAP_DATUM[]         = "GPSMapDatum";
+static const char TAG_GPS_PROCESSING_METHOD[] = "GPSProcessingMethod";
+static const char TAG_GPS_VERSION_ID[]        = "GPSVersionID";
+static const char TAG_GPS_TIMESTAMP[]         = "GPSTimeStamp";
+static const char TAG_GPS_DATESTAMP[]         = "GPSDateStamp";
+static const char TAG_ORIENTATION[]           = "Orientation";
+
+#define GPS_MIN_DIV                 60
+#define GPS_SEC_DIV                 60
+#define GPS_SEC_ACCURACY            1000
+
+#define GPS_NORTH_REF               "N"
+#define GPS_SOUTH_REF               "S"
+#define GPS_EAST_REF                "E"
+#define GPS_WEST_REF                "W"
+
+#define EXIF_DATE_TIME_SIZE         20
+
+#define GPS_DATESTAMP_SIZE          11
+#define GPS_REF_SIZE                2
+#define GPS_MAPDATUM_SIZE           100
+#define GPS_PROCESSING_SIZE         100
+#define GPS_VERSION_SIZE            4
+
+struct GPSData
+{
+    int           mLongDeg, mLongMin, mLongSec, mLongSecDiv;
+    char          mLongRef[GPS_REF_SIZE];
+    bool          mLongValid;
+    int           mLatDeg, mLatMin, mLatSec, mLatSecDiv;
+    char          mLatRef[GPS_REF_SIZE];
+    bool          mLatValid;
+    int           mAltitude;
+    unsigned char mAltitudeRef;
+    bool          mAltitudeValid;
+    char          mMapDatum[GPS_MAPDATUM_SIZE];
+    bool          mMapDatumValid;
+    char          mVersionId[GPS_VERSION_SIZE];
+    bool          mVersionIdValid;
+    char          mProcMethod[GPS_PROCESSING_SIZE];
+    bool          mProcMethodValid;
+    char          mDatestamp[GPS_DATESTAMP_SIZE];
+    bool          mDatestampValid;
+    uint32_t      mTimeStampHour;
+    uint32_t      mTimeStampMin;
+    uint32_t      mTimeStampSec;
+    bool          mTimeStampValid;
+};
+
+struct EXIFData
+{
+    GPSData mGPSData;
+    bool    mMakeValid;
+    bool    mModelValid;
+};
+
+struct JpegParams {
+    JpegParams(uint8_t *uSrc,
+		  uint8_t*uSrcPhy,
+               int     srcSize,
+               uint8_t *uDst,
+               int     dstSize,
+               int     quality,
+               int     inWidth,
+               int     inHeight,
+               int     outWidth,
+               int     outHeight,
+               int     format)
+        : src(uSrc), srcPhy(uSrcPhy),src_size(srcSize), dst(uDst), dst_size(dstSize),
+          quality(quality), in_width(inWidth), in_height(inHeight),
+          out_width(outWidth), out_height(outHeight), format(format),
+          jpeg_size(0)
+    {}
+
+    uint8_t    *src;
+    uint8_t    *srcPhy;
+    int         src_size;
+    uint8_t    *dst;
+    int         dst_size;
+    int         quality;
+    int         in_width;
+    int         in_height;
+    int         out_width;
+    int         out_height;
+    int         format;
+    size_t      jpeg_size;
+};
+
+
+class JpegBuilder : public LightRefBase<JpegBuilder> {
+public:
+    JpegBuilder();
+    ~JpegBuilder();
+
+    status_t prepareImage(const StreamBuffer *streamBuf);
+
+    status_t encodeImage(JpegParams *mainJpeg,
+                         JpegParams *thumbNail);
+    size_t   getImageSize();
+    status_t buildImage(const StreamBuffer *streamBuf);
+    void     reset();
+    void setMetadata(sp<Metadata> meta);
+
+private:
+    status_t insertElement(const char *tag,
+                           const char *value);
+    void     insertExifToJpeg(unsigned char *jpeg,
+                              size_t         jpeg_size);
+    status_t insertExifThumbnailImage(const char *,
+                                      int);
+    void     saveJpeg(unsigned char *picture,
+                      size_t         jpeg_size);
+
+private:
+    status_t    encodeJpeg(JpegParams *input);
+    const char* degreesToExifOrientation(const char *);
+    void        stringToRational(const    char *,
+                                 unsigned int *,
+                                 unsigned int *);
+    bool        isAsciiTag(const char *tag);
+    status_t    convertGPSCoord(double coord,
+                                int  & deg,
+                                int  & min,
+                                int  & sec,
+                                int  & secDivisor);
+
+private:
+    JpegParams *mMainInput;
+    JpegParams *mThumbnailInput;
+
+    bool mCancelEncoding;
+    EXIFData mEXIFData;
+
+private:
+    ExifElement_t table[MAX_EXIF_TAGS_SUPPORTED];
+    unsigned int  gps_tag_count;
+    unsigned int  exif_tag_count;
+    unsigned int  position;
+    bool jpeg_opened;
+    bool has_datetime_tag;
+
+    sp<Metadata> mMeta;
+};
+};
+
+#endif // ifndef _JPEG_BUILDER_H_
diff --git a/mx6/libcamera3/MessageQueue.cpp b/mx6/libcamera3/MessageQueue.cpp
new file mode 100644
index 0000000..b36ed6c
--- /dev/null
+++ b/mx6/libcamera3/MessageQueue.cpp
@@ -0,0 +1,140 @@
+/*
+ * Copyright (C) 2009-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+#include <stdint.h>
+#include <errno.h>
+#include <sys/types.h>
+
+#include <utils/threads.h>
+#include <utils/Timers.h>
+#include <utils/Log.h>
+#include <binder/IPCThreadState.h>
+
+#include "MessageQueue.h"
+
+using namespace android;
+
+void CMessageList::insert(const sp<CMessage>& node)
+{
+    mList.push_back(node);
+}
+
+void CMessageList::remove(CMessageList::LIST::iterator pos)
+{
+    mList.erase(pos);
+}
+
+void CMessageList::clear()
+{
+    mList.clear();
+}
+
+CMessageQueue::CMessageQueue()
+{
+    Mutex::Autolock _l(mLock);
+    mMessages.clear();
+    mCommands.clear();
+}
+
+CMessageQueue::~CMessageQueue()
+{
+    Mutex::Autolock _l(mLock);
+
+    mMessages.clear();
+    mCommands.clear();
+}
+void CMessageQueue::clearMessages()
+{
+    Mutex::Autolock _l(mLock);
+
+    mMessages.clear();
+}
+
+void CMessageQueue::clearCommands()
+{
+    Mutex::Autolock _l(mLock);
+
+    mCommands.clear();
+}
+
+sp<CMessage> CMessageQueue::waitMessage(nsecs_t timeout)
+{
+    sp<CMessage>    result;
+    nsecs_t timeoutTime = systemTime() + timeout;
+    while (true) {
+        Mutex::Autolock _l(mLock);
+        nsecs_t now = systemTime();
+
+        // handle command firstly.
+        LIST::iterator cur(mCommands.begin());
+        if (cur != mCommands.end()) {
+            result = *cur;
+        }
+
+        if (result != 0) {
+            mCommands.remove(cur);
+            break;
+        }
+
+        // handle message secondly.
+        cur = mMessages.begin();
+        if (cur != mMessages.end()) {
+            result = *cur;
+        }
+
+        if (result != 0) {
+            mMessages.remove(cur);
+            break;
+        }
+
+        if (timeout >= 0) {
+            if (timeoutTime < now) {
+                result = 0;
+                break;
+            }
+            nsecs_t relTime = timeoutTime - systemTime();
+            mCondition.waitRelative(mLock, relTime);
+        } else {
+            mCondition.wait(mLock);
+        }
+    }
+
+    return result;
+}
+
+status_t CMessageQueue::postMessage(const sp<CMessage> message,
+                                    int32_t             flags)
+{
+    return queueMessage(message, flags);
+}
+
+status_t CMessageQueue::queueMessage(const sp<CMessage>& message,
+                                     int32_t             flags)
+{
+    Mutex::Autolock _l(mLock);
+
+    if (flags == 0) {
+        mMessages.insert(message);
+    }
+    else {
+        mCommands.insert(message);
+    }
+
+    mCondition.signal();
+    return NO_ERROR;
+}
+
diff --git a/mx6/libcamera3/MessageQueue.h b/mx6/libcamera3/MessageQueue.h
new file mode 100644
index 0000000..3a00eba
--- /dev/null
+++ b/mx6/libcamera3/MessageQueue.h
@@ -0,0 +1,100 @@
+/*
+ * Copyright (C) 2009-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+#ifndef _MESSAGE_QUEUE_H
+#define _MESSAGE_QUEUE_H
+
+#include <stdint.h>
+#include <errno.h>
+#include <sys/types.h>
+#include <utils/threads.h>
+#include <utils/Timers.h>
+#include <utils/List.h>
+#include <semaphore.h>
+
+using namespace android;
+class CMessage;
+
+class CMessageList {
+    List< sp<CMessage> > mList;
+    typedef List< sp<CMessage> > LIST;
+
+public:
+    inline LIST::iterator begin() {
+        return mList.begin();
+    }
+
+    inline LIST::const_iterator begin() const {
+        return mList.begin();
+    }
+
+    inline LIST::iterator end() {
+        return mList.end();
+    }
+
+    inline LIST::const_iterator end() const {
+        return mList.end();
+    }
+
+    inline bool isEmpty() const {
+        return mList.empty();
+    }
+
+    void insert(const sp<CMessage>& node);
+    void remove(LIST::iterator pos);
+    void clear();
+};
+
+class CMessage : public LightRefBase<CMessage>{
+public:
+    int32_t what;
+    int32_t arg0;
+
+    CMessage(int32_t what,
+             int32_t arg0 = 0)
+        : what(what), arg0(arg0) {}
+
+    virtual ~CMessage() {}
+
+private:
+    friend class LightRefBase<CMessage>;
+};
+
+class CMessageQueue {
+    typedef List< sp<CMessage> > LIST;
+
+public:
+    CMessageQueue();
+    ~CMessageQueue();
+
+    sp<CMessage> waitMessage(nsecs_t timeout = -1);
+    status_t     postMessage(const sp<CMessage> message,
+                             int32_t             flags = 0);
+	void clearMessages();
+	void clearCommands();
+
+private:
+    status_t queueMessage(const sp<CMessage>& message,
+                          int32_t             flags);
+
+    Mutex mLock;
+    Condition mCondition;
+    CMessageList mMessages;
+    CMessageList mCommands;
+};
+
+#endif // ifndef CAMERA_HAL_MESSAGE_QUEUE_H
diff --git a/mx6/libcamera3/Metadata.cpp b/mx6/libcamera3/Metadata.cpp
new file mode 100644
index 0000000..6e47723
--- /dev/null
+++ b/mx6/libcamera3/Metadata.cpp
@@ -0,0 +1,613 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <system/camera_metadata.h>
+
+//#define LOG_NDEBUG 0
+#include <cutils/log.h>
+#include "Metadata.h"
+
+Metadata::Metadata(const camera_metadata_t *metadata)
+{
+    mData = metadata;
+}
+
+Metadata::~Metadata()
+{
+    mData.clear();
+}
+
+camera_metadata_entry_t Metadata::find(uint32_t tag)
+{
+    return mData.find(tag);
+}
+
+int32_t Metadata::getRequestType()
+{
+    camera_metadata_entry_t intent =
+            mData.find(ANDROID_CONTROL_CAPTURE_INTENT);
+    if (intent.count <= 0) {
+        return 0;
+    }
+
+    if (intent.data.u8[0] == ANDROID_CONTROL_CAPTURE_INTENT_STILL_CAPTURE) {
+        return TYPE_STILLCAP;
+    }
+    else if (intent.data.u8[0] == ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT) {
+        return TYPE_SNAPSHOT;
+    }
+
+    return TYPE_PREVIEW;
+}
+
+int32_t Metadata::getGpsCoordinates(double *pCoords, int count)
+{
+    camera_metadata_entry_t entry;
+    entry = mData.find(ANDROID_JPEG_GPS_COORDINATES);
+    if (entry.count == 0) {
+        ALOGE("%s: error reading jpeg Coordinates tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    for (int i=0; i<(int)entry.count && i<count; i++) {
+        pCoords[i] = entry.data.d[i];
+    }
+
+    return NO_ERROR;
+}
+
+int32_t Metadata::getGpsTimeStamp(int64_t &timeStamp)
+{
+    camera_metadata_entry_t entry;
+    entry = mData.find(ANDROID_JPEG_GPS_TIMESTAMP);
+    if (entry.count == 0) {
+        ALOGE("%s: error reading jpeg TimeStamp tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    timeStamp = entry.data.i64[0];
+    return NO_ERROR;
+}
+
+int32_t Metadata::getGpsProcessingMethod(uint8_t* src, int count)
+{
+    camera_metadata_entry_t entry;
+    entry = mData.find(ANDROID_JPEG_GPS_PROCESSING_METHOD);
+    if (entry.count == 0) {
+        ALOGE("%s: error reading jpeg ProcessingMethod tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    int i;
+    for (i=0; i<(int)entry.count && i<count-1; i++) {
+        src[i] = entry.data.u8[i];
+    }
+    src[i] = '\0';
+
+    return NO_ERROR;
+}
+
+int32_t Metadata::getJpegRotation(int32_t &jpegRotation)
+{
+    camera_metadata_entry_t entry;
+    entry = mData.find(ANDROID_JPEG_ORIENTATION);
+    if (entry.count == 0) {
+        ALOGE("%s: error reading jpeg Rotation tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    jpegRotation = entry.data.i32[0];
+    return NO_ERROR;
+}
+
+int32_t Metadata::getJpegQuality(int32_t &quality)
+{
+    uint8_t u8Quality = 0;
+    camera_metadata_entry_t entry;
+    entry = mData.find(ANDROID_JPEG_QUALITY);
+    if (entry.count == 0) {
+        ALOGE("%s: error reading jpeg quality tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    //4.3 framework change quality type from i32 to u8
+    u8Quality = entry.data.u8[0];
+    quality = u8Quality;
+
+    return NO_ERROR;
+}
+
+int32_t Metadata::getJpegThumbQuality(int32_t &thumb)
+{
+    uint8_t u8Quality = 0;
+    camera_metadata_entry_t entry;
+    entry = mData.find(ANDROID_JPEG_THUMBNAIL_QUALITY);
+    if (entry.count == 0) {
+        ALOGE("%s: error reading jpeg thumbnail quality tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    //4.3 framework change quality type from i32 to u8
+    u8Quality = entry.data.u8[0];
+    thumb = u8Quality;
+
+    return NO_ERROR;
+}
+
+int32_t Metadata::getJpegThumbSize(int &width, int &height)
+{
+    camera_metadata_entry_t entry;
+    entry = mData.find(ANDROID_JPEG_THUMBNAIL_SIZE);
+    if (entry.count == 0) {
+        ALOGE("%s: error reading jpeg thumbnail size tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    width = entry.data.i32[0];
+    height = entry.data.i32[1];
+    return NO_ERROR;
+}
+
+int32_t Metadata::getFocalLength(float &focalLength)
+{
+    camera_metadata_entry_t entry;
+    entry = mData.find(ANDROID_LENS_FOCAL_LENGTH);
+    if (entry.count == 0) {
+        ALOGE("%s: error reading lens focal length size tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    focalLength = entry.data.f[0];
+
+    return 0;
+}
+#if 0
+void Metadata::clear()
+{
+    mData.clear();
+}
+#endif
+camera_metadata_t* Metadata::createStaticInfo(SensorData& sensor)
+{
+    /*
+     * Setup static camera info.  This will have to customized per camera
+     * device.
+     */
+    Metadata m;
+
+    /* android.control */
+    m.addInt32(ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES,
+            ARRAY_SIZE(sensor.mTargetFpsRange),
+            sensor.mTargetFpsRange);
+
+    int32_t android_control_ae_compensation_range[] = {-3, 3};
+    m.addInt32(ANDROID_CONTROL_AE_COMPENSATION_RANGE,
+            ARRAY_SIZE(android_control_ae_compensation_range),
+            android_control_ae_compensation_range);
+
+    camera_metadata_rational_t android_control_ae_compensation_step[] = {{1,1}};
+    m.addRational(ANDROID_CONTROL_AE_COMPENSATION_STEP,
+            ARRAY_SIZE(android_control_ae_compensation_step),
+            android_control_ae_compensation_step);
+
+    int32_t android_control_max_regions[] = {/*AE*/ 1,/*AWB*/ 1,/*AF*/ 1};
+    m.addInt32(ANDROID_CONTROL_MAX_REGIONS,
+            ARRAY_SIZE(android_control_max_regions),
+            android_control_max_regions);
+
+    /* android.jpeg */
+    int32_t android_jpeg_available_thumbnail_sizes[] = {96, 96, 160, 120, 0, 0};
+    m.addInt32(ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES,
+            ARRAY_SIZE(android_jpeg_available_thumbnail_sizes),
+            android_jpeg_available_thumbnail_sizes);
+
+    int32_t android_jpeg_max_size[] = {8 * 1024 * 1024}; // 8MB
+    m.addInt32(ANDROID_JPEG_MAX_SIZE,
+            ARRAY_SIZE(android_jpeg_max_size),
+            android_jpeg_max_size);
+
+    /* android.lens */
+    float android_lens_info_available_focal_lengths[] = {sensor.mFocalLength};
+    m.addFloat(ANDROID_LENS_INFO_AVAILABLE_FOCAL_LENGTHS,
+            ARRAY_SIZE(android_lens_info_available_focal_lengths),
+            android_lens_info_available_focal_lengths);
+#if 0
+    /* android.request */
+    int32_t android_request_max_num_output_streams[] = {0, 3, 1};
+    m.addInt32(ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS,
+            ARRAY_SIZE(android_request_max_num_output_streams),
+            android_request_max_num_output_streams);
+#endif
+    /* android.scaler */
+    m.addInt32(ANDROID_SCALER_AVAILABLE_FORMATS,
+            sensor.mAvailableFormatCount,
+            sensor.mAvailableFormats);
+
+    int64_t android_scaler_available_jpeg_min_durations[] = {sensor.mMinFrameDuration};
+    m.addInt64(ANDROID_SCALER_AVAILABLE_JPEG_MIN_DURATIONS,
+            ARRAY_SIZE(android_scaler_available_jpeg_min_durations),
+            android_scaler_available_jpeg_min_durations);
+
+    m.addInt32(ANDROID_SCALER_AVAILABLE_JPEG_SIZES,
+            sensor.mPictureResolutionCount,
+            sensor.mPictureResolutions);
+
+    float android_scaler_available_max_digital_zoom[] = {4};
+    m.addFloat(ANDROID_SCALER_AVAILABLE_MAX_DIGITAL_ZOOM,
+            ARRAY_SIZE(android_scaler_available_max_digital_zoom),
+            android_scaler_available_max_digital_zoom);
+
+    int64_t android_scaler_available_processed_min_durations[] = {sensor.mMinFrameDuration};
+    m.addInt64(ANDROID_SCALER_AVAILABLE_PROCESSED_MIN_DURATIONS,
+            ARRAY_SIZE(android_scaler_available_processed_min_durations),
+            android_scaler_available_processed_min_durations);
+
+    m.addInt32(ANDROID_SCALER_AVAILABLE_PROCESSED_SIZES,
+            sensor.mPreviewResolutionCount,
+            sensor.mPreviewResolutions);
+
+    int64_t android_scaler_available_raw_min_durations[] = {sensor.mMinFrameDuration};
+    m.addInt64(ANDROID_SCALER_AVAILABLE_RAW_MIN_DURATIONS,
+            ARRAY_SIZE(android_scaler_available_raw_min_durations),
+            android_scaler_available_raw_min_durations);
+
+    int32_t android_scaler_available_raw_sizes[] = {sensor.mMaxWidth, sensor.mMaxHeight};
+    m.addInt32(ANDROID_SCALER_AVAILABLE_RAW_SIZES,
+            ARRAY_SIZE(android_scaler_available_raw_sizes),
+            android_scaler_available_raw_sizes);
+
+    /* android.sensor */
+
+    int32_t android_sensor_info_active_array_size[] = {sensor.mMaxWidth, sensor.mMaxHeight};
+    m.addInt32(ANDROID_SENSOR_INFO_ACTIVE_ARRAY_SIZE,
+            ARRAY_SIZE(android_sensor_info_active_array_size),
+            android_sensor_info_active_array_size);
+#if 0
+    int32_t android_sensor_info_sensitivity_range[] =
+            {100, 1600};
+    m.addInt32(ANDROID_SENSOR_INFO_SENSITIVITY_RANGE,
+            ARRAY_SIZE(android_sensor_info_sensitivity_range),
+            android_sensor_info_sensitivity_range);
+#endif
+    int64_t android_sensor_info_max_frame_duration[] = {sensor.mMaxFrameDuration};
+    m.addInt64(ANDROID_SENSOR_INFO_MAX_FRAME_DURATION,
+            ARRAY_SIZE(android_sensor_info_max_frame_duration),
+            android_sensor_info_max_frame_duration);
+
+    float android_sensor_info_physical_size[] = {sensor.mPhysicalWidth, sensor.mPhysicalHeight};
+    m.addFloat(ANDROID_SENSOR_INFO_PHYSICAL_SIZE,
+            ARRAY_SIZE(android_sensor_info_physical_size),
+            android_sensor_info_physical_size);
+
+    int32_t android_sensor_info_pixel_array_size[] = {sensor.mMaxWidth, sensor.mMaxHeight};
+    m.addInt32(ANDROID_SENSOR_INFO_PIXEL_ARRAY_SIZE,
+            ARRAY_SIZE(android_sensor_info_pixel_array_size),
+            android_sensor_info_pixel_array_size);
+#if 0
+    int32_t android_sensor_orientation[] = {0};
+    m.addInt32(ANDROID_SENSOR_ORIENTATION,
+            ARRAY_SIZE(android_sensor_orientation),
+            android_sensor_orientation);
+#endif
+    /* End of static camera characteristics */
+
+    return clone_camera_metadata(m.get());
+}
+
+void Metadata::createSettingTemplate(Metadata& base, SensorData& sensor,
+                                     int request_template)
+{
+    /** android.request */
+    static const uint8_t metadataMode = ANDROID_REQUEST_METADATA_MODE_NONE;
+    base.addUInt8(ANDROID_REQUEST_METADATA_MODE, 1, &metadataMode);
+
+    static const int32_t id = 0;
+    base.addInt32(ANDROID_REQUEST_ID, 1, &id);
+
+    static const int32_t frameCount = 0;
+    base.addInt32(ANDROID_REQUEST_FRAME_COUNT, 1, &frameCount);
+
+    /** android.lens */
+    static const float focusDistance = 0;
+    base.addFloat(ANDROID_LENS_FOCUS_DISTANCE, 1, &focusDistance);
+
+    static float aperture = 2.8;
+    base.addFloat(ANDROID_LENS_APERTURE, 1, &aperture);
+    base.addFloat(ANDROID_LENS_FOCAL_LENGTH, 1, &sensor.mFocalLength);
+
+    static const float filterDensity = 0;
+    base.addFloat(ANDROID_LENS_FILTER_DENSITY, 1, &filterDensity);
+
+    static const uint8_t opticalStabilizationMode =
+            ANDROID_LENS_OPTICAL_STABILIZATION_MODE_OFF;
+    base.addUInt8(ANDROID_LENS_OPTICAL_STABILIZATION_MODE,
+            1, &opticalStabilizationMode);
+
+    /** android.sensor */
+    static const int64_t frameDuration = 33333333L; // 1/30 s
+    base.addInt64(ANDROID_SENSOR_FRAME_DURATION, 1, &frameDuration);
+
+
+    /** android.flash */
+    static const uint8_t flashMode = ANDROID_FLASH_MODE_OFF;
+    base.addUInt8(ANDROID_FLASH_MODE, 1, &flashMode);
+
+    static const uint8_t flashPower = 10;
+    base.addUInt8(ANDROID_FLASH_FIRING_POWER, 1, &flashPower);
+
+    static const int64_t firingTime = 0;
+    base.addInt64(ANDROID_FLASH_FIRING_TIME, 1, &firingTime);
+
+    /** Processing block modes */
+    uint8_t hotPixelMode = 0;
+    uint8_t demosaicMode = 0;
+    uint8_t noiseMode = 0;
+    uint8_t shadingMode = 0;
+    uint8_t colorMode = 0;
+    uint8_t tonemapMode = 0;
+    uint8_t edgeMode = 0;
+    uint8_t vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF;
+
+    switch (request_template) {
+      case CAMERA3_TEMPLATE_PREVIEW:
+        break;
+      case CAMERA3_TEMPLATE_STILL_CAPTURE:
+        break;
+      case CAMERA3_TEMPLATE_VIDEO_RECORD:
+        vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_ON;
+        break;
+      case CAMERA3_TEMPLATE_VIDEO_SNAPSHOT:
+        vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_ON;
+        break;
+      case CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG:
+        hotPixelMode = ANDROID_HOT_PIXEL_MODE_HIGH_QUALITY;
+        demosaicMode = ANDROID_DEMOSAIC_MODE_HIGH_QUALITY;
+        noiseMode = ANDROID_NOISE_REDUCTION_MODE_HIGH_QUALITY;
+        shadingMode = ANDROID_SHADING_MODE_HIGH_QUALITY;
+        colorMode = ANDROID_COLOR_CORRECTION_MODE_HIGH_QUALITY;
+        tonemapMode = ANDROID_TONEMAP_MODE_HIGH_QUALITY;
+        edgeMode = ANDROID_EDGE_MODE_HIGH_QUALITY;
+        break;
+      default:
+        hotPixelMode = ANDROID_HOT_PIXEL_MODE_FAST;
+        demosaicMode = ANDROID_DEMOSAIC_MODE_FAST;
+        noiseMode = ANDROID_NOISE_REDUCTION_MODE_FAST;
+        shadingMode = ANDROID_SHADING_MODE_FAST;
+        colorMode = ANDROID_COLOR_CORRECTION_MODE_FAST;
+        tonemapMode = ANDROID_TONEMAP_MODE_FAST;
+        edgeMode = ANDROID_EDGE_MODE_FAST;
+        break;
+    }
+    base.addUInt8(ANDROID_HOT_PIXEL_MODE, 1, &hotPixelMode);
+    base.addUInt8(ANDROID_DEMOSAIC_MODE, 1, &demosaicMode);
+    base.addUInt8(ANDROID_NOISE_REDUCTION_MODE, 1, &noiseMode);
+    base.addUInt8(ANDROID_SHADING_MODE, 1, &shadingMode);
+    base.addUInt8(ANDROID_COLOR_CORRECTION_MODE, 1, &colorMode);
+    base.addUInt8(ANDROID_TONEMAP_MODE, 1, &tonemapMode);
+    base.addUInt8(ANDROID_EDGE_MODE, 1, &edgeMode);
+    base.addUInt8(ANDROID_CONTROL_VIDEO_STABILIZATION_MODE, 1, &vstabMode);
+
+    /** android.noise */
+    static const uint8_t noiseStrength = 5;
+    base.addUInt8(ANDROID_NOISE_REDUCTION_STRENGTH, 1, &noiseStrength);
+
+    /** android.color */
+    static const float colorTransform[9] = {
+        1.0f, 0.f, 0.f,
+        0.f, 1.f, 0.f,
+        0.f, 0.f, 1.f
+    };
+    base.addFloat(ANDROID_COLOR_CORRECTION_TRANSFORM, 9, colorTransform);
+
+    /** android.tonemap */
+    static const float tonemapCurve[4] = {
+        0.f, 0.f,
+        1.f, 1.f
+    };
+    base.addFloat(ANDROID_TONEMAP_CURVE_RED, 4, tonemapCurve); // sungjoong
+    base.addFloat(ANDROID_TONEMAP_CURVE_GREEN, 4, tonemapCurve);
+    base.addFloat(ANDROID_TONEMAP_CURVE_BLUE, 4, tonemapCurve);
+
+    /** android.edge */
+    static const uint8_t edgeStrength = 5;
+    base.addUInt8(ANDROID_EDGE_STRENGTH, 1, &edgeStrength);
+
+    /** android.scaler */
+    int32_t cropRegion[3] = {
+        0, 0, /*mSensorInfo->mMaxWidth*/
+    };
+    base.addInt32(ANDROID_SCALER_CROP_REGION, 3, cropRegion);
+
+    /** android.jpeg */
+    //4.3 framework change quality type from i32 to u8
+    static const uint8_t jpegQuality = 100;
+    base.addUInt8(ANDROID_JPEG_QUALITY, 1, &jpegQuality);
+
+    static const int32_t thumbnailSize[2] = {
+        160, 120
+    };
+    base.addInt32(ANDROID_JPEG_THUMBNAIL_SIZE, 2, thumbnailSize);
+
+    //4.3 framework change quality type from i32 to u8
+    static const uint8_t thumbnailQuality = 100;
+    base.addUInt8(ANDROID_JPEG_THUMBNAIL_QUALITY, 1, &thumbnailQuality);
+
+    static const double gpsCoordinates[3] = {
+        0, 0, 0
+    };
+    base.addDouble(ANDROID_JPEG_GPS_COORDINATES, 3, gpsCoordinates);
+
+    static const uint8_t gpsProcessingMethod[32] = "None";
+    base.addUInt8(ANDROID_JPEG_GPS_PROCESSING_METHOD, 32, gpsProcessingMethod);
+
+    static const int64_t gpsTimestamp = 0;
+    base.addInt64(ANDROID_JPEG_GPS_TIMESTAMP, 1, &gpsTimestamp);
+
+    static const int32_t jpegOrientation = 0;
+    base.addInt32(ANDROID_JPEG_ORIENTATION, 1, &jpegOrientation);
+
+    /** android.stats */
+
+    static const uint8_t faceDetectMode = ANDROID_STATISTICS_FACE_DETECT_MODE_FULL;
+    base.addUInt8(ANDROID_STATISTICS_FACE_DETECT_MODE, 1, &faceDetectMode);
+
+    static const uint8_t histogramMode = ANDROID_STATISTICS_HISTOGRAM_MODE_OFF;
+    base.addUInt8(ANDROID_STATISTICS_HISTOGRAM_MODE, 1, &histogramMode);
+
+    static const uint8_t sharpnessMapMode = ANDROID_STATISTICS_HISTOGRAM_MODE_OFF;
+    base.addUInt8(ANDROID_STATISTICS_SHARPNESS_MAP_MODE, 1, &sharpnessMapMode);
+
+    /** android.control */
+
+    uint8_t controlIntent = 0;
+    switch (request_template) {
+      case CAMERA3_TEMPLATE_PREVIEW:
+        controlIntent = ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW;
+        break;
+      case CAMERA3_TEMPLATE_STILL_CAPTURE:
+        controlIntent = ANDROID_CONTROL_CAPTURE_INTENT_STILL_CAPTURE;
+        break;
+      case CAMERA3_TEMPLATE_VIDEO_RECORD:
+        controlIntent = ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_RECORD;
+        break;
+      case CAMERA3_TEMPLATE_VIDEO_SNAPSHOT:
+        controlIntent = ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT;
+        break;
+      case CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG:
+        controlIntent = ANDROID_CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG;
+        break;
+      default:
+        controlIntent = ANDROID_CONTROL_CAPTURE_INTENT_CUSTOM;
+        break;
+    }
+    base.addUInt8(ANDROID_CONTROL_CAPTURE_INTENT, 1, &controlIntent);
+
+    static const uint8_t controlMode = ANDROID_CONTROL_MODE_AUTO;
+    base.addUInt8(ANDROID_CONTROL_MODE, 1, &controlMode);
+
+    static const uint8_t effectMode = ANDROID_CONTROL_EFFECT_MODE_OFF;
+    base.addUInt8(ANDROID_CONTROL_EFFECT_MODE, 1, &effectMode);
+
+    static const uint8_t sceneMode = ANDROID_CONTROL_SCENE_MODE_DISABLED;
+    base.addUInt8(ANDROID_CONTROL_SCENE_MODE, 1, &sceneMode);
+
+    static const uint8_t aeMode = ANDROID_CONTROL_AE_MODE_ON;
+    base.addUInt8(ANDROID_CONTROL_AE_MODE, 1, &aeMode);
+
+    int32_t controlRegions[5] = {
+        0, 0, sensor.mMaxWidth, sensor.mMaxHeight, 1000
+    };
+    base.addInt32(ANDROID_CONTROL_AE_REGIONS, 5, controlRegions);
+
+    static const int32_t aeExpCompensation = 0;
+    base.addInt32(ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION, 1, &aeExpCompensation);
+
+    static const int32_t aeTargetFpsRange[2] = {
+        15, 30
+    };
+    base.addInt32(ANDROID_CONTROL_AE_TARGET_FPS_RANGE, 2, aeTargetFpsRange);
+
+    static const uint8_t aeAntibandingMode =
+            ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO;
+    base.addUInt8(ANDROID_CONTROL_AE_ANTIBANDING_MODE, 1, &aeAntibandingMode);
+
+    static const uint8_t awbMode =
+            ANDROID_CONTROL_AWB_MODE_AUTO;
+    base.addUInt8(ANDROID_CONTROL_AWB_MODE, 1, &awbMode);
+
+    base.addInt32(ANDROID_CONTROL_AWB_REGIONS, 5, controlRegions);
+
+    uint8_t afMode = 0;
+    switch (request_template) {
+      case CAMERA3_TEMPLATE_PREVIEW:
+        afMode = ANDROID_CONTROL_AF_MODE_CONTINUOUS_PICTURE;
+        break;
+      case CAMERA3_TEMPLATE_STILL_CAPTURE:
+        afMode = ANDROID_CONTROL_AF_MODE_CONTINUOUS_PICTURE;
+        break;
+      case CAMERA3_TEMPLATE_VIDEO_RECORD:
+        afMode = ANDROID_CONTROL_AF_MODE_CONTINUOUS_VIDEO;
+        break;
+      case CAMERA3_TEMPLATE_VIDEO_SNAPSHOT:
+        afMode = ANDROID_CONTROL_AF_MODE_CONTINUOUS_VIDEO;
+        break;
+      case CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG:
+        afMode = ANDROID_CONTROL_AF_MODE_CONTINUOUS_PICTURE;
+        break;
+      default:
+        afMode = ANDROID_CONTROL_AF_MODE_AUTO;
+        break;
+    }
+    base.addUInt8(ANDROID_CONTROL_AF_MODE, 1, &afMode);
+
+    base.addInt32(ANDROID_CONTROL_AF_REGIONS, 5, controlRegions);
+}
+#if 0
+int Metadata::init(const camera_metadata_t *metadata)
+{
+    mData = metadata;
+
+    return 0;
+}
+#endif
+int Metadata::addUInt8(uint32_t tag, int count, const uint8_t *data)
+{
+    return mData.update(tag, data, count);
+}
+
+int Metadata::add1UInt8(uint32_t tag, const uint8_t data)
+{
+    return addUInt8(tag, 1, &data);
+}
+
+int Metadata::addInt32(uint32_t tag, int count, const int32_t *data)
+{
+    return mData.update(tag, data, count);
+}
+
+int Metadata::addFloat(uint32_t tag, int count, const float *data)
+{
+    return mData.update(tag, data, count);
+}
+
+int Metadata::addInt64(uint32_t tag, int count, const int64_t *data)
+{
+    return mData.update(tag, data, count);
+}
+
+int Metadata::addDouble(uint32_t tag, int count, const double *data)
+{
+    return mData.update(tag, data, count);
+}
+
+int Metadata::addRational(uint32_t tag, int count,
+        const camera_metadata_rational_t *data)
+{
+    return mData.update(tag, data, count);
+}
+
+bool Metadata::isEmpty() const {
+    return mData.isEmpty();
+}
+
+camera_metadata_t* Metadata::get()
+{
+    const camera_metadata_t* data = mData.getAndLock();
+    mData.unlock(data);
+
+    return (camera_metadata_t*)data;
+}
+
diff --git a/mx6/libcamera3/Metadata.h b/mx6/libcamera3/Metadata.h
new file mode 100644
index 0000000..8e5eb01
--- /dev/null
+++ b/mx6/libcamera3/Metadata.h
@@ -0,0 +1,77 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _METADATA_H_
+#define _METADATA_H_
+
+#include <stdint.h>
+#include <hardware/camera3.h>
+#include <system/camera_metadata.h>
+#include <camera/CameraMetadata.h>
+#include "CameraUtils.h"
+
+// Metadata is a convenience class for dealing with libcamera_metadata
+class Metadata : public LightRefBase<Metadata>
+{
+public:
+    Metadata() {}
+    Metadata(const camera_metadata_t *metadata);
+    ~Metadata();
+
+    static camera_metadata_t* createStaticInfo(SensorData& sensor);
+    static void createSettingTemplate(Metadata& base, SensorData& sensor,
+                                      int request_template);
+
+    camera_metadata_entry_t find(uint32_t tag);
+    //void clear();
+    int32_t getRequestType();
+
+    int32_t getGpsCoordinates(double *pCoords, int count);
+    int32_t getGpsTimeStamp(int64_t &timeStamp);
+    int32_t getGpsProcessingMethod(uint8_t* src, int count);
+    int32_t getFocalLength(float &focalLength);
+    int32_t getJpegRotation(int32_t &jpegRotation);
+    int32_t getJpegQuality(int32_t &quality);
+    int32_t getJpegThumbQuality(int32_t &thumb);
+    int32_t getJpegThumbSize(int &width, int &height);
+
+    // Initialize with framework metadata
+    //int init(const camera_metadata_t *metadata);
+
+    // Parse and add an entry. Allocates and copies new storage for *data.
+    int addUInt8(uint32_t tag, int count, const uint8_t *data);
+    int add1UInt8(uint32_t tag, const uint8_t data);
+    int addInt32(uint32_t tag, int count, const int32_t *data);
+    int addFloat(uint32_t tag, int count, const float *data);
+    int addInt64(uint32_t tag, int count, const int64_t *data);
+    int addDouble(uint32_t tag, int count, const double *data);
+    int addRational(uint32_t tag, int count,
+            const camera_metadata_rational_t *data);
+
+    /**
+     * Is the buffer empty (no entires)
+     */
+    bool isEmpty() const;
+    // Get a handle to the current metadata
+    // This is not a durable handle, and may be destroyed by add*/init
+    camera_metadata_t* get();
+
+private:
+    // Actual internal storage
+    CameraMetadata mData;
+};
+
+#endif // METADATA_H_
diff --git a/mx6/libcamera3/NV12_resize.c b/mx6/libcamera3/NV12_resize.c
new file mode 100644
index 0000000..20b7afe
--- /dev/null
+++ b/mx6/libcamera3/NV12_resize.c
@@ -0,0 +1,303 @@
+#include "NV12_resize.h"
+
+//#define LOG_NDEBUG 0
+#define LOG_NIDEBUG 0
+#define LOG_NDDEBUG 0
+
+#define LOG_TAG "NV12_resize"
+#define STRIDE 4096
+#include <utils/Log.h>
+
+/*==========================================================================
+* Function Name  : VT_resizeFrame_Video_opt2_lp
+*
+* Description    : Resize a yuv frame.
+*
+* Input(s)       : input_img_ptr        -> Input Image Structure
+*                : output_img_ptr       -> Output Image Structure
+*                : cropout             -> crop structure
+*
+* Value Returned : mmBool               -> FALSE on error TRUE on success
+* NOTE:
+*            Not tested for crop funtionallity.
+*            faster version.
+============================================================================*/
+mmBool
+VT_resizeFrame_Video_opt2_lp
+(
+ structConvImage* i_img_ptr,        /* Points to the input image           */
+ structConvImage* o_img_ptr,        /* Points to the output image          */
+ IC_rect_type*  cropout,          /* how much to resize to in final image */
+ mmUint16 dummy __unused          /* Transparent pixel value              */
+ )
+{
+  ALOGV("VT_resizeFrame_Video_opt2_lp+");
+
+  mmUint16 row,col;
+  mmUint32 resizeFactorX;
+  mmUint32 resizeFactorY;
+
+
+  mmUint16 x, y;
+
+  mmUchar* ptr8;
+  mmUchar *ptr8Cb, *ptr8Cr;
+
+
+  mmUint16 xf, yf;
+  mmUchar* inImgPtrY;
+  mmUchar* inImgPtrU;
+  mmUchar* inImgPtrV;
+  mmUint32 cox, coy, codx, cody;
+  mmUint16 idx,idy, idxC;
+
+  if(i_img_ptr->uWidth == o_img_ptr->uWidth)
+	{
+		if(i_img_ptr->uHeight == o_img_ptr->uHeight)
+			{
+				ALOGV("************************f(i_img_ptr->uHeight == o_img_ptr->uHeight) are same *********************\n");
+				ALOGV("************************(i_img_ptr->width == %d" , i_img_ptr->uWidth );
+				ALOGV("************************(i_img_ptr->uHeight == %d" , i_img_ptr->uHeight );
+				ALOGV("************************(o_img_ptr->width == %d" ,o_img_ptr->uWidth );
+				ALOGV("************************(o_img_ptr->uHeight == %d" , o_img_ptr->uHeight );
+			}
+	}
+
+  if (!i_img_ptr || !i_img_ptr->imgPtr ||
+    !o_img_ptr || !o_img_ptr->imgPtr)
+  {
+	ALOGE("Image Point NULL");
+	ALOGV("VT_resizeFrame_Video_opt2_lp-");
+	return FALSE;
+  }
+  inImgPtrY = (mmUchar *) i_img_ptr->imgPtr + i_img_ptr->uOffset;
+  inImgPtrU = (mmUchar *) i_img_ptr->clrPtr + i_img_ptr->uOffset/2;
+  inImgPtrV = (mmUchar*)inImgPtrU + 1;
+
+  if (cropout == NULL)
+  {
+    cox = 0;
+    coy = 0;
+    codx = o_img_ptr->uWidth;
+    cody = o_img_ptr->uHeight;
+  }
+  else
+  {
+    cox = cropout->x;
+    coy = cropout->y;
+    codx = cropout->uWidth;
+    cody = cropout->uHeight;
+  }
+  idx = i_img_ptr->uWidth;
+  idy = i_img_ptr->uHeight;
+
+  /* make sure valid input size */
+  if (idx < 1 || idy < 1 || i_img_ptr->uStride < 1)
+	{
+	ALOGE("idx or idy less then 1 idx = %d idy = %d stride = %d", idx, idy, i_img_ptr->uStride);
+	ALOGV("VT_resizeFrame_Video_opt2_lp-");
+	return FALSE;
+	}
+
+  resizeFactorX = ((idx-1)<<9) / codx;
+  resizeFactorY = ((idy-1)<<9) / cody;
+
+  if(i_img_ptr->eFormat == IC_FORMAT_YCbCr420_lp &&
+    o_img_ptr->eFormat == IC_FORMAT_YCbCr420_lp)
+  {
+    ptr8 = (mmUchar*)o_img_ptr->imgPtr + cox + coy*o_img_ptr->uWidth;
+
+
+    ////////////////////////////for Y//////////////////////////
+    for (row=0; row < cody; row++)
+    {
+        mmUchar *pu8Yrow1 = NULL;
+        mmUchar *pu8Yrow2 = NULL;
+        y  = (mmUint16) ((mmUint32) (row*resizeFactorY) >> 9);
+        yf = (mmUchar)  ((mmUint32)((row*resizeFactorY) >> 6) & 0x7);
+        pu8Yrow1 = inImgPtrY + (y) * i_img_ptr->uStride;
+        pu8Yrow2 = pu8Yrow1 + i_img_ptr->uStride;
+
+        for (col=0; col < codx; col++)
+        {
+            mmUchar in11, in12, in21, in22;
+            mmUchar *pu8ptr1 = NULL;
+            mmUchar *pu8ptr2 = NULL;
+            mmUchar w;
+            mmUint16 accum_1;
+            //mmUint32 accum_W;
+
+
+
+            x  = (mmUint16) ((mmUint32)  (col*resizeFactorX) >> 9);
+            xf = (mmUchar)  ((mmUint32) ((col*resizeFactorX) >> 6) & 0x7);
+
+
+            //accum_W = 0;
+            accum_1 =  0;
+
+            pu8ptr1 = pu8Yrow1 + (x);
+            pu8ptr2 = pu8Yrow2 + (x);
+
+            /* A pixel */
+            //in = *(inImgPtrY + (y)*idx + (x));
+            in11 = *(pu8ptr1);
+
+            w = bWeights[xf][yf][0];
+            accum_1 = (w * in11);
+            //accum_W += (w);
+
+            /* B pixel */
+            //in = *(inImgPtrY + (y)*idx + (x+1));
+            in12 = *(pu8ptr1+1);
+            w = bWeights[xf][yf][1];
+            accum_1 += (w * in12);
+            //accum_W += (w);
+
+            /* C pixel */
+            //in = *(inImgPtrY + (y+1)*idx + (x));
+            in21 = *(pu8ptr2);
+            w = bWeights[xf][yf][3];
+            accum_1 += (w * in21);
+            //accum_W += (w);
+
+            /* D pixel */
+            //in = *(inImgPtrY + (y+1)*idx + (x+1));
+            in22 = *(pu8ptr2+1);
+            w = bWeights[xf][yf][2];
+            accum_1 += (w * in22);
+            //accum_W += (w);
+
+            /* divide by sum of the weights */
+            //accum_1 /= (accum_W);
+            //accum_1 = (accum_1/64);
+            accum_1 = (accum_1>>6);
+            *ptr8 = (mmUchar)accum_1 ;
+
+
+            ptr8++;
+        }
+        ptr8 = ptr8 + (o_img_ptr->uStride - codx);
+    }
+    ////////////////////////////for Y//////////////////////////
+
+    ///////////////////////////////for Cb-Cr//////////////////////
+
+    ptr8Cb = (mmUchar*)o_img_ptr->clrPtr + cox + coy*o_img_ptr->uWidth;
+
+    ptr8Cr = (mmUchar*)(ptr8Cb+1);
+
+    idxC = (idx>>1);
+    for (row=0; row < (((cody)>>1)); row++)
+    {
+        mmUchar *pu8Cbr1 = NULL;
+        mmUchar *pu8Cbr2 = NULL;
+        mmUchar *pu8Crr1 = NULL;
+        mmUchar *pu8Crr2 = NULL;
+
+        y  = (mmUint16) ((mmUint32) (row*resizeFactorY) >> 9);
+        yf = (mmUchar)  ((mmUint32)((row*resizeFactorY) >> 6) & 0x7);
+
+        pu8Cbr1 = inImgPtrU + (y) * i_img_ptr->uStride;
+        pu8Cbr2 = pu8Cbr1 + i_img_ptr->uStride;
+        pu8Crr1 = inImgPtrV + (y) * i_img_ptr->uStride;
+        pu8Crr2 = pu8Crr1 + i_img_ptr->uStride;
+
+        for (col=0; col < (((codx)>>1)); col++)
+        {
+            mmUchar in11, in12, in21, in22;
+            mmUchar *pu8Cbc1 = NULL;
+            mmUchar *pu8Cbc2 = NULL;
+            mmUchar *pu8Crc1 = NULL;
+            mmUchar *pu8Crc2 = NULL;
+
+            mmUchar w;
+            mmUint16 accum_1Cb, accum_1Cr;
+            //mmUint32 accum_WCb, accum_WCr;
+
+
+            x  = (mmUint16) ((mmUint32)  (col*resizeFactorX) >> 9);
+            xf = (mmUchar)  ((mmUint32) ((col*resizeFactorX) >> 6) & 0x7);
+
+
+            //accum_WCb = accum_WCr =  0;
+            accum_1Cb = accum_1Cr =  0;
+
+            pu8Cbc1 = pu8Cbr1 + (x*2);
+            pu8Cbc2 = pu8Cbr2 + (x*2);
+	    pu8Crc1 = pu8Crr1 + (x*2);
+            pu8Crc2 = pu8Crr2 + (x*2);
+
+            /* A pixel */
+            w = bWeights[xf][yf][0];
+
+            in11 = *(pu8Cbc1);
+            accum_1Cb = (w * in11);
+            //    accum_WCb += (w);
+
+			in11 = *(pu8Crc1);
+            accum_1Cr = (w * in11);
+            //accum_WCr += (w);
+
+            /* B pixel */
+            w = bWeights[xf][yf][1];
+
+            in12 = *(pu8Cbc1+2);
+            accum_1Cb += (w * in12);
+            //accum_WCb += (w);
+
+            in12 = *(pu8Crc1+2);
+            accum_1Cr += (w * in12);
+            //accum_WCr += (w);
+
+            /* C pixel */
+            w = bWeights[xf][yf][3];
+
+            in21 = *(pu8Cbc2);
+            accum_1Cb += (w * in21);
+            //accum_WCb += (w);
+
+			in21 = *(pu8Crc2);
+            accum_1Cr += (w * in21);
+            //accum_WCr += (w);
+
+            /* D pixel */
+            w = bWeights[xf][yf][2];
+
+            in22 = *(pu8Cbc2+2);
+            accum_1Cb += (w * in22);
+            //accum_WCb += (w);
+
+            in22 = *(pu8Crc2+2);
+            accum_1Cr += (w * in22);
+            //accum_WCr += (w);
+
+            /* divide by sum of the weights */
+            //accum_1Cb /= (accum_WCb);
+            accum_1Cb = (accum_1Cb>>6);
+            *ptr8Cb = (mmUchar)accum_1Cb ;
+
+            accum_1Cr = (accum_1Cr >> 6);
+            *ptr8Cr = (mmUchar)accum_1Cr ;
+
+            ptr8Cb++;
+            ptr8Cr++;
+
+            ptr8Cb++;
+            ptr8Cr++;
+        }
+        ptr8Cb = ptr8Cb + (o_img_ptr->uStride-codx);
+        ptr8Cr = ptr8Cr + (o_img_ptr->uStride-codx);
+    }
+    ///////////////////For Cb- Cr////////////////////////////////////////
+  }
+  else
+  {
+	ALOGE("eFormat not supported");
+	ALOGV("VT_resizeFrame_Video_opt2_lp-");
+	return FALSE;
+  }
+  ALOGV("success");
+  ALOGV("VT_resizeFrame_Video_opt2_lp-");
+  return TRUE;
+}
diff --git a/mx6/libcamera3/NV12_resize.h b/mx6/libcamera3/NV12_resize.h
new file mode 100644
index 0000000..927faf8
--- /dev/null
+++ b/mx6/libcamera3/NV12_resize.h
@@ -0,0 +1,148 @@
+#ifndef NV12_RESIZE_H_
+#define NV12_RESIZE_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+typedef unsigned char       mmBool;
+typedef unsigned char       mmUchar;
+typedef unsigned char       mmUint8;
+typedef unsigned char       mmByte;
+typedef unsigned short      mmUint16;
+typedef unsigned int        mmUint32;
+typedef unsigned long       mmUint64;
+typedef signed char         mmInt8;
+typedef char		        mmChar;
+typedef signed short        mmInt16;
+typedef signed int          mmInt32;
+typedef signed long         mmLong;
+typedef signed int          mmHandle;
+typedef float        mmFloat;
+typedef double       mmDouble;
+typedef int 		    HObj;
+typedef HObj		    HFile;
+typedef int 		    HDir;
+typedef void* mmMutexHandle;
+typedef struct _fstat
+{
+      mmInt32 fileSize;
+}VE_FileAttribute;
+
+typedef struct
+{
+	mmInt32		second;
+	mmInt32 	millisecond;
+}tsVE_Time;
+
+typedef struct
+{
+	mmInt32 	year;
+	mmInt32 	month;
+	mmInt32 	day;
+	mmInt32 	hour;
+	mmInt32 	minute;
+	mmInt32 	second;
+} TmDateTime;
+
+/*----------------------------------------------------------------------------
+    Define : TRUE/FALSE for boolean operations
+----------------------------------------------------------------------------*/
+
+#ifndef TRUE
+    #define TRUE    1
+#endif
+
+#ifndef FALSE
+    #define FALSE   0
+#endif
+
+#ifndef NULL
+   #define NULL        0
+#endif
+
+const mmUint8 bWeights[8][8][4] = {
+  {{64, 0, 0, 0}, {56, 0, 0, 8}, {48, 0, 0,16}, {40, 0, 0,24},
+   {32, 0, 0,32}, {24, 0, 0,40}, {16, 0, 0,48}, { 8, 0, 0,56}},
+
+  {{56, 8, 0, 0}, {49, 7, 1, 7}, {42, 6, 2,14}, {35, 5, 3,21},
+   {28, 4, 4,28}, {21, 3, 5,35}, {14, 2, 6,42}, { 7, 1, 7,49}},
+
+  {{48,16, 0, 0}, {42,14, 2, 6}, {36,12,4 ,12}, {30,10,6 ,18},
+   {24, 8, 8,24}, {18, 6,10,30}, {12,4 ,12,36}, { 6, 2,14,42}},
+
+  {{40,24,0 ,0 }, {35,21, 3, 5}, {30,18, 6,10}, {25,15, 9,15},
+   {20,12,12,20}, {15, 9,15,25}, {10, 6,18,30}, { 5, 3,21,35}},
+
+  {{32,32, 0,0 }, {28,28, 4, 4}, {24,24, 8, 8}, {20,20,12,12},
+   {16,16,16,16}, {12,12,20,20}, { 8, 8,24,24}, { 4, 4,28,28}},
+
+  {{24,40,0 ,0 }, {21,35, 5, 3}, {18,30,10, 6}, {15,25,15, 9},
+   {12,20,20,12}, { 9,15,25,15}, { 6,10,30,18}, { 3, 5,35,21}},
+
+  {{16,48, 0,0 }, {14,42, 6, 2}, {12,36,12, 4}, {10,30,18, 6},
+   {8 ,24,24,8 }, { 6,18,30,10}, { 4,12,36,12}, { 2, 6,42,14}},
+
+  {{ 8,56, 0,0 }, { 7,49, 7, 1}, { 6,42,14, 2}, { 5,35,21, 3},
+   { 4,28,28,4 }, { 3,21,35, 5}, { 2,14,42, 6}, { 1,7 ,49, 7}}
+};
+
+typedef enum
+{
+    IC_FORMAT_NONE,
+    IC_FORMAT_RGB565,
+    IC_FORMAT_RGB888,
+    IC_FORMAT_YCbCr420_lp,
+    IC_FORMAT_YCbCr,
+    IC_FORMAT_YCbCr420_FRAME_PK,
+    IC_FORMAT_MAX
+}enumImageFormat;
+
+/* This structure defines the format of an image */
+typedef struct
+{
+  mmInt32                       uWidth;
+  mmInt32                       uHeight;
+  mmInt32                       uStride;
+  enumImageFormat               eFormat;
+  mmByte                        *imgPtr;
+  mmByte                        *clrPtr;
+  mmInt32                       uOffset;
+} structConvImage;
+
+typedef struct IC_crop_struct
+{
+  mmUint32 x;             /* x pos of rectangle                              */
+  mmUint32 y;             /* y pos of rectangle                              */
+  mmUint32 uWidth;        /* dx of rectangle                                 */
+  mmUint32 uHeight;       /* dy of rectangle                                 */
+} IC_rect_type;
+
+/*==========================================================================
+* Function Name  : VT_resizeFrame_Video_opt2_lp
+*
+* Description    : Resize a yuv frame.
+*
+* Input(s)       : input_img_ptr        -> Input Image Structure
+*                : output_img_ptr       -> Output Image Structure
+*                : cropout             -> crop structure
+*
+* Value Returned : mmBool               -> FALSE on error TRUE on success
+* NOTE:
+*            Not tested for crop funtionallity.
+*            faster version.
+============================================================================*/
+mmBool
+VT_resizeFrame_Video_opt2_lp
+(
+ structConvImage* i_img_ptr,        /* Points to the input image           */
+ structConvImage* o_img_ptr,        /* Points to the output image          */
+ IC_rect_type*  cropout,          /* how much to resize to in final image */
+ mmUint16 dummy                         /* Transparent pixel value              */
+ );
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif //#define NV12_RESIZE_H_
diff --git a/mx6/libcamera3/Ov5640Csi.cpp b/mx6/libcamera3/Ov5640Csi.cpp
new file mode 100644
index 0000000..20ecd04
--- /dev/null
+++ b/mx6/libcamera3/Ov5640Csi.cpp
@@ -0,0 +1,177 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "Ov5640Csi.h"
+
+Ov5640Csi::Ov5640Csi(int32_t id, int32_t facing, int32_t orientation, char* path)
+    : Camera(id, facing, orientation, path)
+{
+}
+
+Ov5640Csi::~Ov5640Csi()
+{
+}
+
+status_t Ov5640Csi::initSensorStaticData()
+{
+    int32_t fd = open(mDevPath, O_RDWR);
+    if (fd < 0) {
+        ALOGE("OvDevice: initParameters sensor has not been opened");
+        return BAD_VALUE;
+    }
+
+    // first read sensor format.
+    int ret = 0, index = 0;
+    int sensorFormats[MAX_SENSOR_FORMAT];
+    int availFormats[MAX_SENSOR_FORMAT];
+    memset(sensorFormats, 0, sizeof(sensorFormats));
+    memset(availFormats, 0, sizeof(availFormats));
+#if 0
+    struct v4l2_fmtdesc vid_fmtdesc;
+    while (ret == 0) {
+        vid_fmtdesc.index = index;
+        vid_fmtdesc.type  = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        ret               = ioctl(fd, VIDIOC_ENUM_FMT, &vid_fmtdesc);
+        ALOGV("index:%d,ret:%d, format:%c%c%c%c", index, ret,
+                     vid_fmtdesc.pixelformat & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 8) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 16) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0) {
+            sensorFormats[index++] = vid_fmtdesc.pixelformat;
+        }
+    }
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+#endif
+
+    // v4l2 does not support enum format, now hard code here.
+    sensorFormats[index] = v4l2_fourcc('N', 'V', '1', '2');
+    availFormats[index++] = v4l2_fourcc('N', 'V', '1', '2');
+    sensorFormats[index] = v4l2_fourcc('Y', 'V', '1', '2');
+    availFormats[index++] = v4l2_fourcc('Y', 'V', '1', '2');
+    mSensorFormatCount = changeSensorFormats(sensorFormats, mSensorFormats, index);
+    if (mSensorFormatCount == 0) {
+        ALOGE("%s no sensor format enum", __func__);
+        return BAD_VALUE;
+    }
+
+    availFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    availFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+    //availFormats[2] = v4l2_fourcc('Y', 'U', 'Y', 'V');
+    mAvailableFormatCount = changeSensorFormats(availFormats, mAvailableFormats, index);
+
+    index = 0;
+    char TmpStr[20];
+    int  previewCnt = 0, pictureCnt = 0;
+    struct v4l2_frmsizeenum vid_frmsize;
+    struct v4l2_frmivalenum vid_frmval;
+    while (ret == 0) {
+        memset(TmpStr, 0, 20);
+        memset(&vid_frmsize, 0, sizeof(struct v4l2_frmsizeenum));
+        vid_frmsize.index        = index++;
+        vid_frmsize.pixel_format = convertPixelFormatToV4L2Format(mSensorFormats[0]);
+        ret = ioctl(fd,
+                    VIDIOC_ENUM_FRAMESIZES, &vid_frmsize);
+        if (ret == 0) {
+            ALOGV("enum frame size w:%d, h:%d",
+                         vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+            memset(&vid_frmval, 0, sizeof(struct v4l2_frmivalenum));
+            vid_frmval.index        = 0;
+            vid_frmval.pixel_format = vid_frmsize.pixel_format;
+            vid_frmval.width        = vid_frmsize.discrete.width;
+            vid_frmval.height       = vid_frmsize.discrete.height;
+
+            // ret = ioctl(fd, VIDIOC_ENUM_FRAMEINTERVALS,
+            // &vid_frmval);
+            // v4l2 does not support, now hard code here.
+            if (ret == 0) {
+                ALOGV("vid_frmval denominator:%d, numeraton:%d",
+                             vid_frmval.discrete.denominator,
+                             vid_frmval.discrete.numerator);
+                if ((vid_frmsize.discrete.width > 1280) ||
+                    (vid_frmsize.discrete.height > 800)) {
+                    vid_frmval.discrete.denominator = 15;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+                else if ((vid_frmsize.discrete.width == 1024) ||
+                    (vid_frmsize.discrete.height == 768)) {
+                    // Max fps for ov5640 csi xga cannot reach to 30fps
+                    vid_frmval.discrete.denominator = 15;
+                    vid_frmval.discrete.numerator   = 1;
+
+                }
+                else {
+                    vid_frmval.discrete.denominator = 30;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+
+                //If w/h ratio is not same with senserW/sensorH, framework assume that
+	        //first crop little width or little height, then scale.
+		//But 1920x1080, 176x144 not work in this mode.
+		if( !((vid_frmsize.discrete.width == 1920 && vid_frmsize.discrete.height == 1080) ||
+		      (vid_frmsize.discrete.width == 176 && vid_frmsize.discrete.height == 144))	){
+	                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.width;
+	                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.height;
+		}
+
+
+                if (vid_frmval.discrete.denominator /
+                    vid_frmval.discrete.numerator > 15) {
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.width;
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.height;;
+                }
+            }
+        }
+    } // end while
+
+    mPreviewResolutionCount = previewCnt;
+    mPictureResolutionCount = pictureCnt;
+
+    mMinFrameDuration = 33331760L;
+    mMaxFrameDuration = 30000000000L;
+    int i;
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<pictureCnt; i+=2) {
+        ALOGI("SupportedPictureSizes: %d x %d", mPictureResolutions[i], mPictureResolutions[i+1]);
+    }
+
+    adjustPreviewResolutions();
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<previewCnt; i+=2) {
+        ALOGI("SupportedPreviewSizes: %d x %d", mPreviewResolutions[i], mPreviewResolutions[i+1]);
+    }
+    ALOGI("FrameDuration is %lld, %lld", mMinFrameDuration, mMaxFrameDuration);
+
+    i = 0;
+    mTargetFpsRange[i++] = 10;
+    mTargetFpsRange[i++] = 15;
+    mTargetFpsRange[i++] = 23;
+    mTargetFpsRange[i++] = 30;
+
+    setMaxPictureResolutions();
+    ALOGI("mMaxWidth:%d, mMaxHeight:%d", mMaxWidth, mMaxHeight);
+
+    mFocalLength = 3.37f;
+    mPhysicalWidth = 3.6288f;	//2592 x 1.4u
+    mPhysicalHeight = 2.7216f;  //1944 x 1.4u
+
+    ALOGI("ov5640Csi, mFocalLength:%f, mPhysicalWidth:%f, mPhysicalHeight %f",
+        mFocalLength, mPhysicalWidth, mPhysicalHeight);
+
+    close(fd);
+    return NO_ERROR;
+}
+
+
diff --git a/mx6/libcamera3/Ov5640Csi.h b/mx6/libcamera3/Ov5640Csi.h
new file mode 100644
index 0000000..d8d0187
--- /dev/null
+++ b/mx6/libcamera3/Ov5640Csi.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _OV5640_CSI_H
+#define _OV5640_CSI_H
+
+#include "Camera.h"
+
+class Ov5640Csi : public Camera
+{
+public:
+    Ov5640Csi(int32_t id, int32_t facing, int32_t orientation, char* path);
+    ~Ov5640Csi();
+
+    virtual status_t initSensorStaticData();
+
+private:
+
+};
+
+#endif
diff --git a/mx6/libcamera3/Ov5640Mipi.cpp b/mx6/libcamera3/Ov5640Mipi.cpp
new file mode 100644
index 0000000..6de908f
--- /dev/null
+++ b/mx6/libcamera3/Ov5640Mipi.cpp
@@ -0,0 +1,170 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "Ov5640Mipi.h"
+
+Ov5640Mipi::Ov5640Mipi(int32_t id, int32_t facing, int32_t orientation, char* path)
+    : Camera(id, facing, orientation, path)
+{
+}
+
+Ov5640Mipi::~Ov5640Mipi()
+{
+}
+
+status_t Ov5640Mipi::initSensorStaticData()
+{
+    ALOGV("%s", __func__);
+    int32_t fd = open(mDevPath, O_RDWR);
+    if (fd < 0) {
+        ALOGE("OvDevice: initParameters sensor has not been opened");
+        return BAD_VALUE;
+    }
+
+    // first read sensor format.
+    int ret = 0, index = 0;
+    int sensorFormats[MAX_SENSOR_FORMAT];
+    int availFormats[MAX_SENSOR_FORMAT];
+    memset(sensorFormats, 0, sizeof(sensorFormats));
+    memset(availFormats, 0, sizeof(availFormats));
+#if 0
+    struct v4l2_fmtdesc vid_fmtdesc;
+    while (ret == 0) {
+        vid_fmtdesc.index = index;
+        vid_fmtdesc.type  = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        ret               = ioctl(fd, VIDIOC_ENUM_FMT, &vid_fmtdesc);
+        ALOGV("index:%d,ret:%d, format:%c%c%c%c", index, ret,
+                     vid_fmtdesc.pixelformat & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 8) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 16) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0) {
+            sensorFormats[index++] = vid_fmtdesc.pixelformat;
+        }
+    }
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+#endif
+
+    // v4l2 does not support enum format, now hard code here.
+    sensorFormats[index] = v4l2_fourcc('N', 'V', '1', '2');
+    availFormats[index++] = v4l2_fourcc('N', 'V', '1', '2');
+    sensorFormats[index] = v4l2_fourcc('Y', 'V', '1', '2');
+    availFormats[index++] = v4l2_fourcc('Y', 'V', '1', '2');
+    mSensorFormatCount = changeSensorFormats(sensorFormats, mSensorFormats, index);
+    if (mSensorFormatCount == 0) {
+        ALOGE("%s no sensor format enum", __func__);
+        return BAD_VALUE;
+    }
+
+    availFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    availFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+    //availFormats[2] = v4l2_fourcc('Y', 'U', 'Y', 'V');
+    mAvailableFormatCount = changeSensorFormats(availFormats, mAvailableFormats, index);
+
+    index = 0;
+    char TmpStr[20];
+    int  previewCnt = 0, pictureCnt = 0;
+    struct v4l2_frmsizeenum vid_frmsize;
+    struct v4l2_frmivalenum vid_frmval;
+    while (ret == 0) {
+        memset(TmpStr, 0, 20);
+        memset(&vid_frmsize, 0, sizeof(struct v4l2_frmsizeenum));
+        vid_frmsize.index        = index++;
+        vid_frmsize.pixel_format = convertPixelFormatToV4L2Format(mSensorFormats[0]);
+        ret = ioctl(fd,
+                    VIDIOC_ENUM_FRAMESIZES, &vid_frmsize);
+        if (ret == 0) {
+            ALOGV("enum frame size w:%d, h:%d",
+                         vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+            memset(&vid_frmval, 0, sizeof(struct v4l2_frmivalenum));
+            vid_frmval.index        = 0;
+            vid_frmval.pixel_format = vid_frmsize.pixel_format;
+            vid_frmval.width        = vid_frmsize.discrete.width;
+            vid_frmval.height       = vid_frmsize.discrete.height;
+
+            // ret = ioctl(fd, VIDIOC_ENUM_FRAMEINTERVALS,
+            // &vid_frmval);
+            // v4l2 does not support, now hard code here.
+            if (ret == 0) {
+                ALOGV("vid_frmval denominator:%d, numeraton:%d",
+                             vid_frmval.discrete.denominator,
+                             vid_frmval.discrete.numerator);
+                if ((vid_frmsize.discrete.width > 1920) ||
+                    (vid_frmsize.discrete.height > 1080)) {
+                    vid_frmval.discrete.denominator = 15;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+                else {
+                    vid_frmval.discrete.denominator = 30;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+
+			//If w/h ratio is not same with senserW/sensorH, framework assume that
+			//first crop little width or little height, then scale.
+			//But 1920x1080, 176x144 not work in this mode.
+			if( !((vid_frmsize.discrete.width == 1920 && vid_frmsize.discrete.height == 1080) ||
+			      (vid_frmsize.discrete.width == 176 && vid_frmsize.discrete.height == 144))	){
+	                    mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.width;
+	                    mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.height;
+			}
+
+                if (vid_frmval.discrete.denominator /
+                    vid_frmval.discrete.numerator > 15) {
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.width;
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.height;;
+                }
+            }
+        }
+    } // end while
+
+    mPreviewResolutionCount = previewCnt;
+    mPictureResolutionCount = pictureCnt;
+
+    mMinFrameDuration = 33331760L;
+    mMaxFrameDuration = 30000000000L;
+    int i;
+    for (i=0; i<MAX_RESOLUTION_SIZE  && i<pictureCnt; i+=2) {
+        ALOGI("SupportedPictureSizes: %d x %d", mPictureResolutions[i], mPictureResolutions[i+1]);
+    }
+
+    adjustPreviewResolutions();
+    for (i=0; i<MAX_RESOLUTION_SIZE  && i<previewCnt; i+=2) {
+        ALOGI("SupportedPreviewSizes: %d x %d", mPreviewResolutions[i], mPreviewResolutions[i+1]);
+    }
+    ALOGI("FrameDuration is %lld, %lld", mMinFrameDuration, mMaxFrameDuration);
+
+    i = 0;
+    mTargetFpsRange[i++] = 10;
+    mTargetFpsRange[i++] = 15;
+    mTargetFpsRange[i++] = 23;
+    mTargetFpsRange[i++] = 30;
+
+    setMaxPictureResolutions();
+    ALOGI("mMaxWidth:%d, mMaxHeight:%d", mMaxWidth, mMaxHeight);
+
+    mFocalLength = 3.37f;
+    mPhysicalWidth = 3.6288f;	//2592 x 1.4u
+    mPhysicalHeight = 2.7216f;  //1944 x 1.4u
+
+    ALOGI("ov5640Mipi, mFocalLength:%f, mPhysicalWidth:%f, mPhysicalHeight %f",
+	mFocalLength, mPhysicalWidth, mPhysicalHeight);
+
+    close(fd);
+    return NO_ERROR;
+}
+
+
diff --git a/mx6/libcamera3/Ov5640Mipi.h b/mx6/libcamera3/Ov5640Mipi.h
new file mode 100644
index 0000000..66b7610
--- /dev/null
+++ b/mx6/libcamera3/Ov5640Mipi.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _OV5640_MIPI_H_
+#define _OV5640_MIPI_H_
+
+#include "Camera.h"
+
+class Ov5640Mipi : public Camera
+{
+public:
+    Ov5640Mipi(int32_t id, int32_t facing, int32_t orientation, char* path);
+    ~Ov5640Mipi();
+
+    virtual status_t initSensorStaticData();
+
+private:
+
+};
+
+#endif
diff --git a/mx6/libcamera3/Ov5642Csi.cpp b/mx6/libcamera3/Ov5642Csi.cpp
new file mode 100644
index 0000000..0ee1e6b
--- /dev/null
+++ b/mx6/libcamera3/Ov5642Csi.cpp
@@ -0,0 +1,173 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "Ov5642Csi.h"
+
+Ov5642Csi::Ov5642Csi(int32_t id, int32_t facing, int32_t orientation, char* path)
+    : Camera(id, facing, orientation, path)
+{
+}
+
+Ov5642Csi::~Ov5642Csi()
+{
+}
+
+status_t Ov5642Csi::initSensorStaticData()
+{
+    int32_t fd = open(mDevPath, O_RDWR);
+    if (fd < 0) {
+        ALOGE("OvDevice: initParameters sensor has not been opened");
+        return BAD_VALUE;
+    }
+
+    // first read sensor format.
+    int ret = 0, index = 0;
+    int sensorFormats[MAX_SENSOR_FORMAT];
+    int availFormats[MAX_SENSOR_FORMAT];
+    memset(sensorFormats, 0, sizeof(sensorFormats));
+    memset(availFormats, 0, sizeof(availFormats));
+#if 0
+    struct v4l2_fmtdesc vid_fmtdesc;
+    while (ret == 0) {
+        vid_fmtdesc.index = index;
+        vid_fmtdesc.type  = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        ret               = ioctl(fd, VIDIOC_ENUM_FMT, &vid_fmtdesc);
+        ALOGV("index:%d,ret:%d, format:%c%c%c%c", index, ret,
+                     vid_fmtdesc.pixelformat & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 8) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 16) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0) {
+            sensorFormats[index++] = vid_fmtdesc.pixelformat;
+        }
+    }
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+#endif
+
+    // v4l2 does not support enum format, now hard code here.
+    sensorFormats[index] = v4l2_fourcc('N', 'V', '1', '2');
+    availFormats[index++] = v4l2_fourcc('N', 'V', '1', '2');
+    sensorFormats[index] = v4l2_fourcc('Y', 'V', '1', '2');
+    availFormats[index++] = v4l2_fourcc('Y', 'V', '1', '2');
+    mSensorFormatCount = changeSensorFormats(sensorFormats, mSensorFormats, index);
+    if (mSensorFormatCount == 0) {
+        ALOGE("%s no sensor format enum", __func__);
+        return BAD_VALUE;
+    }
+
+    availFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    availFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+    //availFormats[2] = v4l2_fourcc('Y', 'U', 'Y', 'V');
+    mAvailableFormatCount = changeSensorFormats(availFormats, mAvailableFormats, index);
+
+    index = 0;
+    char TmpStr[20];
+    int  previewCnt = 0, pictureCnt = 0;
+    struct v4l2_frmsizeenum vid_frmsize;
+    struct v4l2_frmivalenum vid_frmval;
+    while (ret == 0) {
+        memset(TmpStr, 0, 20);
+        memset(&vid_frmsize, 0, sizeof(struct v4l2_frmsizeenum));
+        vid_frmsize.index        = index++;
+        vid_frmsize.pixel_format = convertPixelFormatToV4L2Format(mSensorFormats[0]);
+        ret = ioctl(fd,
+                    VIDIOC_ENUM_FRAMESIZES, &vid_frmsize);
+        if (ret == 0) {
+            ALOGV("enum frame size w:%d, h:%d",
+                         vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+            memset(&vid_frmval, 0, sizeof(struct v4l2_frmivalenum));
+            vid_frmval.index        = 0;
+            vid_frmval.pixel_format = vid_frmsize.pixel_format;
+            vid_frmval.width        = vid_frmsize.discrete.width;
+            vid_frmval.height       = vid_frmsize.discrete.height;
+
+            // ret = ioctl(fd, VIDIOC_ENUM_FRAMEINTERVALS,
+            // &vid_frmval);
+            // v4l2 does not support, now hard code here.
+            if (ret == 0) {
+                ALOGV("vid_frmval denominator:%d, numeraton:%d",
+                             vid_frmval.discrete.denominator,
+                             vid_frmval.discrete.numerator);
+                if ((vid_frmsize.discrete.width > 1280) ||
+                    (vid_frmsize.discrete.height > 800)) {
+                    vid_frmval.discrete.denominator = 15;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+                else {
+                    vid_frmval.discrete.denominator = 30;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+
+                //If w/h ratio is not same with senserW/sensorH, framework assume that
+		//first crop little width or little height, then scale.
+		//But 1920x1080, 176x144 not work in this mode.
+		//For 1M pixel, 720p sometimes may take green picture(5%), so not report it,
+		//use 1024x768 for 1M pixel
+		if( !((vid_frmsize.discrete.width == 1920 && vid_frmsize.discrete.height == 1080) ||
+		      (vid_frmsize.discrete.width == 176 && vid_frmsize.discrete.height == 144) ||
+		      (vid_frmsize.discrete.width == 1280 && vid_frmsize.discrete.height == 720)) ){
+	            mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.width;
+	            mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.height;
+		}
+
+
+                if (vid_frmval.discrete.denominator /
+                    vid_frmval.discrete.numerator > 15) {
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.width;
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.height;;
+                }
+            }
+        }
+    } // end while
+
+    mPreviewResolutionCount = previewCnt;
+    mPictureResolutionCount = pictureCnt;
+
+    mMinFrameDuration = 33331760L;
+    mMaxFrameDuration = 30000000000L;
+    int i;
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<pictureCnt; i+=2) {
+        ALOGI("SupportedPictureSizes: %d x %d", mPictureResolutions[i], mPictureResolutions[i+1]);
+    }
+
+    adjustPreviewResolutions();
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<previewCnt; i+=2) {
+        ALOGI("SupportedPreviewSizes: %d x %d", mPreviewResolutions[i], mPreviewResolutions[i+1]);
+    }
+    ALOGI("FrameDuration is %lld, %lld", mMinFrameDuration, mMaxFrameDuration);
+
+    i = 0;
+    mTargetFpsRange[i++] = 10;
+    mTargetFpsRange[i++] = 15;
+    mTargetFpsRange[i++] = 23;
+    mTargetFpsRange[i++] = 30;
+
+    setMaxPictureResolutions();
+    ALOGI("mMaxWidth:%d, mMaxHeight:%d", mMaxWidth, mMaxHeight);
+
+    mFocalLength = 3.37f;
+    mPhysicalWidth = 3.6288f;	//2592 x 1.4u
+    mPhysicalHeight = 2.7216f;  //1944 x 1.4u
+
+    ALOGI("ov5642Csi, mFocalLength:%f, mPhysicalWidth:%f, mPhysicalHeight %f",
+        mFocalLength, mPhysicalWidth, mPhysicalHeight);
+
+    close(fd);
+    return NO_ERROR;
+}
+
+
diff --git a/mx6/libcamera3/Ov5642Csi.h b/mx6/libcamera3/Ov5642Csi.h
new file mode 100644
index 0000000..8c2a676
--- /dev/null
+++ b/mx6/libcamera3/Ov5642Csi.h
@@ -0,0 +1,35 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _OV5642_CSI_H
+#define _OV5642_CSI_H
+
+#include "Camera.h"
+
+class Ov5642Csi : public Camera
+{
+public:
+    Ov5642Csi(int32_t id, int32_t facing, int32_t orientation, char* path);
+    ~Ov5642Csi();
+
+    virtual status_t initSensorStaticData();
+
+private:
+
+};
+
+#endif
+
diff --git a/mx6/libcamera3/OvStream.cpp b/mx6/libcamera3/OvStream.cpp
new file mode 100644
index 0000000..d125fda
--- /dev/null
+++ b/mx6/libcamera3/OvStream.cpp
@@ -0,0 +1,362 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "OvStream.h"
+
+OvStream::OvStream(Camera* device)
+    : DeviceStream(device), mIonFd(-1)
+{
+    mIonFd = ion_open();
+}
+
+OvStream::~OvStream()
+{
+    if (mIonFd > 0) {
+        close(mIonFd);
+        mIonFd = -1;
+    }
+}
+
+// configure device.
+int32_t OvStream::onDeviceConfigureLocked()
+{
+    ALOGV("%s", __func__);
+    int32_t ret = 0;
+    if (mDev <= 0) {
+        ALOGE("%s invalid fd handle", __func__);
+        return BAD_VALUE;
+    }
+
+    int32_t input = 1;
+    ret = ioctl(mDev, VIDIOC_S_INPUT, &input);
+    if (ret < 0) {
+        ALOGE("Open: VIDIOC_S_INPUT Failed: %s", strerror(errno));
+        return ret;
+    }
+
+    int32_t fps = 30;
+    int32_t vformat;
+    vformat = convertPixelFormatToV4L2Format(mFormat);
+
+    if ((mWidth > 1920) || (mHeight > 1080)) {
+        fps = 15;
+    }
+
+    ALOGI("Width * Height %d x %d format %c%c%c%c, fps: %d",
+          mWidth, mHeight, vformat&0xFF, (vformat>>8)&0xFF,
+          (vformat>>16)&0xFF, (vformat>>24)&0xFF, fps);
+
+    struct v4l2_streamparm param;
+    memset(&param, 0, sizeof(param));
+    param.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    param.parm.capture.timeperframe.numerator   = 1;
+    param.parm.capture.timeperframe.denominator = fps;
+    param.parm.capture.capturemode = mCamera->getCaptureMode(mWidth, mHeight);
+    ret = ioctl(mDev, VIDIOC_S_PARM, &param);
+    if (ret < 0) {
+        ALOGE("%s: VIDIOC_S_PARM Failed: %s", __func__, strerror(errno));
+        return ret;
+    }
+
+    struct v4l2_format fmt;
+    memset(&fmt, 0, sizeof(fmt));
+    fmt.type                 = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    fmt.fmt.pix.width        = mWidth & 0xFFFFFFF8;
+    fmt.fmt.pix.height       = mHeight & 0xFFFFFFF8;
+    fmt.fmt.pix.pixelformat  = vformat;
+    fmt.fmt.pix.priv         = 0;
+    fmt.fmt.pix.sizeimage    = 0;
+    fmt.fmt.pix.bytesperline = 0;
+
+    // Special stride alignment for YU12
+    if (vformat == v4l2_fourcc('Y', 'U', '1', '2')){
+        // Goolge define the the stride and c_stride for YUV420 format
+        // y_size = stride * height
+        // c_stride = ALIGN(stride/2, 16)
+        // c_size = c_stride * height/2
+        // size = y_size + c_size * 2
+        // cr_offset = y_size
+        // cb_offset = y_size + c_size
+        // int stride = (width+15)/16*16;
+        // int c_stride = (stride/2+16)/16*16;
+        // y_size = stride * height
+        // c_stride = ALIGN(stride/2, 16)
+        // c_size = c_stride * height/2
+        // size = y_size + c_size * 2
+        // cr_offset = y_size
+        // cb_offset = y_size + c_size
+
+        // GPU and IPU take below stride calculation
+        // GPU has the Y stride to be 32 alignment, and UV stride to be
+        // 16 alignment.
+        // IPU have the Y stride to be 2x of the UV stride alignment
+        int32_t stride = (mWidth+31)/32*32;
+        int32_t c_stride = (stride/2+15)/16*16;
+        fmt.fmt.pix.bytesperline = stride;
+        fmt.fmt.pix.sizeimage    = stride*mHeight+c_stride * mHeight;
+        ALOGI("Special handling for YV12 on Stride %d, size %d",
+            fmt.fmt.pix.bytesperline,
+            fmt.fmt.pix.sizeimage);
+    }
+
+    ret = ioctl(mDev, VIDIOC_S_FMT, &fmt);
+    if (ret < 0) {
+        ALOGE("%s: VIDIOC_S_FMT Failed: %s", __func__, strerror(errno));
+        return ret;
+    }
+
+    return 0;
+}
+
+int32_t OvStream::onDeviceStartLocked()
+{
+    ALOGV("%s", __func__);
+    if (mDev <= 0) {
+        ALOGE("%s invalid dev node", __func__);
+        return BAD_VALUE;
+    }
+
+    //-------register buffers----------
+    struct v4l2_buffer buf;
+    struct v4l2_requestbuffers req;
+
+    memset(&req, 0, sizeof (req));
+    req.count = mNumBuffers;
+    req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    req.memory = V4L2_MEMORY_USERPTR;
+    if (ioctl(mDev, VIDIOC_REQBUFS, &req) < 0) {
+        ALOGE("%s VIDIOC_REQBUFS failed", __func__);
+        return BAD_VALUE;
+    }
+
+    for (uint32_t i = 0; i < mNumBuffers; i++) {
+        memset(&buf, 0, sizeof (buf));
+        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        buf.index = i;
+        buf.memory = V4L2_MEMORY_USERPTR;
+        buf.m.offset = mBuffers[i]->mPhyAddr;
+        buf.length   = mBuffers[i]->mSize;
+        if (ioctl(mDev, VIDIOC_QUERYBUF, &buf) < 0) {
+            ALOGE("%s VIDIOC_QUERYBUF error", __func__);
+            return BAD_VALUE;
+        }
+    }
+
+    int32_t ret = 0;
+    //----------qbuf----------
+    struct v4l2_buffer cfilledbuffer;
+    for (uint32_t i = 0; i < mNumBuffers; i++) {
+        memset(&cfilledbuffer, 0, sizeof (struct v4l2_buffer));
+        cfilledbuffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        cfilledbuffer.memory = V4L2_MEMORY_USERPTR;
+        cfilledbuffer.index    = i;
+        cfilledbuffer.m.offset = mBuffers[i]->mPhyAddr;
+        ALOGI("%s VIDIOC_QBUF phy:0x%x", __func__, mBuffers[i]->mPhyAddr);
+        ret = ioctl(mDev, VIDIOC_QBUF, &cfilledbuffer);
+        if (ret < 0) {
+            ALOGE("%s VIDIOC_QBUF Failed", __func__);
+            return BAD_VALUE;
+        }
+    }
+
+    //-------stream on-------
+    enum v4l2_buf_type bufType;
+    bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    ret = ioctl(mDev, VIDIOC_STREAMON, &bufType);
+    if (ret < 0) {
+        ALOGE("%s VIDIOC_STREAMON failed:%s", __func__, strerror(errno));
+        return ret;
+    }
+
+    return 0;
+}
+
+int32_t OvStream::onDeviceStopLocked()
+{
+    ALOGV("%s", __func__);
+    int32_t ret = 0;
+
+    if (mDev <= 0) {
+        ALOGE("%s invalid fd handle", __func__);
+        return BAD_VALUE;
+    }
+
+    enum v4l2_buf_type bufType;
+    bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    ret = ioctl(mDev, VIDIOC_STREAMOFF, &bufType);
+    if (ret < 0) {
+        ALOGE("%s VIDIOC_STREAMOFF failed: %s", __func__, strerror(errno));
+        return ret;
+    }
+
+    return 0;
+}
+
+int32_t OvStream::onFrameAcquireLocked()
+{
+    ALOGV("%s", __func__);
+    int32_t ret = 0;
+    struct v4l2_buffer cfilledbuffer;
+    memset(&cfilledbuffer, 0, sizeof (cfilledbuffer));
+    cfilledbuffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    cfilledbuffer.memory = V4L2_MEMORY_USERPTR;
+
+    ret = ioctl(mDev, VIDIOC_DQBUF, &cfilledbuffer);
+    if (ret < 0) {
+        ALOGE("%s: VIDIOC_DQBUF Failed", __func__);
+        return -1;
+    }
+
+    return cfilledbuffer.index;
+}
+
+int32_t OvStream::onFrameReturnLocked(int32_t index, StreamBuffer& buf)
+{
+    ALOGV("%s", __func__);
+    int32_t ret = 0;
+    struct v4l2_buffer cfilledbuffer;
+    memset(&cfilledbuffer, 0, sizeof (struct v4l2_buffer));
+    cfilledbuffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    cfilledbuffer.memory = V4L2_MEMORY_USERPTR;
+    cfilledbuffer.index    = index;
+    cfilledbuffer.m.offset = buf.mPhyAddr;
+
+    ret = ioctl(mDev, VIDIOC_QBUF, &cfilledbuffer);
+    if (ret < 0) {
+        ALOGE("%s VIDIOC_QBUF Failed", __func__);
+        return BAD_VALUE;
+    }
+
+    return ret;
+}
+
+int32_t OvStream::allocateBuffersLocked()
+{
+    ALOGV("%s", __func__);
+    if (mIonFd <= 0) {
+        ALOGE("%s ion invalid", __func__);
+        return BAD_VALUE;
+    }
+
+    if (mRegistered) {
+        ALOGI("%s but buffer is already registered", __func__);
+        return 0;
+    }
+
+    int32_t size = 0;
+    if ((mWidth == 0) || (mHeight == 0)) {
+        ALOGE("%s: width or height = 0", __func__);
+        return BAD_VALUE;
+    }
+
+    switch (mFormat) {
+        case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+            size = ((mWidth + 16) & (~15)) * mHeight * 3 / 2;
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_420_P: {
+            int32_t stride = (mWidth+31)/32*32;
+            int32_t c_stride = (stride/2+15)/16*16;
+            size = (stride + c_stride) * mHeight;
+            break;
+        }
+        case HAL_PIXEL_FORMAT_YCbCr_422_I:
+            size = mWidth * mHeight * 2;
+            break;
+
+        default:
+            ALOGE("Error: format not supported int ion alloc");
+            return BAD_VALUE;
+    }
+
+    unsigned char *ptr = NULL;
+    int32_t sharedFd;
+    int32_t phyAddr;
+    ion_user_handle_t ionHandle;
+    size = (size + PAGE_SIZE) & (~(PAGE_SIZE - 1));
+
+    ALOGI("allocateBufferFromIon buffer num:%d", mNumBuffers);
+    for (uint32_t i = 0; i < mNumBuffers; i++) {
+        ionHandle = -1;
+        int32_t err = ion_alloc(mIonFd, size, 8, 1, 0, &ionHandle);
+        if (err) {
+            ALOGE("ion_alloc failed.");
+            return BAD_VALUE;
+        }
+
+        err = ion_map(mIonFd,
+                      ionHandle,
+                      size,
+                      PROT_READ | PROT_WRITE,
+                      MAP_SHARED,
+                      0,
+                      &ptr,
+                      &sharedFd);
+
+        if (err) {
+            ALOGE("ion_map failed.");
+            return BAD_VALUE;
+        }
+        phyAddr = ion_phys(mIonFd, ionHandle);
+        if (phyAddr == 0) {
+            ALOGE("ion_phys failed.");
+            return BAD_VALUE;
+        }
+        ALOGI("phyalloc ptr:0x%x, phy:0x%x, size:%d", (int32_t)ptr, phyAddr, size);
+        mBuffers[i] = new StreamBuffer();
+        mBuffers[i]->mVirtAddr  = ptr;
+        mBuffers[i]->mPhyAddr   = phyAddr;
+        mBuffers[i]->mSize      =  size;
+        mBuffers[i]->mBufHandle = (buffer_handle_t*)ionHandle;
+        mBuffers[i]->mStream = this;
+        close(sharedFd);
+    }
+
+    mRegistered = true;
+    mAllocatedBuffers = mNumBuffers;
+
+    return 0;
+}
+
+int32_t OvStream::freeBuffersLocked()
+{
+    ALOGV("%s", __func__);
+    if (mIonFd <= 0) {
+        ALOGE("%s ion invalid", __func__);
+        return BAD_VALUE;
+    }
+
+    if (!mRegistered) {
+        ALOGI("%s but buffer is not registered", __func__);
+        return 0;
+    }
+
+    ALOGI("freeBufferToIon buffer num:%d", mAllocatedBuffers);
+    for (uint32_t i = 0; i < mAllocatedBuffers; i++) {
+        ion_user_handle_t ionHandle =
+            (ion_user_handle_t)mBuffers[i]->mBufHandle;
+        ion_free(mIonFd, ionHandle);
+        munmap(mBuffers[i]->mVirtAddr, mBuffers[i]->mSize);
+        delete mBuffers[i];
+        mBuffers[i] = NULL;
+    }
+
+    mRegistered = false;
+    mAllocatedBuffers = 0;
+
+    return 0;
+}
+
diff --git a/mx6/libcamera3/OvStream.h b/mx6/libcamera3/OvStream.h
new file mode 100644
index 0000000..ca24d99
--- /dev/null
+++ b/mx6/libcamera3/OvStream.h
@@ -0,0 +1,49 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _OV_STREAM_H
+#define _OV_STREAM_H
+
+#include "DeviceStream.h"
+
+class OvStream : public DeviceStream
+{
+public:
+    OvStream(Camera* device);
+    virtual ~OvStream();
+
+    // configure device.
+    virtual int32_t onDeviceConfigureLocked();
+    // start device.
+    virtual int32_t onDeviceStartLocked();
+    // stop device.
+    virtual int32_t onDeviceStopLocked();
+
+    // get buffer from V4L2.
+    virtual int32_t onFrameAcquireLocked();
+    // put buffer back to V4L2.
+    virtual int32_t onFrameReturnLocked(int32_t index, StreamBuffer& buf);
+
+    // allocate buffers.
+    virtual int32_t allocateBuffersLocked();
+    // free buffers.
+    virtual int32_t freeBuffersLocked();
+
+private:
+    int32_t mIonFd;
+};
+
+#endif
diff --git a/mx6/libcamera3/Stream.cpp b/mx6/libcamera3/Stream.cpp
new file mode 100644
index 0000000..ffdbfa1
--- /dev/null
+++ b/mx6/libcamera3/Stream.cpp
@@ -0,0 +1,515 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <stdio.h>
+#include <hardware/camera3.h>
+#include <hardware/gralloc.h>
+#include <system/graphics.h>
+#include <utils/Mutex.h>
+#include <utils/StrongPointer.h>
+#include <binder/MemoryBase.h>
+#include <binder/MemoryHeapBase.h>
+#include <sync/sync.h>
+
+//#define LOG_NDEBUG 0
+#include <cutils/log.h>
+#include "Camera.h"
+#include "Stream.h"
+#include "CameraUtils.h"
+
+Stream::Stream(int id, camera3_stream_t *s, Camera* camera)
+  : mReuse(false),
+    mPreview(false),
+    mJpeg(false),
+    mCallback(false),
+    mId(id),
+    mStream(s),
+    mType(s->stream_type),
+    mWidth(s->width),
+    mHeight(s->height),
+    mFormat(s->format),
+    mUsage(0),
+    mNumBuffers(0),
+    mRegistered(false),
+    mCamera(camera)
+{
+    if (s->format == HAL_PIXEL_FORMAT_BLOB) {
+        ALOGI("%s create capture stream", __func__);
+        mJpeg = true;
+        mFormat = mCamera->getPicturePixelFormat();
+        s->format = mFormat;
+
+        mUsage = CAMERA_GRALLOC_USAGE_JPEG;
+        mNumBuffers = NUM_CAPTURE_BUFFER;
+    }
+    else if (s->format == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
+        ALOGI("%s create preview stream", __func__);
+        mFormat = mCamera->getPreviewPixelFormat();
+        s->format = mFormat;
+        mUsage = CAMERA_GRALLOC_USAGE;
+        mNumBuffers = NUM_PREVIEW_BUFFER;
+        mPreview = true;
+        if (s->usage & GRALLOC_USAGE_HW_VIDEO_ENCODER) {
+            ALOGI("%s create video recording stream", __func__);
+            mPreview = false;
+        }
+    }
+    else {
+        ALOGI("create callback stream", __func__);
+        mCallback = true;
+        mUsage = CAMERA_GRALLOC_USAGE;
+        mNumBuffers = NUM_PREVIEW_BUFFER;
+    }
+
+    s->usage |= mUsage;
+    s->max_buffers = mNumBuffers;
+    mNumBuffers += 1;
+
+    ALOGI("stream: w:%d, h:%d, format:0x%x, usage:0x%x, buffers:%d",
+          s->width, s->height, s->format, s->usage, mNumBuffers);
+    mIpuFd = open("/dev/mxc_ipu", O_RDWR, 0);
+
+    for (uint32_t i=0; i<MAX_STREAM_BUFFERS; i++) {
+        mBuffers[i] = NULL;
+    }
+
+    mJpegBuilder = new JpegBuilder();
+}
+
+Stream::Stream(Camera* camera)
+  : mReuse(false),
+    mPreview(false),
+    mJpeg(false),
+    mId(-1),
+    mStream(NULL),
+    mType(-1),
+    mWidth(0),
+    mHeight(0),
+    mFormat(0),
+    mUsage(0),
+    mNumBuffers(0),
+    mRegistered(false),
+    mCamera(camera)
+{
+    mIpuFd = open("/dev/mxc_ipu", O_RDWR, 0);
+    for (uint32_t i=0; i<MAX_STREAM_BUFFERS; i++) {
+        mBuffers[i] = NULL;
+    }
+}
+
+Stream::~Stream()
+{
+    android::Mutex::Autolock al(mLock);
+    if (mIpuFd > 0) {
+        close(mIpuFd);
+        mIpuFd = -1;
+    }
+}
+
+int32_t Stream::processJpegBuffer(StreamBuffer& src,
+                                  sp<Metadata> meta)
+{
+    int32_t ret = 0;
+    int32_t encodeQuality = 100, thumbQuality = 100;
+    int32_t thumbWidth, thumbHeight;
+    JpegParams *mainJpeg = NULL, *thumbJpeg = NULL;
+    void *rawBuf = NULL, *thumbBuf = NULL;
+    size_t imageSize = 0;
+
+    StreamBuffer* dstBuf = mCurrent;
+    sp<Stream>& srcStream = src.mStream;
+    if (dstBuf == NULL || srcStream == NULL) {
+        ALOGE("%s invalid param", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    sp<MemoryHeapBase> rawFrame(
+                    new MemoryHeapBase(src.mSize, 0, "rawFrame"));
+    rawBuf = rawFrame->getBase();
+    if (rawBuf == MAP_FAILED) {
+        ALOGE("%s new MemoryHeapBase failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    sp<MemoryHeapBase> thumbFrame(
+                new MemoryHeapBase(src.mSize, 0, "thumbFrame"));
+    thumbBuf = thumbFrame->getBase();
+    if (thumbBuf == MAP_FAILED) {
+        ALOGE("%s new MemoryHeapBase failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    ret = meta->getJpegQuality(encodeQuality);
+    if (ret != NO_ERROR) {
+        ALOGE("%s getJpegQuality failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    if ((encodeQuality < 0) || (encodeQuality > 100)) {
+        encodeQuality = 100;
+    }
+
+    ret = meta->getJpegThumbQuality(thumbQuality);
+    if (ret != NO_ERROR) {
+        ALOGE("%s getJpegThumbQuality failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    if ((thumbQuality < 0) || (thumbQuality > 100)) {
+        thumbQuality = 100;
+    }
+
+    mainJpeg = new JpegParams((uint8_t *)src.mVirtAddr,
+                       (uint8_t *)src.mPhyAddr,
+                       src.mSize, (uint8_t *)rawBuf,
+                       src.mSize, encodeQuality,
+                       srcStream->mWidth, srcStream->mHeight,
+                       srcStream->mWidth, srcStream->mHeight,
+                       srcStream->format());
+
+    ret = meta->getJpegThumbSize(thumbWidth, thumbHeight);
+    if (ret != NO_ERROR) {
+        ALOGE("%s getJpegThumbSize failed", __FUNCTION__);
+        goto err_out;
+    }
+
+    if ((thumbWidth > 0) && (thumbHeight > 0)) {
+        int thumbSize   = 0;
+        int thumbFormat = convertPixelFormatToV4L2Format(srcStream->format());
+        switch (thumbFormat) {
+            case v4l2_fourcc('N', 'V', '1', '2'):
+                thumbSize = thumbWidth * thumbHeight * 3 / 2;
+                break;
+
+            case v4l2_fourcc('Y', 'U', '1', '2'):
+                thumbSize = thumbWidth * thumbHeight * 3 / 2;
+                break;
+
+            case v4l2_fourcc('Y', 'U', 'Y', 'V'):
+                thumbSize = thumbWidth * thumbHeight * 2;
+                break;
+
+            default:
+                ALOGE("Error: %s format not supported", __FUNCTION__);
+                goto err_out;
+        }
+        thumbSize = src.mSize;
+        thumbJpeg = new JpegParams((uint8_t *)src.mVirtAddr,
+                           (uint8_t *)src.mPhyAddr,
+                           src.mSize,
+                           (uint8_t *)thumbBuf,
+                           thumbSize,
+                           thumbQuality,
+                           srcStream->mWidth,
+                           srcStream->mHeight,
+                           thumbWidth,
+                           thumbHeight,
+                           srcStream->format());
+    }
+
+    mJpegBuilder->prepareImage(&src);
+    ret = mJpegBuilder->encodeImage(mainJpeg, thumbJpeg);
+    if (ret != NO_ERROR) {
+        ALOGE("%s encodeImage failed", __FUNCTION__);
+        goto err_out;
+    }
+
+    imageSize = mJpegBuilder->getImageSize();
+    ret = mJpegBuilder->buildImage(dstBuf);
+    if (ret != NO_ERROR) {
+        ALOGE("%s buildImage failed", __FUNCTION__);
+        goto err_out;
+    }
+
+err_out:
+    if (mainJpeg) {
+        delete mainJpeg;
+    }
+
+    if (thumbJpeg) {
+        delete thumbJpeg;
+    }
+
+    return ret;
+}
+
+int32_t Stream::processBufferWithIPU(StreamBuffer& src)
+{
+    ALOGV("%s", __func__);
+    sp<Stream>& device = src.mStream;
+    if (device == NULL) {
+        ALOGE("%s invalid device stream", __func__);
+        return 0;
+    }
+
+    StreamBuffer* out = mCurrent;
+    if (out == NULL || out->mBufHandle == NULL) {
+        ALOGE("%s invalid buffer handle", __func__);
+        return 0;
+    }
+
+    struct ipu_task mTask;
+    memset(&mTask, 0, sizeof(mTask));
+
+    mTask.input.width = device->mWidth;
+    mTask.input.height = device->mHeight;
+    mTask.input.crop.pos.x = 0;
+    mTask.input.crop.pos.y = 0;
+    mTask.input.crop.w = device->mWidth;
+    mTask.input.crop.h = device->mHeight;
+    mTask.input.format = convertPixelFormatToV4L2Format(device->mFormat);
+    mTask.input.paddr = src.mPhyAddr;
+
+    if (!mCallback) {
+        mTask.output.format = convertPixelFormatToV4L2Format(mFormat);
+    }
+    else {
+        mTask.output.format = convertPixelFormatToV4L2Format(mFormat, true);
+    }
+    mTask.output.width = mWidth;
+    mTask.output.height = mHeight;
+    mTask.output.crop.pos.x = 0;
+    mTask.output.crop.pos.y = 0;
+    mTask.output.crop.w = mWidth;
+    mTask.output.crop.h = mHeight;
+    mTask.output.rotate = 0;
+    mTask.output.paddr = out->mPhyAddr;
+
+    int32_t ret = IPU_CHECK_ERR_INPUT_CROP;
+    while(ret != IPU_CHECK_OK && ret > IPU_CHECK_ERR_MIN) {
+        ret = ioctl(mIpuFd, IPU_CHECK_TASK, &mTask);
+        ALOGV("%s:%d, IPU_CHECK_TASK ret=%d", __FUNCTION__, __LINE__, ret);
+        switch(ret) {
+            case IPU_CHECK_OK:
+                break;
+            case IPU_CHECK_ERR_SPLIT_INPUTW_OVER:
+                mTask.input.crop.w -= 8;
+                break;
+            case IPU_CHECK_ERR_SPLIT_INPUTH_OVER:
+                mTask.input.crop.h -= 8;
+                break;
+            case IPU_CHECK_ERR_SPLIT_OUTPUTW_OVER:
+                mTask.output.crop.w -= 8;
+                break;
+            case IPU_CHECK_ERR_SPLIT_OUTPUTH_OVER:
+                mTask.output.crop.h -= 8;;
+                break;
+            default:
+                ALOGE("%s:%d, IPU_CHECK_TASK ret=%d", __FUNCTION__, __LINE__, ret);
+                return ret;
+        }
+    }
+
+    ret = ioctl(mIpuFd, IPU_QUEUE_TASK, &mTask);
+    if(ret < 0) {
+        ALOGE("%s:%d, IPU_QUEUE_TASK failed %d", __FUNCTION__, __LINE__ ,ret);
+        return ret;
+    }
+
+    return ret;
+}
+
+static void bufferDump(StreamBuffer *frame, bool in)
+{
+    // for test code
+    char value[100];
+    char name[100];
+    memset(value, 0, sizeof(value));
+    bool vflg = false;
+    static int dump_num = 1;
+    property_get("rw.camera.test", value, "");
+    if (strcmp(value, "true") == 0)
+        vflg = true;
+
+    if (vflg) {
+        FILE *pf = NULL;
+        memset(name, 0, sizeof(name));
+        snprintf(name, 100, "/data/dump/camera_dump_%s_%d.data",
+                   in ? "in" : "out", dump_num++);
+        pf = fopen(name, "wb");
+        if (pf == NULL) {
+            ALOGI("open %s failed", name);
+        }
+        else {
+            ALOGV("write yuv data");
+            fwrite(frame->mVirtAddr, frame->mSize, 1, pf);
+            fclose(pf);
+        }
+    }
+}
+
+int32_t Stream::processBufferWithGPU(StreamBuffer& src)
+{
+    sp<Stream>& device = src.mStream;
+    if (device == NULL) {
+        ALOGE("%s invalid device stream", __func__);
+        return 0;
+    }
+
+    StreamBuffer* out = mCurrent;
+    if (out == NULL || out->mBufHandle == NULL) {
+        ALOGE("%s invalid buffer handle", __func__);
+        return 0;
+    }
+
+    void* g2dHandle = device->getG2dHandle();
+    if (g2dHandle == NULL) {
+        ALOGE("%s invalid g2d handle", __func__);
+        return 0;
+    }
+    struct g2d_buf s_buf, d_buf;
+    s_buf.buf_paddr = src.mPhyAddr;
+    s_buf.buf_vaddr = src.mVirtAddr;
+    d_buf.buf_paddr = out->mPhyAddr;
+    d_buf.buf_vaddr = out->mVirtAddr;
+    g2d_copy(g2dHandle, &d_buf, &s_buf, out->mSize);
+    g2d_finish(g2dHandle);
+
+    bufferDump(&src, true);
+    bufferDump(out, false);
+
+    return 0;
+}
+
+int32_t Stream::processFrameBuffer(StreamBuffer& src,
+                                   sp<Metadata> meta)
+{
+    ALOGV("%s", __func__);
+    sp<Stream>& device = src.mStream;
+    if (device == NULL) {
+        ALOGE("%s invalid device stream", __func__);
+        return 0;
+    }
+
+    int32_t ret = 0;
+    // IPU can't support NV12->NV21 conversion.
+    if ((mWidth != device->mWidth) || (mHeight != device->mHeight) ||
+         (mFormat != device->mFormat) || ((mFormat == device->mFormat) &&
+         (mCallback && (mFormat != HAL_PIXEL_FORMAT_YCbCr_420_SP)))) {
+        ret = processBufferWithIPU(src);
+    }
+    else {
+        ret = processBufferWithGPU(src);
+    }
+
+    return ret;
+}
+
+int32_t Stream::processCaptureBuffer(StreamBuffer& src,
+                                     sp<Metadata> meta)
+{
+    int32_t res = 0;
+
+    ALOGV("%s", __func__);
+    StreamBuffer* out = mCurrent;
+    if (out == NULL || out->mBufHandle == NULL) {
+        ALOGE("%s invalid buffer handle", __func__);
+        return 0;
+    }
+
+    if (out->mAcquireFence != -1) {
+        res = sync_wait(out->mAcquireFence, CAMERA_SYNC_TIMEOUT);
+        if (res == -ETIME) {
+            ALOGE("%s: Timeout waiting on buffer acquire fence",
+                    __func__);
+            return res;
+        } else if (res) {
+            ALOGE("%s: Error waiting on buffer acquire fence: %s(%d)",
+                    __func__, strerror(-res), res);
+            ALOGV("fence id:%d", out->mAcquireFence);
+        }
+        close(out->mAcquireFence);
+    }
+
+    if (mJpeg) {
+        mJpegBuilder->reset();
+        mJpegBuilder->setMetadata(meta);
+
+        res = processJpegBuffer(src, meta);
+        mJpegBuilder->setMetadata(NULL);
+    }
+    else {
+        res = processFrameBuffer(src, meta);
+    }
+
+    return res;
+}
+
+int Stream::getType()
+{
+    return mType;
+}
+
+bool Stream::isInputType()
+{
+    return mType == CAMERA3_STREAM_INPUT ||
+        mType == CAMERA3_STREAM_BIDIRECTIONAL;
+}
+
+bool Stream::isOutputType()
+{
+    return mType == CAMERA3_STREAM_OUTPUT ||
+        mType == CAMERA3_STREAM_BIDIRECTIONAL;
+}
+
+bool Stream::isRegistered()
+{
+    return mRegistered;
+}
+
+bool Stream::isValidReuseStream(int id, camera3_stream_t *s)
+{
+    if (id != mId) {
+        ALOGE("%s:%d: Invalid camera id for reuse. Got %d expect %d",
+                __func__, mId, id, mId);
+        return false;
+    }
+
+    if (s != mStream || s->stream_type != mType) {
+        ALOGE("%s:%d: Invalid stream handle for reuse. Got %p expect %p",
+                __func__, mId, s, mStream);
+        return false;
+    }
+
+    if (s->width != mWidth || s->height != mHeight || s->format != mFormat) {
+        ALOGE("%s:%d: Mismatched reused stream."
+              "Got w:%d, h:%d, f:%d expect w:%d, h:%d, f:%d",
+                __func__, mId, s->width, s->height, s->format,
+                mWidth, mHeight, mFormat);
+        return false;
+    }
+
+    return true;
+}
+
+void Stream::dump(int fd)
+{
+    android::Mutex::Autolock al(mLock);
+
+    dprintf(fd, "Stream ID: %d (%p)\n", mId, mStream);
+    dprintf(fd, "Stream Type: (%d)\n", mType);
+    dprintf(fd, "Width: %d Height: %d\n", mWidth, mHeight);
+    dprintf(fd, "Stream Format: (%d)", mFormat);
+    // ToDo: prettyprint usage mask flags
+    dprintf(fd, "Gralloc Usage Mask: %d\n", mUsage);
+    dprintf(fd, "Buffers Registered: %s\n", mRegistered ? "true" : "false");
+    dprintf(fd, "Number of Buffers: %d\n", mNumBuffers);
+    for (uint32_t i = 0; i < mNumBuffers; i++) {
+        dprintf(fd, "Buffer %d %d : %p\n", i, mNumBuffers,
+                mBuffers[i]->mBufHandle);
+    }
+}
+
diff --git a/mx6/libcamera3/Stream.h b/mx6/libcamera3/Stream.h
new file mode 100644
index 0000000..eecfaf1
--- /dev/null
+++ b/mx6/libcamera3/Stream.h
@@ -0,0 +1,107 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _STREAM_H_
+#define _STREAM_H_
+
+#include <hardware/camera3.h>
+#include <hardware/gralloc.h>
+#include <system/graphics.h>
+#include <utils/Mutex.h>
+#include <utils/RefBase.h>
+#include <linux/ipu.h>
+#include <ion/ion.h>
+#include "JpegBuilder.h"
+#include "g2d.h"
+
+using namespace android;
+
+class Camera;
+// Stream represents a single input or output stream for a camera device.
+class Stream : public LightRefBase<Stream>
+{
+public:
+    Stream(Camera* camera);
+    Stream(int id, camera3_stream_t *s, Camera* camera);
+    virtual ~Stream();
+
+    // validate that astream's parameters match this stream's parameters
+    bool isValidReuseStream(int id, camera3_stream_t *s);
+
+    int32_t processCaptureBuffer(StreamBuffer& buf,
+                                 sp<Metadata> meta);
+
+    void setCurrentBuffer(StreamBuffer* out) {mCurrent = out;}
+    virtual void* getG2dHandle() {return NULL;}
+    bool isPreview() {return mPreview;}
+    bool isJpeg() {return mJpeg;}
+    uint32_t width() {return mWidth;}
+    uint32_t height() {return mHeight;}
+    int32_t format() {return mFormat;}
+    uint32_t bufferNum() {return mNumBuffers;}
+    camera3_stream_t* stream() {return mStream;}
+    void setReuse(bool reuse) {mReuse = mReuse;}
+
+    int getType();
+    bool isInputType();
+    bool isOutputType();
+    bool isRegistered();
+    void dump(int fd);
+
+protected:
+    int32_t processJpegBuffer(StreamBuffer& src,
+                              sp<Metadata> meta);
+    int32_t processFrameBuffer(StreamBuffer& src,
+                               sp<Metadata> meta);
+    int32_t processBufferWithIPU(StreamBuffer& src);
+    int32_t processBufferWithGPU(StreamBuffer& src);
+
+protected:
+    // This stream is being reused. Used in stream configuration passes
+    bool mReuse;
+    bool mPreview;
+    bool mJpeg;
+    bool mCallback;
+    // The camera device id this stream belongs to
+    const int mId;
+    // Handle to framework's stream, used as a cookie for buffers
+    camera3_stream_t *mStream;
+    // Stream type: CAMERA3_STREAM_* (see <hardware/camera3.h>)
+    const int mType;
+    // Width in pixels of the buffers in this stream
+    uint32_t mWidth;
+    // Height in pixels of the buffers in this stream
+    uint32_t mHeight;
+    // Gralloc format: HAL_PIXEL_FORMAT_* (see <system/graphics.h>)
+    int32_t mFormat;
+    // Gralloc usage mask : GRALLOC_USAGE_* (see <hardware/gralloc.h>)
+    uint32_t mUsage;
+    // Max simultaneous in-flight buffers for this stream
+    uint32_t mNumBuffers;
+    // Buffers have been registered for this stream and are ready
+    bool mRegistered;
+    // Array of handles to buffers currently in use by the stream
+    StreamBuffer* mBuffers[MAX_STREAM_BUFFERS];
+    // Lock protecting the Stream object for modifications
+    android::Mutex mLock;
+
+    int32_t mIpuFd;
+    StreamBuffer* mCurrent;
+    Camera* mCamera;
+    sp<JpegBuilder> mJpegBuilder;
+};
+
+#endif // STREAM_H_
diff --git a/mx6/libcamera3/UvcDevice.cpp b/mx6/libcamera3/UvcDevice.cpp
new file mode 100644
index 0000000..8c3e451
--- /dev/null
+++ b/mx6/libcamera3/UvcDevice.cpp
@@ -0,0 +1,153 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "UvcDevice.h"
+
+#define LOGI_C920 "HD Pro Webcam C920"
+
+UvcDevice::UvcDevice(int32_t id, int32_t facing, int32_t orientation, char* path)
+    : Camera(id, facing, orientation, path)
+{
+}
+
+UvcDevice::~UvcDevice()
+{
+}
+
+status_t UvcDevice::initSensorStaticData()
+{
+    int32_t fd = open(mDevPath, O_RDWR);
+    if (fd < 0) {
+        ALOGE("OvDevice: initParameters sensor has not been opened");
+        return BAD_VALUE;
+    }
+
+    // first read sensor format.
+    int ret = 0, index = 0;
+    int sensorFormats[MAX_SENSOR_FORMAT];
+    int availFormats[MAX_SENSOR_FORMAT];
+    memset(sensorFormats, 0, sizeof(sensorFormats));
+    memset(availFormats, 0, sizeof(availFormats));
+
+    struct v4l2_fmtdesc vid_fmtdesc;
+    while (ret == 0) {
+        vid_fmtdesc.index = index;
+        vid_fmtdesc.type  = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        ret = ioctl(fd, VIDIOC_ENUM_FMT, &vid_fmtdesc);
+        ALOGV("index:%d,ret:%d, format:%c%c%c%c", index, ret,
+                     vid_fmtdesc.pixelformat & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 8) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 16) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0) {
+            sensorFormats[index] = vid_fmtdesc.pixelformat;
+            availFormats[index++] = vid_fmtdesc.pixelformat;
+        }
+    }
+
+    mSensorFormatCount = changeSensorFormats(sensorFormats, mSensorFormats, index);
+    if (mSensorFormatCount == 0) {
+        ALOGE("%s no sensor format enum", __func__);
+        return BAD_VALUE;
+    }
+
+    availFormats[index++] = v4l2_fourcc('N', 'V', '1', '2');
+    availFormats[index++] = v4l2_fourcc('Y', 'V', '1', '2');
+    availFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    availFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+    mAvailableFormatCount = changeSensorFormats(availFormats, mAvailableFormats, index);
+
+    ret = 0;
+    index = 0;
+    char TmpStr[20];
+    int  previewCnt = 0, pictureCnt = 0;
+    struct v4l2_frmsizeenum vid_frmsize;
+    struct v4l2_frmivalenum vid_frmval;
+    while (ret == 0) {
+        memset(TmpStr, 0, 20);
+        memset(&vid_frmsize, 0, sizeof(struct v4l2_frmsizeenum));
+        vid_frmsize.index        = index++;
+        vid_frmsize.pixel_format = convertPixelFormatToV4L2Format(mSensorFormats[0]);
+        ret = ioctl(fd,
+                    VIDIOC_ENUM_FRAMESIZES, &vid_frmsize);
+
+        if (ret == 0) {
+            //uvc need do csc, so omit large resolution.
+            if (vid_frmsize.discrete.width > 1920 ||
+                     vid_frmsize.discrete.height > 1080) {
+                continue;
+            }
+
+            ALOGI("enum frame size w:%d, h:%d",
+                       vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+            memset(&vid_frmval, 0, sizeof(struct v4l2_frmivalenum));
+            vid_frmval.index        = 0;
+            vid_frmval.pixel_format = vid_frmsize.pixel_format;
+            vid_frmval.width        = vid_frmsize.discrete.width;
+            vid_frmval.height       = vid_frmsize.discrete.height;
+
+            ret = ioctl(fd, VIDIOC_ENUM_FRAMEINTERVALS, &vid_frmval);
+            if (ret == 0) {
+                ALOGI("vid_frmval denominator:%d, numeraton:%d",
+                             vid_frmval.discrete.denominator,
+                             vid_frmval.discrete.numerator);
+                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.width;
+                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.height;
+
+                if (vid_frmval.discrete.denominator /
+                    vid_frmval.discrete.numerator > 15) {
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.width;
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.height;;
+                }
+            }
+        }
+    } // end while
+
+    mPreviewResolutionCount = previewCnt;
+    mPictureResolutionCount = pictureCnt;
+
+    mMinFrameDuration = 33331760L;
+    mMaxFrameDuration = 30000000000L;
+    int i;
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<pictureCnt; i+=2) {
+        ALOGI("SupportedPictureSizes: %d x %d", mPictureResolutions[i], mPictureResolutions[i+1]);
+    }
+
+    adjustPreviewResolutions();
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<previewCnt; i+=2) {
+        ALOGI("SupportedPreviewSizes: %d x %d", mPreviewResolutions[i], mPreviewResolutions[i+1]);
+    }
+    ALOGI("FrameDuration is %lld, %lld", mMinFrameDuration, mMaxFrameDuration);
+
+    i = 0;
+    mTargetFpsRange[i++] = 10;
+    mTargetFpsRange[i++] = 15;
+    mTargetFpsRange[i++] = 25;
+    mTargetFpsRange[i++] = 30;
+
+    setMaxPictureResolutions();
+    ALOGI("mMaxWidth:%d, mMaxHeight:%d", mMaxWidth, mMaxHeight);
+    mFocalLength = 3.42f;
+    mPhysicalWidth = 3.673f;
+    mPhysicalHeight = 2.738f;
+
+    ALOGI("UvcDevice, mFocalLength:%f, mPhysicalWidth:%f, mPhysicalHeight %f",
+        mFocalLength, mPhysicalWidth, mPhysicalHeight);
+
+    close(fd);
+    return 0;
+}
+
diff --git a/mx6/libcamera3/UvcDevice.h b/mx6/libcamera3/UvcDevice.h
new file mode 100644
index 0000000..f0a6a7e
--- /dev/null
+++ b/mx6/libcamera3/UvcDevice.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _UVC_DEVICE_H
+#define _UVC_DEVICE_H
+
+#include "Camera.h"
+
+class UvcDevice : public Camera
+{
+public:
+    UvcDevice(int32_t id, int32_t facing, int32_t orientation, char* path);
+    virtual ~UvcDevice();
+
+    virtual status_t initSensorStaticData();
+
+private:
+
+};
+
+#endif
diff --git a/mx6/libcamera3/UvcStream.cpp b/mx6/libcamera3/UvcStream.cpp
new file mode 100644
index 0000000..c4202fb
--- /dev/null
+++ b/mx6/libcamera3/UvcStream.cpp
@@ -0,0 +1,328 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "UvcStream.h"
+
+UvcStream::UvcStream(Camera* device, const char* name)
+    : DeviceStream(device), mIonFd(-1), mUvcSize(0)
+{
+    mIonFd = ion_open();
+    strncpy(mUvcPath, name, CAMAERA_FILENAME_LENGTH);
+}
+
+UvcStream::~UvcStream()
+{
+    if (mIonFd > 0) {
+        close(mIonFd);
+        mIonFd = -1;
+    }
+}
+
+// configure device.
+int32_t UvcStream::onDeviceConfigureLocked()
+{
+    ALOGV("%s", __func__);
+
+    int32_t ret = 0;
+    if (mDev <= 0) {
+        // usb camera should open dev node again.
+        // because when stream off, the dev node must close.
+        mDev = open(mUvcPath, O_RDWR);
+        if (mDev <= 0) {
+            ALOGE("%s invalid fd handle", __func__);
+            return BAD_VALUE;
+        }
+    }
+
+    int32_t fps = 30;
+    int32_t vformat;
+    vformat = convertPixelFormatToV4L2Format(mFormat);
+
+    if ((mWidth > 1920) || (mHeight > 1080)) {
+        fps = 15;
+    }
+    ALOGI("Width * Height %d x %d format %c%c%c%c, fps: %d",
+          mWidth, mHeight, vformat&0xFF, (vformat>>8)&0xFF,
+          (vformat>>16)&0xFF, (vformat>>24)&0xFF, fps);
+
+    struct v4l2_streamparm param;
+    memset(&param, 0, sizeof(param));
+    param.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    param.parm.capture.timeperframe.numerator   = 1;
+    param.parm.capture.timeperframe.denominator = fps;
+    ret = ioctl(mDev, VIDIOC_S_PARM, &param);
+    if (ret < 0) {
+        ALOGE("%s VIDIOC_S_PARM Failed: %s", __func__, strerror(errno));
+        return ret;
+    }
+
+    struct v4l2_format fmt;
+    memset(&fmt, 0, sizeof(fmt));
+    fmt.type                 = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    fmt.fmt.pix.width        = mWidth & 0xFFFFFFF8;
+    fmt.fmt.pix.height       = mHeight & 0xFFFFFFF8;
+    fmt.fmt.pix.pixelformat  = vformat;
+    fmt.fmt.pix.priv         = 0;
+    fmt.fmt.pix.sizeimage    = 0;
+    fmt.fmt.pix.bytesperline = 0;
+
+    ret = ioctl(mDev, VIDIOC_S_FMT, &fmt);
+    if (ret < 0) {
+        ALOGE("%s VIDIOC_S_FMT Failed: %s", __func__, strerror(errno));
+        return ret;
+    }
+
+
+    return 0;
+}
+
+int32_t UvcStream::onDeviceStartLocked()
+{
+    ALOGV("%s", __func__);
+
+    if (mDev <= 0) {
+        ALOGE("----%s invalid fd-----", __func__);
+        return BAD_VALUE;
+    }
+
+    //-------register buffers----------
+    struct v4l2_buffer buf;
+    struct v4l2_requestbuffers req;
+
+    memset(&req, 0, sizeof (req));
+    req.count = mNumBuffers;
+    req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    req.memory = V4L2_MEMORY_DMABUF;
+    if (ioctl(mDev, VIDIOC_REQBUFS, &req) < 0) {
+        ALOGE("%s: VIDIOC_REQBUFS failed", __func__);
+        return BAD_VALUE;
+    }
+
+    int32_t ret = 0;
+    //----------qbuf----------
+    struct v4l2_buffer cfilledbuffer;
+    for (uint32_t i = 0; i < mNumBuffers; i++) {
+        memset(&cfilledbuffer, 0, sizeof (struct v4l2_buffer));
+        cfilledbuffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        cfilledbuffer.memory = V4L2_MEMORY_DMABUF;
+        cfilledbuffer.m.fd = mBuffers[i]->mFd;
+        cfilledbuffer.index    = i;
+        cfilledbuffer.length = mUvcSize;
+        ALOGI("buf[%d] length:%d", i, cfilledbuffer.length);
+        ret = ioctl(mDev, VIDIOC_QBUF, &cfilledbuffer);
+        if (ret < 0) {
+            ALOGE("%s VIDIOC_QBUF Failed: %s", __func__, strerror(errno));
+            return BAD_VALUE;
+        }
+    }
+
+    //-------stream on-------
+    enum v4l2_buf_type bufType;
+    bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    ret = ioctl(mDev, VIDIOC_STREAMON, &bufType);
+    if (ret < 0) {
+        ALOGE("%s VIDIOC_STREAMON failed: %s", __func__, strerror(errno));
+        return ret;
+    }
+
+    return 0;
+}
+
+int32_t UvcStream::onDeviceStopLocked()
+{
+    ALOGV("%s", __func__);
+    int32_t ret = 0;
+
+    if (mDev <= 0) {
+        ALOGE("%s invalid fd handle", __func__);
+        return BAD_VALUE;
+    }
+
+    enum v4l2_buf_type bufType;
+    bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    ret = ioctl(mDev, VIDIOC_STREAMOFF, &bufType);
+    if (ret < 0) {
+        ALOGE("%s VIDIOC_STREAMOFF failed:%s", __func__, strerror(errno));
+        return ret;
+    }
+
+    // usb camera must close device after stream off.
+    if (mDev > 0) {
+        close(mDev);
+        mDev = -1;
+    }
+
+    return 0;
+}
+
+int32_t UvcStream::onFrameAcquireLocked()
+{
+    ALOGV("%s", __func__);
+    int32_t ret = 0;
+    struct v4l2_buffer cfilledbuffer;
+    memset(&cfilledbuffer, 0, sizeof (cfilledbuffer));
+    cfilledbuffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    cfilledbuffer.memory = V4L2_MEMORY_DMABUF;
+
+    ret = ioctl(mDev, VIDIOC_DQBUF, &cfilledbuffer);
+    if (ret < 0) {
+        ALOGE("%s: VIDIOC_DQBUF Failed: %s", __func__, strerror(errno));
+        return -1;
+    }
+
+    int32_t index = cfilledbuffer.index;
+    ALOGV("acquire index:%d", cfilledbuffer.index);
+    return cfilledbuffer.index;
+}
+
+int32_t UvcStream::onFrameReturnLocked(int32_t index, StreamBuffer& buf)
+{
+    ALOGV("%s: index:%d", __func__, index);
+    int32_t ret = 0;
+    struct v4l2_buffer cfilledbuffer;
+    memset(&cfilledbuffer, 0, sizeof (struct v4l2_buffer));
+    cfilledbuffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    cfilledbuffer.memory = V4L2_MEMORY_DMABUF;
+    cfilledbuffer.m.fd = buf.mFd;
+    cfilledbuffer.index = index;
+    cfilledbuffer.length = mUvcSize;
+
+    ret = ioctl(mDev, VIDIOC_QBUF, &cfilledbuffer);
+    if (ret < 0) {
+        ALOGE("%s: VIDIOC_QBUF Failed: %s", __func__, strerror(errno));
+        return BAD_VALUE;
+    }
+
+    return 0;
+}
+
+int32_t UvcStream::allocateBuffersLocked()
+{
+    ALOGI("%s", __func__);
+    if (mIonFd <= 0) {
+        ALOGE("%s ion invalid", __func__);
+        return BAD_VALUE;
+    }
+
+    if (mRegistered) {
+        ALOGI("%s but buffer is already registered", __func__);
+        return 0;
+    }
+
+    int32_t size = 0;
+    if ((mWidth == 0) || (mHeight == 0)) {
+        ALOGE("%s: width or height = 0", __func__);
+        return BAD_VALUE;
+    }
+
+    switch (mFormat) {
+        case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+            size = mWidth * ((mHeight + 16) & (~15)) * 3 / 2;
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_420_P:
+            size = mWidth * mHeight * 3 / 2;
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_422_I:
+            size = mWidth * mHeight * 2;
+            break;
+
+        default:
+            ALOGE("Error: format:0x%x not supported int ion alloc", mFormat);
+            return BAD_VALUE;
+    }
+    mUvcSize = size;
+
+    unsigned char *ptr = NULL;
+    int32_t sharedFd;
+    int32_t phyAddr;
+    ion_user_handle_t ionHandle;
+    size = (size + PAGE_SIZE) & (~(PAGE_SIZE - 1));
+
+    ALOGI("allocateBufferFromIon buffer num:%d", mNumBuffers);
+    for (uint32_t i = 0; i < mNumBuffers; i++) {
+        ionHandle = -1;
+        int32_t err = ion_alloc(mIonFd, size, 8, 1, 0, &ionHandle);
+        if (err) {
+            ALOGE("ion_alloc failed.");
+            return BAD_VALUE;
+        }
+
+        err = ion_map(mIonFd,
+                      ionHandle,
+                      size,
+                      PROT_READ | PROT_WRITE,
+                      MAP_SHARED,
+                      0,
+                      &ptr,
+                      &sharedFd);
+
+        if (err) {
+            ALOGE("ion_map failed.");
+            return BAD_VALUE;
+        }
+        phyAddr = ion_phys(mIonFd, ionHandle);
+        if (phyAddr == 0) {
+            ALOGE("ion_phys failed.");
+            return BAD_VALUE;
+        }
+        ALOGI("phyalloc ptr:0x%x, phy:0x%x, size:%d", (int32_t)ptr, phyAddr, size);
+        mBuffers[i] = new StreamBuffer();
+        mBuffers[i]->mVirtAddr  = ptr;
+        mBuffers[i]->mPhyAddr   = phyAddr;
+        mBuffers[i]->mSize      =  size;
+        mBuffers[i]->mBufHandle = (buffer_handle_t*)ionHandle;
+        mBuffers[i]->mStream = this;
+        mBuffers[i]->mFd = sharedFd;
+    }
+
+    mRegistered = true;
+    mAllocatedBuffers = mNumBuffers;
+
+    return 0;
+}
+
+int32_t UvcStream::freeBuffersLocked()
+{
+    ALOGI("%s", __func__);
+    if (mIonFd <= 0) {
+        ALOGE("%s ion invalid", __func__);
+        return BAD_VALUE;
+    }
+
+    if (!mRegistered) {
+        ALOGI("%s but buffer is not registered", __func__);
+        return 0;
+    }
+
+    ALOGI("freeBufferToIon buffer num:%d", mAllocatedBuffers);
+    for (uint32_t i = 0; i < mAllocatedBuffers; i++) {
+        ion_user_handle_t ionHandle =
+            (ion_user_handle_t)mBuffers[i]->mBufHandle;
+        close(mBuffers[i]->mFd);
+        ion_free(mIonFd, ionHandle);
+        munmap(mBuffers[i]->mVirtAddr, mBuffers[i]->mSize);
+        delete mBuffers[i];
+        mBuffers[i] = NULL;
+    }
+
+    mRegistered = false;
+    mAllocatedBuffers = 0;
+
+    return 0;
+}
+
diff --git a/mx6/libcamera3/UvcStream.h b/mx6/libcamera3/UvcStream.h
new file mode 100644
index 0000000..5433d28
--- /dev/null
+++ b/mx6/libcamera3/UvcStream.h
@@ -0,0 +1,51 @@
+/*
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _UVC_STREAM_H
+#define _UVC_STREAM_H
+
+#include "DeviceStream.h"
+
+class UvcStream : public DeviceStream
+{
+public:
+    UvcStream(Camera* device, const char* name);
+    virtual ~UvcStream();
+
+    // configure device.
+    virtual int32_t onDeviceConfigureLocked();
+    // start device.
+    virtual int32_t onDeviceStartLocked();
+    // stop device.
+    virtual int32_t onDeviceStopLocked();
+
+    // get buffer from V4L2.
+    virtual int32_t onFrameAcquireLocked();
+    // put buffer back to V4L2.
+    virtual int32_t onFrameReturnLocked(int32_t index, StreamBuffer& buf);
+
+    // allocate buffers.
+    virtual int32_t allocateBuffersLocked();
+    // free buffers.
+    virtual int32_t freeBuffersLocked();
+
+private:
+    int32_t mIonFd;
+    int32_t mUvcSize;
+    char mUvcPath[CAMAERA_FILENAME_LENGTH];
+};
+
+#endif
diff --git a/mx6/libcamera3/VendorTags.cpp b/mx6/libcamera3/VendorTags.cpp
new file mode 100644
index 0000000..be9813f
--- /dev/null
+++ b/mx6/libcamera3/VendorTags.cpp
@@ -0,0 +1,182 @@
+/*
+ * Copyright (C) 2013 The Android Open Source Project
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <system/camera_metadata.h>
+#include "Metadata.h"
+
+//#define LOG_NDEBUG 0
+#include <cutils/log.h>
+
+#include "VendorTags.h"
+
+// Internal representations of vendor tags for convenience.
+// Other classes must access this data via public interfaces.
+// Structured to be easy to extend and contain complexity.
+namespace {
+// Describes a single vendor tag entry
+struct Entry {
+    const char* name;
+    uint8_t     type;
+};
+// Describes a vendor tag section
+struct Section {
+    const char* name;
+    uint32_t start;
+    uint32_t end;
+    const Entry* tags;
+};
+
+// Entry arrays for each section
+const Entry DemoWizardry[demo_wizardry_end - demo_wizardry_start] = {
+    [demo_wizardry_dimension_size - demo_wizardry_start] =
+        {"dimensionSize",   TYPE_INT32},
+    [demo_wizardry_dimensions - demo_wizardry_start] =
+        {"dimensions",      TYPE_INT32},
+    [demo_wizardry_familiar - demo_wizardry_start] =
+        {"familiar",        TYPE_BYTE},
+    [demo_wizardry_fire - demo_wizardry_start] =
+        {"fire",            TYPE_RATIONAL}
+};
+
+const Entry DemoSorcery[demo_sorcery_end - demo_sorcery_start] = {
+    [demo_sorcery_difficulty - demo_sorcery_start] =
+        {"difficulty",      TYPE_INT64},
+    [demo_sorcery_light - demo_sorcery_start] =
+        {"light",           TYPE_BYTE}
+};
+
+const Entry DemoMagic[demo_magic_end - demo_magic_start] = {
+    [demo_magic_card_trick - demo_magic_start] =
+        {"cardTrick",       TYPE_DOUBLE},
+    [demo_magic_levitation - demo_magic_start] =
+        {"levitation",      TYPE_FLOAT}
+};
+
+// Array of all sections
+const Section DemoSections[DEMO_SECTION_COUNT] = {
+    [DEMO_WIZARDRY] = { "demo.wizardry",
+                        demo_wizardry_start,
+                        demo_wizardry_end,
+                        DemoWizardry },
+    [DEMO_SORCERY]  = { "demo.sorcery",
+                        demo_sorcery_start,
+                        demo_sorcery_end,
+                        DemoSorcery },
+    [DEMO_MAGIC]    = { "demo.magic",
+                        demo_magic_start,
+                        demo_magic_end,
+                        DemoMagic }
+};
+
+// Get a static handle to a specific vendor tag section
+const Section* getSection(uint32_t tag)
+{
+    uint32_t section = (tag - vendor_section_start) >> 16;
+
+    if (tag < vendor_section_start) {
+        ALOGE("%s: Tag 0x%x before vendor section", __func__, tag);
+        return NULL;
+    }
+
+    if (section >= DEMO_SECTION_COUNT) {
+        ALOGE("%s: Tag 0x%x after vendor section", __func__, tag);
+        return NULL;
+    }
+
+    return &DemoSections[section];
+}
+
+// Get a static handle to a specific vendor tag entry
+const Entry* getEntry(uint32_t tag)
+{
+    const Section* section = getSection(tag);
+    int index;
+
+    if (section == NULL)
+        return NULL;
+
+    if (tag >= section->end) {
+        ALOGE("%s: Tag 0x%x outside section", __func__, tag);
+        return NULL;
+    }
+
+    index = tag - section->start;
+    return &section->tags[index];
+}
+} // namespace
+
+VendorTags::VendorTags()
+  : mTagCount(0)
+{
+    for (int i = 0; i < DEMO_SECTION_COUNT; i++) {
+        mTagCount += DemoSections[i].end - DemoSections[i].start;
+    }
+}
+
+VendorTags::~VendorTags()
+{
+}
+
+int VendorTags::getTagCount(const vendor_tag_ops_t* ops)
+{
+    return mTagCount;
+}
+
+void VendorTags::getAllTags(const vendor_tag_ops_t* ops, uint32_t* tag_array)
+{
+    if (tag_array == NULL) {
+        ALOGE("%s: NULL tag_array", __func__);
+        return;
+    }
+
+    for (int i = 0; i < DEMO_SECTION_COUNT; i++) {
+        for (uint32_t tag = DemoSections[i].start;
+                tag < DemoSections[i].end; tag++) {
+            *tag_array++ = tag;
+        }
+    }
+}
+
+const char* VendorTags::getSectionName(const vendor_tag_ops_t* ops, uint32_t tag)
+{
+    const Section* section = getSection(tag);
+
+    if (section == NULL)
+        return NULL;
+
+    return section->name;
+}
+
+const char* VendorTags::getTagName(const vendor_tag_ops_t* ops, uint32_t tag)
+{
+    const Entry* entry = getEntry(tag);
+
+    if (entry == NULL)
+        return NULL;
+
+    return entry->name;
+}
+
+int VendorTags::getTagType(const vendor_tag_ops_t* ops, uint32_t tag)
+{
+    const Entry* entry = getEntry(tag);
+
+    if (entry == NULL)
+        return -1;
+
+    return entry->type;
+}
diff --git a/mx6/libcamera3/VendorTags.h b/mx6/libcamera3/VendorTags.h
new file mode 100644
index 0000000..a42ff33
--- /dev/null
+++ b/mx6/libcamera3/VendorTags.h
@@ -0,0 +1,73 @@
+/*
+ * Copyright (C) 2013 The Android Open Source Project
+ * Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef VENDOR_TAGS_H_
+#define VENDOR_TAGS_H_
+
+#include <hardware/camera_common.h>
+#include <system/camera_metadata.h>
+
+// VendorTags contains all vendor-specific metadata tag functionality
+class VendorTags {
+    public:
+        VendorTags();
+        ~VendorTags();
+
+        // Vendor Tags Operations (see <hardware/camera_common.h>)
+        int getTagCount(const vendor_tag_ops_t* ops);
+        void getAllTags(const vendor_tag_ops_t* ops, uint32_t* tag_array);
+        const char* getSectionName(const vendor_tag_ops_t* ops, uint32_t tag);
+        const char* getTagName(const vendor_tag_ops_t* ops, uint32_t tag);
+        int getTagType(const vendor_tag_ops_t* ops, uint32_t tag);
+
+    private:
+        // Total number of vendor tags
+        int mTagCount;
+};
+
+// Tag sections start at the beginning of vendor tags (0x8000_0000)
+// See <system/camera_metadata.h>
+enum {
+    DEMO_WIZARDRY,
+    DEMO_SORCERY,
+    DEMO_MAGIC,
+    DEMO_SECTION_COUNT
+};
+
+const uint32_t vendor_section_start = VENDOR_SECTION_START;
+
+// Each section starts at increments of 0x1_0000
+const uint32_t demo_wizardry_start = (DEMO_WIZARDRY + VENDOR_SECTION) << 16;
+const uint32_t demo_sorcery_start  = (DEMO_SORCERY  + VENDOR_SECTION) << 16;
+const uint32_t demo_magic_start    = (DEMO_MAGIC    + VENDOR_SECTION) << 16;
+
+// Vendor Tag values, start value begins each section
+const uint32_t demo_wizardry_dimension_size = demo_wizardry_start;
+const uint32_t demo_wizardry_dimensions = demo_wizardry_start + 1;
+const uint32_t demo_wizardry_familiar = demo_wizardry_start + 2;
+const uint32_t demo_wizardry_fire = demo_wizardry_start + 3;
+const uint32_t demo_wizardry_end = demo_wizardry_start + 4;
+
+const uint32_t demo_sorcery_difficulty = demo_sorcery_start;
+const uint32_t demo_sorcery_light = demo_sorcery_start + 1;
+const uint32_t demo_sorcery_end = demo_sorcery_start + 2;
+
+const uint32_t demo_magic_card_trick = demo_magic_start;
+const uint32_t demo_magic_levitation = demo_magic_start + 1;
+const uint32_t demo_magic_end = demo_magic_start + 2;
+
+#endif // VENDOR_TAGS_H_
diff --git a/mx6/libcamera3/YuvToJpegEncoder.cpp b/mx6/libcamera3/YuvToJpegEncoder.cpp
new file mode 100644
index 0000000..729c77f
--- /dev/null
+++ b/mx6/libcamera3/YuvToJpegEncoder.cpp
@@ -0,0 +1,839 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "YuvToJpegEncoder.h"
+#include <ui/PixelFormat.h>
+#include <hardware/hardware.h>
+#include "NV12_resize.h"
+#include "vpu_wrapper.h"
+
+
+#define Align(ptr,align)	(((unsigned int)ptr+(align)-1)/(align)*(align))
+#define VPU_ENC_MAX_NUM_MEM_REQS	(6)
+#define MAX_FRAME_NUM	(4)
+
+typedef struct{
+	//virtual mem info
+	int nVirtNum;
+	unsigned int virtMem[VPU_ENC_MAX_NUM_MEM_REQS];
+
+	//phy mem info
+	int nPhyNum;
+	unsigned int phyMem_virtAddr[VPU_ENC_MAX_NUM_MEM_REQS];
+	unsigned int phyMem_phyAddr[VPU_ENC_MAX_NUM_MEM_REQS];
+	unsigned int phyMem_cpuAddr[VPU_ENC_MAX_NUM_MEM_REQS];
+	unsigned int phyMem_size[VPU_ENC_MAX_NUM_MEM_REQS];
+}EncMemInfo;
+
+
+int EncOutFrameBufCreateRegisterFrame(VpuCodStd eFormat,int nInColor,
+	VpuFrameBuffer* pOutRegisterFrame,int nInCnt,int nWidth,int nHeight,
+	EncMemInfo* pOutEncMemInfo, int nInRot,int* pOutSrcStride,int nInAlign,int nInMapType)
+{
+	int i;
+	VpuEncRetCode ret;
+	int yStride;
+	int uvStride;
+	int ySize;
+	int uvSize;
+	int mvSize;
+	VpuMemDesc vpuMem;
+	unsigned char* ptr;
+	unsigned char* ptrVirt;
+	int nPadW;
+	int nPadH;
+	int multifactor=1;
+
+//    ALOGI("==== EOFBCRF, eFormat %d, nInColor %d, nInAlign %d, nInMapType %d",
+  //      eFormat, nInColor, nInAlign, nInMapType);
+
+	nPadW=Align(nWidth,16);
+	nPadH=Align(nHeight,16);
+	if((nInRot==90)||(nInRot==270)){
+		yStride=nPadH;
+		ySize=yStride*nPadW;
+	}
+	else	{
+		yStride=nPadW;
+		ySize=yStride*nPadH;
+	}
+	if(VPU_V_MJPG==eFormat)	{
+		switch(nInColor){
+			case 0:	//4:2:0
+				uvStride=yStride/2;
+				uvSize=ySize/4;
+				mvSize=uvSize;
+				break;
+			case 1:	//4:2:2 hor
+				uvStride=yStride/2;
+				uvSize=ySize/2;
+				mvSize=uvSize;
+				break;
+			case 2:	//4:2:2 ver
+				uvStride=yStride;
+				uvSize=ySize/2;
+				mvSize=uvSize;
+				break;
+			case 3:	//4:4:4
+				uvStride=yStride;
+				uvSize=ySize;
+				mvSize=uvSize;
+				break;
+			case 4:	//4:0:0
+				uvStride=0;
+				uvSize=0;
+				mvSize=uvSize;
+				break;
+			default:	//4:2:0
+				ALOGE("unknown color format: %d ",nInColor);
+				uvStride=yStride/2;
+				uvSize=ySize/4;
+				mvSize=uvSize;
+				break;
+		}
+    }else {
+		//4:2:0 for all video
+		uvStride=yStride/2;
+		uvSize=ySize/4;
+		mvSize=uvSize;
+	}
+
+	if(nInMapType==2){
+		//only consider Y since interleave must be enabled
+		multifactor=2;	//for field, we need to consider alignment for top and bot
+	}
+
+	//we need to align the Y/Cb/Cr address
+	if(nInAlign>1){
+		ySize=Align(ySize,multifactor*nInAlign);
+		uvSize=Align(uvSize,nInAlign);
+	}
+
+	for(i=0;i<nInCnt;i++){
+		vpuMem.nSize=ySize+uvSize*2+mvSize+nInAlign;
+		ret=VPU_EncGetMem(&vpuMem);
+		if(VPU_ENC_RET_SUCCESS!=ret){
+			ALOGE("%s: vpu malloc frame buf failure: ret=0x%X ",__FUNCTION__,ret);
+			return -1;//OMX_ErrorInsufficientResources;
+		}
+
+		ptr=(unsigned char*)vpuMem.nPhyAddr;
+		ptrVirt=(unsigned char*)vpuMem.nVirtAddr;
+
+		/*align the base address*/
+		if(nInAlign>1){
+			ptr=(unsigned char*)Align(ptr,nInAlign);
+			ptrVirt=(unsigned char*)Align(ptrVirt,nInAlign);
+		}
+
+		/* fill stride info */
+		pOutRegisterFrame[i].nStrideY=yStride;
+		pOutRegisterFrame[i].nStrideC=uvStride;
+
+		/* fill phy addr*/
+		pOutRegisterFrame[i].pbufY=ptr;
+		pOutRegisterFrame[i].pbufCb=ptr+ySize;
+		pOutRegisterFrame[i].pbufCr=ptr+ySize+uvSize;
+		pOutRegisterFrame[i].pbufMvCol=ptr+ySize+uvSize*2;
+
+		/* fill virt addr */
+		pOutRegisterFrame[i].pbufVirtY=ptrVirt;
+		pOutRegisterFrame[i].pbufVirtCb=ptrVirt+ySize;
+		pOutRegisterFrame[i].pbufVirtCr=ptrVirt+ySize+uvSize;
+		pOutRegisterFrame[i].pbufVirtMvCol=ptrVirt+ySize+uvSize*2;
+
+		/* fill bottom address for field tile*/
+		if(nInMapType==2){
+			pOutRegisterFrame[i].pbufY_tilebot=pOutRegisterFrame[i].pbufY+ySize/2;
+			pOutRegisterFrame[i].pbufCb_tilebot=pOutRegisterFrame[i].pbufCr;
+			pOutRegisterFrame[i].pbufVirtY_tilebot=pOutRegisterFrame[i].pbufVirtY+ySize/2;
+			pOutRegisterFrame[i].pbufVirtCb_tilebot=pOutRegisterFrame[i].pbufVirtCr;
+		}
+		else	{
+			pOutRegisterFrame[i].pbufY_tilebot=0;
+			pOutRegisterFrame[i].pbufCb_tilebot=0;
+			pOutRegisterFrame[i].pbufVirtY_tilebot=0;
+			pOutRegisterFrame[i].pbufVirtCb_tilebot=0;
+		}
+
+		//record memory info for release
+		pOutEncMemInfo->phyMem_phyAddr[pOutEncMemInfo->nPhyNum]=vpuMem.nPhyAddr;
+		pOutEncMemInfo->phyMem_virtAddr[pOutEncMemInfo->nPhyNum]=vpuMem.nVirtAddr;
+		pOutEncMemInfo->phyMem_cpuAddr[pOutEncMemInfo->nPhyNum]=vpuMem.nCpuAddr;
+		pOutEncMemInfo->phyMem_size[pOutEncMemInfo->nPhyNum]=vpuMem.nSize;
+		pOutEncMemInfo->nPhyNum++;
+
+	}
+
+	*pOutSrcStride=nWidth;//nPadW;
+	return i;
+}
+
+int EncFreeMemBlock(EncMemInfo* pEncMem)
+{
+	int i;
+	VpuMemDesc vpuMem;
+	VpuEncRetCode vpuRet;
+	int retOk=1;
+
+	//free virtual mem
+	for(i=0;i<pEncMem->nVirtNum;i++){
+		free((void*)pEncMem->virtMem[i]);
+	}
+
+	//free physical mem
+	for(i=0;i<pEncMem->nPhyNum;i++)	{
+		vpuMem.nPhyAddr=pEncMem->phyMem_phyAddr[i];
+		vpuMem.nVirtAddr=pEncMem->phyMem_virtAddr[i];
+		vpuMem.nCpuAddr=pEncMem->phyMem_cpuAddr[i];
+		vpuMem.nSize=pEncMem->phyMem_size[i];
+		vpuRet=VPU_EncFreeMem(&vpuMem);
+		if(vpuRet!=VPU_ENC_RET_SUCCESS){
+			ALOGE("%s: free vpu memory failure : ret=%d ",__FUNCTION__,(unsigned int)vpuRet);
+			retOk=0;
+		}
+	}
+
+	return retOk;
+}
+
+
+int EncMallocMemBlock(VpuMemInfo* pMemBlock,EncMemInfo* pEncMem)
+{
+	int i;
+	unsigned char * ptr=NULL;
+	int size;
+
+	for(i=0;i<pMemBlock->nSubBlockNum;i++){
+     /*   ALOGI("==== EncMallocMemBlock, i %d, align %d, size %d, memType %d",
+            i, pMemBlock->MemSubBlock[i].nAlignment, pMemBlock->MemSubBlock[i].nSize,
+            pMemBlock->MemSubBlock[i].MemType); */
+
+		size=pMemBlock->MemSubBlock[i].nAlignment+pMemBlock->MemSubBlock[i].nSize;
+		if(pMemBlock->MemSubBlock[i].MemType==VPU_MEM_VIRT){
+			ptr=(unsigned char *)malloc(size);
+			if(ptr==NULL)	{
+				ALOGE("%s: get virtual memory failure, size=%d ",__FUNCTION__,(unsigned int)size);
+				goto failure;
+			}
+			pMemBlock->MemSubBlock[i].pVirtAddr=(unsigned char*)Align(ptr,pMemBlock->MemSubBlock[i].nAlignment);
+
+			//record virtual base addr
+			pEncMem->virtMem[pEncMem->nVirtNum]=(unsigned int)ptr;
+			pEncMem->nVirtNum++;
+		}
+		else{ // if(memInfo.MemSubBlock[i].MemType==VPU_MEM_PHY)
+			VpuMemDesc vpuMem;
+			VpuEncRetCode ret;
+			vpuMem.nSize=size;
+			ret=VPU_EncGetMem(&vpuMem);
+			if(ret!=VPU_ENC_RET_SUCCESS){
+				ALOGE("%s: get vpu memory failure, size=%d, ret=%d ",__FUNCTION__,size,ret);
+				goto failure;
+			}
+			pMemBlock->MemSubBlock[i].pVirtAddr=(unsigned char*)Align(vpuMem.nVirtAddr,pMemBlock->MemSubBlock[i].nAlignment);
+			pMemBlock->MemSubBlock[i].pPhyAddr=(unsigned char*)Align(vpuMem.nPhyAddr,pMemBlock->MemSubBlock[i].nAlignment);
+
+			//record physical base addr
+			pEncMem->phyMem_phyAddr[pEncMem->nPhyNum]=(unsigned int)vpuMem.nPhyAddr;
+			pEncMem->phyMem_virtAddr[pEncMem->nPhyNum]=(unsigned int)vpuMem.nVirtAddr;
+			pEncMem->phyMem_cpuAddr[pEncMem->nPhyNum]=(unsigned int)vpuMem.nCpuAddr;
+			pEncMem->phyMem_size[pEncMem->nPhyNum]=size;
+			pEncMem->nPhyNum++;
+		}
+    }
+
+	return 1;
+
+failure:
+	EncFreeMemBlock(pEncMem);
+	return 0;
+}
+
+int vpu_encode(void *inYuv,
+                             void* inYuvPhy,
+                             int   Width,
+                             int   Height,
+                             int   /*quality*/,
+                             int   color,
+                             void *outBuf,
+                             int   outSize)
+{
+	VpuEncRetCode ret;
+	int size=0;
+	VpuVersionInfo ver;
+	VpuWrapperVersionInfo w_ver;
+	VpuEncHandle handle=0;
+	VpuMemInfo sMemInfo;
+	EncMemInfo sEncMemInfo;
+	VpuEncOpenParamSimp sEncOpenParamSimp;
+	VpuEncInitInfo sEncInitInfo;
+	VpuFrameBuffer sFrameBuf[MAX_FRAME_NUM];
+	int nBufNum;
+	int nSrcStride;
+	VpuEncEncParam sEncEncParam;
+	char* tempOut=0;
+	static FILE* fpjpg=0;
+
+	memset(&sMemInfo,0,sizeof(VpuMemInfo));
+	memset(&sEncMemInfo,0,sizeof(EncMemInfo));
+	memset(&sFrameBuf,0,sizeof(VpuFrameBuffer)*MAX_FRAME_NUM);
+
+	ret=VPU_EncLoad();
+	if (ret!=VPU_ENC_RET_SUCCESS){
+		ALOGE("load vpu encoder failure !");
+		return 0;
+	}
+	ret=VPU_EncGetVersionInfo(&ver);
+	if (ret!=VPU_ENC_RET_SUCCESS){
+		ALOGE("vpu get version info failure: ret=%d ",ret);
+		goto finish;
+	}
+	ALOGI("vpu lib version : major.minor.rel=%d.%d.%d ",ver.nLibMajor,ver.nLibMinor,ver.nLibRelease);
+	ALOGI("vpu fw version : major.minor.rel_rcode=%d.%d.%d_r%d ",ver.nFwMajor,ver.nFwMinor,ver.nFwRelease,ver.nFwCode);
+
+	ret=(VpuEncRetCode)VPU_EncGetWrapperVersionInfo(&w_ver);
+	if (ret!=VPU_ENC_RET_SUCCESS){
+		ALOGE("%s: vpu get wrapper version failure: ret=%d ",__FUNCTION__,ret);
+		goto finish;
+	}
+	//ALOGI("vpu wrapper version : major.minor.rel=%d.%d.%d: %s ",w_ver.nMajor,w_ver.nMinor,w_ver.nRelease,w_ver.pBinary);
+
+	//query memory
+	ret=VPU_EncQueryMem(&sMemInfo);
+	if (ret!=VPU_ENC_RET_SUCCESS){
+		ALOGE("%s: vpu query memory failure: ret=0x%X ",__FUNCTION__,ret);
+		goto finish;
+	}
+
+	//malloc memory for vpu
+	if(0==EncMallocMemBlock(&sMemInfo,&sEncMemInfo))
+	{
+		ALOGE("%s: malloc memory failure: ",__FUNCTION__);
+		goto finish;
+	}
+
+	memset(&sEncOpenParamSimp,0,sizeof(VpuEncOpenParamSimp));
+	sEncOpenParamSimp.eFormat=VPU_V_MJPG;
+	sEncOpenParamSimp.sMirror=VPU_ENC_MIRDIR_NONE;
+	sEncOpenParamSimp.nPicWidth= Width;
+	sEncOpenParamSimp.nPicHeight=Height;
+	sEncOpenParamSimp.nRotAngle=0;
+	sEncOpenParamSimp.nFrameRate=30;
+	sEncOpenParamSimp.nBitRate=0;
+	sEncOpenParamSimp.nGOPSize=30;
+	sEncOpenParamSimp.nChromaInterleave=1;
+
+	//open vpu
+	ret=VPU_EncOpenSimp(&handle, &sMemInfo,&sEncOpenParamSimp);
+	if (ret!=VPU_ENC_RET_SUCCESS){
+		ALOGE("%s: vpu open failure: ret=0x%X ",__FUNCTION__,ret);
+		goto finish;
+	}
+
+	//get initinfo
+	ret=VPU_EncGetInitialInfo(handle,&sEncInitInfo);
+	if(VPU_ENC_RET_SUCCESS!=ret){
+		ALOGE("%s: init vpu failure ",__FUNCTION__);
+		goto finish;
+	}
+
+	nBufNum=sEncInitInfo.nMinFrameBufferCount;
+//	ALOGI("==== Init OK: min buffer cnt: %d, alignment: %d ",sEncInitInfo.nMinFrameBufferCount,sEncInitInfo.nAddressAlignment);
+	//fill frameBuf[]
+	if(-1==EncOutFrameBufCreateRegisterFrame(sEncOpenParamSimp.eFormat,color,sFrameBuf, nBufNum,Width, Height, &sEncMemInfo,0,&nSrcStride,sEncInitInfo.nAddressAlignment,0)){
+		ALOGE("%s: allocate vpu frame buffer failure ",__FUNCTION__);
+		goto finish;
+	}
+
+	//register frame buffs
+	ret=VPU_EncRegisterFrameBuffer(handle, sFrameBuf, nBufNum,nSrcStride);
+	if(VPU_ENC_RET_SUCCESS!=ret){
+		ALOGE("%s: vpu register frame failure: ret=0x%X ",__FUNCTION__,ret);
+		goto finish;
+	}
+
+	//allocate temporary physical output buffer
+	memset(&sMemInfo,0,sizeof(VpuMemInfo));
+	sMemInfo.nSubBlockNum=1;
+	sMemInfo.MemSubBlock[0].MemType=VPU_MEM_PHY;
+	sMemInfo.MemSubBlock[0].nAlignment=sEncInitInfo.nAddressAlignment;//8;
+	sMemInfo.MemSubBlock[0].nSize=outSize;
+	if(0==EncMallocMemBlock(&sMemInfo,&sEncMemInfo))	{
+		ALOGE("%s: malloc memory failure: ",__FUNCTION__);
+		goto finish;
+	}
+
+	//encode frame
+	memset(&sEncEncParam,0,sizeof(VpuEncEncParam));
+	sEncEncParam.eFormat=VPU_V_MJPG;
+	sEncEncParam.nPicWidth=Width;
+	sEncEncParam.nPicHeight=Height;
+	sEncEncParam.nFrameRate=30;
+	sEncEncParam.nQuantParam=10;
+	sEncEncParam.nInPhyInput=(unsigned int)inYuvPhy;
+	sEncEncParam.nInVirtInput=(unsigned int)inYuv;
+	sEncEncParam.nInInputSize=(color==0)?(Width*Height*3/2):(Width*Height*2);
+	sEncEncParam.nInPhyOutput=(unsigned int)sMemInfo.MemSubBlock[0].pPhyAddr;
+	sEncEncParam.nInVirtOutput=(unsigned int)sMemInfo.MemSubBlock[0].pVirtAddr;
+	sEncEncParam.nInOutputBufLen=outSize;
+
+	ret=VPU_EncEncodeFrame(handle, &sEncEncParam);
+	if(VPU_ENC_RET_SUCCESS!=ret){
+		ALOGE("%s, vpu encode frame failure: ret=0x%X ",__FUNCTION__,ret);
+		if(VPU_ENC_RET_FAILURE_TIMEOUT==ret){
+			VPU_EncReset(handle);
+		}
+	}
+
+	if((sEncEncParam.eOutRetCode & VPU_ENC_OUTPUT_DIS)||(sEncEncParam.eOutRetCode & VPU_ENC_OUTPUT_SEQHEADER)){
+		size=sEncEncParam.nOutOutputSize;
+		//ALOGI("encode succeed, output size: %d ",size);
+	}
+	else{
+		ALOGE("%s, vpu encode frame failure: no output,  ret=0x%X ",__FUNCTION__,sEncEncParam.eOutRetCode);
+	}
+
+	memcpy(outBuf,(void*)sEncEncParam.nInVirtOutput,sEncEncParam.nOutOutputSize);
+
+finish:
+
+	//close vpu
+	if(handle!=0){
+		ret=VPU_EncClose(handle);
+		if (ret!=VPU_ENC_RET_SUCCESS){
+			ALOGE("%s: vpu close failure: ret=%d ",__FUNCTION__,ret);
+		}
+	}
+
+	//unload
+	ret=VPU_EncUnLoad();
+	if (ret!=VPU_ENC_RET_SUCCESS){
+		ALOGE("%s: vpu unload failure: ret=%d \r\n",__FUNCTION__,ret);
+	}
+
+	//release mem
+	if(0==EncFreeMemBlock(&sEncMemInfo)){
+		ALOGE("%s: free memory failure:  ",__FUNCTION__);
+	}
+
+	return size;
+}
+
+YuvToJpegEncoder * YuvToJpegEncoder::create(int format) {
+    // Only ImageFormat.NV21 and ImageFormat.YUY2 are supported
+    // for now.
+    if (format == HAL_PIXEL_FORMAT_YCbCr_420_SP) {
+        return new Yuv420SpToJpegEncoder();
+    } else if (format == HAL_PIXEL_FORMAT_YCbCr_422_I) {
+        return new Yuv422IToJpegEncoder();
+    } else {
+        ALOGE("YuvToJpegEncoder:create format:%d not support", format);
+        return NULL;
+    }
+}
+
+YuvToJpegEncoder::YuvToJpegEncoder()
+    : supportVpu(false)
+{}
+
+int YuvToJpegEncoder::encode(void *inYuv,
+                             void* inYuvPhy,
+                             int   inWidth,
+                             int   inHeight,
+                             int   quality,
+                             void *outBuf,
+                             int   outSize,
+                             int   outWidth,
+                             int   outHeight) {
+    //use vpu to encode
+	if((inWidth == outWidth) && (inHeight == outHeight) && supportVpu){
+		int size;
+		size=vpu_encode(inYuv, inYuvPhy, outWidth, outHeight,quality,color,outBuf,outSize);
+		return size;
+	}
+
+    jpeg_compress_struct  cinfo;
+    jpegBuilder_error_mgr sk_err;
+    uint8_t *resize_src = NULL;
+    jpegBuilder_destination_mgr dest_mgr((uint8_t *)outBuf, outSize);
+
+
+    memset(&cinfo, 0, sizeof(cinfo));
+    if ((inWidth != outWidth) || (inHeight != outHeight)) {
+        resize_src = (uint8_t *)malloc(outSize);
+        yuvResize((uint8_t *)inYuv,
+                  inWidth,
+                  inHeight,
+                  resize_src,
+                  outWidth,
+                  outHeight);
+        inYuv = resize_src;
+    }
+
+    cinfo.err = jpeg_std_error(&sk_err);
+    jpeg_create_compress(&cinfo);
+
+    cinfo.dest = &dest_mgr;
+
+    setJpegCompressStruct(&cinfo, outWidth, outHeight, quality);
+
+    jpeg_start_compress(&cinfo, TRUE);
+
+    compress(&cinfo, (uint8_t *)inYuv);
+    jpeg_finish_compress(&cinfo);
+
+    if (resize_src != NULL) {
+        free(resize_src);
+    }
+
+    return dest_mgr.jpegsize;
+}
+
+void YuvToJpegEncoder::setJpegCompressStruct(jpeg_compress_struct *cinfo,
+                                             int                   width,
+                                             int                   height,
+                                             int                   quality) {
+    cinfo->image_width      = width;
+    cinfo->image_height     = height;
+    cinfo->input_components = 3;
+    cinfo->in_color_space   = JCS_YCbCr;
+    jpeg_set_defaults(cinfo);
+
+    jpeg_set_quality(cinfo, quality, TRUE);
+    jpeg_set_colorspace(cinfo, JCS_YCbCr);
+    cinfo->raw_data_in = TRUE;
+    cinfo->dct_method  = JDCT_IFAST;
+    configSamplingFactors(cinfo);
+}
+
+// /////////////////////////////////////////////////////////////////
+Yuv420SpToJpegEncoder::Yuv420SpToJpegEncoder() :
+    YuvToJpegEncoder() {
+    fNumPlanes = 2;
+    color=0;
+    supportVpu = true;
+}
+
+void Yuv420SpToJpegEncoder::compress(jpeg_compress_struct *cinfo,
+                                     uint8_t              *yuv) {
+    JSAMPROW   y[16];
+    JSAMPROW   cb[8];
+    JSAMPROW   cr[8];
+    JSAMPARRAY planes[3];
+
+    planes[0] = y;
+    planes[1] = cb;
+    planes[2] = cr;
+
+    int width         = cinfo->image_width;
+    int height        = cinfo->image_height;
+    uint8_t *yPlanar  = yuv;
+    uint8_t *vuPlanar = yuv + width * height;
+    uint8_t *uRows    = new uint8_t[8 * (width >> 1)];
+    uint8_t *vRows    = new uint8_t[8 * (width >> 1)];
+
+    // process 16 lines of Y and 8 lines of U/V each time.
+    while (cinfo->next_scanline < cinfo->image_height) {
+        // deitnerleave u and v
+        deinterleave(vuPlanar, uRows, vRows, cinfo->next_scanline, width, height);
+
+        for (int i = 0; i < 16; i++) {
+            // y row
+            y[i] = yPlanar + (cinfo->next_scanline + i) * width;
+
+            // construct u row and v row
+            if ((i & 1) == 0) {
+                // height and width are both halved because of downsampling
+                int offset = (i >> 1) * (width >> 1);
+                cb[i / 2] = uRows + offset;
+                cr[i / 2] = vRows + offset;
+            }
+        }
+        jpeg_write_raw_data(cinfo, planes, 16);
+    }
+    delete[] uRows;
+    delete[] vRows;
+}
+
+void Yuv420SpToJpegEncoder::deinterleave(uint8_t *vuPlanar,
+                                         uint8_t *uRows,
+                                         uint8_t *vRows,
+                                         int      rowIndex,
+                                         int      width,
+                                         int      height) {
+    for (int row = 0; row < 8; ++row) {
+        int hoff = (rowIndex >> 1) + row;
+        if (hoff >= (height >> 1)) {
+            return;
+        }
+        int offset  = hoff * width;
+        uint8_t *vu = vuPlanar + offset;
+        for (int i = 0; i < (width >> 1); ++i) {
+            int index = row * (width >> 1) + i;
+            uRows[index] = vu[0];
+            vRows[index] = vu[1];
+            vu          += 2;
+        }
+    }
+}
+
+void Yuv420SpToJpegEncoder::configSamplingFactors(jpeg_compress_struct *cinfo) {
+    // cb and cr are horizontally downsampled and vertically downsampled as
+    // well.
+    cinfo->comp_info[0].h_samp_factor = 2;
+    cinfo->comp_info[0].v_samp_factor = 2;
+    cinfo->comp_info[1].h_samp_factor = 1;
+    cinfo->comp_info[1].v_samp_factor = 1;
+    cinfo->comp_info[2].h_samp_factor = 1;
+    cinfo->comp_info[2].v_samp_factor = 1;
+}
+
+int Yuv420SpToJpegEncoder::yuvResize(uint8_t *srcBuf,
+                                     int      srcWidth,
+                                     int      srcHeight,
+                                     uint8_t *dstBuf,
+                                     int      dstWidth,
+                                     int      dstHeight)
+{
+    if (!srcBuf || !dstBuf) {
+        return -1;
+    }
+
+    structConvImage o_img_ptr, i_img_ptr;
+    memset(&o_img_ptr, 0, sizeof(o_img_ptr));
+    memset(&i_img_ptr, 0, sizeof(i_img_ptr));
+
+    // input
+    i_img_ptr.uWidth  =  srcWidth;
+    i_img_ptr.uStride =  i_img_ptr.uWidth;
+    i_img_ptr.uHeight =  srcHeight;
+    i_img_ptr.eFormat = IC_FORMAT_YCbCr420_lp;
+    i_img_ptr.imgPtr  = srcBuf;
+    i_img_ptr.clrPtr  = i_img_ptr.imgPtr + (i_img_ptr.uWidth * i_img_ptr.uHeight);
+
+    // ouput
+    o_img_ptr.uWidth  = dstWidth;
+    o_img_ptr.uStride = o_img_ptr.uWidth;
+    o_img_ptr.uHeight = dstHeight;
+    o_img_ptr.eFormat = IC_FORMAT_YCbCr420_lp;
+    o_img_ptr.imgPtr  = dstBuf;
+    o_img_ptr.clrPtr  = o_img_ptr.imgPtr + (o_img_ptr.uWidth * o_img_ptr.uHeight);
+
+    VT_resizeFrame_Video_opt2_lp(&i_img_ptr, &o_img_ptr, NULL, 0);
+
+    return 0;
+}
+
+// /////////////////////////////////////////////////////////////////////////////
+Yuv422IToJpegEncoder::Yuv422IToJpegEncoder() :
+    YuvToJpegEncoder() {
+    fNumPlanes = 1;
+    color=1;
+}
+
+void Yuv422IToJpegEncoder::compress(jpeg_compress_struct *cinfo,
+                                    uint8_t              *yuv) {
+    JSAMPROW   y[16];
+    JSAMPROW   cb[16];
+    JSAMPROW   cr[16];
+    JSAMPARRAY planes[3];
+
+    planes[0] = y;
+    planes[1] = cb;
+    planes[2] = cr;
+
+    int width      = cinfo->image_width;
+    int height     = cinfo->image_height;
+    uint8_t *yRows = new uint8_t[16 * width];
+    uint8_t *uRows = new uint8_t[16 * (width >> 1)];
+    uint8_t *vRows = new uint8_t[16 * (width >> 1)];
+
+    uint8_t *yuvOffset = yuv;
+
+    // process 16 lines of Y and 16 lines of U/V each time.
+    while (cinfo->next_scanline < cinfo->image_height) {
+        deinterleave(yuvOffset,
+                     yRows,
+                     uRows,
+                     vRows,
+                     cinfo->next_scanline,
+                     width,
+                     height);
+
+        for (int i = 0; i < 16; i++) {
+            // y row
+            y[i] = yRows + i * width;
+
+            // construct u row and v row
+            // width is halved because of downsampling
+            int offset = i * (width >> 1);
+            cb[i] = uRows + offset;
+            cr[i] = vRows + offset;
+        }
+
+        jpeg_write_raw_data(cinfo, planes, 16);
+    }
+    delete[] yRows;
+    delete[] uRows;
+    delete[] vRows;
+}
+
+void Yuv422IToJpegEncoder::deinterleave(uint8_t *yuv,
+                                        uint8_t *yRows,
+                                        uint8_t *uRows,
+                                        uint8_t *vRows,
+                                        int      rowIndex,
+                                        int      width,
+                                        int      /*height*/) {
+    for (int row = 0; row < 16; ++row) {
+        uint8_t *yuvSeg = yuv + (rowIndex + row) * width * 2;
+        for (int i = 0; i < (width >> 1); ++i) {
+            int indexY = row * width + (i << 1);
+            int indexU = row * (width >> 1) + i;
+            yRows[indexY]     = yuvSeg[0];
+            yRows[indexY + 1] = yuvSeg[2];
+            uRows[indexU]     = yuvSeg[1];
+            vRows[indexU]     = yuvSeg[3];
+            yuvSeg           += 4;
+        }
+    }
+}
+
+void Yuv422IToJpegEncoder::configSamplingFactors(jpeg_compress_struct *cinfo) {
+    // cb and cr are horizontally downsampled and vertically downsampled as
+    // well.
+    cinfo->comp_info[0].h_samp_factor = 2;
+    cinfo->comp_info[0].v_samp_factor = 2;
+    cinfo->comp_info[1].h_samp_factor = 1;
+    cinfo->comp_info[1].v_samp_factor = 2;
+    cinfo->comp_info[2].h_samp_factor = 1;
+    cinfo->comp_info[2].v_samp_factor = 2;
+}
+
+int Yuv422IToJpegEncoder::yuvResize(uint8_t *srcBuf,
+                                    int      srcWidth,
+                                    int      srcHeight,
+                                    uint8_t *dstBuf,
+                                    int      dstWidth,
+                                    int      dstHeight)
+{
+    int i, j, s;
+    int h_offset;
+    int v_offset;
+    unsigned char *ptr, cc;
+    int h_scale_ratio;
+    int v_scale_ratio;
+
+    s = 0;
+
+_resize_begin:
+
+    if (!dstWidth) return -1;
+
+    if (!dstHeight) return -1;
+
+    h_scale_ratio = srcWidth / dstWidth;
+    if (!h_scale_ratio) return -1;
+
+    v_scale_ratio = srcHeight / dstHeight;
+    if (!v_scale_ratio) return -1;
+
+    h_offset = (srcWidth - dstWidth * h_scale_ratio) / 2;
+    v_offset = (srcHeight - dstHeight * v_scale_ratio) / 2;
+
+    for (i = 0; i < dstHeight * v_scale_ratio; i += v_scale_ratio)
+    {
+        for (j = 0; j < dstWidth * h_scale_ratio; j += h_scale_ratio)
+        {
+            ptr = srcBuf + i * srcWidth + j + v_offset * srcWidth + h_offset;
+            cc  = ptr[0];
+
+            ptr    = dstBuf + (i / v_scale_ratio) * dstWidth + (j / h_scale_ratio);
+            ptr[0] = cc;
+        }
+    }
+
+    srcBuf += srcWidth * srcHeight;
+    dstBuf += dstWidth * dstHeight;
+
+    if (s < 2)
+    {
+        if (!s++)
+        {
+            srcWidth  >>= 1;
+            srcHeight >>= 1;
+
+            dstWidth  >>= 1;
+            dstHeight >>= 1;
+        }
+
+        goto _resize_begin;
+    }
+
+    return 0;
+}
+
+void jpegBuilder_error_exit(j_common_ptr cinfo)
+{
+    jpegBuilder_error_mgr *error = (jpegBuilder_error_mgr *)cinfo->err;
+
+    (*error->output_message)(cinfo);
+
+    /* Let the memory manager delete any temp files before we die */
+    jpeg_destroy(cinfo);
+
+    longjmp(error->fJmpBuf, -1);
+}
+
+static void jpegBuilder_init_destination(j_compress_ptr cinfo) {
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
+
+    dest->next_output_byte = dest->buf;
+    dest->free_in_buffer   = dest->bufsize;
+    dest->jpegsize         = 0;
+}
+
+static boolean jpegBuilder_empty_output_buffer(j_compress_ptr cinfo) {
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
+
+    dest->next_output_byte = dest->buf;
+    dest->free_in_buffer   = dest->bufsize;
+    return TRUE; // ?
+}
+
+static void jpegBuilder_term_destination(j_compress_ptr cinfo) {
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
+
+    dest->jpegsize = dest->bufsize - dest->free_in_buffer;
+}
+
+jpegBuilder_destination_mgr::jpegBuilder_destination_mgr(uint8_t *input,
+                                                         int      size) {
+    this->init_destination    = jpegBuilder_init_destination;
+    this->empty_output_buffer = jpegBuilder_empty_output_buffer;
+    this->term_destination    = jpegBuilder_term_destination;
+
+    this->buf     = input;
+    this->bufsize = size;
+
+    jpegsize = 0;
+}
+
diff --git a/mx6/libcamera3/YuvToJpegEncoder.h b/mx6/libcamera3/YuvToJpegEncoder.h
new file mode 100644
index 0000000..b374709
--- /dev/null
+++ b/mx6/libcamera3/YuvToJpegEncoder.h
@@ -0,0 +1,151 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef YuvToJpegEncoder_DEFINED
+#define YuvToJpegEncoder_DEFINED
+
+#include <string.h>
+#include <unistd.h>
+#include <time.h>
+#include <dlfcn.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <linux/time.h>
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include "CameraUtils.h"
+
+extern "C" {
+    #include "jpeglib.h"
+    #include "jerror.h"
+}
+#include <setjmp.h>
+
+class YuvToJpegEncoder {
+public:
+    /** Create an encoder based on the YUV format.
+     */
+    static YuvToJpegEncoder* create(int pixelFormat);
+
+    YuvToJpegEncoder();
+
+    /** Encode YUV data to jpeg,  which is output to a stream.
+     */
+    int encode(void *inYuv,
+               void* inYuvPhy,
+               int   inWidth,
+               int   inHeight,
+               int   quality,
+               void *outBuf,
+               int   outSize,
+               int   outWidth,
+               int   outHeight);
+
+    virtual ~YuvToJpegEncoder() {}
+
+protected:
+    int fNumPlanes;
+    int color;
+
+    void setJpegCompressStruct(jpeg_compress_struct *cinfo,
+                               int                   width,
+                               int                   height,
+                               int                   quality);
+    virtual void configSamplingFactors(jpeg_compress_struct *cinfo) = 0;
+    virtual void compress(jpeg_compress_struct *cinfo,
+                          uint8_t              *yuv)                = 0;
+    virtual int  yuvResize(uint8_t *srcBuf,
+                           int      srcWidth,
+                           int      srcHeight,
+                           uint8_t *dstBuf,
+                           int      dstWidth,
+                           int      dstHeight) = 0;
+    bool supportVpu;
+};
+
+class Yuv420SpToJpegEncoder : public YuvToJpegEncoder {
+public:
+    Yuv420SpToJpegEncoder();
+    virtual ~Yuv420SpToJpegEncoder() {}
+
+private:
+    void configSamplingFactors(jpeg_compress_struct *cinfo);
+    void deinterleaveYuv(uint8_t   *yuv,
+                         int        width,
+                         int        height,
+                         uint8_t *& yPlanar,
+                         uint8_t *& uPlanar,
+                         uint8_t *& vPlanar);
+    void deinterleave(uint8_t *vuPlanar,
+                      uint8_t *uRows,
+                      uint8_t *vRows,
+                      int      rowIndex,
+                      int      width,
+                      int      height);
+    void        compress(jpeg_compress_struct *cinfo,
+                         uint8_t              *yuv);
+    virtual int yuvResize(uint8_t *srcBuf,
+                          int      srcWidth,
+                          int      srcHeight,
+                          uint8_t *dstBuf,
+                          int      dstWidth,
+                          int      dstHeight);
+};
+
+class Yuv422IToJpegEncoder : public YuvToJpegEncoder {
+public:
+    Yuv422IToJpegEncoder();
+    virtual ~Yuv422IToJpegEncoder() {}
+
+private:
+    void configSamplingFactors(jpeg_compress_struct *cinfo);
+    void compress(jpeg_compress_struct *cinfo,
+                  uint8_t              *yuv);
+    void deinterleave(uint8_t *yuv,
+                      uint8_t *yRows,
+                      uint8_t *uRows,
+                      uint8_t *vRows,
+                      int      rowIndex,
+                      int      width,
+                      int      height);
+    virtual int yuvResize(uint8_t *srcBuf,
+                          int      srcWidth,
+                          int      srcHeight,
+                          uint8_t *dstBuf,
+                          int      dstWidth,
+                          int      dstHeight);
+};
+
+struct jpegBuilder_destination_mgr : jpeg_destination_mgr {
+    jpegBuilder_destination_mgr(uint8_t *input,
+                                int size);
+
+    uint8_t *buf;
+    int      bufsize;
+    size_t   jpegsize;
+};
+
+
+struct jpegBuilder_error_mgr : jpeg_error_mgr {
+    jmp_buf fJmpBuf;
+};
+
+void jpegBuilder_error_exit(j_common_ptr cinfo);
+
+#endif // ifndef YuvToJpegEncoder_DEFINED
-- 
1.8.0

