From dd227fd9bbe93c1fe44567b65df1fcf1b800a0c7 Mon Sep 17 00:00:00 2001
From: Xiaowen Liu <b37945@freescale.com>
Date: Tue, 27 Nov 2012 16:36:45 +0800
Subject: [PATCH 375/635] ENGR00215174 adjust the coding style.

adjust coding style to match android code style.

Change-Id: Idedf8c5f67599e975d32da5a52fc451f7ed3b7be
Signed-off-by: Xiaowen Liu <b37945@freescale.com>
---
 mx6/libcamera/CameraBridge.cpp     | 524 +++++++++++++++++++++++--------------
 mx6/libcamera/CameraBridge.h       |  88 ++++---
 mx6/libcamera/CameraHal.cpp        | 204 +++++++++------
 mx6/libcamera/CameraHal.h          |  61 ++---
 mx6/libcamera/CameraModule.cpp     | 486 ++++++++++++++++++----------------
 mx6/libcamera/CameraUtil.cpp       | 194 +++++++-------
 mx6/libcamera/CameraUtil.h         | 182 ++++++-------
 mx6/libcamera/DeviceAdapter.cpp    | 299 +++++++++++----------
 mx6/libcamera/DeviceAdapter.h      |  92 ++++---
 mx6/libcamera/DisplayAdapter.cpp   | 102 ++++----
 mx6/libcamera/DisplayAdapter.h     |  36 +--
 mx6/libcamera/JpegBuilder.cpp      | 416 +++++++++++++++--------------
 mx6/libcamera/JpegBuilder.h        | 181 +++++++------
 mx6/libcamera/OvDevice.cpp         | 256 +++++++++++-------
 mx6/libcamera/OvDevice.h           |  22 +-
 mx6/libcamera/PhysMemAdapter.cpp   |  84 +++---
 mx6/libcamera/PhysMemAdapter.h     |  19 +-
 mx6/libcamera/SurfaceAdapter.cpp   | 193 ++++++++------
 mx6/libcamera/SurfaceAdapter.h     |  45 ++--
 mx6/libcamera/UvcDevice.h          |  39 ++-
 mx6/libcamera/YuvToJpegEncoder.cpp | 297 ++++++++++++---------
 mx6/libcamera/YuvToJpegEncoder.h   |  98 ++++---
 mx6/libcamera/messageQueue.cpp     |  51 ++--
 mx6/libcamera/messageQueue.h       |  66 +++--
 24 files changed, 2313 insertions(+), 1722 deletions(-)
 mode change 100755 => 100644 mx6/libcamera/CameraBridge.cpp
 mode change 100755 => 100644 mx6/libcamera/CameraBridge.h
 mode change 100755 => 100644 mx6/libcamera/CameraHal.cpp
 mode change 100755 => 100644 mx6/libcamera/CameraHal.h
 mode change 100755 => 100644 mx6/libcamera/CameraModule.cpp
 mode change 100755 => 100644 mx6/libcamera/CameraUtil.cpp
 mode change 100755 => 100644 mx6/libcamera/CameraUtil.h
 mode change 100755 => 100644 mx6/libcamera/DeviceAdapter.cpp
 mode change 100755 => 100644 mx6/libcamera/DeviceAdapter.h
 mode change 100755 => 100644 mx6/libcamera/DisplayAdapter.cpp
 mode change 100755 => 100644 mx6/libcamera/DisplayAdapter.h
 mode change 100755 => 100644 mx6/libcamera/JpegBuilder.cpp
 mode change 100755 => 100644 mx6/libcamera/JpegBuilder.h
 mode change 100755 => 100644 mx6/libcamera/OvDevice.cpp
 mode change 100755 => 100644 mx6/libcamera/OvDevice.h
 mode change 100755 => 100644 mx6/libcamera/SurfaceAdapter.cpp
 mode change 100755 => 100644 mx6/libcamera/SurfaceAdapter.h
 mode change 100755 => 100644 mx6/libcamera/UvcDevice.h
 mode change 100755 => 100644 mx6/libcamera/YuvToJpegEncoder.cpp
 mode change 100755 => 100644 mx6/libcamera/YuvToJpegEncoder.h
 mode change 100755 => 100644 mx6/libcamera/messageQueue.cpp
 mode change 100755 => 100644 mx6/libcamera/messageQueue.h

diff --git a/mx6/libcamera/CameraBridge.cpp b/mx6/libcamera/CameraBridge.cpp
old mode 100755
new mode 100644
index 8e2ac91..9f948ac
--- a/mx6/libcamera/CameraBridge.cpp
+++ b/mx6/libcamera/CameraBridge.cpp
@@ -29,21 +29,21 @@ CameraBridge::CameraBridge()
 {
     memset(mSupprotedThumbnailSizes, 0, sizeof(mSupprotedThumbnailSizes));
     mMetaDataBufsMap.clear();
-    mVpuSupportFmt[0] = v4l2_fourcc('N','V','1','2');
-    mVpuSupportFmt[1] = v4l2_fourcc('Y','U','1','2');
+    mVpuSupportFmt[0] = v4l2_fourcc('N', 'V', '1', '2');
+    mVpuSupportFmt[1] = v4l2_fourcc('Y', 'U', '1', '2');
 }
 
 CameraBridge::~CameraBridge()
 {
-    if(mFrameProvider != NULL) {
+    if (mFrameProvider != NULL) {
         mFrameProvider->removeFrameListener(this);
     }
 
-    if(mEventProvider != NULL) {
+    if (mEventProvider != NULL) {
         mEventProvider->removeEventListener(this);
     }
 
-    if(mBridgeThread != NULL) {
+    if (mBridgeThread != NULL) {
         mThreadQueue.postSyncMessage(new SyncMessage(BridgeThread::BRIDGE_EXIT, 0));
         mBridgeThread->requestExitAndWait();
         mBridgeThread.clear();
@@ -52,36 +52,38 @@ CameraBridge::~CameraBridge()
 
 status_t CameraBridge::initialize()
 {
-    ///Create the app notifier thread
+    // /Create the app notifier thread
     mBridgeThread = new BridgeThread(this);
-    if(!mBridgeThread.get()) {
+    if (!mBridgeThread.get()) {
         FLOGE("Couldn't create bridge thread");
         return NO_MEMORY;
     }
 
-    ///Start the display thread
+    // /Start the display thread
     status_t ret = mBridgeThread->run("BridgeThread", PRIORITY_URGENT_DISPLAY);
-    if(ret!=NO_ERROR) {
+    if (ret != NO_ERROR) {
         FLOGE("Couldn't run BridgeThread");
         mBridgeThread.clear();
         return ret;
     }
 
     mUseMetaDataBufferMode = false;
-    mBridgeState = CameraBridge::BRIDGE_INIT;
-    mJpegBuilder = new JpegBuilder();
-    if(mJpegBuilder == NULL) {
+    mBridgeState           = CameraBridge::BRIDGE_INIT;
+    mJpegBuilder           = new JpegBuilder();
+    if (mJpegBuilder == NULL) {
         FLOGE("Couldn't create JpegBuilder");
         return NO_MEMORY;
     }
-    ret = mJpegBuilder->getSupportedPictureFormat(mPictureSupportFmt, MAX_PICTURE_SUPPORT_FORMAT);
+    ret = mJpegBuilder->getSupportedPictureFormat(mPictureSupportFmt,
+                                                  MAX_PICTURE_SUPPORT_FORMAT);
 
     return ret;
 }
 
-status_t CameraBridge::getSupportedRecordingFormat(int* pFormat, int len)
+status_t CameraBridge::getSupportedRecordingFormat(int *pFormat,
+                                                   int  len)
 {
-    if(pFormat != 0 && len > 0) {
+    if ((pFormat != 0) && (len > 0)) {
         memcpy(pFormat, mVpuSupportFmt, len * sizeof(pFormat[0]));
         return NO_ERROR;
     }
@@ -89,9 +91,10 @@ status_t CameraBridge::getSupportedRecordingFormat(int* pFormat, int len)
     return BAD_VALUE;
 }
 
-status_t CameraBridge::getSupportedPictureFormat(int* pFormat, int len)
+status_t CameraBridge::getSupportedPictureFormat(int *pFormat,
+                                                 int  len)
 {
-    if(pFormat != 0 && len > 0) {
+    if ((pFormat != 0) && (len > 0)) {
         memcpy(pFormat, mPictureSupportFmt, len * sizeof(pFormat[0]));
         return NO_ERROR;
     }
@@ -106,59 +109,127 @@ status_t CameraBridge::initParameters(CameraParameters& params)
     /*hard code here*/
     params.set(CameraParameters::KEY_FOCUS_DISTANCES, "24.0,50.0,2147483648.0");
     params.setPictureFormat(CameraParameters::PIXEL_FORMAT_JPEG);
-    params.set(CameraParameters::KEY_SUPPORTED_PICTURE_FORMATS, CameraParameters::PIXEL_FORMAT_JPEG);
+    params.set(CameraParameters::KEY_SUPPORTED_PICTURE_FORMATS,
+               CameraParameters::PIXEL_FORMAT_JPEG);
     params.set(CameraParameters::KEY_JPEG_QUALITY, 100);
     strcpy(mSupprotedThumbnailSizes, "0x0,128x128,96x96");
-    params.set(CameraParameters::KEY_SUPPORTED_JPEG_THUMBNAIL_SIZES, mSupprotedThumbnailSizes);
+    params.set(CameraParameters::KEY_SUPPORTED_JPEG_THUMBNAIL_SIZES,
+               mSupprotedThumbnailSizes);
     params.set(CameraParameters::KEY_JPEG_THUMBNAIL_WIDTH, "96");
     params.set(CameraParameters::KEY_JPEG_THUMBNAIL_HEIGHT, "96");
     params.set(CameraParameters::KEY_JPEG_THUMBNAIL_QUALITY, "90");
 
     memset(tmpBuffer, '\0', sizeof(*tmpBuffer));
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::WHITE_BALANCE_AUTO, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::WHITE_BALANCE_INCANDESCENT, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::WHITE_BALANCE_FLUORESCENT, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::WHITE_BALANCE_DAYLIGHT, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::WHITE_BALANCE_SHADE, CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::WHITE_BALANCE_AUTO,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::WHITE_BALANCE_INCANDESCENT,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::WHITE_BALANCE_FLUORESCENT,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::WHITE_BALANCE_DAYLIGHT,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::WHITE_BALANCE_SHADE,
+            CAMER_PARAM_BUFFER_SIZE);
     params.set(CameraParameters::KEY_SUPPORTED_WHITE_BALANCE, tmpBuffer);
-    params.set(CameraParameters::KEY_WHITE_BALANCE, CameraParameters::WHITE_BALANCE_AUTO);
+    params.set(CameraParameters::KEY_WHITE_BALANCE,
+               CameraParameters::WHITE_BALANCE_AUTO);
 
     memset(tmpBuffer, '\0', sizeof(*tmpBuffer));
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::EFFECT_NONE, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::EFFECT_MONO, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::EFFECT_NEGATIVE, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::EFFECT_SOLARIZE,  CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::EFFECT_SEPIA, CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::EFFECT_NONE,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::EFFECT_MONO,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::EFFECT_NEGATIVE,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::EFFECT_SOLARIZE,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::EFFECT_SEPIA,
+            CAMER_PARAM_BUFFER_SIZE);
     params.set(CameraParameters::KEY_SUPPORTED_EFFECTS, tmpBuffer);
     params.set(CameraParameters::KEY_EFFECT, CameraParameters::EFFECT_NONE);
 
     memset(tmpBuffer, '\0', sizeof(*tmpBuffer));
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::SCENE_MODE_AUTO, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::SCENE_MODE_PORTRAIT, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::SCENE_MODE_LANDSCAPE, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::SCENE_MODE_SPORTS, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::SCENE_MODE_NIGHT_PORTRAIT, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::SCENE_MODE_FIREWORKS, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::SCENE_MODE_NIGHT, CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::SCENE_MODE_AUTO,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::SCENE_MODE_PORTRAIT,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::SCENE_MODE_LANDSCAPE,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::SCENE_MODE_SPORTS,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::SCENE_MODE_NIGHT_PORTRAIT,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::SCENE_MODE_FIREWORKS,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::SCENE_MODE_NIGHT,
+            CAMER_PARAM_BUFFER_SIZE);
     params.set(CameraParameters::KEY_SUPPORTED_SCENE_MODES, tmpBuffer);
-    params.set(CameraParameters::KEY_SCENE_MODE, CameraParameters::SCENE_MODE_AUTO);
+    params.set(CameraParameters::KEY_SCENE_MODE,
+               CameraParameters::SCENE_MODE_AUTO);
 
-    params.set(CameraParameters::KEY_SUPPORTED_FOCUS_MODES, CameraParameters::FOCUS_MODE_AUTO);
-    params.set(CameraParameters::KEY_FOCUS_MODE, CameraParameters::FOCUS_MODE_AUTO);
+    params.set(CameraParameters::KEY_SUPPORTED_FOCUS_MODES,
+               CameraParameters::FOCUS_MODE_AUTO);
+    params.set(CameraParameters::KEY_FOCUS_MODE,
+               CameraParameters::FOCUS_MODE_AUTO);
 
     params.set(CameraParameters::KEY_FOCAL_LENGTH, "10.001");
     params.set(CameraParameters::KEY_HORIZONTAL_VIEW_ANGLE, "54.8");
@@ -169,47 +240,63 @@ status_t CameraBridge::initParameters(CameraParameters& params)
     params.set(CameraParameters::KEY_EXPOSURE_COMPENSATION_STEP, "0.0");
 
     memset(tmpBuffer, '\0', sizeof(*tmpBuffer));
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::ANTIBANDING_50HZ, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::ANTIBANDING_60HZ, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-    strncat((char*) tmpBuffer, (const char*) CameraParameters::ANTIBANDING_OFF, CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::ANTIBANDING_50HZ,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::ANTIBANDING_60HZ,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)PARAMS_DELIMITER,
+            CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::ANTIBANDING_OFF,
+            CAMER_PARAM_BUFFER_SIZE);
     params.set(CameraParameters::KEY_SUPPORTED_ANTIBANDING, tmpBuffer);
-    params.set(CameraParameters::KEY_ANTIBANDING, CameraParameters::ANTIBANDING_OFF);
+    params.set(CameraParameters::KEY_ANTIBANDING,
+               CameraParameters::ANTIBANDING_OFF);
 
     memset(tmpBuffer, '\0', sizeof(*tmpBuffer));
-    strncat( (char*) tmpBuffer, (const char*) CameraParameters::FLASH_MODE_OFF, CAMER_PARAM_BUFFER_SIZE);
+    strncat((char *)tmpBuffer,
+            (const char *)CameraParameters::FLASH_MODE_OFF,
+            CAMER_PARAM_BUFFER_SIZE);
     params.set(CameraParameters::KEY_SUPPORTED_FLASH_MODES, tmpBuffer);
     params.set(CameraParameters::KEY_FLASH_MODE, CameraParameters::FLASH_MODE_OFF);
     params.set(CameraParameters::KEY_ZOOM_SUPPORTED, "true");
-    //params.set(CameraParameters::KEY_ZOOM_SUPPORTED, CameraParameters::TRUE);
+
+    // params.set(CameraParameters::KEY_ZOOM_SUPPORTED, CameraParameters::TRUE);
     params.set(CameraParameters::KEY_MAX_ZOOM, "1");
+
     // default zoom should be 0 as CTS defined
     params.set(CameraParameters::KEY_ZOOM, "0");
-    //the zoom ratios in 1/100 increments. Ex: a zoom of 3.2x is
-    //returned as 320. The number of elements is {@link
-    //#getMaxZoom} + 1. The list is sorted from small to large. The
-    //first element is always 100. The last element is the zoom
-    //ratio of the maximum zoom value.
+
+    // the zoom ratios in 1/100 increments. Ex: a zoom of 3.2x is
+    // returned as 320. The number of elements is {@link
+    // #getMaxZoom} + 1. The list is sorted from small to large. The
+    // first element is always 100. The last element is the zoom
+    // ratio of the maximum zoom value.
     params.set(CameraParameters::KEY_ZOOM_RATIOS, "100,200");
 
     mParameters = params;
     return NO_ERROR;
 }
 
-void CameraBridge::setCallbacks(camera_notify_callback notify_cb,
-                                camera_data_callback data_cb,
+void CameraBridge::setCallbacks(camera_notify_callback         notify_cb,
+                                camera_data_callback           data_cb,
                                 camera_data_timestamp_callback data_cb_timestamp,
-                                camera_request_memory get_memory,
-                                void *user)
+                                camera_request_memory          get_memory,
+                                void                          *user)
 {
     Mutex::Autolock lock(mLock);
 
-    mNotifyCb = notify_cb;
-    mDataCb = data_cb;
+    mNotifyCb        = notify_cb;
+    mDataCb          = data_cb;
     mDataCbTimestamp = data_cb_timestamp;
-    mRequestMemory = get_memory;
-    mCallbackCookie = user;
+    mRequestMemory   = get_memory;
+    mCallbackCookie  = user;
 }
 
 status_t CameraBridge::setParameters(CameraParameters& params)
@@ -217,19 +304,31 @@ status_t CameraBridge::setParameters(CameraParameters& params)
     Mutex::Autolock lock(mLock);
 
     const char *pFlashStr;
+
     pFlashStr = params.get(CameraParameters::KEY_FLASH_MODE);
-    if (strcmp(pFlashStr, CameraParameters::FLASH_MODE_OFF) != 0 && strcmp(pFlashStr, CameraParameters::FLASH_MODE_AUTO) != 0
-            && strcmp(pFlashStr, CameraParameters::FLASH_MODE_ON) != 0 && strcmp(pFlashStr, CameraParameters::FLASH_MODE_RED_EYE) != 0
-            && strcmp(pFlashStr, CameraParameters::FLASH_MODE_TORCH) != 0) {
+    if ((strcmp(pFlashStr,
+                CameraParameters::FLASH_MODE_OFF) != 0) &&
+        (strcmp(pFlashStr, CameraParameters::FLASH_MODE_AUTO) != 0)
+        && (strcmp(pFlashStr,
+                   CameraParameters::FLASH_MODE_ON) != 0) &&
+        (strcmp(pFlashStr, CameraParameters::FLASH_MODE_RED_EYE) != 0)
+        && (strcmp(pFlashStr, CameraParameters::FLASH_MODE_TORCH) != 0)) {
         FLOGE("The flash mode is not corrected");
         return BAD_VALUE;
     }
 
     const char *pFocusStr;
     pFocusStr = params.get(CameraParameters::KEY_FOCUS_MODE);
-    if(strcmp(pFocusStr, CameraParameters::FOCUS_MODE_AUTO) != 0 && strcmp(pFocusStr, CameraParameters::FOCUS_MODE_INFINITY) != 0
-            && strcmp(pFocusStr, CameraParameters::FOCUS_MODE_MACRO) != 0 && strcmp(pFocusStr, CameraParameters::FOCUS_MODE_FIXED) != 0
-            && strcmp(pFocusStr, CameraParameters::FOCUS_MODE_EDOF) != 0 && strcmp(pFocusStr, CameraParameters::FOCUS_MODE_CONTINUOUS_VIDEO) != 0) {
+    if ((strcmp(pFocusStr,
+                CameraParameters::FOCUS_MODE_AUTO) != 0) &&
+        (strcmp(pFocusStr, CameraParameters::FOCUS_MODE_INFINITY) != 0)
+        && (strcmp(pFocusStr,
+                   CameraParameters::FOCUS_MODE_MACRO) != 0) &&
+        (strcmp(pFocusStr, CameraParameters::FOCUS_MODE_FIXED) != 0)
+        && (strcmp(pFocusStr,
+                   CameraParameters::FOCUS_MODE_EDOF) != 0) &&
+        (strcmp(pFocusStr,
+                CameraParameters::FOCUS_MODE_CONTINUOUS_VIDEO) != 0)) {
         FLOGE("The focus mode is not corrected");
         return BAD_VALUE;
     }
@@ -238,17 +337,18 @@ status_t CameraBridge::setParameters(CameraParameters& params)
     return NO_ERROR;
 }
 
-void CameraBridge::setCameraFrameProvider(CameraFrameProvider* frameProvider)
+void CameraBridge::setCameraFrameProvider(CameraFrameProvider *frameProvider)
 {
-    if(frameProvider != NULL) {
+    if (frameProvider != NULL) {
         frameProvider->addFrameListener(this);
     }
     mFrameProvider = frameProvider;
 }
 
-void CameraBridge::setCameraEventProvider(int32_t msgs, CameraEventProvider* eventProvider)
+void CameraBridge::setCameraEventProvider(int32_t              msgs,
+                                          CameraEventProvider *eventProvider)
 {
-    if(eventProvider != NULL) {
+    if (eventProvider != NULL) {
         eventProvider->addEventListener(this);
     }
     mEventProvider = eventProvider;
@@ -284,7 +384,8 @@ status_t CameraBridge::useMetaDataBufferMode(bool enable)
 status_t CameraBridge::startRecording()
 {
     Mutex::Autolock lock(mRecordingLock);
-    if(mRecording) {
+
+    if (mRecording) {
         FLOGW("CameraBridge has started Recording");
         return ALREADY_EXISTS;
     }
@@ -298,7 +399,8 @@ status_t CameraBridge::startRecording()
 status_t CameraBridge::stopRecording()
 {
     Mutex::Autolock lock(mRecordingLock);
-    if(!mRecording) {
+
+    if (!mRecording) {
         FLOGW("CameraBridge has not started Recording");
         return NO_INIT;
     }
@@ -311,36 +413,36 @@ status_t CameraBridge::stopRecording()
 
 status_t CameraBridge::start()
 {
-    if(mBridgeState == CameraBridge::BRIDGE_STARTED) {
+    if (mBridgeState == CameraBridge::BRIDGE_STARTED) {
         FLOGW("CameraBridge already running");
         return ALREADY_EXISTS;
     }
 
     Mutex::Autolock lock(mLock);
-    if(!mFrameProvider) {
+    if (!mFrameProvider) {
         FLOGE("CameraBridge: frameProvider does not initialize");
         return NO_INIT;
     }
-    if(!mEventProvider) {
+    if (!mEventProvider) {
         FLOGE("CameraBridge: eventProvider does not initialize");
         return NO_INIT;
     }
 
     int bufSize = mFrameProvider->getFrameSize();
-    int bufCnt = mFrameProvider->getFrameCount();
-    if(mMsgEnabled & CAMERA_MSG_PREVIEW_FRAME) {
-        if(mPreviewMemory != NULL) {
+    int bufCnt  = mFrameProvider->getFrameCount();
+    if (mMsgEnabled & CAMERA_MSG_PREVIEW_FRAME) {
+        if (mPreviewMemory != NULL) {
             mPreviewMemory->release(mPreviewMemory);
             mPreviewMemory = NULL;
         }
 
         mPreviewMemory = mRequestMemory(-1, bufSize, bufCnt, NULL);
-        if(mPreviewMemory == NULL) {
+        if (mPreviewMemory == NULL) {
             FLOGE("CameraBridge: notifyBufferCreat mRequestMemory failed");
         }
     }
 
-    mBufferSize = bufSize;
+    mBufferSize  = bufSize;
     mBufferCount = bufCnt;
     mThreadQueue.postSyncMessage(new SyncMessage(BridgeThread::BRIDGE_START, 0));
     FSL_ASSERT(mFrameProvider.get() != NULL);
@@ -351,7 +453,7 @@ status_t CameraBridge::start()
 
 status_t CameraBridge::stop()
 {
-    if(mBridgeState == CameraBridge::BRIDGE_STOPPED) {
+    if (mBridgeState == CameraBridge::BRIDGE_STOPPED) {
         FLOGW("CameraBridge already stopped");
         return ALREADY_EXISTS;
     }
@@ -369,12 +471,12 @@ bool CameraBridge::bridgeThread()
     bool shouldLive = true;
 
     sp<CMessage> msg = mThreadQueue.waitMessage();
-    if(msg == 0) {
+    if (msg == 0) {
         FLOGE("displayThread: get invalid message");
         return false;
     }
 
-    switch(msg->what) {
+    switch (msg->what) {
         case BridgeThread::BRIDGE_START:
             FLOGI("BridgeThread received BRIDGE_START command from Camera HAL");
             mBridgeState = CameraBridge::BRIDGE_STARTED;
@@ -387,26 +489,28 @@ bool CameraBridge::bridgeThread()
 
         case BridgeThread::BRIDGE_EVENT:
             FLOGI("BridgeThread received BRIDGE_EVENT command from Camera HAL");
-            if(mBridgeState == CameraBridge::BRIDGE_INIT) {
+            if (mBridgeState == CameraBridge::BRIDGE_INIT) {
                 break;
             }
-            if(mBridgeState == CameraBridge::BRIDGE_STARTED) {
-                shouldLive = processEvent((CameraEvent*)msg->arg0);
+            if (mBridgeState == CameraBridge::BRIDGE_STARTED) {
+                shouldLive = processEvent((CameraEvent *)msg->arg0);
             }
-            if(mBridgeState == CameraBridge::BRIDGE_EXITED) {
+            if (mBridgeState == CameraBridge::BRIDGE_EXITED) {
                 shouldLive = false;
             }
             break;
 
         case BridgeThread::BRIDGE_FRAME:
-            //FLOGI("BridgeThread received BRIDGE_FRAME command from Camera HAL");
-            if(mBridgeState == CameraBridge::BRIDGE_INIT) {
+
+            // FLOGI("BridgeThread received BRIDGE_FRAME command from Camera
+            // HAL");
+            if (mBridgeState == CameraBridge::BRIDGE_INIT) {
                 break;
             }
-            if(mBridgeState == CameraBridge::BRIDGE_STARTED) {
-                shouldLive = processFrame((CameraFrame*)msg->arg0);
+            if (mBridgeState == CameraBridge::BRIDGE_STARTED) {
+                shouldLive = processFrame((CameraFrame *)msg->arg0);
             }
-            if(mBridgeState == CameraBridge::BRIDGE_EXITED) {
+            if (mBridgeState == CameraBridge::BRIDGE_EXITED) {
                 shouldLive = false;
             }
             break;
@@ -421,26 +525,26 @@ bool CameraBridge::bridgeThread()
     return shouldLive;
 }
 
-bool CameraBridge::processEvent(CameraEvent* event)
+bool CameraBridge::processEvent(CameraEvent *event)
 {
-    ///Receive and send the event notifications to app
+    // /Receive and send the event notifications to app
     bool ret = true;
 
-    if(NULL == event) {
+    if (NULL == event) {
         FLOGE("CameraBridge: processEvent receive null event");
         return false;
     }
 
-    switch(event->mEventType) {
+    switch (event->mEventType) {
         case CameraEvent::EVENT_SHUTTER:
-            if((NULL != mNotifyCb) && (mMsgEnabled & CAMERA_MSG_SHUTTER)) {
+            if ((NULL != mNotifyCb) && (mMsgEnabled & CAMERA_MSG_SHUTTER)) {
                 mNotifyCb(CAMERA_MSG_SHUTTER, 0, 0, mCallbackCookie);
             }
 
             break;
 
         case CameraEvent::EVENT_FOCUS:
-            if((NULL != mNotifyCb) && (mMsgEnabled & CAMERA_MSG_FOCUS)) {
+            if ((NULL != mNotifyCb) && (mMsgEnabled & CAMERA_MSG_FOCUS)) {
                 mNotifyCb(CAMERA_MSG_FOCUS, true, 0, mCallbackCookie);
             }
 
@@ -455,147 +559,168 @@ bool CameraBridge::processEvent(CameraEvent* event)
     return ret;
 }
 
-bool CameraBridge::processFrame(CameraFrame* frame)
+bool CameraBridge::processFrame(CameraFrame *frame)
 {
     MemoryHeapBase *heap;
-    MemoryBase *buffer = NULL;
+    MemoryBase     *buffer = NULL;
+
     sp<MemoryBase> memBase;
     void *buf = NULL;
 
     bool ret = true;
 
-    if(!frame || !frame->mBufHandle) {
+    if (!frame || !frame->mBufHandle) {
         FLOGE("CameraBridge: processFrame receive null frame");
         return false;
     }
 
-    if((frame->mFrameType & CameraFrame::IMAGE_FRAME)) {
-        if((mMsgEnabled & CAMERA_MSG_RAW_IMAGE) && (NULL != mDataCb)) {
+    if ((frame->mFrameType & CameraFrame::IMAGE_FRAME)) {
+        if ((mMsgEnabled & CAMERA_MSG_RAW_IMAGE) && (NULL != mDataCb)) {
             sendRawImageFrame(frame);
         }
 
-        if(mMsgEnabled & CAMERA_MSG_RAW_IMAGE_NOTIFY && mNotifyCb != NULL) {
+        if (mMsgEnabled & CAMERA_MSG_RAW_IMAGE_NOTIFY && (mNotifyCb != NULL)) {
             mNotifyCb(CAMERA_MSG_RAW_IMAGE_NOTIFY, 0, 0, mCallbackCookie);
         }
 
-        if(mMsgEnabled & CAMERA_MSG_COMPRESSED_IMAGE) {
+        if (mMsgEnabled & CAMERA_MSG_COMPRESSED_IMAGE) {
             ret = processImageFrame(frame);
         }
     }
-    else if(frame->mFrameType & CameraFrame::PREVIEW_FRAME) {
-        if((mMsgEnabled & CAMERA_MSG_VIDEO_FRAME) && (NULL != mDataCbTimestamp)) {
+    else if (frame->mFrameType & CameraFrame::PREVIEW_FRAME) {
+        if ((mMsgEnabled & CAMERA_MSG_VIDEO_FRAME) &&
+            (NULL != mDataCbTimestamp)) {
             sendVideoFrame(frame);
         }
 
-        if((mMsgEnabled & CAMERA_MSG_PREVIEW_FRAME) && (NULL != mDataCb)) {
+        if ((mMsgEnabled & CAMERA_MSG_PREVIEW_FRAME) && (NULL != mDataCb)) {
             sendPreviewFrame(frame);
         }
     }
 
-    //the frame release from CameraBridge.
+    // the frame release from CameraBridge.
     frame->release();
     return ret;
 }
 
-bool CameraBridge::processImageFrame(CameraFrame* frame)
+bool CameraBridge::processImageFrame(CameraFrame *frame)
 {
     FSL_ASSERT(frame);
-    status_t ret = NO_ERROR;
+    status_t ret      = NO_ERROR;
     int encodeQuality = 100, thumbQuality = 100;
     int thumbWidth, thumbHeight;
     JpegParams *mainJpeg = NULL, *thumbJpeg = NULL;
-    void* rawBuf = NULL, *thumbBuf = NULL;
+    void *rawBuf         = NULL, *thumbBuf = NULL;
 
-    camera_memory_t* rawFrame = mRequestMemory(-1, frame->mSize, 1, NULL);
-    if(!rawFrame || !rawFrame->data) {
+    camera_memory_t *rawFrame = mRequestMemory(-1, frame->mSize, 1, NULL);
+    if (!rawFrame || !rawFrame->data) {
         FLOGE("CameraBridge:processImageFrame mRequestMemory rawFrame failed");
         return false;
     }
     rawBuf = rawFrame->data;
 
-    camera_memory_t* thumbFrame = mRequestMemory(-1, frame->mSize, 1, NULL);
-    if(!thumbFrame || !thumbFrame->data) {
+    camera_memory_t *thumbFrame = mRequestMemory(-1, frame->mSize, 1, NULL);
+    if (!thumbFrame || !thumbFrame->data) {
         FLOGE("CameraBridge:processImageFrame mRequestMemory thumbFrame failed");
         return false;
     }
     thumbBuf = thumbFrame->data;
 
     encodeQuality = mParameters.getInt(CameraParameters::KEY_JPEG_QUALITY);
-    if (encodeQuality < 0 || encodeQuality > 100) {
+    if ((encodeQuality < 0) || (encodeQuality > 100)) {
         encodeQuality = 100;
     }
 
-    thumbQuality = mParameters.getInt(CameraParameters::KEY_JPEG_THUMBNAIL_QUALITY);
-    if (thumbQuality < 0 || thumbQuality > 100) {
+    thumbQuality = mParameters.getInt(
+        CameraParameters::KEY_JPEG_THUMBNAIL_QUALITY);
+    if ((thumbQuality < 0) || (thumbQuality > 100)) {
         thumbQuality = 100;
     }
 
-    mainJpeg = new JpegParams((uint8_t*)frame->mVirtAddr, frame->mSize, (uint8_t*)rawBuf,
-        frame->mSize, encodeQuality, frame->mWidth, frame->mHeight, frame->mWidth,
-        frame->mHeight, mParameters.getPreviewFormat());
+    mainJpeg =
+        new JpegParams((uint8_t *)frame->mVirtAddr,
+                       frame->mSize,
+                       (uint8_t *)rawBuf,
+                       frame->mSize,
+                       encodeQuality,
+                       frame->mWidth,
+                       frame->mHeight,
+                       frame->mWidth,
+                       frame->mHeight,
+                       mParameters.getPreviewFormat());
 
-    thumbWidth = mParameters.getInt(CameraParameters::KEY_JPEG_THUMBNAIL_WIDTH);
+    thumbWidth  = mParameters.getInt(CameraParameters::KEY_JPEG_THUMBNAIL_WIDTH);
     thumbHeight = mParameters.getInt(CameraParameters::KEY_JPEG_THUMBNAIL_HEIGHT);
 
     if ((thumbWidth > 0) && (thumbHeight > 0)) {
-
-        int thumbSize = 0;
+        int thumbSize   = 0;
         int thumbFormat = convertStringToV4L2Format(mParameters.getPreviewFormat());
-        switch(thumbFormat) {
-            case v4l2_fourcc('N','V','1','2'):
-                thumbSize = thumbWidth * thumbHeight * 3/2;
+        switch (thumbFormat) {
+            case v4l2_fourcc('N', 'V', '1', '2'):
+                thumbSize = thumbWidth * thumbHeight * 3 / 2;
                 break;
-            case v4l2_fourcc('Y','U','1','2'):
-                thumbSize = thumbWidth * thumbHeight * 3/2;
+
+            case v4l2_fourcc('Y', 'U', '1', '2'):
+                thumbSize = thumbWidth * thumbHeight * 3 / 2;
                 break;
-            case v4l2_fourcc('Y','U','Y','V'):
+
+            case v4l2_fourcc('Y', 'U', 'Y', 'V'):
                 thumbSize = thumbWidth * thumbHeight * 2;
                 break;
+
             default:
                 FLOGE("Error: format not supported int ion alloc");
                 return false;
         }
         thumbSize = frame->mSize;
-        thumbJpeg = new JpegParams((uint8_t*)frame->mVirtAddr, frame->mSize, (uint8_t*)thumbBuf,
-                thumbSize, thumbQuality, frame->mWidth, frame->mHeight, thumbWidth,
-                thumbHeight, mParameters.getPreviewFormat());
+        thumbJpeg =
+            new JpegParams((uint8_t *)frame->mVirtAddr,
+                           frame->mSize,
+                           (uint8_t *)thumbBuf,
+                           thumbSize,
+                           thumbQuality,
+                           frame->mWidth,
+                           frame->mHeight,
+                           thumbWidth,
+                           thumbHeight,
+                           mParameters.getPreviewFormat());
     }
 
     mJpegBuilder->prepareImage(mParameters);
     ret = mJpegBuilder->encodeImage(mainJpeg, thumbJpeg);
-    if(ret != NO_ERROR) {
+    if (ret != NO_ERROR) {
         FLOGE("CameraBridge:processImageFrame encodeImage failed");
         return false;
     }
 
-    size_t imageSize = mJpegBuilder->getImageSize();
-    camera_memory_t* picture = NULL;
+    size_t imageSize         = mJpegBuilder->getImageSize();
+    camera_memory_t *picture = NULL;
     ret = mJpegBuilder->buildImage(mRequestMemory, &picture);
-    if(ret != NO_ERROR || !picture) {
+    if ((ret != NO_ERROR) || !picture) {
         FLOGE("CameraBridge:processImageFrame buildImage failed");
         return false;
     }
     mDataCb(CAMERA_MSG_COMPRESSED_IMAGE, picture, 0, NULL, mCallbackCookie);
 
-    if(mainJpeg) {
+    if (mainJpeg) {
         delete mainJpeg;
     }
 
-    if(thumbJpeg) {
+    if (thumbJpeg) {
         delete thumbJpeg;
     }
 
-    if(rawFrame) {
+    if (rawFrame) {
         rawFrame->release(rawFrame);
         rawFrame = NULL;
     }
 
-    if(thumbFrame) {
+    if (thumbFrame) {
         thumbFrame->release(thumbFrame);
         thumbFrame = NULL;
     }
 
-    if(picture) {
+    if (picture) {
         picture->release(picture);
         picture = NULL;
     }
@@ -603,12 +728,12 @@ bool CameraBridge::processImageFrame(CameraFrame* frame)
     return true;
 }
 
-void CameraBridge::sendRawImageFrame(CameraFrame* frame)
+void CameraBridge::sendRawImageFrame(CameraFrame *frame)
 {
     FSL_ASSERT(frame);
     camera_memory_t *RawMemBase = NULL;
     RawMemBase = mRequestMemory(-1, frame->mSize, 1, NULL);
-    if(NULL == RawMemBase) {
+    if (NULL == RawMemBase) {
         FLOGE("CameraBridge: allocateRecordVideoBuf mRequestMemory failed");
         return;
     }
@@ -624,44 +749,50 @@ void CameraBridge::sendRawImageFrame(CameraFrame* frame)
     RawMemBase = NULL;
 }
 
-void CameraBridge::sendPreviewFrame(CameraFrame* frame)
+void CameraBridge::sendPreviewFrame(CameraFrame *frame)
 {
     FSL_ASSERT(frame);
     FSL_ASSERT(mPreviewMemory);
     int bufIdx = frame->mIndex;
     FSL_ASSERT(bufIdx >= 0);
 
-    convertNV12toYUV420SP((uint8_t*)(frame->mVirtAddr),
-          (uint8_t*)((unsigned char*)mPreviewMemory->data + bufIdx * mBufferSize),
-          frame->mWidth, frame->mHeight);
-    mDataCb(CAMERA_MSG_PREVIEW_FRAME, mPreviewMemory, bufIdx, NULL, mCallbackCookie);
+    convertNV12toYUV420SP((uint8_t *)(frame->mVirtAddr),
+                          (uint8_t *)((unsigned char *)mPreviewMemory->data +
+                                      bufIdx * mBufferSize),
+                          frame->mWidth, frame->mHeight);
+    mDataCb(CAMERA_MSG_PREVIEW_FRAME,
+            mPreviewMemory,
+            bufIdx,
+            NULL,
+            mCallbackCookie);
 }
 
-void CameraBridge::sendVideoFrame(CameraFrame* frame)
+void CameraBridge::sendVideoFrame(CameraFrame *frame)
 {
     FSL_ASSERT(frame);
-    if(!mRecording) {
+    if (!mRecording) {
         FLOGE("CameraBridge: sendVideoFrame but mRecording not enable");
         return;
     }
 
     mRecordingLock.lock();
     nsecs_t timeStamp = systemTime(SYSTEM_TIME_MONOTONIC);
-    int bufIdx = frame->mIndex;
+    int     bufIdx    = frame->mIndex;
     FSL_ASSERT(bufIdx >= 0);
     FSL_ASSERT(mVideoMemory);
 
-    unsigned char* pVideoBuf = (unsigned char*)mVideoMemory->data + bufIdx * mMetaDataBufsSize;
-    if(mUseMetaDataBufferMode) {
-        VideoMetadataBuffer* pMetaBuf = (VideoMetadataBuffer*)pVideoBuf;
+    unsigned char *pVideoBuf = (unsigned char *)mVideoMemory->data + bufIdx *
+                               mMetaDataBufsSize;
+    if (mUseMetaDataBufferMode) {
+        VideoMetadataBuffer *pMetaBuf = (VideoMetadataBuffer *)pVideoBuf;
         pMetaBuf->phyOffset = frame->mPhyAddr;
-        pMetaBuf->length = frame->mSize;
+        pMetaBuf->length    = frame->mSize;
     }
     else {
-        memcpy(pVideoBuf, (void*)frame->mVirtAddr, mMetaDataBufsSize);
+        memcpy(pVideoBuf, (void *)frame->mVirtAddr, mMetaDataBufsSize);
     }
 
-    if(mMetaDataBufsMap.indexOfKey((int)pVideoBuf) >= 0) {
+    if (mMetaDataBufsMap.indexOfKey((int)pVideoBuf) >= 0) {
         int fAddr = mMetaDataBufsMap.valueFor((int)pVideoBuf);
         FSL_ASSERT(fAddr == (int)frame);
     }
@@ -669,27 +800,32 @@ void CameraBridge::sendVideoFrame(CameraFrame* frame)
         mMetaDataBufsMap.add((int)pVideoBuf, (int)frame);
     }
 
-    //the frame held in mediaRecorder.
+    // the frame held in mediaRecorder.
     frame->addReference();
-    mDataCbTimestamp(timeStamp, CAMERA_MSG_VIDEO_FRAME, mVideoMemory, bufIdx, mCallbackCookie);
+    mDataCbTimestamp(timeStamp,
+                     CAMERA_MSG_VIDEO_FRAME,
+                     mVideoMemory,
+                     bufIdx,
+                     mCallbackCookie);
     mRecordingLock.unlock();
 }
 
-void CameraBridge::releaseRecordingFrame(const void* mem)
+void CameraBridge::releaseRecordingFrame(const void *mem)
 {
-    CameraFrame* pFrame = (CameraFrame*)mMetaDataBufsMap.valueFor((int)mem);
-    //the frame release from mediaRecorder.
+    CameraFrame *pFrame = (CameraFrame *)mMetaDataBufsMap.valueFor((int)mem);
+
+    // the frame release from mediaRecorder.
     pFrame->release();
 }
 
-void CameraBridge::handleCameraFrame(CameraFrame* frame)
+void CameraBridge::handleCameraFrame(CameraFrame *frame)
 {
-    if(!frame || !frame->mBufHandle) {
+    if (!frame || !frame->mBufHandle) {
         FLOGI("CameraBridge: notifyCameraFrame receive null frame");
         return;
     }
 
-    //the frame held in CameraBridge.
+    // the frame held in CameraBridge.
     frame->addReference();
     mThreadQueue.postMessage(
         new CMessage(BridgeThread::BRIDGE_FRAME, (int)frame));
@@ -704,12 +840,12 @@ void CameraBridge::handleEvent(sp<CameraEvent>& event)
 
 status_t CameraBridge::allocateVideoBufs()
 {
-    if(mVideoMemory != NULL) {
+    if (mVideoMemory != NULL) {
         mVideoMemory->release(mVideoMemory);
         mVideoMemory = NULL;
     }
 
-    if(mUseMetaDataBufferMode) {
+    if (mUseMetaDataBufferMode) {
         mMetaDataBufsSize = sizeof(VideoMetadataBuffer);
     }
     else {
@@ -717,7 +853,7 @@ status_t CameraBridge::allocateVideoBufs()
     }
 
     mVideoMemory = mRequestMemory(-1, mMetaDataBufsSize, mBufferCount, NULL);
-    if(mVideoMemory == NULL) {
+    if (mVideoMemory == NULL) {
         FLOGE("CameraBridge: allocateRecordVideoBuf mRequestMemory failed");
         return NO_MEMORY;
     }
@@ -727,7 +863,7 @@ status_t CameraBridge::allocateVideoBufs()
 
 void CameraBridge::releaseVideoBufs()
 {
-    if(mVideoMemory != NULL) {
+    if (mVideoMemory != NULL) {
         mVideoMemory->release(mVideoMemory);
         mVideoMemory = NULL;
     }
@@ -744,23 +880,26 @@ status_t CameraBridge::initImageCapture()
 
 void CameraBridge::handleError(CAMERA_ERROR err)
 {
-    if(err == ERROR_FATAL) {
+    if (err == ERROR_FATAL) {
         abort();
         return;
     }
 
-    if(mNotifyCb != NULL && (mMsgEnabled & CAMERA_MSG_ERROR)) {
+    if ((mNotifyCb != NULL) && (mMsgEnabled & CAMERA_MSG_ERROR)) {
         mNotifyCb(CAMERA_MSG_ERROR, CAMERA_ERROR_UNKNOWN, 0, mCallbackCookie);
     }
 }
 
-void CameraBridge::convertNV12toYUV420SP(uint8_t *inputBuffer, uint8_t *outputBuffer, int width, int height)
+void CameraBridge::convertNV12toYUV420SP(uint8_t *inputBuffer,
+                                         uint8_t *outputBuffer,
+                                         int      width,
+                                         int      height)
 {
     /* Color space conversion from I420 to YUV420SP */
     int Ysize = 0, UVsize = 0;
     uint8_t *Yin, *Uin, *Vin, *Yout, *Uout, *Vout;
 
-    Ysize = width * height;
+    Ysize  = width * height;
     UVsize = width *  height >> 2;
 
     Yin = inputBuffer;
@@ -773,14 +912,13 @@ void CameraBridge::convertNV12toYUV420SP(uint8_t *inputBuffer, uint8_t *outputBu
 
     memcpy(Yout, Yin, Ysize);
 
-    for(int k = 0; k < UVsize; k++) {
+    for (int k = 0; k < UVsize; k++) {
         *Uout = *Uin;
         *Vout = *Vin;
         Uout += 2;
         Vout += 2;
         Uin  += 2;
-        Vin += 2;
+        Vin  += 2;
     }
 }
 
-
diff --git a/mx6/libcamera/CameraBridge.h b/mx6/libcamera/CameraBridge.h
old mode 100755
new mode 100644
index 44b7104..804f826
--- a/mx6/libcamera/CameraBridge.h
+++ b/mx6/libcamera/CameraBridge.h
@@ -31,14 +31,13 @@ using namespace android;
 #define MAX_PICTURE_SUPPORT_FORMAT 2
 
 class CameraBridge : public CameraEventListener,
-    public CameraFrameListener,
-    public CameraErrorListener,
-    public LightRefBase<CameraBridge>
-{
+                     public CameraFrameListener,
+                     public CameraErrorListener,
+                     public LightRefBase<CameraBridge>{
 public:
     enum BridgeState {
         BRIDGE_INVALID = 0,
-        BRIDGE_INIT = 1,
+        BRIDGE_INIT    = 1,
         BRIDGE_STARTED,
         BRIDGE_STOPPED,
         BRIDGE_EXITED
@@ -51,8 +50,10 @@ public:
     status_t stop();
 
     status_t initImageCapture();
-    status_t getSupportedRecordingFormat(int* pFormat, int len);
-    status_t getSupportedPictureFormat(int* pFormat, int len);
+    status_t getSupportedRecordingFormat(int *pFormat,
+                                         int  len);
+    status_t getSupportedPictureFormat(int *pFormat,
+                                       int  len);
 
     status_t enableMsgType(int32_t msgType);
     status_t disableMsgType(int32_t msgType);
@@ -60,40 +61,44 @@ public:
     status_t startRecording();
     status_t stopRecording();
     status_t useMetaDataBufferMode(bool enable);
-    void releaseRecordingFrame(const void* mem);
+    void     releaseRecordingFrame(const void *mem);
 
 public:
-    void setCallbacks(camera_notify_callback notify_cb,
-                      camera_data_callback data_cb,
-                      camera_data_timestamp_callback data_cb_timestamp,
-                      camera_request_memory get_memory,
-                      void *user);
+    void     setCallbacks(camera_notify_callback         notify_cb,
+                          camera_data_callback           data_cb,
+                          camera_data_timestamp_callback data_cb_timestamp,
+                          camera_request_memory          get_memory,
+                          void                          *user);
 
     virtual status_t setParameters(CameraParameters& params);
     virtual status_t initParameters(CameraParameters& params);
 
-    void setCameraFrameProvider(CameraFrameProvider* frameProvider);
-    void setCameraEventProvider(int32_t msgs, CameraEventProvider* eventProvider);
+    void             setCameraFrameProvider(CameraFrameProvider *frameProvider);
+    void             setCameraEventProvider(int32_t              msgs,
+                                            CameraEventProvider *eventProvider);
 
 protected:
-    void handleCameraFrame(CameraFrame* frame);
-    void handleEvent(sp<CameraEvent>& event);
-    void handleError(CAMERA_ERROR err);
+    void         handleCameraFrame(CameraFrame *frame);
+    void         handleEvent(sp<CameraEvent>& event);
+    void         handleError(CAMERA_ERROR err);
 
-    virtual bool processImageFrame(CameraFrame* frame);
+    virtual bool processImageFrame(CameraFrame *frame);
 
 private:
-    bool bridgeThread();
-    bool processEvent(CameraEvent* event);
-    bool processFrame(CameraFrame* frame);
+    bool         bridgeThread();
+    bool         processEvent(CameraEvent *event);
+    bool         processFrame(CameraFrame *frame);
 
-    void sendPreviewFrame(CameraFrame* frame);
-    void sendVideoFrame(CameraFrame* frame);
-    void sendRawImageFrame(CameraFrame* frame);
+    void         sendPreviewFrame(CameraFrame *frame);
+    void         sendVideoFrame(CameraFrame *frame);
+    void         sendRawImageFrame(CameraFrame *frame);
 
-    status_t allocateVideoBufs();
-    void releaseVideoBufs();
-    void convertNV12toYUV420SP(uint8_t *inputBuffer, uint8_t *outputBuffer, int width, int height);
+    status_t     allocateVideoBufs();
+    void         releaseVideoBufs();
+    void         convertNV12toYUV420SP(uint8_t *inputBuffer,
+                                       uint8_t *outputBuffer,
+                                       int      width,
+                                       int      height);
 
 public:
     class BridgeThread : public Thread {
@@ -107,24 +112,23 @@ public:
         };
 
     public:
-        BridgeThread(CameraBridge* camera)
+        BridgeThread(CameraBridge *camera)
             : Thread(false), mCamera(camera)
-        {
-        }
+        {}
 
         virtual bool threadLoop() {
             return mCamera->bridgeThread();
         }
 
     private:
-        CameraBridge* mCamera;
+        CameraBridge *mCamera;
     };
 
 private:
     sp<BridgeThread> mBridgeThread;
-    CMessageQueue mThreadQueue;
-    CameraEventProvider* mEventProvider;
-    CameraFrameProvider* mFrameProvider;
+    CMessageQueue    mThreadQueue;
+    CameraEventProvider *mEventProvider;
+    CameraFrameProvider *mFrameProvider;
 
 private:
     bool mUseMetaDataBufferMode;
@@ -138,19 +142,19 @@ private:
 private:
     mutable Mutex mLock;
     int32_t mMsgEnabled;
-    char mSupprotedThumbnailSizes[MAX_THUMBNAIL_BUFFER_SIZE];
+    char    mSupprotedThumbnailSizes[MAX_THUMBNAIL_BUFFER_SIZE];
 
-    BridgeState mBridgeState;
+    BridgeState   mBridgeState;
     mutable Mutex mRecordingLock;
     bool mRecording;
-    int mVideoWidth;
-    int mVideoHeight;
+    int  mVideoWidth;
+    int  mVideoHeight;
 
     int mBufferCount;
     int mBufferSize;
     int mMetaDataBufsSize;
-    camera_memory_t* mPreviewMemory;
-    camera_memory_t* mVideoMemory;
+    camera_memory_t *mPreviewMemory;
+    camera_memory_t *mVideoMemory;
     KeyedVector<int, int> mMetaDataBufsMap;
 
     int mVpuSupportFmt[MAX_VPU_SUPPORT_FORMAT];
@@ -158,4 +162,4 @@ private:
     sp<JpegBuilder> mJpegBuilder;
 };
 
-#endif
+#endif // ifndef _CAMERA_BRIDGE_H_
diff --git a/mx6/libcamera/CameraHal.cpp b/mx6/libcamera/CameraHal.cpp
old mode 100755
new mode 100644
index 591fbe7..f2dc61f
--- a/mx6/libcamera/CameraHal.cpp
+++ b/mx6/libcamera/CameraHal.cpp
@@ -26,7 +26,7 @@ CameraHal::CameraHal(int cameraId)
       mSetPreviewWindowCalled(false),
       mPreviewStartInProgress(false), mMsgEnabled(0), mUseIon(true)
 {
-    if(mUseIon) {
+    if (mUseIon) {
         mPhysAdapter = new PhysMemAdapter();
     }
 }
@@ -37,7 +37,7 @@ CameraHal::~CameraHal()
     mCameraBridge.clear();
     mDeviceAdapter.clear();
     mDisplayAdapter.clear();
-    if(mUseIon && mPhysAdapter) {
+    if (mUseIon && mPhysAdapter) {
         delete mPhysAdapter;
     }
 }
@@ -45,67 +45,79 @@ CameraHal::~CameraHal()
 status_t CameraHal::initialize(const CameraInfo& info)
 {
     status_t ret = NO_ERROR;
+
     FLOG_RUNTIME("initialize name:%s, path:%s", info.name, info.devPath);
     mDeviceAdapter = DeviceAdapter::Create(info);
-    if(mDeviceAdapter == NULL) {
+    if (mDeviceAdapter == NULL) {
         FLOGE("CameraHal: DeviceAdapter create failed");
         return BAD_VALUE;
     }
 
     ret = mDeviceAdapter->initialize(info);
-    if(ret) {
+    if (ret) {
         FLOGE("CameraHal: DeviceAdapter initialize failed");
         return ret;
     }
 
     mCameraBridge = new CameraBridge();
-    if(mCameraBridge == NULL) {
+    if (mCameraBridge == NULL) {
         FLOGE("CameraHal: new CameraBridge failed");
         return BAD_VALUE;
     }
 
     ret = mCameraBridge->initialize();
-    if(ret) {
+    if (ret) {
         FLOGE("CameraHal: CameraBridge initialize failed");
         return ret;
     }
 
-    mCameraBridge->getSupportedRecordingFormat(mSupportedRecordingFormat, MAX_VPU_SUPPORT_FORMAT);
-    mCameraBridge->getSupportedPictureFormat(mSupportedPictureFormat, MAX_PICTURE_SUPPORT_FORMAT);
-    ret = mDeviceAdapter->initParameters(mParameters, mSupportedRecordingFormat,
-            MAX_VPU_SUPPORT_FORMAT, mSupportedPictureFormat, MAX_PICTURE_SUPPORT_FORMAT);
-    if(ret) {
+    mCameraBridge->getSupportedRecordingFormat(mSupportedRecordingFormat,
+                                               MAX_VPU_SUPPORT_FORMAT);
+    mCameraBridge->getSupportedPictureFormat(mSupportedPictureFormat,
+                                             MAX_PICTURE_SUPPORT_FORMAT);
+    ret = mDeviceAdapter->initParameters(mParameters,
+                                         mSupportedRecordingFormat,
+                                         MAX_VPU_SUPPORT_FORMAT,
+                                         mSupportedPictureFormat,
+                                         MAX_PICTURE_SUPPORT_FORMAT);
+    if (ret) {
         FLOGE("CameraHal: DeviceAdapter initParameters failed");
         return ret;
     }
 
     ret = mCameraBridge->initParameters(mParameters);
-    if(ret) {
+    if (ret) {
         FLOGE("CameraHal: CameraBridge initParameters failed");
         return ret;
     }
 
     mDeviceAdapter->setErrorListener(mCameraBridge.get());
     mCameraBridge->setCameraFrameProvider(mDeviceAdapter.get());
-    mCameraBridge->setCameraEventProvider(CameraEvent::EVENT_INVALID, mDeviceAdapter.get());
+    mCameraBridge->setCameraEventProvider(CameraEvent::EVENT_INVALID,
+                                          mDeviceAdapter.get());
     mBufferProvider = NULL;
 
     return ret;
 }
 
-void CameraHal::setCallbacks(camera_notify_callback notify_cb,
-        camera_data_callback data_cb,
-        camera_data_timestamp_callback data_cb_timestamp,
-        camera_request_memory get_memory,
-        void* user)
+void CameraHal::setCallbacks(camera_notify_callback         notify_cb,
+                             camera_data_callback           data_cb,
+                             camera_data_timestamp_callback data_cb_timestamp,
+                             camera_request_memory          get_memory,
+                             void                          *user)
 {
     Mutex::Autolock lock(mLock);
-    return mCameraBridge->setCallbacks(notify_cb, data_cb, data_cb_timestamp, get_memory, user);
+
+    return mCameraBridge->setCallbacks(notify_cb,
+                                       data_cb,
+                                       data_cb_timestamp,
+                                       get_memory,
+                                       user);
 }
 
 void CameraHal::enableMsgType(int32_t msgType)
 {
-    if(mMsgEnabled & CAMERA_MSG_PREVIEW_FRAME) {
+    if (mMsgEnabled & CAMERA_MSG_PREVIEW_FRAME) {
         FLOGI("Enabling Preview Callback");
     }
     else {
@@ -120,7 +132,7 @@ void CameraHal::enableMsgType(int32_t msgType)
 
 void CameraHal::disableMsgType(int32_t msgType)
 {
-    if(msgType & CAMERA_MSG_PREVIEW_FRAME) {
+    if (msgType & CAMERA_MSG_PREVIEW_FRAME) {
         FLOGI("Disabling Preview Callback");
     }
 
@@ -133,6 +145,7 @@ void CameraHal::disableMsgType(int32_t msgType)
 bool CameraHal::msgTypeEnabled(int32_t msgType)
 {
     Mutex::Autolock lock(mLock);
+
     return (mMsgEnabled & msgType);
 }
 
@@ -141,20 +154,20 @@ void CameraHal::putParameters(char *params)
     free(params);
 }
 
-char* CameraHal::getParameters() const
+char * CameraHal::getParameters() const
 {
     Mutex::Autolock lock(mLock);
-    char* params_string;
+    char   *params_string;
     String8 params_str8;
     CameraParameters mParams = mParameters;
 
-    params_str8 = mParams.flatten();
-    params_string = (char*)malloc(sizeof(char) * (params_str8.length() + 1));
+    params_str8   = mParams.flatten();
+    params_string = (char *)malloc(sizeof(char) * (params_str8.length() + 1));
     strcpy(params_string, params_str8.string());
     return params_string;
 }
 
-status_t CameraHal::setParameters(const char* params)
+status_t CameraHal::setParameters(const char *params)
 {
     CameraParameters parameters;
     String8 str_params(params);
@@ -167,16 +180,17 @@ status_t CameraHal::setParameters(CameraParameters& params)
 {
     status_t ret = NO_ERROR;
     Mutex::Autolock lock(mLock);
+
     FSL_ASSERT(mDeviceAdapter.get() != NULL);
     ret = mDeviceAdapter->setParameters(params);
-    if(ret) {
+    if (ret) {
         FLOGE("CameraHal: initialize mDevice->setParameters failed");
         return ret;
     }
 
     FSL_ASSERT(mCameraBridge.get() != NULL);
     ret = mCameraBridge->setParameters(params);
-    if(ret) {
+    if (ret) {
         FLOGE("CameraHal: initialize mCameraBridge->setParameters failed");
         return ret;
     }
@@ -184,7 +198,10 @@ status_t CameraHal::setParameters(CameraParameters& params)
     mParameters = params;
     return ret;
 }
-status_t CameraHal::sendCommand(int32_t command, int32_t arg1, int32_t arg2)
+
+status_t CameraHal::sendCommand(int32_t command,
+                                int32_t arg1,
+                                int32_t arg2)
 {
     return BAD_VALUE;
 }
@@ -192,11 +209,12 @@ status_t CameraHal::sendCommand(int32_t command, int32_t arg1, int32_t arg2)
 status_t CameraHal::setPreviewWindow(struct preview_stream_ops *window)
 {
     status_t ret = NO_ERROR;
+
     FLOG_RUNTIME("setPreviewWindow");
     mSetPreviewWindowCalled = true;
 
-    if(!window) {
-        if(mDisplayAdapter.get() != NULL) {
+    if (!window) {
+        if (mDisplayAdapter.get() != NULL) {
             FLOGI("NULL window passed, destroying display adapter");
             stopPreview();
             mDisplayAdapter.clear();
@@ -206,10 +224,11 @@ status_t CameraHal::setPreviewWindow(struct preview_stream_ops *window)
         FLOGI("NULL ANativeWindow passed to setPreviewWindow");
         return NO_ERROR;
     }
-    else if(mDisplayAdapter.get() == NULL) {
+    else if (mDisplayAdapter.get() == NULL) {
         mDisplayAdapter = new DisplayAdapter();
-        if(!mDisplayAdapter.get() || ((ret=mDisplayAdapter->initialize())!=NO_ERROR)) {
-            if(ret != NO_ERROR) {
+        if (!mDisplayAdapter.get() ||
+            ((ret = mDisplayAdapter->initialize()) != NO_ERROR)) {
+            if (ret != NO_ERROR) {
                 mDisplayAdapter.clear();
                 FLOGE("DisplayAdapter initialize failed");
                 return ret;
@@ -226,11 +245,11 @@ status_t CameraHal::setPreviewWindow(struct preview_stream_ops *window)
         mDisplayAdapter->setErrorListener(mCameraBridge.get());
 
         ret = mDisplayAdapter->setPreviewWindow(window);
-        if(ret != NO_ERROR) {
+        if (ret != NO_ERROR) {
             FLOGE("DisplayAdapter setPreviewWindow returned error %d", ret);
         }
 
-        if(mPreviewStartInProgress) {
+        if (mPreviewStartInProgress) {
             FLOGI("setPreviewWindow called when preview running");
             ret = startPreview();
         }
@@ -241,7 +260,6 @@ status_t CameraHal::setPreviewWindow(struct preview_stream_ops *window)
     }
 
     return ret;
-
 }
 
 status_t CameraHal::startPreview()
@@ -250,17 +268,17 @@ status_t CameraHal::startPreview()
     status_t ret = NO_ERROR;
     Mutex::Autolock lock(mLock);
 
-    if(mPreviewEnabled) {
+    if (mPreviewEnabled) {
         FLOGE("Preview already running");
         return ALREADY_EXISTS;
     }
 
-    if(mTakePictureInProcess) {
+    if (mTakePictureInProcess) {
         FLOGI("stop takePicture");
         stopPicture();
     }
 
-    if(!mSetPreviewWindowCalled || (mDisplayAdapter.get() == NULL)) {
+    if (!mSetPreviewWindowCalled || (mDisplayAdapter.get() == NULL)) {
         FLOGI("Preview not started. Preview in progress flag set");
         mPreviewStartInProgress = true;
         return NO_ERROR;
@@ -277,39 +295,42 @@ status_t CameraHal::startPreview()
     FSL_ASSERT(mDisplayAdapter.get() != NULL);
     mBufferProvider = mDisplayAdapter.get();
     mDeviceAdapter->setCameraBufferProvide(mBufferProvider);
-    ret = mBufferProvider->allocatePreviewBuffer(width, height, format, MAX_PREVIEW_BUFFER);
-    if(NO_ERROR != ret) {
+    ret = mBufferProvider->allocatePreviewBuffer(width,
+                                                 height,
+                                                 format,
+                                                 MAX_PREVIEW_BUFFER);
+    if (NO_ERROR != ret) {
         FLOGE("Couldn't allocate buffers for Preview");
         goto error;
     }
 
     FSL_ASSERT(mCameraBridge.get() != NULL);
     ret = mCameraBridge->start();
-    if(ALREADY_EXISTS == ret) {
+    if (ALREADY_EXISTS == ret) {
         FLOGI("mCameraBridge already running");
         ret = NO_ERROR;
     }
-    else if(ret) {
+    else if (ret) {
         FLOGE("Couldn't start mCameraBridge");
         goto error;
     }
 
     FLOG_RUNTIME("start display");
     ret = mDisplayAdapter->startDisplay(width, height);
-    if(ret != NO_ERROR) {
+    if (ret != NO_ERROR) {
         FLOGE("Couldn't enable display");
         goto error;
     }
 
     FLOG_RUNTIME("Starting DeviceAdapter preview mode");
     ret = mDeviceAdapter->startPreview();
-    if(ret!=NO_ERROR) {
+    if (ret != NO_ERROR) {
         FLOGE("Couldn't start preview for DeviceAdapter");
         goto error;
     }
     FLOG_RUNTIME("Started preview");
 
-    mPreviewEnabled = true;
+    mPreviewEnabled         = true;
     mPreviewStartInProgress = false;
     LockWakeLock();
     return ret;
@@ -322,9 +343,9 @@ error:
     mBufferProvider->freeBuffer();
 
     mCameraBridge->stop();
-    mBufferProvider = NULL;
+    mBufferProvider         = NULL;
     mPreviewStartInProgress = false;
-    mPreviewEnabled = false;
+    mPreviewEnabled         = false;
 
     return ret;
 }
@@ -333,12 +354,12 @@ void CameraHal::stopPreview()
 {
     FLOG_RUNTIME("stopPreview");
     Mutex::Autolock lock(mLock);
-    if(mTakePictureInProcess && !(mMsgEnabled & CAMERA_MSG_COMPRESSED_IMAGE)) {
+    if (mTakePictureInProcess && !(mMsgEnabled & CAMERA_MSG_COMPRESSED_IMAGE)) {
         FLOGI("stop takePicture");
         stopPicture();
     }
 
-    if(!previewEnabled() || mRecordingEnabled) {
+    if (!previewEnabled() || mRecordingEnabled) {
         return;
     }
 
@@ -369,20 +390,20 @@ void CameraHal::forceStopPreview()
         mDeviceAdapter->stopPreview();
     }
 
-    if(mDisplayAdapter.get() != NULL) {
+    if (mDisplayAdapter.get() != NULL) {
         mDisplayAdapter->stopDisplay();
     }
 
-    if(mCameraBridge.get() != NULL) {
+    if (mCameraBridge.get() != NULL) {
         mCameraBridge->stop();
     }
 
-    if(mBufferProvider != NULL) {
+    if (mBufferProvider != NULL) {
         mBufferProvider->freeBuffer();
     }
 
-    mBufferProvider = NULL;
-    mPreviewEnabled = false;
+    mBufferProvider         = NULL;
+    mPreviewEnabled         = false;
     mPreviewStartInProgress = false;
 }
 
@@ -391,9 +412,10 @@ status_t CameraHal::autoFocus()
     status_t ret = NO_ERROR;
 
     Mutex::Autolock lock(mLock);
+
     mMsgEnabled |= CAMERA_MSG_FOCUS;
 
-    if(mDeviceAdapter != NULL) {
+    if (mDeviceAdapter != NULL) {
         ret = mDeviceAdapter->autoFocus();
     }
     else {
@@ -407,9 +429,10 @@ status_t CameraHal::cancelAutoFocus()
 {
     status_t ret = NO_ERROR;
     Mutex::Autolock lock(mLock);
+
     mMsgEnabled &= ~CAMERA_MSG_FOCUS;
 
-    if(mDeviceAdapter != NULL) {
+    if (mDeviceAdapter != NULL) {
         ret = mDeviceAdapter->cancelAutoFocus();
     }
 
@@ -418,28 +441,28 @@ status_t CameraHal::cancelAutoFocus()
 
 status_t CameraHal::storeMetaDataInBuffers(bool enable)
 {
-    //return mCameraBridge->useMetaDataBufferMode(enable);
+    // return mCameraBridge->useMetaDataBufferMode(enable);
     return -1;
 }
 
 status_t CameraHal::startRecording()
 {
     FLOG_RUNTIME("startRecording");
-    if(!previewEnabled()) {
+    if (!previewEnabled()) {
         FLOGE("startRecording: preview not enabled");
         return NO_INIT;
     }
 
     status_t ret = NO_ERROR;
     mEncodeLock.lock();
-    if(mRecordingEnabled == true) {
+    if (mRecordingEnabled == true) {
         FLOGW("%s: Recording is already existed\n", __FUNCTION__);
         mEncodeLock.unlock();
         return ret;
     }
 
     ret = mCameraBridge->startRecording();
-    if(ret) {
+    if (ret) {
         FLOGE("CameraBridge startRecording failed");
         return ret;
     }
@@ -454,16 +477,16 @@ void CameraHal::stopRecording()
 {
     FLOG_RUNTIME("stopRecording");
     mEncodeLock.lock();
-    if(mRecordingEnabled) {
+    if (mRecordingEnabled) {
         mRecordingEnabled = false;
         mCameraBridge->stopRecording();
     }
     mEncodeLock.unlock();
 }
 
-void CameraHal::releaseRecordingFrame(const void* mem)
+void CameraHal::releaseRecordingFrame(const void *mem)
 {
-    if(mCameraBridge.get() != NULL) {
+    if (mCameraBridge.get() != NULL) {
         mCameraBridge->releaseRecordingFrame(mem);
     }
 }
@@ -479,12 +502,12 @@ status_t CameraHal::takePicture()
     status_t ret = NO_ERROR;
     Mutex::Autolock lock(mLock);
 
-    if(!previewEnabled()) {
+    if (!previewEnabled()) {
         FLOGE("takePicture: preview not start");
         return NO_INIT;
     }
 
-    if(mTakePictureInProcess) {
+    if (mTakePictureInProcess) {
         FLOGE("takePicture already running");
         return ALREADY_EXISTS;
     }
@@ -503,37 +526,47 @@ status_t CameraHal::takePicture()
     mDeviceAdapter->setDeviceConfig(width, height, format, frameRate);
 
     FSL_ASSERT(mDisplayAdapter.get() != NULL);
-    if(mUseIon) {
+    if (mUseIon) {
         FSL_ASSERT(mPhysAdapter);
         mBufferProvider = mPhysAdapter;
         mDeviceAdapter->setCameraBufferProvide(mBufferProvider);
-        FLOG_RUNTIME("mPhysAdapter allocatePictureBuffer w:%d, h:%d", width, height);
-        ret = mBufferProvider->allocatePictureBuffer(width, height, format, MAX_CAPTURE_BUFFER-1);
+        FLOG_RUNTIME("mPhysAdapter allocatePictureBuffer w:%d, h:%d",
+                     width,
+                     height);
+        ret = mBufferProvider->allocatePictureBuffer(width,
+                                                     height,
+                                                     format,
+                                                     MAX_CAPTURE_BUFFER - 1);
     }
     else {
         mBufferProvider = mDisplayAdapter.get();
         mDeviceAdapter->setCameraBufferProvide(mBufferProvider);
-        FLOG_RUNTIME("mBufferProvider allocatePictureBuffer w:%d, h:%d", width, height);
-        ret = mBufferProvider->allocatePictureBuffer(width, height, format, MAX_CAPTURE_BUFFER);
-    }
-    if(NO_ERROR != ret) {
+        FLOG_RUNTIME("mBufferProvider allocatePictureBuffer w:%d, h:%d",
+                     width,
+                     height);
+        ret = mBufferProvider->allocatePictureBuffer(width,
+                                                     height,
+                                                     format,
+                                                     MAX_CAPTURE_BUFFER);
+    }
+    if (NO_ERROR != ret) {
         FLOGE("Couldn't allocate buffers for Picture");
         goto error;
     }
 
     ret = mCameraBridge->start();
-    if(ALREADY_EXISTS == ret) {
+    if (ALREADY_EXISTS == ret) {
         FLOGI("mCameraBridge already running");
         ret = NO_ERROR;
     }
-    else if(ret) {
+    else if (ret) {
         FLOGE("Couldn't start mCameraBridge");
         goto error;
     }
 
     FLOG_RUNTIME("Starting DeviceAdapter ImageCapture mode");
     ret = mDeviceAdapter->startImageCapture();
-    if(ret!=NO_ERROR) {
+    if (ret != NO_ERROR) {
         FLOGE("Couldn't start ImageCapture w/ DeviceAdapter");
         goto error;
     }
@@ -551,7 +584,7 @@ error:
 
     mCameraBridge->stop();
 
-    mBufferProvider = NULL;
+    mBufferProvider       = NULL;
     mTakePictureInProcess = false;
 
     return ret;
@@ -560,7 +593,7 @@ error:
 status_t CameraHal::stopPicture()
 {
     FLOG_RUNTIME("stopPicture");
-    if(!mTakePictureInProcess) {
+    if (!mTakePictureInProcess) {
         FLOGE("takePicture not running");
         return NO_INIT;
     }
@@ -569,15 +602,15 @@ status_t CameraHal::stopPicture()
         mDeviceAdapter->stopImageCapture();
     }
 
-    if(mCameraBridge.get() != NULL) {
+    if (mCameraBridge.get() != NULL) {
         mCameraBridge->stop();
     }
 
-    if(mBufferProvider != NULL) {
+    if (mBufferProvider != NULL) {
         mBufferProvider->freeBuffer();
     }
 
-    mBufferProvider = NULL;
+    mBufferProvider       = NULL;
     mTakePictureInProcess = false;
     UnLockWakeLock();
     return NO_ERROR;
@@ -593,7 +626,8 @@ status_t CameraHal::cancelPicture()
 void CameraHal::release()
 {
     Mutex::Autolock lock(mLock);
-    if(mPreviewEnabled) {
+
+    if (mPreviewEnabled) {
         forceStopPreview();
     }
 
@@ -602,7 +636,7 @@ void CameraHal::release()
 
 void CameraHal::LockWakeLock()
 {
-    if(!mPowerLock) {
+    if (!mPowerLock) {
         acquire_wake_lock(PARTIAL_WAKE_LOCK, V4LSTREAM_WAKE_LOCK);
         mPowerLock = true;
     }
@@ -610,7 +644,7 @@ void CameraHal::LockWakeLock()
 
 void CameraHal::UnLockWakeLock()
 {
-    if(mPowerLock) {
+    if (mPowerLock) {
         release_wake_lock(V4LSTREAM_WAKE_LOCK);
         mPowerLock = false;
     }
diff --git a/mx6/libcamera/CameraHal.h b/mx6/libcamera/CameraHal.h
old mode 100755
new mode 100644
index 7f978b3..a698e35
--- a/mx6/libcamera/CameraHal.h
+++ b/mx6/libcamera/CameraHal.h
@@ -28,65 +28,66 @@ using namespace android;
 
 class PhysMemAdapter;
 
-class CameraHal
-{
+class CameraHal {
 public:
     CameraHal(int cameraId);
     ~CameraHal();
     status_t initialize(const CameraInfo& info);
 
-    void setCallbacks(camera_notify_callback notify_cb,
-        camera_data_callback data_cb,
-        camera_data_timestamp_callback data_cb_timestamp,
-        camera_request_memory get_memory,
-        void* user);
-    void enableMsgType(int32_t msgType);
-    void disableMsgType(int32_t msgType);
-    bool msgTypeEnabled(int32_t msgType);
-    void putParameters(char *params);
-    char* getParameters() const;
-    status_t setParameters(const char* params);
+    void     setCallbacks(camera_notify_callback         notify_cb,
+                          camera_data_callback           data_cb,
+                          camera_data_timestamp_callback data_cb_timestamp,
+                          camera_request_memory          get_memory,
+                          void                          *user);
+    void     enableMsgType(int32_t msgType);
+    void     disableMsgType(int32_t msgType);
+    bool     msgTypeEnabled(int32_t msgType);
+    void     putParameters(char *params);
+    char*    getParameters() const;
+    status_t setParameters(const char *params);
     status_t setParameters(CameraParameters& params);
     status_t setPreviewWindow(struct preview_stream_ops *window);
 
-    bool previewEnabled();
+    bool     previewEnabled();
     status_t restartPreview();
     status_t startPreview();
-    void stopPreview();
-    void forceStopPreview();
+    void     stopPreview();
+    void     forceStopPreview();
 
     status_t autoFocus();
     status_t cancelAutoFocus();
 
     status_t startRecording();
-    void stopRecording();
-    void releaseRecordingFrame(const void* mem);
+    void     stopRecording();
+    void     releaseRecordingFrame(const void *mem);
     status_t storeMetaDataInBuffers(bool enable);
-    bool recordingEnabled();
+    bool     recordingEnabled();
 
     status_t takePicture();
     status_t stopPicture();
     status_t cancelPicture();
 
-    status_t sendCommand(int32_t cmd, int32_t arg1, int32_t arg2);
-    void release();
+    status_t sendCommand(int32_t cmd,
+                         int32_t arg1,
+                         int32_t arg2);
+    void     release();
     status_t dump(int fd) const;
 
-    void LockWakeLock();
-    void UnLockWakeLock();
+    void     LockWakeLock();
+    void     UnLockWakeLock();
 
 private:
-    sp<CameraBridge> mCameraBridge;
-    sp<DeviceAdapter> mDeviceAdapter;
+    sp<CameraBridge>   mCameraBridge;
+    sp<DeviceAdapter>  mDeviceAdapter;
     sp<DisplayAdapter> mDisplayAdapter;
-    CameraBufferProvider* mBufferProvider;
+    CameraBufferProvider *mBufferProvider;
 
 private:
     bool mPowerLock;
-    int mCameraId;
+    int  mCameraId;
     mutable Mutex mLock;
     CameraParameters mParameters;
-    mutable Mutex mEncodeLock;
+    mutable Mutex    mEncodeLock;
     bool mPreviewEnabled;
     bool mRecordingEnabled;
     bool mTakePictureInProcess;
@@ -97,8 +98,8 @@ private:
 
     int mSupportedRecordingFormat[MAX_VPU_SUPPORT_FORMAT];
     int mSupportedPictureFormat[MAX_PICTURE_SUPPORT_FORMAT];
-    PhysMemAdapter* mPhysAdapter;
+    PhysMemAdapter *mPhysAdapter;
     bool mUseIon;
 };
 
-#endif
+#endif // ifndef _CAMERA_HAL_H
diff --git a/mx6/libcamera/CameraModule.cpp b/mx6/libcamera/CameraModule.cpp
old mode 100755
new mode 100644
index dbcdee8..36d7380
--- a/mx6/libcamera/CameraModule.cpp
+++ b/mx6/libcamera/CameraModule.cpp
@@ -30,31 +30,33 @@
 
 #define MAX_CAMERAS_SUPPORTED 2
 
-static CameraHal* gCameraHals[MAX_CAMERAS_SUPPORTED];
-static unsigned int gCamerasOpen = 0;
+static CameraHal *gCameraHals[MAX_CAMERAS_SUPPORTED];
+static unsigned int   gCamerasOpen = 0;
 static android::Mutex gCameraHalDeviceLock;
 
-static int camera_device_open(const hw_module_t* module, const char* name,
-                hw_device_t** device);
-static int camera_device_close(hw_device_t* device);
+static int camera_device_open(const hw_module_t *module,
+                              const char        *name,
+                              hw_device_t      **device);
+static int camera_device_close(hw_device_t *device);
 static int camera_get_number_of_cameras(void);
-static int camera_get_camera_info(int camera_id, struct camera_info *info);
+static int camera_get_camera_info(int                 camera_id,
+                                  struct camera_info *info);
 
 static struct hw_module_methods_t camera_module_methods = {
-        open: camera_device_open
+open: camera_device_open
 };
 
 camera_module_t HAL_MODULE_INFO_SYM = {
-    common: {
-         tag: HARDWARE_MODULE_TAG,
-         version_major: 1,
-         version_minor: 0,
-         id: CAMERA_HARDWARE_MODULE_ID,
-         name: "Freescale CameraHal Module",
-         author: "Freescale",
-         methods: &camera_module_methods,
-         dso: NULL, /* remove compilation warnings */
-         reserved: {0}, /* remove compilation warnings */
+    common:       {
+        tag: HARDWARE_MODULE_TAG,
+        version_major: 1,
+        version_minor: 0,
+        id: CAMERA_HARDWARE_MODULE_ID,
+        name: "Freescale CameraHal Module",
+        author: "Freescale",
+        methods: &camera_module_methods,
+        dso: NULL,       /* remove compilation warnings */
+        reserved: { 0 }, /* remove compilation warnings */
     },
     get_number_of_cameras: camera_get_number_of_cameras,
     get_camera_info: camera_get_camera_info,
@@ -62,370 +64,383 @@ camera_module_t HAL_MODULE_INFO_SYM = {
 
 typedef struct fsl_camera_device {
     camera_device_t base;
-    int cameraid;
+    int             cameraid;
 } fsl_camera_device_t;
 
 
 /*******************************************************************
- * implementation of camera_device_ops functions
- *******************************************************************/
-
-int camera_set_preview_window(struct camera_device * device,
-        struct preview_stream_ops *window)
+* implementation of camera_device_ops functions
+*******************************************************************/
+int camera_set_preview_window(struct camera_device      *device,
+                              struct preview_stream_ops *window)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->setPreviewWindow(window);
 
     return rv;
 }
 
-void camera_set_callbacks(struct camera_device * device,
-        camera_notify_callback notify_cb,
-        camera_data_callback data_cb,
-        camera_data_timestamp_callback data_cb_timestamp,
-        camera_request_memory get_memory,
-        void *user)
+void camera_set_callbacks(struct camera_device          *device,
+                          camera_notify_callback         notify_cb,
+                          camera_data_callback           data_cb,
+                          camera_data_timestamp_callback data_cb_timestamp,
+                          camera_request_memory          get_memory,
+                          void                          *user)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
-    gCameraHals[fsl_dev->cameraid]->setCallbacks(notify_cb, data_cb, data_cb_timestamp, get_memory, user);
+    gCameraHals[fsl_dev->cameraid]->setCallbacks(notify_cb,
+                                                 data_cb,
+                                                 data_cb_timestamp,
+                                                 get_memory,
+                                                 user);
 }
 
-void camera_enable_msg_type(struct camera_device * device, int32_t msg_type)
+void camera_enable_msg_type(struct camera_device *device,
+                            int32_t               msg_type)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     gCameraHals[fsl_dev->cameraid]->enableMsgType(msg_type);
 }
 
-void camera_disable_msg_type(struct camera_device * device, int32_t msg_type)
+void camera_disable_msg_type(struct camera_device *device,
+                             int32_t               msg_type)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     gCameraHals[fsl_dev->cameraid]->disableMsgType(msg_type);
 }
 
-int camera_msg_type_enabled(struct camera_device * device, int32_t msg_type)
+int camera_msg_type_enabled(struct camera_device *device,
+                            int32_t               msg_type)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return 0;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     return gCameraHals[fsl_dev->cameraid]->msgTypeEnabled(msg_type);
 }
 
-int camera_start_preview(struct camera_device * device)
+int camera_start_preview(struct camera_device *device)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->startPreview();
 
     return rv;
 }
 
-void camera_stop_preview(struct camera_device * device)
+void camera_stop_preview(struct camera_device *device)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     gCameraHals[fsl_dev->cameraid]->stopPreview();
 }
 
-int camera_preview_enabled(struct camera_device * device)
+int camera_preview_enabled(struct camera_device *device)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->previewEnabled();
     return rv;
 }
 
-int camera_store_meta_data_in_buffers(struct camera_device * device, int enable)
+int camera_store_meta_data_in_buffers(struct camera_device *device,
+                                      int                   enable)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     //  TODO: meta data buffer not current supported
     rv = gCameraHals[fsl_dev->cameraid]->storeMetaDataInBuffers(enable);
     return rv;
-    //return enable ? android::INVALID_OPERATION: android::OK;
+
+    // return enable ? android::INVALID_OPERATION: android::OK;
 }
 
-int camera_start_recording(struct camera_device * device)
+int camera_start_recording(struct camera_device *device)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->startRecording();
     return rv;
 }
 
-void camera_stop_recording(struct camera_device * device)
+void camera_stop_recording(struct camera_device *device)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     gCameraHals[fsl_dev->cameraid]->stopRecording();
 }
 
-int camera_recording_enabled(struct camera_device * device)
+int camera_recording_enabled(struct camera_device *device)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->recordingEnabled();
     return rv;
 }
 
-void camera_release_recording_frame(struct camera_device * device,
-                const void *opaque)
+void camera_release_recording_frame(struct camera_device *device,
+                                    const void           *opaque)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     gCameraHals[fsl_dev->cameraid]->releaseRecordingFrame(opaque);
 }
 
-int camera_auto_focus(struct camera_device * device)
+int camera_auto_focus(struct camera_device *device)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->autoFocus();
     return rv;
 }
 
-int camera_cancel_auto_focus(struct camera_device * device)
+int camera_cancel_auto_focus(struct camera_device *device)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->cancelAutoFocus();
     return rv;
 }
 
-int camera_take_picture(struct camera_device * device)
+int camera_take_picture(struct camera_device *device)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->takePicture();
     return rv;
 }
 
-int camera_cancel_picture(struct camera_device * device)
+int camera_cancel_picture(struct camera_device *device)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->cancelPicture();
     return rv;
 }
 
-int camera_set_parameters(struct camera_device * device, const char *params)
+int camera_set_parameters(struct camera_device *device,
+                          const char           *params)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->setParameters(params);
     return rv;
 }
 
-char* camera_get_parameters(struct camera_device * device)
+char* camera_get_parameters(struct camera_device *device)
 {
-    char* param = NULL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    char *param                  = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return NULL;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     param = gCameraHals[fsl_dev->cameraid]->getParameters();
 
     return param;
 }
 
-static void camera_put_parameters(struct camera_device *device, char *parms)
+static void camera_put_parameters(struct camera_device *device,
+                                  char                 *parms)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     gCameraHals[fsl_dev->cameraid]->putParameters(parms);
 }
 
-int camera_send_command(struct camera_device * device,
-            int32_t cmd, int32_t arg1, int32_t arg2)
+int camera_send_command(struct camera_device *device,
+                        int32_t               cmd,
+                        int32_t               arg1,
+                        int32_t               arg2)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->sendCommand(cmd, arg1, arg2);
     return rv;
 }
 
-void camera_release(struct camera_device * device)
+void camera_release(struct camera_device *device)
 {
-    fsl_camera_device_t* fsl_dev = NULL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
-    if(!device)
+    if (!device)
         return;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     gCameraHals[fsl_dev->cameraid]->release();
 }
 
-int camera_dump(struct camera_device * device, int fd)
+int camera_dump(struct camera_device *device,
+                int                   fd)
 {
-    int rv = -EINVAL;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int rv                       = -EINVAL;
+    fsl_camera_device_t *fsl_dev = NULL;
 
-    if(!device)
+    if (!device)
         return rv;
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     rv = gCameraHals[fsl_dev->cameraid]->dump(fd);
     return rv;
@@ -433,10 +448,10 @@ int camera_dump(struct camera_device * device, int fd)
 
 extern "C" void heaptracker_free_leaked_memory(void);
 
-int camera_device_close(hw_device_t* device)
+int             camera_device_close(hw_device_t *device)
 {
-    int ret = 0;
-    fsl_camera_device_t* fsl_dev = NULL;
+    int ret                      = 0;
+    fsl_camera_device_t *fsl_dev = NULL;
 
     ALOGV("%s", __FUNCTION__);
 
@@ -447,7 +462,7 @@ int camera_device_close(hw_device_t* device)
         goto done;
     }
 
-    fsl_dev = (fsl_camera_device_t*) device;
+    fsl_dev = (fsl_camera_device_t *)device;
 
     if (fsl_dev) {
         if (gCameraHals[fsl_dev->cameraid]) {
@@ -464,7 +479,7 @@ int camera_device_close(hw_device_t* device)
 done:
 #ifdef HEAPTRACKER
     heaptracker_free_leaked_memory();
-#endif
+#endif // ifdef HEAPTRACKER
     return ret;
 }
 
@@ -477,25 +492,26 @@ done:
 #define UVC_NAME "uvc"
 static struct CameraInfo sCameraInfo[2];
 static int gCameraNum = 0;
+
 /*******************************************************************
- * implementation of camera_module functions
- *******************************************************************/
+* implementation of camera_module functions
+*******************************************************************/
 
 /* open device handle to one of the cameras
  *
  * assume camera service will keep singleton of each camera
  * so this function will always only be called once per camera instance
  */
-
-int camera_device_open(const hw_module_t* module, const char* name,
-                hw_device_t** device)
+int camera_device_open(const hw_module_t *module,
+                       const char        *name,
+                       hw_device_t      **device)
 {
-    int rv = 0;
+    int rv          = 0;
     int num_cameras = 0;
     int cameraid;
-    fsl_camera_device_t* camera_device = NULL;
-    camera_device_ops_t* camera_ops = NULL;
-    CameraHal* camera = NULL;
+    fsl_camera_device_t *camera_device = NULL;
+    camera_device_ops_t *camera_ops    = NULL;
+    CameraHal *camera                  = NULL;
     char *SelectedCameraName;
 
     android::Mutex::Autolock lock(gCameraHalDeviceLock);
@@ -503,28 +519,28 @@ int camera_device_open(const hw_module_t* module, const char* name,
     ALOGI("camera_device open: %s", name);
 
     if (name != NULL) {
-        cameraid = atoi(name);
+        cameraid    = atoi(name);
         num_cameras = camera_get_number_of_cameras();
 
-        if(cameraid > num_cameras)
+        if (cameraid > num_cameras)
         {
             ALOGE("camera service provided cameraid out of bounds, "
-                    "cameraid = %d, num supported = %d",
-                    cameraid, num_cameras);
+                  "cameraid = %d, num supported = %d",
+                  cameraid, num_cameras);
             rv = -EINVAL;
             goto fail;
         }
 
-        camera_device = (fsl_camera_device_t*)malloc(sizeof(*camera_device));
-        if(!camera_device)
+        camera_device = (fsl_camera_device_t *)malloc(sizeof(*camera_device));
+        if (!camera_device)
         {
             ALOGE("camera_device allocation fail");
             rv = -ENOMEM;
             goto fail;
         }
 
-        camera_ops = (camera_device_ops_t*)malloc(sizeof(*camera_ops));
-        if(!camera_ops)
+        camera_ops = (camera_device_ops_t *)malloc(sizeof(*camera_ops));
+        if (!camera_ops)
         {
             ALOGE("camera_ops allocation fail");
             rv = -ENOMEM;
@@ -534,35 +550,36 @@ int camera_device_open(const hw_module_t* module, const char* name,
         memset(camera_device, 0, sizeof(*camera_device));
         memset(camera_ops, 0, sizeof(*camera_ops));
 
-        camera_device->base.common.tag = HARDWARE_DEVICE_TAG;
+        camera_device->base.common.tag     = HARDWARE_DEVICE_TAG;
         camera_device->base.common.version = 0;
-        camera_device->base.common.module = (hw_module_t *)(module);
-        camera_device->base.common.close = camera_device_close;
-        camera_device->base.ops = camera_ops;
-
-        camera_ops->set_preview_window = camera_set_preview_window;
-        camera_ops->set_callbacks = camera_set_callbacks;
-        camera_ops->enable_msg_type = camera_enable_msg_type;
-        camera_ops->disable_msg_type = camera_disable_msg_type;
-        camera_ops->msg_type_enabled = camera_msg_type_enabled;
-        camera_ops->start_preview = camera_start_preview;
-        camera_ops->stop_preview = camera_stop_preview;
-        camera_ops->preview_enabled = camera_preview_enabled;
-        camera_ops->store_meta_data_in_buffers = camera_store_meta_data_in_buffers;
-        camera_ops->start_recording = camera_start_recording;
-        camera_ops->stop_recording = camera_stop_recording;
-        camera_ops->recording_enabled = camera_recording_enabled;
+        camera_device->base.common.module  = (hw_module_t *)(module);
+        camera_device->base.common.close   = camera_device_close;
+        camera_device->base.ops            = camera_ops;
+
+        camera_ops->set_preview_window         = camera_set_preview_window;
+        camera_ops->set_callbacks              = camera_set_callbacks;
+        camera_ops->enable_msg_type            = camera_enable_msg_type;
+        camera_ops->disable_msg_type           = camera_disable_msg_type;
+        camera_ops->msg_type_enabled           = camera_msg_type_enabled;
+        camera_ops->start_preview              = camera_start_preview;
+        camera_ops->stop_preview               = camera_stop_preview;
+        camera_ops->preview_enabled            = camera_preview_enabled;
+        camera_ops->store_meta_data_in_buffers =
+            camera_store_meta_data_in_buffers;
+        camera_ops->start_recording         = camera_start_recording;
+        camera_ops->stop_recording          = camera_stop_recording;
+        camera_ops->recording_enabled       = camera_recording_enabled;
         camera_ops->release_recording_frame = camera_release_recording_frame;
-        camera_ops->auto_focus = camera_auto_focus;
-        camera_ops->cancel_auto_focus = camera_cancel_auto_focus;
-        camera_ops->take_picture = camera_take_picture;
-        camera_ops->cancel_picture = camera_cancel_picture;
-        camera_ops->set_parameters = camera_set_parameters;
-        camera_ops->get_parameters = camera_get_parameters;
-        camera_ops->put_parameters = camera_put_parameters;
-        camera_ops->send_command = camera_send_command;
-        camera_ops->release = camera_release;
-        camera_ops->dump = camera_dump;
+        camera_ops->auto_focus              = camera_auto_focus;
+        camera_ops->cancel_auto_focus       = camera_cancel_auto_focus;
+        camera_ops->take_picture            = camera_take_picture;
+        camera_ops->cancel_picture          = camera_cancel_picture;
+        camera_ops->set_parameters          = camera_set_parameters;
+        camera_ops->get_parameters          = camera_get_parameters;
+        camera_ops->put_parameters          = camera_put_parameters;
+        camera_ops->send_command            = camera_send_command;
+        camera_ops->release                 = camera_release;
+        camera_ops->dump                    = camera_dump;
 
         *device = &camera_device->base.common;
 
@@ -570,7 +587,7 @@ int camera_device_open(const hw_module_t* module, const char* name,
 
         camera = new CameraHal(cameraid);
 
-        if(!camera)
+        if (!camera)
         {
             ALOGE("Couldn't create instance of CameraHal class");
             rv = -ENOMEM;
@@ -589,15 +606,15 @@ int camera_device_open(const hw_module_t* module, const char* name,
     return rv;
 
 fail:
-    if(camera_device) {
+    if (camera_device) {
         free(camera_device);
         camera_device = NULL;
     }
-    if(camera_ops) {
+    if (camera_ops) {
         free(camera_ops);
         camera_ops = NULL;
     }
-    if(camera) {
+    if (camera) {
         delete camera;
         camera = NULL;
     }
@@ -605,40 +622,44 @@ fail:
     return rv;
 }
 
-static int GetDevPath(const char *pCameraName, char *pCameraDevPath, unsigned int pathLen)
+static int GetDevPath(const char  *pCameraName,
+                      char        *pCameraDevPath,
+                      unsigned int pathLen)
 {
-    int retCode = -1;
-    int fd = 0;
-    char   dev_node[CAMAERA_FILENAME_LENGTH];
+    int  retCode = -1;
+    int  fd      = 0;
+    char dev_node[CAMAERA_FILENAME_LENGTH];
     DIR *v4l_dir = NULL;
     struct dirent *dir_entry;
     struct v4l2_capability v4l2_cap;
     struct v4l2_dbg_chip_ident vid_chip;
 
     v4l_dir = opendir("/sys/class/video4linux");
-    if (v4l_dir){
-        while((dir_entry = readdir(v4l_dir))) {
+    if (v4l_dir) {
+        while ((dir_entry = readdir(v4l_dir))) {
             memset((void *)dev_node, 0, CAMAERA_FILENAME_LENGTH);
-            if(strncmp(dir_entry->d_name, "video", 5))
+            if (strncmp(dir_entry->d_name, "video", 5))
                 continue;
             sprintf(dev_node, "/dev/%s", dir_entry->d_name);
             if ((fd = open(dev_node, O_RDWR, O_NONBLOCK)) < 0)
                 continue;
-            if(ioctl(fd, VIDIOC_QUERYCAP, &v4l2_cap) < 0 ) {
+            if (ioctl(fd, VIDIOC_QUERYCAP, &v4l2_cap) < 0) {
                 close(fd);
                 fd = 0;
                 continue;
             } else if (v4l2_cap.capabilities & V4L2_CAP_VIDEO_CAPTURE) {
-                if(ioctl(fd, VIDIOC_DBG_G_CHIP_IDENT, &vid_chip) < 0 ) {
+                if (ioctl(fd, VIDIOC_DBG_G_CHIP_IDENT, &vid_chip) < 0) {
                     close(fd);
                     fd = 0;
                     continue;
                 }
-                if(strstr(vid_chip.match.name, pCameraName)){
-                    //fsl csi/mipi camera name and path match
-                    if(pathLen > strlen(dev_node)) {
+                if (strstr(vid_chip.match.name, pCameraName)) {
+                    // fsl csi/mipi camera name and path match
+                    if (pathLen > strlen(dev_node)) {
                         strcpy(pCameraDevPath, dev_node);
-                        ALOGI("Get sensor %s's dev path %s", pCameraName, pCameraDevPath);
+                        ALOGI("Get sensor %s's dev path %s",
+                              pCameraName,
+                              pCameraDevPath);
                         retCode = 0;
                     }
                     close(fd);
@@ -655,58 +676,77 @@ static int GetDevPath(const char *pCameraName, char *pCameraDevPath, unsigned in
     return retCode;
 }
 
-static void GetCameraPropery(char * pFaceBackCameraName, char *pFaceFrontCameraName, int *pFaceBackOrient, int *pFaceFrontOrient)
+static void GetCameraPropery(char *pFaceBackCameraName,
+                             char *pFaceFrontCameraName,
+                             int  *pFaceBackOrient,
+                             int  *pFaceFrontOrient)
 {
     char orientStr[10];
 
-    property_get (FACE_BACK_CAMERA_NAME, pFaceBackCameraName, DEFAULT_ERROR_NAME_str );
-    property_get (FACE_BACK_CAMERA_ORIENT, orientStr, DEFAULT_ERROR_NAME_str );
+    property_get(FACE_BACK_CAMERA_NAME,
+                 pFaceBackCameraName,
+                 DEFAULT_ERROR_NAME_str);
+    property_get(FACE_BACK_CAMERA_ORIENT, orientStr, DEFAULT_ERROR_NAME_str);
 
-    if (orientStr[0] == DEFAULT_ERROR_NAME )
+    if (orientStr[0] == DEFAULT_ERROR_NAME)
         *pFaceBackOrient = 0;
     else
         *pFaceBackOrient = atoi(orientStr);
 
-    ALOGI("Face Back Camera is %s, orient is %d", pFaceBackCameraName, *pFaceBackOrient);
+    ALOGI("Face Back Camera is %s, orient is %d",
+          pFaceBackCameraName,
+          *pFaceBackOrient);
 
-    property_get(FACE_FRONT_CAMERA_NAME, pFaceFrontCameraName, DEFAULT_ERROR_NAME_str );
+    property_get(FACE_FRONT_CAMERA_NAME,
+                 pFaceFrontCameraName,
+                 DEFAULT_ERROR_NAME_str);
 
-    property_get(FACE_FRONT_CAMERA_ORIENT, orientStr, DEFAULT_ERROR_NAME_str );
+    property_get(FACE_FRONT_CAMERA_ORIENT, orientStr, DEFAULT_ERROR_NAME_str);
 
 
-    if (orientStr[0] == DEFAULT_ERROR_NAME )
+    if (orientStr[0] == DEFAULT_ERROR_NAME)
         *pFaceFrontOrient = 0;
     else
         *pFaceFrontOrient = atoi(orientStr);
 
-    ALOGI("Face Front Camera is %s, orient is %d", pFaceFrontCameraName, *pFaceFrontOrient);
+    ALOGI("Face Front Camera is %s, orient is %d",
+          pFaceFrontCameraName,
+          *pFaceFrontOrient);
 }
 
 int camera_get_number_of_cameras()
 {
-    int back_orient =0,  front_orient = 0;
-    if(gCameraNum == 0) {
-        GetCameraPropery(sCameraInfo[0].name, sCameraInfo[1].name, &back_orient, &front_orient);
-        if (sCameraInfo[0].name[0] != DEFAULT_ERROR_NAME){
-            sCameraInfo[gCameraNum].facing = CAMERA_FACING_BACK;
+    int back_orient = 0,  front_orient = 0;
+
+    if (gCameraNum == 0) {
+        GetCameraPropery(sCameraInfo[0].name,
+                         sCameraInfo[1].name,
+                         &back_orient,
+                         &front_orient);
+        if (sCameraInfo[0].name[0] != DEFAULT_ERROR_NAME) {
+            sCameraInfo[gCameraNum].facing      = CAMERA_FACING_BACK;
             sCameraInfo[gCameraNum].orientation = back_orient;
             memset(sCameraInfo[gCameraNum].devPath, 0, CAMAERA_FILENAME_LENGTH);
-            GetDevPath(sCameraInfo[gCameraNum].name, sCameraInfo[gCameraNum].devPath, CAMAERA_FILENAME_LENGTH);
+            GetDevPath(sCameraInfo[gCameraNum].name,
+                       sCameraInfo[gCameraNum].devPath,
+                       CAMAERA_FILENAME_LENGTH);
             gCameraNum++;
         }
-        if (sCameraInfo[1].name[0] != DEFAULT_ERROR_NAME){
-            sCameraInfo[gCameraNum].facing = CAMERA_FACING_FRONT;
+        if (sCameraInfo[1].name[0] != DEFAULT_ERROR_NAME) {
+            sCameraInfo[gCameraNum].facing      = CAMERA_FACING_FRONT;
             sCameraInfo[gCameraNum].orientation = front_orient;
             memset(sCameraInfo[gCameraNum].devPath, 0, CAMAERA_FILENAME_LENGTH);
-            GetDevPath(sCameraInfo[gCameraNum].name, sCameraInfo[gCameraNum].devPath, CAMAERA_FILENAME_LENGTH);
+            GetDevPath(sCameraInfo[gCameraNum].name,
+                       sCameraInfo[gCameraNum].devPath,
+                       CAMAERA_FILENAME_LENGTH);
             gCameraNum++;
         }
     }
     return gCameraNum;
-
 }
 
-int camera_get_camera_info(int cameraId, struct camera_info* cameraInfo)
+int camera_get_camera_info(int                 cameraId,
+                           struct camera_info *cameraInfo)
 {
     memcpy(cameraInfo, &sCameraInfo[cameraId], sizeof(camera_info));
     return 0;
diff --git a/mx6/libcamera/CameraUtil.cpp b/mx6/libcamera/CameraUtil.cpp
old mode 100755
new mode 100644
index dfa3f0f..a98e167
--- a/mx6/libcamera/CameraUtil.cpp
+++ b/mx6/libcamera/CameraUtil.cpp
@@ -21,16 +21,20 @@
 int convertPixelFormatToV4L2Format(PixelFormat format)
 {
     int nFormat = 0;
-    switch(format) {
+
+    switch (format) {
         case HAL_PIXEL_FORMAT_YCbCr_420_SP:
-            nFormat = v4l2_fourcc('N','V','1','2');
+            nFormat = v4l2_fourcc('N', 'V', '1', '2');
             break;
+
         case HAL_PIXEL_FORMAT_YCbCr_420_P:
-            nFormat = v4l2_fourcc('Y','U','1','2');
+            nFormat = v4l2_fourcc('Y', 'U', '1', '2');
             break;
+
         case HAL_PIXEL_FORMAT_YCbCr_422_I:
-            nFormat = v4l2_fourcc('Y','U','Y','V');
+            nFormat = v4l2_fourcc('Y', 'U', 'Y', 'V');
             break;
+
         default:
             FLOGE("Error: format not supported!");
             break;
@@ -42,16 +46,20 @@ int convertPixelFormatToV4L2Format(PixelFormat format)
 PixelFormat convertV4L2FormatToPixelFormat(unsigned int format)
 {
     PixelFormat nFormat = 0;
-    switch(format) {
-        case v4l2_fourcc('N','V','1','2'):
+
+    switch (format) {
+        case v4l2_fourcc('N', 'V', '1', '2'):
             nFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
             break;
-        case v4l2_fourcc('Y','U','1','2'):
+
+        case v4l2_fourcc('Y', 'U', '1', '2'):
             nFormat = HAL_PIXEL_FORMAT_YCbCr_420_P;
             break;
-        case v4l2_fourcc('Y','U','Y','V'):
+
+        case v4l2_fourcc('Y', 'U', 'Y', 'V'):
             nFormat = HAL_PIXEL_FORMAT_YCbCr_422_I;
             break;
+
         default:
             FLOGE("Error: format not supported!");
             break;
@@ -60,20 +68,20 @@ PixelFormat convertV4L2FormatToPixelFormat(unsigned int format)
     return nFormat;
 }
 
-int convertStringToPixelFormat(const char* pFormat)
+int convertStringToPixelFormat(const char *pFormat)
 {
-    if(pFormat == NULL) {
+    if (pFormat == NULL) {
         return 0;
     }
 
-    if(!strcmp(pFormat, "yuv420p")) {
+    if (!strcmp(pFormat, "yuv420p")) {
         return HAL_PIXEL_FORMAT_YCbCr_420_P;
     }
-    else if(!strcmp(pFormat, "yuv420sp")) {
+    else if (!strcmp(pFormat, "yuv420sp")) {
         return HAL_PIXEL_FORMAT_YCbCr_420_SP;
     }
-    else if(!strcmp(pFormat, "yuv422i-yuyv")) {
-      return HAL_PIXEL_FORMAT_YCbCr_422_I;
+    else if (!strcmp(pFormat, "yuv422i-yuyv")) {
+        return HAL_PIXEL_FORMAT_YCbCr_422_I;
     }
     else {
         FLOGE("format %s is not supported", pFormat);
@@ -81,20 +89,20 @@ int convertStringToPixelFormat(const char* pFormat)
     }
 }
 
-int convertStringToV4L2Format(const char* pFormat)
+int convertStringToV4L2Format(const char *pFormat)
 {
-    if(pFormat == NULL) {
+    if (pFormat == NULL) {
         return 0;
     }
 
-    if(!strcmp(pFormat, "yuv420p")) {
-        return v4l2_fourcc('Y','U','1','2');
+    if (!strcmp(pFormat, "yuv420p")) {
+        return v4l2_fourcc('Y', 'U', '1', '2');
     }
-    else if(!strcmp(pFormat, "yuv420sp")) {
-        return v4l2_fourcc('N','V','1','2');
+    else if (!strcmp(pFormat, "yuv420sp")) {
+        return v4l2_fourcc('N', 'V', '1', '2');
     }
-    else if(!strcmp(pFormat, "yuv422i-yuyv")) {
-        return v4l2_fourcc('Y','U','Y','V');
+    else if (!strcmp(pFormat, "yuv422i-yuyv")) {
+        return v4l2_fourcc('Y', 'U', 'Y', 'V');
     }
     else {
         FLOGE("format %s is not supported", pFormat);
@@ -107,23 +115,24 @@ CameraFrame::~CameraFrame()
     reset();
 }
 
-void CameraFrame::initialize(buffer_handle_t* buf_h, int index)
+void CameraFrame::initialize(buffer_handle_t *buf_h,
+                             int              index)
 {
     FSL_ASSERT(buf_h);
     private_handle_t *handle = (private_handle_t *)(*buf_h);
     mBufHandle = buf_h;
-    mVirtAddr =  (void*)handle->base;
-    mPhyAddr =   handle->phys;
-    mSize =   handle->size;
-    mWidth =  handle->width;
-    mHeight = handle->height;
-    mFormat = handle->format;
-
-    mObserver = NULL;
-    mRefCount = 0;
-    mBufState = BUFS_CREATE;
+    mVirtAddr  =  (void *)handle->base;
+    mPhyAddr   =   handle->phys;
+    mSize      =   handle->size;
+    mWidth     =  handle->width;
+    mHeight    = handle->height;
+    mFormat    = handle->format;
+
+    mObserver  = NULL;
+    mRefCount  = 0;
+    mBufState  = BUFS_CREATE;
     mFrameType = INVALID_FRAME;
-    mIndex = index;
+    mIndex     = index;
 }
 
 void CameraFrame::addState(CAMERA_BUFS_STATE state)
@@ -159,15 +168,15 @@ void CameraFrame::setObserver(CameraFrameObserver *observer)
 void CameraFrame::reset()
 {
     mBufHandle = NULL;
-    mVirtAddr = NULL;
-    mPhyAddr = 0;
-    mObserver = NULL;
-    mRefCount = 0;
-    mBufState = BUFS_CREATE;
+    mVirtAddr  = NULL;
+    mPhyAddr   = 0;
+    mObserver  = NULL;
+    mRefCount  = 0;
+    mBufState  = BUFS_CREATE;
     mFrameType = INVALID_FRAME;
 }
 
-////////////CameraBufferProvider////////////////////
+// //////////CameraBufferProvider////////////////////
 CameraBufferProvider::CameraBufferProvider()
 {
     mBufferListeners.clear();
@@ -178,14 +187,14 @@ CameraBufferProvider::~CameraBufferProvider()
     mBufferListeners.clear();
 }
 
-void CameraBufferProvider::addBufferListener(CameraBufferListener* listener)
+void CameraBufferProvider::addBufferListener(CameraBufferListener *listener)
 {
     CameraBufferListener *pNtf = NULL;
-    size_t nSize = mBufferListeners.size();
+    size_t nSize               = mBufferListeners.size();
 
-    for(size_t i=0; i<nSize; i++) {
-        pNtf = (CameraBufferListener*)mBufferListeners[i];
-        if(pNtf == listener) {
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraBufferListener *)mBufferListeners[i];
+        if (pNtf == listener) {
             return;
         }
     }
@@ -193,16 +202,17 @@ void CameraBufferProvider::addBufferListener(CameraBufferListener* listener)
     mBufferListeners.push((int)listener);
 }
 
-void CameraBufferProvider::removeBufferListener(CameraBufferListener* listener)
+void CameraBufferProvider::removeBufferListener(CameraBufferListener *listener)
 {
-    CameraBufferListener* pNtf;
+    CameraBufferListener *pNtf;
     size_t nSize = mBufferListeners.size();
 
-    for(size_t i=0; i<nSize; i++) {
-        pNtf = (CameraBufferListener*)mBufferListeners[i];
-        if(pNtf == listener) {
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraBufferListener *)mBufferListeners[i];
+        if (pNtf == listener) {
             mBufferListeners.removeAt(i);
-            //break;
+
+            // break;
         }
     }
 }
@@ -212,14 +222,16 @@ void CameraBufferProvider::clearBufferListeners()
     mBufferListeners.clear();
 }
 
-void CameraBufferProvider::dispatchBuffers(CameraFrame* pBuffer, int num, BufferState bufState)
+void CameraBufferProvider::dispatchBuffers(CameraFrame *pBuffer,
+                                           int          num,
+                                           BufferState  bufState)
 {
     CameraBufferListener *listener;
     size_t nSize = mBufferListeners.size();
 
-    for(size_t i=0; i<nSize; i++) {
-        listener = (CameraBufferListener*)mBufferListeners[i];
-        switch(bufState) {
+    for (size_t i = 0; i < nSize; i++) {
+        listener = (CameraBufferListener *)mBufferListeners[i];
+        switch (bufState) {
             case BUFFER_CREATE:
                 FSL_ASSERT(pBuffer);
                 listener->onBufferCreat(pBuffer, num);
@@ -228,12 +240,11 @@ void CameraBufferProvider::dispatchBuffers(CameraFrame* pBuffer, int num, Buffer
             case BUFFER_DESTROY:
                 listener->onBufferDestroy();
                 break;
-        }//end switch
-    }//end for
+        } // end switch
+    }     // end for
 }
 
-
-////////////CameraFrameProvider////////////////////
+// //////////CameraFrameProvider////////////////////
 CameraFrameProvider::CameraFrameProvider()
 {
     mFrameListeners.clear();
@@ -244,14 +255,14 @@ CameraFrameProvider::~CameraFrameProvider()
     mFrameListeners.clear();
 }
 
-void CameraFrameProvider::addFrameListener(CameraFrameListener* listener)
+void CameraFrameProvider::addFrameListener(CameraFrameListener *listener)
 {
-    CameraFrameListener* pNtf;
+    CameraFrameListener *pNtf;
     size_t nSize = mFrameListeners.size();
 
-    for(size_t i=0; i<nSize; i++) {
-        pNtf = (CameraFrameListener*)mFrameListeners[i];
-        if(pNtf == listener) {
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraFrameListener *)mFrameListeners[i];
+        if (pNtf == listener) {
             return;
         }
     }
@@ -259,16 +270,17 @@ void CameraFrameProvider::addFrameListener(CameraFrameListener* listener)
     mFrameListeners.push((int)listener);
 }
 
-void CameraFrameProvider::removeFrameListener(CameraFrameListener* listener)
+void CameraFrameProvider::removeFrameListener(CameraFrameListener *listener)
 {
-    CameraFrameListener* pNtf;
+    CameraFrameListener *pNtf;
     size_t nSize = mFrameListeners.size();
 
-    for(size_t i=0; i<nSize; i++) {
-        pNtf = (CameraFrameListener*)mFrameListeners[i];
-        if(pNtf == listener) {
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraFrameListener *)mFrameListeners[i];
+        if (pNtf == listener) {
             mFrameListeners.removeAt(i);
-            //break;
+
+            // break;
         }
     }
 }
@@ -278,30 +290,30 @@ void CameraFrameProvider::clearFrameListeners()
     mFrameListeners.clear();
 }
 
-void CameraFrameProvider::dispatchCameraFrame(CameraFrame* frame)
+void CameraFrameProvider::dispatchCameraFrame(CameraFrame *frame)
 {
     FSL_ASSERT(frame);
-    CameraFrameListener* listener;
+    CameraFrameListener *listener;
     size_t nSize = mFrameListeners.size();
 
-    //add reference here to avoid frame release too early.
+    // add reference here to avoid frame release too early.
     frame->addReference();
-    for(size_t i=0; i<nSize; i++) {
-        listener = (CameraFrameListener*)mFrameListeners[i];
+    for (size_t i = 0; i < nSize; i++) {
+        listener = (CameraFrameListener *)mFrameListeners[i];
         listener->handleCameraFrame(frame);
     }
     frame->release();
 }
 
-//----------------CameraEventProvider----------
-void CameraEventProvider::addEventListener(CameraEventListener* listener)
+// ----------------CameraEventProvider----------
+void CameraEventProvider::addEventListener(CameraEventListener *listener)
 {
-    CameraEventListener* pNtf;
+    CameraEventListener *pNtf;
     size_t nSize = mEventListeners.size();
 
-    for(size_t i=0; i<nSize; i++) {
-        pNtf = (CameraEventListener*)mEventListeners[i];
-        if(pNtf == listener) {
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraEventListener *)mEventListeners[i];
+        if (pNtf == listener) {
             return;
         }
     }
@@ -309,16 +321,17 @@ void CameraEventProvider::addEventListener(CameraEventListener* listener)
     mEventListeners.push((int)listener);
 }
 
-void CameraEventProvider::removeEventListener(CameraEventListener* listener)
+void CameraEventProvider::removeEventListener(CameraEventListener *listener)
 {
-    CameraEventListener* pNtf;
+    CameraEventListener *pNtf;
     size_t nSize = mEventListeners.size();
 
-    for(size_t i=0; i<nSize; i++) {
-        pNtf = (CameraEventListener*)mEventListeners[i];
-        if(pNtf == listener) {
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraEventListener *)mEventListeners[i];
+        if (pNtf == listener) {
             mEventListeners.removeAt(i);
-            //break;
+
+            // break;
         }
     }
 }
@@ -331,11 +344,12 @@ void CameraEventProvider::clearEventListeners()
 void CameraEventProvider::dispatchEvent(sp<CameraEvent>& event)
 {
     FSL_ASSERT(event != NULL);
-    CameraEventListener* listener;
+    CameraEventListener *listener;
     size_t nSize = mEventListeners.size();
 
-    for(size_t i=0; i<nSize; i++) {
-        listener = (CameraEventListener*)mEventListeners[i];
+    for (size_t i = 0; i < nSize; i++) {
+        listener = (CameraEventListener *)mEventListeners[i];
         listener->handleEvent(event);
     }
 }
+
diff --git a/mx6/libcamera/CameraUtil.h b/mx6/libcamera/CameraUtil.h
old mode 100755
new mode 100644
index aacc91b..ca3b3a7
--- a/mx6/libcamera/CameraUtil.h
+++ b/mx6/libcamera/CameraUtil.h
@@ -53,18 +53,18 @@ using namespace android;
 
 #define CAMERA_HAL_DEBUG
 #ifdef CAMERA_HAL_DEBUG
-#define FLOG_RUNTIME(format, ...) ALOGI((format), ## __VA_ARGS__)
-#define FLOG_TRACE(format, ...) ALOGI((format), ## __VA_ARGS__)
-#else
-#define FLOG_RUNTIME(format, ...)
-#define FLOG_TRACE(format, ...)
-#endif
+# define FLOG_RUNTIME(format, ...) ALOGI((format), ## __VA_ARGS__)
+# define FLOG_TRACE(format, ...) ALOGI((format), ## __VA_ARGS__)
+#else // ifdef CAMERA_HAL_DEBUG
+# define FLOG_RUNTIME(format, ...)
+# define FLOG_TRACE(format, ...)
+#endif // ifdef CAMERA_HAL_DEBUG
 
 #define FLOGI(format, ...) ALOGI((format), ## __VA_ARGS__)
 #define FLOGW(format, ...) ALOGW((format), ## __VA_ARGS__)
-#define FLOGE(format, ...) ALOGE((format), ##__VA_ARGS__)
+#define FLOGE(format, ...) ALOGE((format), ## __VA_ARGS__)
 
-#define FSL_ASSERT(cond, ...) ALOG_ASSERT((cond), ##__VA_ARGS__)
+#define FSL_ASSERT(cond, ...) ALOG_ASSERT((cond), ## __VA_ARGS__)
 
 #define UVC_NAME_STRING "uvc"
 #define V4LSTREAM_WAKE_LOCK "V4LCapture"
@@ -79,16 +79,16 @@ using namespace android;
 #define PARAMS_DELIMITER ","
 
 #define CAMERA_GRALLOC_USAGE GRALLOC_USAGE_HW_TEXTURE | \
-                             GRALLOC_USAGE_HW_RENDER | \
-                             GRALLOC_USAGE_SW_READ_RARELY | \
-                             GRALLOC_USAGE_SW_WRITE_NEVER
+    GRALLOC_USAGE_HW_RENDER |                           \
+    GRALLOC_USAGE_SW_READ_RARELY |                      \
+    GRALLOC_USAGE_SW_WRITE_NEVER
 
 #define CAMERA_MAX(x, y) (x) > (y) ? (x) : (y)
 
-int convertPixelFormatToV4L2Format(PixelFormat format);
+int         convertPixelFormatToV4L2Format(PixelFormat format);
 PixelFormat convertV4L2FormatToPixelFormat(unsigned int format);
-int convertStringToPixelFormat(const char* pFormat);
-int convertStringToV4L2Format(const char* pFormat);
+int         convertStringToPixelFormat(const char *pFormat);
+int         convertStringToV4L2Format(const char *pFormat);
 
 struct VideoMetadataBuffer
 {
@@ -104,27 +104,27 @@ struct CameraInfo : public camera_info
 
 struct VideoInfo
 {
-    struct v4l2_capability cap;
-    struct v4l2_format format;
-    struct v4l2_streamparm param;
-    struct v4l2_buffer buf;
+    struct v4l2_capability     cap;
+    struct v4l2_format         format;
+    struct v4l2_streamparm     param;
+    struct v4l2_buffer         buf;
     struct v4l2_requestbuffers rb;
-    bool isStreamOn;
-    int width;
-    int height;
-    int formatIn;
-    int framesizeIn;
+    bool                       isStreamOn;
+    int                        width;
+    int                        height;
+    int                        formatIn;
+    int                        framesizeIn;
 };
 
 class CameraFrame;
 
-class CameraFrameObserver
-{
+class CameraFrameObserver {
 public:
     CameraFrameObserver() {}
+
     virtual ~CameraFrameObserver() {}
 
-    virtual void handleFrameRelease(CameraFrame* buffer) = 0;
+    virtual void handleFrameRelease(CameraFrame *buffer) = 0;
 
 private:
     CameraFrameObserver(const CameraFrameObserver&);
@@ -132,26 +132,27 @@ private:
 };
 
 
-class CameraFrame
-{
+class CameraFrame {
 public:
     enum CAMERA_BUFS_STATE {
-        BUFS_CREATE = 0,
-        BUFS_IN_CAPTURE = 1,
+        BUFS_CREATE      = 0,
+        BUFS_IN_CAPTURE  = 1,
         BUFS_IN_RECORDER = 2,
         BUFS_IN_PREIVIEW = 4,
-        BUFS_IN_DRIVER = 8
+        BUFS_IN_DRIVER   = 8
     };
     enum FrameType {
         INVALID_FRAME = 0,
-        IMAGE_FRAME = 1,
+        IMAGE_FRAME   = 1,
         PREVIEW_FRAME = 2,
     };
 
     CameraFrame() {}
+
     ~CameraFrame();
 
-    void initialize(buffer_handle_t* buf_h, int index);
+    void initialize(buffer_handle_t *buf_h,
+                    int              index);
     void addState(CAMERA_BUFS_STATE state);
     void removeState(CAMERA_BUFS_STATE state);
     void release();
@@ -164,132 +165,137 @@ private:
     CameraFrame& operator=(const CameraFrame&);
 
 public:
-    buffer_handle_t* mBufHandle;
-    void*            mVirtAddr;
-    int              mPhyAddr;
-    size_t           mSize;
-    int              mWidth;
-    int              mHeight;
-    int              mFormat;
-    FrameType        mFrameType;
-    int              mIndex;
+    buffer_handle_t *mBufHandle;
+    void *mVirtAddr;
+    int mPhyAddr;
+    size_t mSize;
+    int mWidth;
+    int mHeight;
+    int mFormat;
+    FrameType mFrameType;
+    int mIndex;
 
 private:
-    CameraFrameObserver* mObserver;
+    CameraFrameObserver *mObserver;
     int                  mRefCount;
     int                  mBufState;
 };
 
 enum CAMERA_ERROR {
     ERROR_FATAL = 1,
-    ERROR_TINY = 2,
+    ERROR_TINY  = 2,
 };
 
-class CameraErrorListener
-{
+class CameraErrorListener {
 public:
     virtual void handleError(CAMERA_ERROR err) = 0;
     virtual ~CameraErrorListener() {}
 };
 
-class CameraBufferListener
-{
+class CameraBufferListener {
 public:
-    virtual void onBufferCreat(CameraFrame* pBuffer, int num) = 0;
-    virtual void onBufferDestroy() = 0;
+    virtual void onBufferCreat(CameraFrame *pBuffer,
+                               int          num) = 0;
+    virtual void onBufferDestroy()               = 0;
     virtual ~CameraBufferListener() {}
 };
 
-class CameraBufferProvider
-{
+class CameraBufferProvider {
 public:
     enum BufferState {
-        BUFFER_CREATE = 1,
+        BUFFER_CREATE  = 1,
         BUFFER_DESTROY = 2,
     };
     CameraBufferProvider();
     virtual ~CameraBufferProvider();
 
-    virtual int allocatePreviewBuffer(int width, int height, int format, int numBufs) = 0;
-    virtual int allocatePictureBuffer(int width, int height, int format, int numBufs) = 0;
-    virtual int freeBuffer() = 0;
-    virtual int maxQueueableBuffers() = 0;
-
-    void addBufferListener(CameraBufferListener* listener);
-    void removeBufferListener(CameraBufferListener* listener);
-    void clearBufferListeners();
-
-    void dispatchBuffers(CameraFrame* pBuffer, int num, BufferState bufState);
+    virtual int allocatePreviewBuffer(int width,
+                                      int height,
+                                      int format,
+                                      int numBufs) = 0;
+    virtual int allocatePictureBuffer(int width,
+                                      int height,
+                                      int format,
+                                      int numBufs) = 0;
+    virtual int freeBuffer()                       = 0;
+    virtual int maxQueueableBuffers()              = 0;
+
+    void        addBufferListener(CameraBufferListener *listener);
+    void        removeBufferListener(CameraBufferListener *listener);
+    void        clearBufferListeners();
+
+    void        dispatchBuffers(CameraFrame *pBuffer,
+                                int          num,
+                                BufferState  bufState);
 
 private:
     Vector<int> mBufferListeners;
 };
 
-class CameraFrameListener
-{
+class CameraFrameListener {
 public:
-    virtual void handleCameraFrame(CameraFrame* frame) = 0;
+    virtual void handleCameraFrame(CameraFrame *frame) = 0;
     virtual ~CameraFrameListener() {}
 };
 
-class CameraFrameProvider
-{
+class CameraFrameProvider {
 public:
     CameraFrameProvider();
     virtual ~CameraFrameProvider();
 
-    virtual int getFrameSize() = 0;
+    virtual int getFrameSize()  = 0;
     virtual int getFrameCount() = 0;
-    void addFrameListener(CameraFrameListener* listener);
-    void removeFrameListener(CameraFrameListener* listener);
-    void clearFrameListeners();
+    void        addFrameListener(CameraFrameListener *listener);
+    void        removeFrameListener(CameraFrameListener *listener);
+    void        clearFrameListeners();
 
-    void dispatchCameraFrame(CameraFrame* frame);
+    void        dispatchCameraFrame(CameraFrame *frame);
 
 private:
     Vector<int> mFrameListeners;
 };
 
-class CameraEvent : public LightRefBase<CameraEvent>
-{
+class CameraEvent : public LightRefBase<CameraEvent>{
 public:
     enum CameraEventType {
         EVENT_INVALID = 0x0,
         EVENT_SHUTTER = 0x1,
-        EVENT_FOCUS = 0x2,
-        EVENT_ZOOM = 0x4,
-        EVENT_FACE = 0x8
+        EVENT_FOCUS   = 0x2,
+        EVENT_ZOOM    = 0x4,
+        EVENT_FACE    = 0x8
     };
 
     CameraEvent()
         : mData(NULL), mEventType(EVENT_INVALID)
     {}
 
-    void* mData;
+    void *mData;
     CameraEventType mEventType;
 };
 
-class CameraEventListener
-{
+class CameraEventListener {
 public:
     virtual void handleEvent(sp<CameraEvent>& event) = 0;
     virtual ~CameraEventListener() {}
 };
 
-class CameraEventProvider
-{
+class CameraEventProvider {
 public:
-    CameraEventProvider() {mEventListeners.clear();};
+    CameraEventProvider() {
+        mEventListeners.clear();
+    }
 
-    void addEventListener(CameraEventListener* listerner);
-    void removeEventListener(CameraEventListener* listerner);
+    void addEventListener(CameraEventListener *listerner);
+    void removeEventListener(CameraEventListener *listerner);
     void clearEventListeners();
     void dispatchEvent(sp<CameraEvent>& event);
 
-    virtual ~CameraEventProvider() {mEventListeners.clear();};
+    virtual ~CameraEventProvider() {
+        mEventListeners.clear();
+    }
 
 private:
     Vector<int> mEventListeners;
 };
 
-#endif
+#endif // ifndef _CAMERA_UTILS_H
diff --git a/mx6/libcamera/DeviceAdapter.cpp b/mx6/libcamera/DeviceAdapter.cpp
old mode 100755
new mode 100644
index 3ebe9c0..d89ccb3
--- a/mx6/libcamera/DeviceAdapter.cpp
+++ b/mx6/libcamera/DeviceAdapter.cpp
@@ -19,10 +19,10 @@
 #include "UvcDevice.h"
 #include "OvDevice.h"
 
-sp<DeviceAdapter> DeviceAdapter::Create(const CameraInfo& info)
+sp<DeviceAdapter>DeviceAdapter::Create(const CameraInfo& info)
 {
     sp<DeviceAdapter> devAdapter;
-    if(strstr(info.name, UVC_NAME_STRING)) {
+    if (strstr(info.name, UVC_NAME_STRING)) {
         FLOGI("DeviceAdapter: Create uvc device");
         devAdapter = new UvcDevice();
     }
@@ -35,15 +35,14 @@ sp<DeviceAdapter> DeviceAdapter::Create(const CameraInfo& info)
 
 DeviceAdapter::DeviceAdapter()
     : mCameraHandle(-1), mQueued(0), mDequeued(0)
-{
-}
+{}
 
 DeviceAdapter::~DeviceAdapter()
 {
     // Close the camera handle and free the video info structure
     close(mCameraHandle);
 
-    if(mVideoInfo) {
+    if (mVideoInfo) {
         delete mVideoInfo;
         mVideoInfo = NULL;
     }
@@ -51,22 +50,22 @@ DeviceAdapter::~DeviceAdapter()
 
 status_t DeviceAdapter::initialize(const CameraInfo& info)
 {
-    if(info.name == NULL) {
+    if (info.name == NULL) {
         FLOGE("invalid camera sensor name in initialize");
         return BAD_VALUE;
     }
-    if(info.devPath == NULL) {
+    if (info.devPath == NULL) {
         FLOGE("invalid camera devpath in initialize");
         return BAD_VALUE;
     }
 
     mCameraHandle = open(info.devPath, O_RDWR);
-    if(mCameraHandle < 0) {
+    if (mCameraHandle < 0) {
         FLOGE("can not open camera devpath:%s", info.devPath);
         return BAD_VALUE;
     }
     mVideoInfo = new VideoInfo();
-    if(mVideoInfo == NULL) {
+    if (mVideoInfo == NULL) {
         close(mCameraHandle);
         FLOGE("new VideoInfo failed");
         return NO_MEMORY;
@@ -74,13 +73,13 @@ status_t DeviceAdapter::initialize(const CameraInfo& info)
 
     int ret = NO_ERROR;
     ret = ioctl(mCameraHandle, VIDIOC_QUERYCAP, &mVideoInfo->cap);
-    if(ret < 0) {
+    if (ret < 0) {
         close(mCameraHandle);
         delete mVideoInfo;
         FLOGE("query v4l2 capability failed");
         return BAD_VALUE;
     }
-    if((mVideoInfo->cap.capabilities & V4L2_CAP_VIDEO_CAPTURE) == 0)
+    if ((mVideoInfo->cap.capabilities & V4L2_CAP_VIDEO_CAPTURE) == 0)
     {
         close(mCameraHandle);
         delete mVideoInfo;
@@ -89,42 +88,43 @@ status_t DeviceAdapter::initialize(const CameraInfo& info)
     }
 
     // Initialize flags
-    mPreviewing = false;
+    mPreviewing            = false;
     mVideoInfo->isStreamOn = false;
-    mImageCapture = false;
+    mImageCapture          = false;
 
     return NO_ERROR;
 }
 
-static int getCaptureMode(int width, int height)
+static int getCaptureMode(int width,
+                          int height)
 {
     int capturemode = 0;
 
-    if(width == 640 && height == 480) {
+    if ((width == 640) && (height == 480)) {
         capturemode = 0;
     }
-    else if(width == 320 && height == 240) {
+    else if ((width == 320) && (height == 240)) {
         capturemode = 1;
     }
-    else if(width == 720 && height == 480) {
+    else if ((width == 720) && (height == 480)) {
         capturemode = 2;
     }
-    else if(width == 720 && height == 576) {
+    else if ((width == 720) && (height == 576)) {
         capturemode = 3;
     }
-    else if(width == 1280 && height == 720) {
+    else if ((width == 1280) && (height == 720)) {
         capturemode = 4;
     }
-    else if(width == 1920 && height == 1080) {
+    else if ((width == 1920) && (height == 1080)) {
         capturemode = 5;
     }
-    else if(width == 2592 && height == 1944) {
+    else if ((width == 2592) && (height == 1944)) {
         capturemode = 6;
     }
-    else if(width == 176 && height == 144) {
+    else if ((width == 176) && (height == 144)) {
         capturemode = 7;
     }
-    else if(width == 1024 && height == 768) {
+    else if ((width == 1024) && (height == 768)) {
         capturemode = 8;
     }
     else {
@@ -133,19 +133,22 @@ static int getCaptureMode(int width, int height)
     return capturemode;
 }
 
-status_t DeviceAdapter::setDeviceConfig(int width, int height, PixelFormat format, int fps)
+status_t DeviceAdapter::setDeviceConfig(int         width,
+                                        int         height,
+                                        PixelFormat format,
+                                        int         fps)
 {
-    if(mCameraHandle <= 0) {
+    if (mCameraHandle <= 0) {
         FLOGE("setDeviceConfig: DeviceAdapter uninitialized");
         return BAD_VALUE;
     }
-    if(width == 0 || height == 0) {
+    if ((width == 0) || (height == 0)) {
         FLOGE("setDeviceConfig: invalid parameters");
         return BAD_VALUE;
     }
 
     status_t ret = NO_ERROR;
-    int input = 1;
+    int input    = 1;
     ret = ioctl(mCameraHandle, VIDIOC_S_INPUT, &input);
     if (ret < 0) {
         FLOGE("Open: VIDIOC_S_INPUT Failed: %s", strerror(errno));
@@ -155,32 +158,43 @@ status_t DeviceAdapter::setDeviceConfig(int width, int height, PixelFormat forma
     int vformat;
     vformat = convertPixelFormatToV4L2Format(format);
 
-    if(width > 1920 || height > 1080) {
+    if ((width > 1920) || (height > 1080)) {
         fps = 15;
     }
-    FLOGI("Width * Height %d x %d format %d, fps: %d", width, height, vformat, fps);
+    FLOGI("Width * Height %d x %d format %d, fps: %d",
+          width,
+          height,
+          vformat,
+          fps);
 
-    mVideoInfo->width = width;
-    mVideoInfo->height = height;
+    mVideoInfo->width       = width;
+    mVideoInfo->height      = height;
     mVideoInfo->framesizeIn = (width * height << 1);
-    mVideoInfo->formatIn = vformat;
+    mVideoInfo->formatIn    = vformat;
 
-    mVideoInfo->param.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-    mVideoInfo->param.parm.capture.timeperframe.numerator = 1;
+    mVideoInfo->param.type =
+        V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    mVideoInfo->param.parm.capture.timeperframe.numerator   = 1;
     mVideoInfo->param.parm.capture.timeperframe.denominator = fps;
-    mVideoInfo->param.parm.capture.capturemode = getCaptureMode(width, height);
-    ret = ioctl(mCameraHandle, VIDIOC_S_PARM, &mVideoInfo->param);
+    mVideoInfo->param.parm.capture.capturemode              = getCaptureMode(
+        width,
+        height);
+    ret                                                     = ioctl(
+        mCameraHandle,
+        VIDIOC_S_PARM,
+        &mVideoInfo->
+        param);
     if (ret < 0) {
         FLOGE("Open: VIDIOC_S_PARM Failed: %s", strerror(errno));
         return ret;
     }
 
-    mVideoInfo->format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-    mVideoInfo->format.fmt.pix.width = width & 0xFFFFFFF8;
-    mVideoInfo->format.fmt.pix.height = height & 0xFFFFFFF8;
-    mVideoInfo->format.fmt.pix.pixelformat = vformat;
-    mVideoInfo->format.fmt.pix.priv = 0;
-    mVideoInfo->format.fmt.pix.sizeimage = 0;
+    mVideoInfo->format.type                 = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    mVideoInfo->format.fmt.pix.width        = width & 0xFFFFFFF8;
+    mVideoInfo->format.fmt.pix.height       = height & 0xFFFFFFF8;
+    mVideoInfo->format.fmt.pix.pixelformat  = vformat;
+    mVideoInfo->format.fmt.pix.priv         = 0;
+    mVideoInfo->format.fmt.pix.sizeimage    = 0;
     mVideoInfo->format.fmt.pix.bytesperline = 0;
 
     ret = ioctl(mCameraHandle, VIDIOC_S_FMT, &mVideoInfo->format);
@@ -202,18 +216,19 @@ int DeviceAdapter::getFrameCount()
     return mPreviewBufferCount;
 }
 
-status_t DeviceAdapter::registerCameraFrames(CameraFrame* pBuffer, int& num)
+status_t DeviceAdapter::registerCameraFrames(CameraFrame *pBuffer,
+                                             int        & num)
 {
     status_t ret = NO_ERROR;
 
-    if(pBuffer == NULL || num <= 0) {
+    if ((pBuffer == NULL) || (num <= 0)) {
         FLOGE("requestCameraBuffers invalid pBuffer");
         return BAD_VALUE;
     }
 
-    mVideoInfo->rb.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    mVideoInfo->rb.type   = V4L2_BUF_TYPE_VIDEO_CAPTURE;
     mVideoInfo->rb.memory = V4L2_MEMORY_USERPTR;
-    mVideoInfo->rb.count = num;
+    mVideoInfo->rb.count  = num;
 
     ret = ioctl(mCameraHandle, VIDIOC_REQBUFS, &mVideoInfo->rb);
     if (ret < 0) {
@@ -222,53 +237,53 @@ status_t DeviceAdapter::registerCameraFrames(CameraFrame* pBuffer, int& num)
     }
 
     for (int i = 0; i < num; i++) {
-        CameraFrame* buffer = pBuffer + i;
-        memset (&mVideoInfo->buf, 0, sizeof (struct v4l2_buffer));
-        mVideoInfo->buf.index = i;
-        mVideoInfo->buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-        mVideoInfo->buf.memory = V4L2_MEMORY_USERPTR;
+        CameraFrame *buffer = pBuffer + i;
+        memset(&mVideoInfo->buf, 0, sizeof(struct v4l2_buffer));
+        mVideoInfo->buf.index    = i;
+        mVideoInfo->buf.type     = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        mVideoInfo->buf.memory   = V4L2_MEMORY_USERPTR;
         mVideoInfo->buf.m.offset = buffer->mPhyAddr;
-        mVideoInfo->buf.length = buffer->mSize;
+        mVideoInfo->buf.length   = buffer->mSize;
 
-        ret = ioctl (mCameraHandle, VIDIOC_QUERYBUF, &mVideoInfo->buf);
+        ret = ioctl(mCameraHandle, VIDIOC_QUERYBUF, &mVideoInfo->buf);
         if (ret < 0) {
             FLOGE("Unable to query buffer (%s)", strerror(errno));
             return ret;
         }
-        //Associate each Camera buffer
+
+        // Associate each Camera buffer
         buffer->setObserver(this);
         mPreviewBufs.add((int)buffer, i);
     }
 
-    mPreviewBufferSize = pBuffer->mSize;
+    mPreviewBufferSize  = pBuffer->mSize;
     mPreviewBufferCount = num;
 
     return ret;
 }
 
-status_t DeviceAdapter::fillCameraFrame(CameraFrame* frame)
+status_t DeviceAdapter::fillCameraFrame(CameraFrame *frame)
 {
-
     status_t ret = NO_ERROR;
 
-    if ( !mVideoInfo->isStreamOn ) {
+    if (!mVideoInfo->isStreamOn) {
         return NO_ERROR;
     }
 
-    int i = mPreviewBufs.valueFor(( unsigned int )frame);
-    if(i<0) {
+    int i = mPreviewBufs.valueFor((unsigned int)frame);
+    if (i < 0) {
         return BAD_VALUE;
     }
 
-    mVideoInfo->buf.index = i;
-    mVideoInfo->buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-    mVideoInfo->buf.memory = V4L2_MEMORY_USERPTR;
+    mVideoInfo->buf.index    = i;
+    mVideoInfo->buf.type     = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    mVideoInfo->buf.memory   = V4L2_MEMORY_USERPTR;
     mVideoInfo->buf.m.offset = frame->mPhyAddr;
 
     ret = ioctl(mCameraHandle, VIDIOC_QBUF, &mVideoInfo->buf);
     if (ret < 0) {
-       FLOGE("fillCameraFrame: VIDIOC_QBUF Failed");
-       return BAD_VALUE;
+        FLOGE("fillCameraFrame: VIDIOC_QBUF Failed");
+        return BAD_VALUE;
     }
     mQueued++;
 
@@ -278,39 +293,40 @@ status_t DeviceAdapter::fillCameraFrame(CameraFrame* frame)
 status_t DeviceAdapter::startDeviceLocked()
 {
     status_t ret = NO_ERROR;
+
     FSL_ASSERT(!mPreviewBufs.isEmpty());
     FSL_ASSERT(mBufferProvider != NULL);
 
     int queueableBufs = mBufferProvider->maxQueueableBuffers();
     FSL_ASSERT(queueableBufs > 0);
 
-    for(int i = 0; i < queueableBufs; i++) {
-        CameraFrame* frame = (CameraFrame*)mPreviewBufs.keyAt(i);
-        mVideoInfo->buf.index = i;
-        mVideoInfo->buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-        mVideoInfo->buf.memory = V4L2_MEMORY_USERPTR;
+    for (int i = 0; i < queueableBufs; i++) {
+        CameraFrame *frame = (CameraFrame *)mPreviewBufs.keyAt(i);
+        mVideoInfo->buf.index    = i;
+        mVideoInfo->buf.type     = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        mVideoInfo->buf.memory   = V4L2_MEMORY_USERPTR;
         mVideoInfo->buf.m.offset = frame->mPhyAddr;
 
         ret = ioctl(mCameraHandle, VIDIOC_QBUF, &mVideoInfo->buf);
         if (ret < 0) {
-           FLOGE("VIDIOC_QBUF Failed");
-           return BAD_VALUE;
+            FLOGE("VIDIOC_QBUF Failed");
+            return BAD_VALUE;
         }
 
         mQueued++;
     }
 
     enum v4l2_buf_type bufType;
-    if(!mVideoInfo->isStreamOn) {
-       bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    if (!mVideoInfo->isStreamOn) {
+        bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
 
-       ret = ioctl(mCameraHandle, VIDIOC_STREAMON, &bufType);
-       if (ret < 0) {
-           FLOGE("VIDIOC_STREAMON failed: %s", strerror(errno));
-           return ret;
-       }
+        ret = ioctl(mCameraHandle, VIDIOC_STREAMON, &bufType);
+        if (ret < 0) {
+            FLOGE("VIDIOC_STREAMON failed: %s", strerror(errno));
+            return ret;
+        }
 
-       mVideoInfo->isStreamOn = true;
+        mVideoInfo->isStreamOn = true;
     }
 
     mDeviceThread = new DeviceThread(this);
@@ -327,7 +343,7 @@ status_t DeviceAdapter::stopDeviceLocked()
     mDeviceThread->requestExitAndWait();
     mDeviceThread.clear();
 
-    if(mVideoInfo->isStreamOn) {
+    if (mVideoInfo->isStreamOn) {
         bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
 
         ret = ioctl(mCameraHandle, VIDIOC_STREAMOFF, &bufType);
@@ -339,7 +355,7 @@ status_t DeviceAdapter::stopDeviceLocked()
         mVideoInfo->isStreamOn = false;
     }
 
-    mQueued = 0;
+    mQueued   = 0;
     mDequeued = 0;
     mPreviewBufs.clear();
 
@@ -350,7 +366,7 @@ status_t DeviceAdapter::startPreview()
 {
     status_t ret = NO_ERROR;
 
-    if(mPreviewing) {
+    if (mPreviewing) {
         FLOGE("DeviceAdapter: startPreview but preview running");
         return BAD_VALUE;
     }
@@ -367,14 +383,14 @@ status_t DeviceAdapter::stopPreview()
 {
     int ret = NO_ERROR;
 
-    if(!mPreviewing) {
+    if (!mPreviewing) {
         FLOGE("DeviceAdapter: stopPreview but preview not running");
         return NO_INIT;
     }
 
     Mutex::Autolock lock(mPreviewBufsLock);
     mPreviewing = false;
-    ret = stopDeviceLocked();
+    ret         = stopDeviceLocked();
 
     return ret;
 }
@@ -383,14 +399,14 @@ status_t DeviceAdapter::startImageCapture()
 {
     status_t ret = NO_ERROR;
 
-    if(mImageCapture) {
+    if (mImageCapture) {
         FLOGE("DeviceAdapter: startPreview but preview running");
         return BAD_VALUE;
     }
 
     Mutex::Autolock lock(mPreviewBufsLock);
     mImageCapture = true;
-    ret = startDeviceLocked();
+    ret           = startDeviceLocked();
 
     return ret;
 }
@@ -399,23 +415,23 @@ status_t DeviceAdapter::stopImageCapture()
 {
     int ret = NO_ERROR;
 
-    if(!mImageCapture) {
+    if (!mImageCapture) {
         FLOGE("DeviceAdapter: stopPreview but preview not running");
         return NO_INIT;
     }
 
     Mutex::Autolock lock(mPreviewBufsLock);
     mImageCapture = false;
-    ret = stopDeviceLocked();
+    ret           = stopDeviceLocked();
 
     return ret;
 }
 
-CameraFrame* DeviceAdapter::acquireCameraFrame()
+CameraFrame * DeviceAdapter::acquireCameraFrame()
 {
     int ret;
 
-    mVideoInfo->buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    mVideoInfo->buf.type   = V4L2_BUF_TYPE_VIDEO_CAPTURE;
     mVideoInfo->buf.memory = V4L2_MEMORY_USERPTR;
 
     /* DQ */
@@ -428,63 +444,64 @@ CameraFrame* DeviceAdapter::acquireCameraFrame()
 
     int index = mVideoInfo->buf.index;
     FSL_ASSERT(!mPreviewBufs.isEmpty(), "mPreviewBufs is empty");
-    return (CameraFrame*)mPreviewBufs.keyAt(index);
+    return (CameraFrame *)mPreviewBufs.keyAt(index);
 }
 
-//#define FSL_CAMERAHAL_DUMP
-static void bufferDump(CameraFrame* frame)
+// #define FSL_CAMERAHAL_DUMP
+static void bufferDump(CameraFrame *frame)
 {
 #ifdef FSL_CAMERAHAL_DUMP
-   //for test code
+
+    // for test code
     char value[100];
     memset(value, 0, sizeof(value));
     static int vflg = 0;
     property_get("rw.camera.test", value, "");
-    if(strcmp(value, "1") == 0)
-	vflg = 1;
-    if(vflg){
-	FILE *pf = NULL;
-	pf = fopen("/sdcard/camera_tst.data", "wb");
-	if(pf == NULL) {
-	    FLOGI("open /sdcard/camera_tst.data failed");
-	}
-	else {
+    if (strcmp(value, "1") == 0)
+        vflg = 1;
+    if (vflg) {
+        FILE *pf = NULL;
+        pf = fopen("/sdcard/camera_tst.data", "wb");
+        if (pf == NULL) {
+            FLOGI("open /sdcard/camera_tst.data failed");
+        }
+        else {
             FLOGI("-----write-----");
-	    fwrite(frame->mVirtAddr, frame->mSize, 1, pf);
-	    fclose(pf);
-	}
-	vflg = 0;
+            fwrite(frame->mVirtAddr, frame->mSize, 1, pf);
+            fclose(pf);
+        }
+        vflg = 0;
     }
-#endif
+#endif // ifdef FSL_CAMERAHAL_DUMP
 }
 
-
 int DeviceAdapter::deviceThread()
 {
-    CameraFrame* frame = NULL;
-
-        frame = acquireCameraFrame();
-        if(!frame) {
-            if(mQueued - mDequeued <= 0) {
-                //if stop preview, then exit.
-                if(!mPreviewing) {
-                    FLOGI("preview stop, so exit device thread");
-                    return BAD_VALUE;
-                }
-                else {
-                    //to check buffer in another cycle.
-                    FLOGI("no buffer in v4l driver, check it next time");
-                    return NO_ERROR;
-                }
+    CameraFrame *frame = NULL;
+
+    frame = acquireCameraFrame();
+    if (!frame) {
+        if (mQueued - mDequeued <= 0) {
+            // if stop preview, then exit.
+            if (!mPreviewing) {
+                FLOGI("preview stop, so exit device thread");
+                return BAD_VALUE;
             }
-            FLOGE("device thread exit with frame = null, %d buffers still in v4l", mQueued - mDequeued);
-            if(mErrorListener != NULL) {
-                mErrorListener->handleError(ERROR_FATAL);
+            else {
+                // to check buffer in another cycle.
+                FLOGI("no buffer in v4l driver, check it next time");
+                return NO_ERROR;
             }
-            return BAD_VALUE;
         }
+        FLOGE("device thread exit with frame = null, %d buffers still in v4l",
+              mQueued - mDequeued);
+        if (mErrorListener != NULL) {
+            mErrorListener->handleError(ERROR_FATAL);
+        }
+        return BAD_VALUE;
+    }
 
-    if(mImageCapture) {
+    if (mImageCapture) {
         sp<CameraEvent> cameraEvt = new CameraEvent();
         cameraEvt->mEventType = CameraEvent::EVENT_SHUTTER;
         dispatchEvent(cameraEvt);
@@ -496,7 +513,7 @@ int DeviceAdapter::deviceThread()
     }
 
     dispatchCameraFrame(frame);
-    if(mImageCapture) {
+    if (mImageCapture) {
         FLOGI("device thread exit after take picture");
         return ALREADY_EXISTS;
     }
@@ -506,12 +523,12 @@ int DeviceAdapter::deviceThread()
 
 status_t DeviceAdapter::autoFocus()
 {
-    if(mAutoFocusThread != NULL) {
+    if (mAutoFocusThread != NULL) {
         mAutoFocusThread.clear();
     }
 
     mAutoFocusThread = new AutoFocusThread(this);
-    if(mAutoFocusThread == NULL) {
+    if (mAutoFocusThread == NULL) {
         return UNKNOWN_ERROR;
     }
     return NO_ERROR;
@@ -528,31 +545,32 @@ int DeviceAdapter::autoFocusThread()
     cameraEvt->mEventType = CameraEvent::EVENT_FOCUS;
     dispatchEvent(cameraEvt);
 
-    //exit the thread.
+    // exit the thread.
     return UNKNOWN_ERROR;
 }
 
-void DeviceAdapter::handleFrameRelease(CameraFrame* buffer)
+void DeviceAdapter::handleFrameRelease(CameraFrame *buffer)
 {
-    if(mPreviewing) {
+    if (mPreviewing) {
         fillCameraFrame(buffer);
     }
 }
 
-void DeviceAdapter::setErrorListener(CameraErrorListener* listener)
+void DeviceAdapter::setErrorListener(CameraErrorListener *listener)
 {
     mErrorListener = listener;
 }
 
-void DeviceAdapter::setCameraBufferProvide(CameraBufferProvider* bufferProvider)
+void DeviceAdapter::setCameraBufferProvide(CameraBufferProvider *bufferProvider)
 {
-    if(bufferProvider != NULL) {
+    if (bufferProvider != NULL) {
         bufferProvider->addBufferListener(this);
     }
     mBufferProvider = bufferProvider;
 }
 
-void DeviceAdapter::onBufferCreat(CameraFrame* pBuffer, int num)
+void DeviceAdapter::onBufferCreat(CameraFrame *pBuffer,
+                                  int          num)
 {
     registerCameraFrames(pBuffer, num);
 }
@@ -561,3 +579,4 @@ void DeviceAdapter::onBufferDestroy()
 {
     mPreviewBufs.clear();
 }
+
diff --git a/mx6/libcamera/DeviceAdapter.h b/mx6/libcamera/DeviceAdapter.h
old mode 100755
new mode 100644
index ed3de67..ae52542
--- a/mx6/libcamera/DeviceAdapter.h
+++ b/mx6/libcamera/DeviceAdapter.h
@@ -23,33 +23,45 @@
 using namespace android;
 
 class DeviceAdapter : public CameraFrameProvider, public CameraBufferListener,
-        public CameraEventProvider,
-        public CameraFrameObserver, public LightRefBase<DeviceAdapter>
-{
+                      public CameraEventProvider,
+                      public CameraFrameObserver,
+                      public LightRefBase<DeviceAdapter>{
 public:
     static sp<DeviceAdapter> Create(const CameraInfo& info);
     DeviceAdapter();
     ~DeviceAdapter();
 
 public:
-    virtual int getFrameSize();
-    virtual int getFrameCount();
+    virtual int      getFrameSize();
+    virtual int      getFrameCount();
 
-    void setErrorListener(CameraErrorListener* listener);
-    void setCameraBufferProvide(CameraBufferProvider* bufferProvider);
+    void             setErrorListener(CameraErrorListener *listener);
+    void             setCameraBufferProvide(CameraBufferProvider *bufferProvider);
     virtual status_t initialize(const CameraInfo& info);
-    status_t setDeviceConfig(int width, int height, PixelFormat format, int fps);
-    PixelFormat getPreviewPixelFormat() {return mPicturePixelFormat;}
-    PixelFormat getPicturePixelFormat() {return mPreviewPixelFormat;}
+    status_t         setDeviceConfig(int         width,
+                                     int         height,
+                                     PixelFormat format,
+                                     int         fps);
+    PixelFormat getPreviewPixelFormat() {
+        return mPicturePixelFormat;
+    }
+
+    PixelFormat getPicturePixelFormat() {
+        return mPreviewPixelFormat;
+    }
 
     virtual status_t setParameters(CameraParameters& params) = 0;
-    virtual status_t initParameters(CameraParameters& params, int* supportRecordingFormat, int rfmtLen,
-                        int* supportPictureFormat, int pfmtLen) = 0;
-
-    //API to send a command to the camera
-    //virtual status_t sendCommand(CameraCommands operation, int value1 = 0, int value2 = 0, int value3 = 0 );
-    status_t autoFocus();
-    status_t cancelAutoFocus();
+    virtual status_t initParameters(CameraParameters& params,
+                                    int              *supportRecordingFormat,
+                                    int               rfmtLen,
+                                    int              *supportPictureFormat,
+                                    int               pfmtLen) = 0;
+
+    // API to send a command to the camera
+    // virtual status_t sendCommand(CameraCommands operation, int value1 = 0,
+    // int value2 = 0, int value3 = 0 );
+    status_t         autoFocus();
+    status_t         cancelAutoFocus();
 
     virtual status_t startPreview();
     virtual status_t stopPreview();
@@ -58,16 +70,18 @@ public:
     virtual status_t stopImageCapture();
 
 protected:
-    void onBufferCreat(CameraFrame* pBuffer, int num);
-    void onBufferDestroy();
-    virtual status_t registerCameraFrames(CameraFrame* pBuffer, int& num);
-    virtual void handleFrameRelease(CameraFrame* buffer);
+    void             onBufferCreat(CameraFrame *pBuffer,
+                                   int          num);
+    void             onBufferDestroy();
+    virtual status_t registerCameraFrames(CameraFrame *pBuffer,
+                                          int        & num);
+    virtual void     handleFrameRelease(CameraFrame *buffer);
 
 private:
     class AutoFocusThread : public Thread {
     public:
-        AutoFocusThread(DeviceAdapter* hw) :
-                Thread(false), mAdapter(hw) { }
+        AutoFocusThread(DeviceAdapter *hw) :
+            Thread(false), mAdapter(hw) {}
 
         virtual void onFirstRef() {
             run("AutoFocusThread", PRIORITY_URGENT_DISPLAY);
@@ -75,22 +89,24 @@ private:
 
         virtual bool threadLoop() {
             int ret = 0;
+
             ret = mAdapter->autoFocusThread();
-            if(ret != 0) {
+            if (ret != 0) {
                 return false;
             }
+
             // loop until we need to quit
             return true;
         }
 
     private:
-        DeviceAdapter* mAdapter;
+        DeviceAdapter *mAdapter;
     };
 
     class DeviceThread : public Thread {
     public:
-        DeviceThread(DeviceAdapter* hw) :
-                Thread(false), mAdapter(hw) { }
+        DeviceThread(DeviceAdapter *hw) :
+            Thread(false), mAdapter(hw) {}
 
         virtual void onFirstRef() {
             run("DeviceThread", PRIORITY_URGENT_DISPLAY);
@@ -98,30 +114,32 @@ private:
 
         virtual bool threadLoop() {
             int ret = 0;
+
             ret = mAdapter->deviceThread();
-            if(ret != 0) {
+            if (ret != 0) {
                 return false;
             }
+
             // loop until we need to quit
             return true;
         }
 
     private:
-        DeviceAdapter* mAdapter;
+        DeviceAdapter *mAdapter;
     };
 
 private:
-    status_t fillCameraFrame(CameraFrame* frame);
+    status_t     fillCameraFrame(CameraFrame *frame);
     CameraFrame* acquireCameraFrame();
 
-    status_t startDeviceLocked();
-    status_t stopDeviceLocked();
-    int deviceThread();
-    int autoFocusThread();
+    status_t     startDeviceLocked();
+    status_t     stopDeviceLocked();
+    int          deviceThread();
+    int          autoFocusThread();
 
 protected:
-    CameraBufferProvider* mBufferProvider;
-    CameraErrorListener* mErrorListener;
+    CameraBufferProvider *mBufferProvider;
+    CameraErrorListener  *mErrorListener;
     int mPreviewBufferCount;
     int mPreviewBufferSize;
     KeyedVector<int, int> mPreviewBufs;
@@ -143,4 +161,4 @@ protected:
     PixelFormat mPreviewPixelFormat;
 };
 
-#endif
+#endif // ifndef _DEVICE_ADAPTER_H_
diff --git a/mx6/libcamera/DisplayAdapter.cpp b/mx6/libcamera/DisplayAdapter.cpp
old mode 100755
new mode 100644
index bd93c9b..d62c4ef
--- a/mx6/libcamera/DisplayAdapter.cpp
+++ b/mx6/libcamera/DisplayAdapter.cpp
@@ -24,28 +24,28 @@ DisplayAdapter::DisplayAdapter()
 {
     mFrameProvider = NULL;
 
-    mPreviewWidth = 0;
+    mPreviewWidth  = 0;
     mPreviewHeight = 0;
 }
 
 DisplayAdapter::~DisplayAdapter()
 {
-    if(mFrameProvider) {
+    if (mFrameProvider) {
         mFrameProvider->removeFrameListener(this);
         mFrameProvider = NULL;
     }
 
-    ///The ANativeWindow object will get destroyed here
+    // /The ANativeWindow object will get destroyed here
     destroy();
 
-    ///If Display thread exists
-    if(mDisplayThread.get()) {
-        mThreadQueue.postSyncMessage(new SyncMessage(DisplayThread::DISPLAY_EXIT, 0));
+    // /If Display thread exists
+    if (mDisplayThread.get()) {
+        mThreadQueue.postSyncMessage(new SyncMessage(DisplayThread::DISPLAY_EXIT,
+                                                     0));
         mDisplayThread->requestExitAndWait();
 
         mDisplayThread.clear();
     }
-
 }
 
 status_t DisplayAdapter::initialize()
@@ -56,7 +56,7 @@ status_t DisplayAdapter::initialize()
         return NO_MEMORY;
     }
 
-    ///Start the display thread
+    // /Start the display thread
     status_t ret = mDisplayThread->run("DisplayThread", PRIORITY_URGENT_DISPLAY);
     if (ret != NO_ERROR) {
         FLOGE("Couldn't run display thread");
@@ -68,29 +68,32 @@ status_t DisplayAdapter::initialize()
     return ret;
 }
 
-int DisplayAdapter::setCameraFrameProvider(CameraFrameProvider* frameProvider)
+int DisplayAdapter::setCameraFrameProvider(CameraFrameProvider *frameProvider)
 {
     mFrameProvider = frameProvider;
     return NO_ERROR;
 }
 
-int DisplayAdapter::startDisplay(int width, int height)
+int DisplayAdapter::startDisplay(int width,
+                                 int height)
 {
-    if(mDisplayEnabled) {
+    if (mDisplayEnabled) {
         FLOGW("Display is already enabled");
         return NO_ERROR;
     }
 
     mThreadQueue.postSyncMessage(new SyncMessage(DisplayThread::DISPLAY_START, 0));
-    //Send START_DISPLAY COMMAND to display thread. Display thread will start and then wait for a message
+
+    // Send START_DISPLAY COMMAND to display thread. Display thread will start
+    // and then wait for a message
 
     // Register with the frame provider for frames
     FSL_ASSERT(mFrameProvider);
     mFrameProvider->addFrameListener(this);
 
     mDisplayEnabled = true;
-    mPreviewWidth = width;
-    mPreviewHeight = height;
+    mPreviewWidth   = width;
+    mPreviewHeight  = height;
 
     FLOGI("mPreviewWidth = %d mPreviewHeight = %d", mPreviewWidth, mPreviewHeight);
 
@@ -99,34 +102,36 @@ int DisplayAdapter::startDisplay(int width, int height)
 
 int DisplayAdapter::stopDisplay()
 {
-    status_t ret = NO_ERROR;
-    GraphicBufferMapper &mapper = GraphicBufferMapper::get();
+    status_t ret                = NO_ERROR;
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
 
-    if(!mDisplayEnabled) {
+    if (!mDisplayEnabled) {
         FLOGW("Display is already disabled");
         return ALREADY_EXISTS;
     }
 
     // Unregister with the frame provider here
-    if(mFrameProvider != NULL) {
+    if (mFrameProvider != NULL) {
         mFrameProvider->removeFrameListener(this);
     }
 
-    if(NULL != mDisplayThread.get()) {
-        //Send STOP_DISPLAY COMMAND to display thread. Display thread will stop and dequeue all messages
+    if (NULL != mDisplayThread.get()) {
+        // Send STOP_DISPLAY COMMAND to display thread. Display thread will stop
+        // and dequeue all messages
         // and then wait for message
-        mThreadQueue.postSyncMessage(new SyncMessage(DisplayThread::DISPLAY_STOP, 0));
+        mThreadQueue.postSyncMessage(new SyncMessage(DisplayThread::DISPLAY_STOP,
+                                                     0));
     }
 
     Mutex::Autolock lock(mLock);
     {
-        ///Reset the display enabled flag
+        // /Reset the display enabled flag
         mDisplayEnabled = false;
 
-        ///Reset the frame width and height values
-        mFrameWidth =0;
-        mFrameHeight = 0;
-        mPreviewWidth = 0;
+        // /Reset the frame width and height values
+        mFrameWidth    = 0;
+        mFrameHeight   = 0;
+        mPreviewWidth  = 0;
         mPreviewHeight = 0;
     }
 
@@ -138,26 +143,29 @@ bool DisplayAdapter::displayThread()
     bool shouldLive = true;
 
     sp<CMessage> msg = mThreadQueue.waitMessage();
-    if(msg == 0) {
+    if (msg == 0) {
         FLOGE("displayThread: get invalid message");
         return false;
     }
 
-    switch(msg->what) {
+    switch (msg->what) {
         case DisplayThread::DISPLAY_FRAME:
-            //FLOGI("Display thread received DISPLAY_FRAME command from Camera HAL");
-            if(mDisplayState== DisplayAdapter::DISPLAY_INIT) {
+
+            // FLOGI("Display thread received DISPLAY_FRAME command from Camera
+            // HAL");
+            if (mDisplayState == DisplayAdapter::DISPLAY_INIT) {
                 break;
             }
-            if(mDisplayState == DisplayAdapter::DISPLAY_STARTED)
+            if (mDisplayState == DisplayAdapter::DISPLAY_STARTED)
             {
                 shouldLive = requestFrameBuffer();
             }
 
-            if(mDisplayState == DisplayAdapter::DISPLAY_EXITED)
+            if (mDisplayState == DisplayAdapter::DISPLAY_EXITED)
             {
-                ///we exit the thread even though there are frames still to dequeue. They will be dequeued
-                ///in stopDisplay
+                // /we exit the thread even though there are frames still to
+                // dequeue. They will be dequeued
+                // /in stopDisplay
                 shouldLive = false;
             }
             break;
@@ -177,43 +185,47 @@ bool DisplayAdapter::displayThread()
         case DisplayThread::DISPLAY_EXIT:
             FLOGI("display thread exiting...");
             mDisplayState = DisplayAdapter::DISPLAY_EXITED;
-            ///Note that the SF can have pending buffers when we disable the display
-            ///This is normal and the expectation is that they may not be displayed.
-            ///This is to ensure that the user experience is not impacted
+
+            // /Note that the SF can have pending buffers when we disable the
+            // display
+            // /This is normal and the expectation is that they may not be
+            // displayed.
+            // /This is to ensure that the user experience is not impacted
             shouldLive = false;
             break;
 
         default:
             FLOGE("Invalid Display Thread Command 0x%x.", msg->what);
             break;
-    }//end switch
+    } // end switch
 
     return shouldLive;
 }
 
 bool DisplayAdapter::requestFrameBuffer()
 {
-    CameraFrame* frame = requestBuffer();
-    if(frame == NULL) {
+    CameraFrame *frame = requestBuffer();
+
+    if (frame == NULL) {
         FLOGE("requestBuffer return null buffer");
         return false;
     }
 
-    //the frame release from SurfaceAdapter.
+    // the frame release from SurfaceAdapter.
     frame->release();
     return true;
 }
 
-void DisplayAdapter::handleCameraFrame(CameraFrame* frame)
+void DisplayAdapter::handleCameraFrame(CameraFrame *frame)
 {
-    if(!frame || !frame->mBufHandle) {
+    if (!frame || !frame->mBufHandle) {
         FLOGI("DisplayAdapter: notifyCameraFrame receive null frame");
         return;
     }
 
-    //the frame held in SurfaceAdapter.
+    // the frame held in SurfaceAdapter.
     frame->addReference();
-    if(mDisplayState == DisplayAdapter::DISPLAY_STARTED) {
+    if (mDisplayState == DisplayAdapter::DISPLAY_STARTED) {
         Mutex::Autolock lock(mLock);
 
         renderBuffer(frame->mBufHandle);
diff --git a/mx6/libcamera/DisplayAdapter.h b/mx6/libcamera/DisplayAdapter.h
old mode 100755
new mode 100644
index cc24338..c2d6a05
--- a/mx6/libcamera/DisplayAdapter.h
+++ b/mx6/libcamera/DisplayAdapter.h
@@ -24,12 +24,11 @@
 
 using namespace android;
 
-class DisplayAdapter : public SurfaceAdapter, public CameraFrameListener
-{
+class DisplayAdapter : public SurfaceAdapter, public CameraFrameListener {
 public:
     enum DisplayStates {
         DISPLAY_INVALID = 0,
-        DISPLAY_INIT = 1,
+        DISPLAY_INIT    = 1,
         DISPLAY_STARTED,
         DISPLAY_STOPPED,
         DISPLAY_EXITED
@@ -40,23 +39,24 @@ public:
 
     virtual status_t initialize();
 
-    virtual int startDisplay(int width, int height);
-    virtual int stopDisplay();
+    virtual int      startDisplay(int width,
+                                  int height);
+    virtual int      stopDisplay();
 
-    int setCameraFrameProvider(CameraFrameProvider* frameProvider);
+    int              setCameraFrameProvider(CameraFrameProvider *frameProvider);
 
 protected:
-    void handleCameraFrame(CameraFrame* frame);
-    bool displayThread();
+    void             handleCameraFrame(CameraFrame *frame);
+    bool             displayThread();
 
 private:
-    bool requestFrameBuffer();
+    bool             requestFrameBuffer();
 
 public:
     class DisplayThread : public Thread {
     public:
-        DisplayThread(DisplayAdapter* da)
-                 : Thread(false), mDisplayAdapter(da) { }
+        DisplayThread(DisplayAdapter *da)
+            : Thread(false), mDisplayAdapter(da) {}
 
         virtual bool threadLoop()
         {
@@ -70,27 +70,27 @@ public:
             DISPLAY_EXIT
         };
 
-        private:
-            DisplayAdapter* mDisplayAdapter;
+    private:
+        DisplayAdapter *mDisplayAdapter;
     };
 
-friend class DisplayThread;
+    friend class DisplayThread;
 
 private:
-    int postBuffer(void* displayBuf);
+    int postBuffer(void *displayBuf);
 
 private:
     uint32_t mPreviewWidth;
     uint32_t mPreviewHeight;
-    CameraFrameProvider* mFrameProvider;
+    CameraFrameProvider *mFrameProvider;
 
     sp<DisplayThread> mDisplayThread;
 
     CMessageQueue mThreadQueue;
-    unsigned int mDisplayState;
+    unsigned int  mDisplayState;
 
     mutable Mutex mLock;
     bool mDisplayEnabled;
 };
 
-#endif
+#endif // ifndef _DISPLAY_ADAPTER_H_
diff --git a/mx6/libcamera/JpegBuilder.cpp b/mx6/libcamera/JpegBuilder.cpp
old mode 100755
new mode 100644
index e48d8de..9b92efb
--- a/mx6/libcamera/JpegBuilder.cpp
+++ b/mx6/libcamera/JpegBuilder.cpp
@@ -36,66 +36,67 @@ extern "C" {
 #define ARRAY_SIZE(array) (sizeof((array)) / sizeof((array)[0]))
 
 namespace android {
-
 struct string_pair {
-    const char* string1;
-    const char* string2;
+    const char *string1;
+    const char *string2;
 };
 
-static string_pair degress_to_exif_lut [] = {
+static string_pair degress_to_exif_lut[] = {
     // degrees, exif_orientation
-    {"0",   "1"},
-    {"90",  "6"},
-    {"180", "3"},
-    {"270", "8"},
+    { "0",   "1"     },
+    { "90",  "6"     },
+    { "180", "3"     },
+    { "270", "8"     },
 };
 
 /* public static functions */
-const char* JpegBuilder::degreesToExifOrientation(const char* degrees) {
-    for(unsigned int i = 0; i < ARRAY_SIZE(degress_to_exif_lut); i++) {
-        if(!strcmp(degrees, degress_to_exif_lut[i].string1)) {
+const char * JpegBuilder::degreesToExifOrientation(const char *degrees) {
+    for (unsigned int i = 0; i < ARRAY_SIZE(degress_to_exif_lut); i++) {
+        if (!strcmp(degrees, degress_to_exif_lut[i].string1)) {
             return degress_to_exif_lut[i].string2;
         }
     }
     return NULL;
 }
 
-void JpegBuilder::stringToRational(const char* str, unsigned int* num, unsigned int* den) {
-    int len;
-    char * tempVal = NULL;
+void JpegBuilder::stringToRational(const char   *str,
+                                   unsigned int *num,
+                                   unsigned int *den) {
+    int   len;
+    char *tempVal = NULL;
 
-    if(str != NULL) {
-        len = strlen(str);
-        tempVal = (char*) malloc( sizeof(char) * (len + 1));
+    if (str != NULL) {
+        len     = strlen(str);
+        tempVal = (char *)malloc(sizeof(char) * (len + 1));
     }
 
-    if(tempVal != NULL) {
+    if (tempVal != NULL) {
         // convert the decimal string into a rational
         size_t den_len;
-        char *ctx;
-        unsigned int numerator = 0;
+        char  *ctx;
+        unsigned int numerator   = 0;
         unsigned int denominator = 0;
-        char* temp = NULL;
+        char *temp               = NULL;
 
         memset(tempVal, '\0', len + 1);
         strncpy(tempVal, str, len);
         temp = strtok_r(tempVal, ".", &ctx);
 
-        if(temp != NULL)
+        if (temp != NULL)
             numerator = atoi(temp);
 
-        if(!numerator)
+        if (!numerator)
             numerator = 1;
 
         temp = strtok_r(NULL, ".", &ctx);
-        if(temp != NULL) {
+        if (temp != NULL) {
             den_len = strlen(temp);
-            if(HUGE_VAL == den_len ) {
+            if (HUGE_VAL == den_len) {
                 den_len = 0;
             }
 
             denominator = static_cast<unsigned int>(pow(10, den_len));
-            numerator = numerator * denominator + atoi(temp);
+            numerator   = numerator * denominator + atoi(temp);
         }
         else {
             denominator = 1;
@@ -108,25 +109,27 @@ void JpegBuilder::stringToRational(const char* str, unsigned int* num, unsigned
     }
 }
 
-bool JpegBuilder::isAsciiTag(const char* tag) {
+bool JpegBuilder::isAsciiTag(const char *tag) {
     // TODO(XXX): Add tags as necessary
     return (strcmp(tag, TAG_GPS_PROCESSING_METHOD) == 0);
 }
 
-void JpegBuilder::insertExifToJpeg(unsigned char* jpeg, size_t jpeg_size) {
+void JpegBuilder::insertExifToJpeg(unsigned char *jpeg,
+                                   size_t         jpeg_size) {
     ReadMode_t read_mode = (ReadMode_t)(READ_METADATA | READ_IMAGE);
 
     ResetJpgfile();
-    if(ReadJpegSectionsFromBuffer(jpeg, jpeg_size, read_mode)) {
+    if (ReadJpegSectionsFromBuffer(jpeg, jpeg_size, read_mode)) {
         jpeg_opened = true;
         create_EXIF(table, exif_tag_count, gps_tag_count, has_datetime_tag);
     }
 }
 
-status_t JpegBuilder::insertExifThumbnailImage(const char* thumb, int len) {
+status_t JpegBuilder::insertExifThumbnailImage(const char *thumb,
+                                               int         len) {
     status_t ret = NO_ERROR;
 
-    if((len > 0) && jpeg_opened) {
+    if ((len > 0) && jpeg_opened) {
         ret = ReplaceThumbnailFromBuffer(thumb, len);
         FLOGI("insertExifThumbnailImage. ReplaceThumbnail(). ret=%d", ret);
     }
@@ -134,53 +137,56 @@ status_t JpegBuilder::insertExifThumbnailImage(const char* thumb, int len) {
     return ret;
 }
 
-void JpegBuilder::saveJpeg(unsigned char* jpeg, size_t jpeg_size) {
-    if(jpeg_opened) {
-       WriteJpegToBuffer(jpeg, jpeg_size);
-       DiscardData();
-       jpeg_opened = false;
+void JpegBuilder::saveJpeg(unsigned char *jpeg,
+                           size_t         jpeg_size) {
+    if (jpeg_opened) {
+        WriteJpegToBuffer(jpeg, jpeg_size);
+        DiscardData();
+        jpeg_opened = false;
     }
 }
 
-status_t JpegBuilder::insertElement(const char* tag, const char* value) {
+status_t JpegBuilder::insertElement(const char *tag,
+                                    const char *value) {
     int value_length = 0;
-    status_t ret = NO_ERROR;
+    status_t ret     = NO_ERROR;
 
-    if(!value || !tag) {
+    if (!value || !tag) {
         return -EINVAL;
     }
 
-    if(position >= MAX_EXIF_TAGS_SUPPORTED) {
+    if (position >= MAX_EXIF_TAGS_SUPPORTED) {
         FLOGE("Max number of EXIF elements already inserted");
         return NO_MEMORY;
     }
 
-    if(isAsciiTag(tag)) {
-        value_length = sizeof(ExifAsciiPrefix) + strlen(value + sizeof(ExifAsciiPrefix));
+    if (isAsciiTag(tag)) {
+        value_length = sizeof(ExifAsciiPrefix) +
+                       strlen(value + sizeof(ExifAsciiPrefix));
     }
     else {
         value_length = strlen(value);
     }
 
-    if(IsGpsTag(tag)) {
+    if (IsGpsTag(tag)) {
         table[position].GpsTag = TRUE;
-        table[position].Tag = GpsTagNameToValue(tag);
+        table[position].Tag    = GpsTagNameToValue(tag);
         gps_tag_count++;
     }
     else {
         table[position].GpsTag = FALSE;
-        table[position].Tag = TagNameToValue(tag);
+        table[position].Tag    = TagNameToValue(tag);
         exif_tag_count++;
 
-        if(strcmp(tag, TAG_DATETIME) == 0) {
+        if (strcmp(tag, TAG_DATETIME) == 0) {
             has_datetime_tag = true;
         }
     }
 
     table[position].DataLength = 0;
-    table[position].Value = (char*) malloc(sizeof(char) * (value_length + 1));
+    table[position].Value      = (char *)malloc(sizeof(char) * (value_length + 1));
 
-    if(table[position].Value) {
+    if (table[position].Value) {
         memcpy(table[position].Value, value, value_length + 1);
         table[position].DataLength = value_length + 1;
     }
@@ -190,22 +196,22 @@ status_t JpegBuilder::insertElement(const char* tag, const char* value) {
 }
 
 JpegBuilder::JpegBuilder()
-   : gps_tag_count(0), exif_tag_count(0), position(0),
-     jpeg_opened(false), has_datetime_tag(false)
+    : gps_tag_count(0), exif_tag_count(0), position(0),
+      jpeg_opened(false), has_datetime_tag(false)
 {
     reset();
 }
 
 void JpegBuilder::reset()
 {
-    gps_tag_count = 0;
-    exif_tag_count = 0;
-    position = 0;
-    jpeg_opened = false;
+    gps_tag_count    = 0;
+    exif_tag_count   = 0;
+    position         = 0;
+    jpeg_opened      = false;
     has_datetime_tag = false;
-    mMainInput = NULL;
-    mThumbnailInput = NULL;
-    mCancelEncoding = false;
+    mMainInput       = NULL;
+    mThumbnailInput  = NULL;
+    mCancelEncoding  = false;
     memset(&mEXIFData, 0, sizeof(mEXIFData));
     memset(&table, 0, sizeof(table));
 }
@@ -214,13 +220,13 @@ JpegBuilder::~JpegBuilder()
 {
     int num_elements = gps_tag_count + exif_tag_count;
 
-    for(int i = 0; i < num_elements; i++) {
-        if(table[i].Value) {
+    for (int i = 0; i < num_elements; i++) {
+        if (table[i].Value) {
             free(table[i].Value);
         }
     }
 
-    if(jpeg_opened) {
+    if (jpeg_opened) {
         DiscardData();
     }
 }
@@ -228,37 +234,37 @@ JpegBuilder::~JpegBuilder()
 void JpegBuilder::prepareImage(const CameraParameters& params)
 {
     status_t ret = NO_ERROR;
-    int eError = 0;
+    int eError   = 0;
     struct timeval sTv;
-    struct tm *pTime;
+    struct tm     *pTime;
 
-    if((NO_ERROR == ret) && (mEXIFData.mModelValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mModelValid)) {
         ret = insertElement(TAG_MODEL, EXIF_MODEL);
     }
 
-     if((NO_ERROR == ret) && (mEXIFData.mMakeValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mMakeValid)) {
         ret = insertElement(TAG_MAKE, EXIF_MAKENOTE);
-     }
+    }
 
-    if((NO_ERROR == ret)) {
+    if ((NO_ERROR == ret)) {
         unsigned int numerator = 0, denominator = 0;
-        JpegBuilder::stringToRational(params.get(CameraParameters::KEY_FOCAL_LENGTH),
-                                            &numerator, &denominator);
-        if(numerator || denominator) {
+        JpegBuilder::stringToRational(params.get(CameraParameters::
+                                                 KEY_FOCAL_LENGTH),
+                                      &numerator, &denominator);
+        if (numerator || denominator) {
             char temp_value[256]; // arbitrarily long string
             snprintf(temp_value,
-                 sizeof(temp_value)/sizeof(char),
-                 "%u/%u", numerator, denominator);
+                     sizeof(temp_value) / sizeof(char),
+                     "%u/%u", numerator, denominator);
             ret = insertElement(TAG_FOCALLENGTH, temp_value);
-
         }
     }
 
-    if((NO_ERROR == ret)) {
-        int status = gettimeofday (&sTv, NULL);
-        pTime = gmtime (&sTv.tv_sec);
+    if ((NO_ERROR == ret)) {
+        int status = gettimeofday(&sTv, NULL);
+        pTime = gmtime(&sTv.tv_sec);
         char temp_value[EXIF_DATE_TIME_SIZE + 1];
-        if((0 == status) && (NULL != pTime)) {
+        if ((0 == status) && (NULL != pTime)) {
             snprintf(temp_value, EXIF_DATE_TIME_SIZE,
                      "%04d:%02d:%02d %02d:%02d:%02d",
                      pTime->tm_year + 1900,
@@ -266,78 +272,82 @@ void JpegBuilder::prepareImage(const CameraParameters& params)
                      pTime->tm_mday,
                      pTime->tm_hour,
                      pTime->tm_min,
-                     pTime->tm_sec );
+                     pTime->tm_sec);
 
             ret = insertElement(TAG_DATETIME, temp_value);
         }
-     }
+    }
 
     int width, height;
     params.getPictureSize(&width, &height);
-    if((NO_ERROR == ret)) {
+    if ((NO_ERROR == ret)) {
         char temp_value[5];
-        snprintf(temp_value, sizeof(temp_value)/sizeof(char), "%lu", (unsigned long)width);
+        snprintf(temp_value, sizeof(temp_value) / sizeof(char), "%lu",
+                 (unsigned long)width);
         ret = insertElement(TAG_IMAGE_WIDTH, temp_value);
-     }
+    }
 
-    if((NO_ERROR == ret)) {
+    if ((NO_ERROR == ret)) {
         char temp_value[5];
-        snprintf(temp_value, sizeof(temp_value)/sizeof(char), "%lu", (unsigned long)height);
+        snprintf(temp_value, sizeof(temp_value) / sizeof(char), "%lu",
+                 (unsigned long)height);
         ret = insertElement(TAG_IMAGE_LENGTH, temp_value);
-     }
+    }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mLatValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLatValid)) {
         char temp_value[256]; // arbitrarily long string
         snprintf(temp_value,
-                 sizeof(temp_value)/sizeof(char) - 1,
+                 sizeof(temp_value) / sizeof(char) - 1,
                  "%d/%d,%d/%d,%d/%d",
                  abs(mEXIFData.mGPSData.mLatDeg), 1,
                  abs(mEXIFData.mGPSData.mLatMin), 1,
-                 abs(mEXIFData.mGPSData.mLatSec), abs(mEXIFData.mGPSData.mLatSecDiv));
+                 abs(mEXIFData.mGPSData.mLatSec),
+                 abs(mEXIFData.mGPSData.mLatSecDiv));
         ret = insertElement(TAG_GPS_LAT, temp_value);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mLatValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLatValid)) {
         ret = insertElement(TAG_GPS_LAT_REF, mEXIFData.mGPSData.mLatRef);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mLongValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLongValid)) {
         char temp_value[256]; // arbitrarily long string
         snprintf(temp_value,
-                 sizeof(temp_value)/sizeof(char) - 1,
+                 sizeof(temp_value) / sizeof(char) - 1,
                  "%d/%d,%d/%d,%d/%d",
                  abs(mEXIFData.mGPSData.mLongDeg), 1,
                  abs(mEXIFData.mGPSData.mLongMin), 1,
-                 abs(mEXIFData.mGPSData.mLongSec), abs(mEXIFData.mGPSData.mLongSecDiv));
+                 abs(mEXIFData.mGPSData.mLongSec),
+                 abs(mEXIFData.mGPSData.mLongSecDiv));
         ret = insertElement(TAG_GPS_LONG, temp_value);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mLongValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLongValid)) {
         ret = insertElement(TAG_GPS_LONG_REF, mEXIFData.mGPSData.mLongRef);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mAltitudeValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mAltitudeValid)) {
         char temp_value[256]; // arbitrarily long string
         snprintf(temp_value,
-                 sizeof(temp_value)/sizeof(char) - 1,
+                 sizeof(temp_value) / sizeof(char) - 1,
                  "%d/%d",
-                 abs( mEXIFData.mGPSData.mAltitude), 1);
+                 abs(mEXIFData.mGPSData.mAltitude), 1);
         ret = insertElement(TAG_GPS_ALT, temp_value);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mAltitudeValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mAltitudeValid)) {
         char temp_value[5];
         snprintf(temp_value,
-                 sizeof(temp_value)/sizeof(char) - 1,
+                 sizeof(temp_value) / sizeof(char) - 1,
                  "%d", mEXIFData.mGPSData.mAltitudeRef);
         ret = insertElement(TAG_GPS_ALT_REF, temp_value);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mMapDatumValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mMapDatumValid)) {
         ret = insertElement(TAG_GPS_MAP_DATUM, mEXIFData.mGPSData.mMapDatum);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mProcMethodValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mProcMethodValid)) {
         char temp_value[GPS_PROCESSING_SIZE];
         memcpy(temp_value, ExifAsciiPrefix, sizeof(ExifAsciiPrefix));
         memcpy(temp_value + sizeof(ExifAsciiPrefix),
@@ -346,10 +356,10 @@ void JpegBuilder::prepareImage(const CameraParameters& params)
         ret = insertElement(TAG_GPS_PROCESSING_METHOD, temp_value);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mVersionIdValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mVersionIdValid)) {
         char temp_value[256]; // arbitrarily long string
         snprintf(temp_value,
-                 sizeof(temp_value)/sizeof(char) - 1,
+                 sizeof(temp_value) / sizeof(char) - 1,
                  "%d,%d,%d,%d",
                  mEXIFData.mGPSData.mVersionId[0],
                  mEXIFData.mGPSData.mVersionId[1],
@@ -358,10 +368,10 @@ void JpegBuilder::prepareImage(const CameraParameters& params)
         ret = insertElement(TAG_GPS_VERSION_ID, temp_value);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mTimeStampValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mTimeStampValid)) {
         char temp_value[256]; // arbitrarily long string
         snprintf(temp_value,
-                 sizeof(temp_value)/sizeof(char) - 1,
+                 sizeof(temp_value) / sizeof(char) - 1,
                  "%d/%d,%d/%d,%d/%d",
                  mEXIFData.mGPSData.mTimeStampHour, 1,
                  mEXIFData.mGPSData.mTimeStampMin, 1,
@@ -369,35 +379,35 @@ void JpegBuilder::prepareImage(const CameraParameters& params)
         ret = insertElement(TAG_GPS_TIMESTAMP, temp_value);
     }
 
-    if((NO_ERROR == ret) && (mEXIFData.mGPSData.mDatestampValid)) {
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mDatestampValid)) {
         ret = insertElement(TAG_GPS_DATESTAMP, mEXIFData.mGPSData.mDatestamp);
     }
 
-    if((NO_ERROR == ret) && params.get(CameraParameters::KEY_ROTATION)) {
-        const char* exif_orient =
-           JpegBuilder::degreesToExifOrientation(params.get(CameraParameters::KEY_ROTATION));
+    if ((NO_ERROR == ret) && params.get(CameraParameters::KEY_ROTATION)) {
+        const char *exif_orient =
+            JpegBuilder::degreesToExifOrientation(params.get(CameraParameters::
+                                                             KEY_ROTATION));
 
-        if(exif_orient) {
-           ret = insertElement(TAG_ORIENTATION, exif_orient);
+        if (exif_orient) {
+            ret = insertElement(TAG_ORIENTATION, exif_orient);
         }
     }
 }
 
-void JpegBuilder::setParameters(const CameraParameters &params)
+void JpegBuilder::setParameters(const CameraParameters& params)
 {
-    status_t ret = NO_ERROR;
+    status_t ret       = NO_ERROR;
     const char *valstr = NULL;
     double gpsPos;
 
-    if((valstr = params.get(CameraParameters::KEY_GPS_LATITUDE)) != NULL) {
+    if ((valstr = params.get(CameraParameters::KEY_GPS_LATITUDE)) != NULL) {
         gpsPos = strtod(valstr, NULL);
 
-        if(convertGPSCoord(gpsPos,
-                             mEXIFData.mGPSData.mLatDeg,
-                             mEXIFData.mGPSData.mLatMin,
-                             mEXIFData.mGPSData.mLatSec,
-                             mEXIFData.mGPSData.mLatSecDiv ) == NO_ERROR) {
-
+        if (convertGPSCoord(gpsPos,
+                            mEXIFData.mGPSData.mLatDeg,
+                            mEXIFData.mGPSData.mLatMin,
+                            mEXIFData.mGPSData.mLatSec,
+                            mEXIFData.mGPSData.mLatSecDiv) == NO_ERROR) {
             if (0 < gpsPos) {
                 strncpy(mEXIFData.mGPSData.mLatRef, GPS_NORTH_REF, GPS_REF_SIZE);
             }
@@ -415,23 +425,22 @@ void JpegBuilder::setParameters(const CameraParameters &params)
         mEXIFData.mGPSData.mLatValid = false;
     }
 
-    if((valstr = params.get(CameraParameters::KEY_GPS_LONGITUDE)) != NULL) {
+    if ((valstr = params.get(CameraParameters::KEY_GPS_LONGITUDE)) != NULL) {
         gpsPos = strtod(valstr, NULL);
 
-        if(convertGPSCoord(gpsPos,
-                             mEXIFData.mGPSData.mLongDeg,
-                             mEXIFData.mGPSData.mLongMin,
-                             mEXIFData.mGPSData.mLongSec,
-                             mEXIFData.mGPSData.mLongSecDiv) == NO_ERROR) {
-
-            if(0 < gpsPos) {
+        if (convertGPSCoord(gpsPos,
+                            mEXIFData.mGPSData.mLongDeg,
+                            mEXIFData.mGPSData.mLongMin,
+                            mEXIFData.mGPSData.mLongSec,
+                            mEXIFData.mGPSData.mLongSecDiv) == NO_ERROR) {
+            if (0 < gpsPos) {
                 strncpy(mEXIFData.mGPSData.mLongRef, GPS_EAST_REF, GPS_REF_SIZE);
             }
             else {
                 strncpy(mEXIFData.mGPSData.mLongRef, GPS_WEST_REF, GPS_REF_SIZE);
             }
 
-            mEXIFData.mGPSData.mLongValid= true;
+            mEXIFData.mGPSData.mLongValid = true;
         }
         else {
             mEXIFData.mGPSData.mLongValid = false;
@@ -441,10 +450,10 @@ void JpegBuilder::setParameters(const CameraParameters &params)
         mEXIFData.mGPSData.mLongValid = false;
     }
 
-    if((valstr = params.get(CameraParameters::KEY_GPS_ALTITUDE)) != NULL) {
-        gpsPos = strtod(valstr, NULL);
+    if ((valstr = params.get(CameraParameters::KEY_GPS_ALTITUDE)) != NULL) {
+        gpsPos                       = strtod(valstr, NULL);
         mEXIFData.mGPSData.mAltitude = floor(fabs(gpsPos));
-        if(gpsPos < 0) {
+        if (gpsPos < 0) {
             mEXIFData.mGPSData.mAltitudeRef = 1;
         }
         else {
@@ -453,16 +462,16 @@ void JpegBuilder::setParameters(const CameraParameters &params)
         mEXIFData.mGPSData.mAltitudeValid = true;
     }
     else {
-        mEXIFData.mGPSData.mAltitudeValid= false;
+        mEXIFData.mGPSData.mAltitudeValid = false;
     }
 
-    if((valstr = params.get(CameraParameters::KEY_GPS_TIMESTAMP)) != NULL) {
-        long gpsTimestamp = strtol(valstr, NULL, 10);
-        struct tm *timeinfo = gmtime((time_t *) & (gpsTimestamp));
-        if(NULL != timeinfo) {
-            mEXIFData.mGPSData.mTimeStampHour = timeinfo->tm_hour;
-            mEXIFData.mGPSData.mTimeStampMin = timeinfo->tm_min;
-            mEXIFData.mGPSData.mTimeStampSec = timeinfo->tm_sec;
+    if ((valstr = params.get(CameraParameters::KEY_GPS_TIMESTAMP)) != NULL) {
+        long gpsTimestamp   = strtol(valstr, NULL, 10);
+        struct tm *timeinfo = gmtime((time_t *)&(gpsTimestamp));
+        if (NULL != timeinfo) {
+            mEXIFData.mGPSData.mTimeStampHour  = timeinfo->tm_hour;
+            mEXIFData.mGPSData.mTimeStampMin   = timeinfo->tm_min;
+            mEXIFData.mGPSData.mTimeStampSec   = timeinfo->tm_sec;
             mEXIFData.mGPSData.mTimeStampValid = true;
         }
         else {
@@ -473,11 +482,14 @@ void JpegBuilder::setParameters(const CameraParameters &params)
         mEXIFData.mGPSData.mTimeStampValid = false;
     }
 
-    if((valstr = params.get(CameraParameters::KEY_GPS_TIMESTAMP)) != NULL) {
-        long gpsDatestamp = strtol(valstr, NULL, 10);
-        struct tm *timeinfo = gmtime((time_t *) & (gpsDatestamp));
-        if(NULL != timeinfo) {
-            strftime(mEXIFData.mGPSData.mDatestamp, GPS_DATESTAMP_SIZE, "%Y:%m:%d", timeinfo);
+    if ((valstr = params.get(CameraParameters::KEY_GPS_TIMESTAMP)) != NULL) {
+        long gpsDatestamp   = strtol(valstr, NULL, 10);
+        struct tm *timeinfo = gmtime((time_t *)&(gpsDatestamp));
+        if (NULL != timeinfo) {
+            strftime(mEXIFData.mGPSData.mDatestamp,
+                     GPS_DATESTAMP_SIZE,
+                     "%Y:%m:%d",
+                     timeinfo);
             mEXIFData.mGPSData.mDatestampValid = true;
         }
         else {
@@ -488,32 +500,34 @@ void JpegBuilder::setParameters(const CameraParameters &params)
         mEXIFData.mGPSData.mDatestampValid = false;
     }
 
-    if((valstr = params.get(CameraParameters::KEY_GPS_PROCESSING_METHOD)) != NULL) {
+    if ((valstr = params.get(CameraParameters::KEY_GPS_PROCESSING_METHOD)) !=
+        NULL) {
         memset(mEXIFData.mGPSData.mProcMethod, 0, GPS_PROCESSING_SIZE);
-        strncpy(mEXIFData.mGPSData.mProcMethod, valstr, GPS_PROCESSING_SIZE-1);
+        strncpy(mEXIFData.mGPSData.mProcMethod, valstr, GPS_PROCESSING_SIZE - 1);
         mEXIFData.mGPSData.mProcMethodValid = true;
     }
     else {
         mEXIFData.mGPSData.mProcMethodValid = false;
     }
 
-    mEXIFData.mGPSData.mMapDatumValid = false;
+    mEXIFData.mGPSData.mMapDatumValid  = false;
     mEXIFData.mGPSData.mVersionIdValid = false;
-    mEXIFData.mModelValid= true;
-    mEXIFData.mMakeValid = true;
+    mEXIFData.mModelValid              = true;
+    mEXIFData.mMakeValid               = true;
 }
 
-status_t JpegBuilder::encodeImage(JpegParams* mainJpeg, JpegParams* thumbNail)
+status_t JpegBuilder::encodeImage(JpegParams *mainJpeg,
+                                  JpegParams *thumbNail)
 {
     status_t ret = NO_ERROR;
 
-    mMainInput = mainJpeg;
+    mMainInput      = mainJpeg;
     mThumbnailInput = thumbNail;
-    if(thumbNail) {
+    if (thumbNail) {
         ret = encodeJpeg(thumbNail);
     }
 
-    if(ret != NO_ERROR) {
+    if (ret != NO_ERROR) {
         FLOGE("JpegBuilder:encodeImage failed");
         return ret;
     }
@@ -521,20 +535,27 @@ status_t JpegBuilder::encodeImage(JpegParams* mainJpeg, JpegParams* thumbNail)
     return encodeJpeg(mainJpeg);
 }
 
-status_t JpegBuilder::encodeJpeg(JpegParams* input)
+status_t JpegBuilder::encodeJpeg(JpegParams *input)
 {
-    PixelFormat format = convertStringToPixelFormat(input->format);
-    YuvToJpegEncoder* encoder = YuvToJpegEncoder::create(format);
-    if(encoder == NULL) {
+    PixelFormat format        = convertStringToPixelFormat(input->format);
+    YuvToJpegEncoder *encoder = YuvToJpegEncoder::create(format);
+
+    if (encoder == NULL) {
         return BAD_VALUE;
     }
 
     int res = 0;
-    res = encoder->encode(input->src, input->in_width, input->in_height, input->quality,
-            input->dst, input->dst_size, input->out_width, input->out_height);
+    res = encoder->encode(input->src,
+                          input->in_width,
+                          input->in_height,
+                          input->quality,
+                          input->dst,
+                          input->dst_size,
+                          input->out_width,
+                          input->out_height);
 
     delete encoder;
-    if(res) {
+    if (res) {
         input->jpeg_size = res;
         return NO_ERROR;
     }
@@ -546,12 +567,12 @@ status_t JpegBuilder::encodeJpeg(JpegParams* input)
 size_t JpegBuilder::getImageSize()
 {
     size_t jpeg_size, image_size;
-    Section_t* exif_section = NULL;
+    Section_t *exif_section = NULL;
 
     jpeg_size = mMainInput->jpeg_size;
 
     exif_section = FindSection(M_EXIF);
-    if(exif_section != NULL) {
+    if (exif_section != NULL) {
         image_size = jpeg_size + exif_section->Size;
     }
     else {
@@ -560,46 +581,50 @@ size_t JpegBuilder::getImageSize()
     return image_size;
 }
 
-status_t JpegBuilder::buildImage(camera_request_memory get_memory, camera_memory_t** image)
+status_t JpegBuilder::buildImage(camera_request_memory get_memory,
+                                 camera_memory_t     **image)
 {
-    size_t jpeg_size;
-    uint8_t* src = NULL;
-    camera_memory_t* picture = NULL;
+    size_t   jpeg_size;
+    uint8_t *src             = NULL;
+    camera_memory_t *picture = NULL;
 
-    if(!image || !mMainInput) {
+    if (!image || !mMainInput) {
         return BAD_VALUE;
     }
 
     jpeg_size = mMainInput->jpeg_size;
-    src = mMainInput->src;
+    src       = mMainInput->src;
 
-    if(mMainInput->dst && (jpeg_size > 0)) {
-        if(position > 0) {
-            Section_t* exif_section = NULL;
+    if (mMainInput->dst && (jpeg_size > 0)) {
+        if (position > 0) {
+            Section_t *exif_section = NULL;
 
-            insertExifToJpeg((unsigned char*)mMainInput->dst, jpeg_size);
+            insertExifToJpeg((unsigned char *)mMainInput->dst, jpeg_size);
 
-            if(mThumbnailInput) {
-                insertExifThumbnailImage((const char*)mThumbnailInput->dst,
-                                               (int)mThumbnailInput->jpeg_size);
+            if (mThumbnailInput) {
+                insertExifThumbnailImage((const char *)mThumbnailInput->dst,
+                                         (int)mThumbnailInput->jpeg_size);
             }
 
             exif_section = FindSection(M_EXIF);
-            if(exif_section) {
+            if (exif_section) {
                 int imageSize = jpeg_size + exif_section->Size;
                 picture = get_memory(-1, imageSize, 1, NULL);
-                if(!picture || !picture->data) {
-                    FLOGE("CameraBridge:processImageFrame mRequestMemory picture failed");
+                if (!picture || !picture->data) {
+                    FLOGE(
+                        "CameraBridge:processImageFrame mRequestMemory picture failed");
                     return false;
                 }
 
-                saveJpeg((unsigned char*)picture->data, jpeg_size + exif_section->Size);
+                saveJpeg((unsigned char *)picture->data,
+                         jpeg_size + exif_section->Size);
             }
         } else {
             int imageSize = jpeg_size;
             picture = get_memory(-1, imageSize, 1, NULL);
-            if(!picture || !picture->data) {
-                FLOGE("CameraBridge:processImageFrame mRequestMemory picture failed");
+            if (!picture || !picture->data) {
+                FLOGE(
+                    "CameraBridge:processImageFrame mRequestMemory picture failed");
                 return false;
             }
             memcpy(picture->data, mMainInput->dst, jpeg_size);
@@ -610,40 +635,43 @@ status_t JpegBuilder::buildImage(camera_request_memory get_memory, camera_memory
     return NO_ERROR;
 }
 
-status_t JpegBuilder::getSupportedPictureFormat(int* pFormat, int len)
+status_t JpegBuilder::getSupportedPictureFormat(int *pFormat,
+                                                int  len)
 {
     return YuvToJpegEncoder::getSupportedPictureFormat(pFormat, len);
 }
 
-status_t JpegBuilder::convertGPSCoord(double coord, int &deg, int &min, int &sec, int &secDivisor)
+status_t JpegBuilder::convertGPSCoord(double coord,
+                                      int  & deg,
+                                      int  & min,
+                                      int  & sec,
+                                      int  & secDivisor)
 {
     double tmp;
 
-    if(coord == 0) {
-
+    if (coord == 0) {
         FLOGE("Invalid GPS coordinate");
 
         return -EINVAL;
     }
 
-    deg = (int) floor(fabs(coord));
-    tmp = ( fabs(coord) - floor(fabs(coord)) ) * GPS_MIN_DIV;
-    min = (int) floor(tmp);
-    tmp = ( tmp - floor(tmp) ) * ( GPS_SEC_DIV * GPS_SEC_ACCURACY );
-    sec = (int) floor(tmp);
+    deg        = (int)floor(fabs(coord));
+    tmp        = (fabs(coord) - floor(fabs(coord))) * GPS_MIN_DIV;
+    min        = (int)floor(tmp);
+    tmp        = (tmp - floor(tmp)) * (GPS_SEC_DIV * GPS_SEC_ACCURACY);
+    sec        = (int)floor(tmp);
     secDivisor = GPS_SEC_ACCURACY;
 
-    if(sec >= (GPS_SEC_DIV * GPS_SEC_ACCURACY)) {
-        sec = 0;
+    if (sec >= (GPS_SEC_DIV * GPS_SEC_ACCURACY)) {
+        sec  = 0;
         min += 1;
     }
 
-    if(min >= 60) {
-        min = 0;
+    if (min >= 60) {
+        min  = 0;
         deg += 1;
     }
 
     return NO_ERROR;
 }
-
 };
diff --git a/mx6/libcamera/JpegBuilder.h b/mx6/libcamera/JpegBuilder.h
old mode 100755
new mode 100644
index 0d2d703..97851d6
--- a/mx6/libcamera/JpegBuilder.h
+++ b/mx6/libcamera/JpegBuilder.h
@@ -27,30 +27,29 @@ extern "C" {
 }
 
 namespace android {
-
 #define EXIF_MAKENOTE "fsl_makernote"
 #define EXIF_MODEL    "fsl_model"
 
 #define MAX_EXIF_TAGS_SUPPORTED 30
 
-static const char TAG_MODEL[] = "Model";
-static const char TAG_MAKE[] = "Make";
-static const char TAG_FOCALLENGTH[] = "FocalLength";
-static const char TAG_DATETIME[] = "DateTime";
-static const char TAG_IMAGE_WIDTH[] = "ImageWidth";
-static const char TAG_IMAGE_LENGTH[] = "ImageLength";
-static const char TAG_GPS_LAT[] = "GPSLatitude";
-static const char TAG_GPS_LAT_REF[] = "GPSLatitudeRef";
-static const char TAG_GPS_LONG[] = "GPSLongitude";
-static const char TAG_GPS_LONG_REF[] = "GPSLongitudeRef";
-static const char TAG_GPS_ALT[] = "GPSAltitude";
-static const char TAG_GPS_ALT_REF[] = "GPSAltitudeRef";
-static const char TAG_GPS_MAP_DATUM[] = "GPSMapDatum";
+static const char TAG_MODEL[]                 = "Model";
+static const char TAG_MAKE[]                  = "Make";
+static const char TAG_FOCALLENGTH[]           = "FocalLength";
+static const char TAG_DATETIME[]              = "DateTime";
+static const char TAG_IMAGE_WIDTH[]           = "ImageWidth";
+static const char TAG_IMAGE_LENGTH[]          = "ImageLength";
+static const char TAG_GPS_LAT[]               = "GPSLatitude";
+static const char TAG_GPS_LAT_REF[]           = "GPSLatitudeRef";
+static const char TAG_GPS_LONG[]              = "GPSLongitude";
+static const char TAG_GPS_LONG_REF[]          = "GPSLongitudeRef";
+static const char TAG_GPS_ALT[]               = "GPSAltitude";
+static const char TAG_GPS_ALT_REF[]           = "GPSAltitudeRef";
+static const char TAG_GPS_MAP_DATUM[]         = "GPSMapDatum";
 static const char TAG_GPS_PROCESSING_METHOD[] = "GPSProcessingMethod";
-static const char TAG_GPS_VERSION_ID[] = "GPSVersionID";
-static const char TAG_GPS_TIMESTAMP[] = "GPSTimeStamp";
-static const char TAG_GPS_DATESTAMP[] = "GPSDateStamp";
-static const char TAG_ORIENTATION[] = "Orientation";
+static const char TAG_GPS_VERSION_ID[]        = "GPSVersionID";
+static const char TAG_GPS_TIMESTAMP[]         = "GPSTimeStamp";
+static const char TAG_GPS_DATESTAMP[]         = "GPSDateStamp";
+static const char TAG_ORIENTATION[]           = "Orientation";
 
 #define GPS_MIN_DIV                 60
 #define GPS_SEC_DIV                 60
@@ -71,91 +70,110 @@ static const char TAG_ORIENTATION[] = "Orientation";
 
 struct GPSData
 {
-    int mLongDeg, mLongMin, mLongSec, mLongSecDiv;
-    char mLongRef[GPS_REF_SIZE];
-    bool mLongValid;
-    int mLatDeg, mLatMin, mLatSec, mLatSecDiv;
-    char mLatRef[GPS_REF_SIZE];
-    bool mLatValid;
-    int mAltitude;
+    int           mLongDeg, mLongMin, mLongSec, mLongSecDiv;
+    char          mLongRef[GPS_REF_SIZE];
+    bool          mLongValid;
+    int           mLatDeg, mLatMin, mLatSec, mLatSecDiv;
+    char          mLatRef[GPS_REF_SIZE];
+    bool          mLatValid;
+    int           mAltitude;
     unsigned char mAltitudeRef;
-    bool mAltitudeValid;
-    char mMapDatum[GPS_MAPDATUM_SIZE];
-    bool mMapDatumValid;
-    char mVersionId[GPS_VERSION_SIZE];
-    bool mVersionIdValid;
-    char mProcMethod[GPS_PROCESSING_SIZE];
-    bool mProcMethodValid;
-    char mDatestamp[GPS_DATESTAMP_SIZE];
-    bool mDatestampValid;
-    uint32_t mTimeStampHour;
-    uint32_t mTimeStampMin;
-    uint32_t mTimeStampSec;
-    bool mTimeStampValid;
+    bool          mAltitudeValid;
+    char          mMapDatum[GPS_MAPDATUM_SIZE];
+    bool          mMapDatumValid;
+    char          mVersionId[GPS_VERSION_SIZE];
+    bool          mVersionIdValid;
+    char          mProcMethod[GPS_PROCESSING_SIZE];
+    bool          mProcMethodValid;
+    char          mDatestamp[GPS_DATESTAMP_SIZE];
+    bool          mDatestampValid;
+    uint32_t      mTimeStampHour;
+    uint32_t      mTimeStampMin;
+    uint32_t      mTimeStampSec;
+    bool          mTimeStampValid;
 };
 
 struct EXIFData
 {
     GPSData mGPSData;
-    bool mMakeValid;
-    bool mModelValid;
+    bool    mMakeValid;
+    bool    mModelValid;
 };
 
 struct JpegParams {
-    JpegParams(uint8_t* uSrc, int srcSize, uint8_t* uDst, int dstSize,
-            int quality, int inWidth, int inHeight, int outWidth,
-            int outHeight, const char* format)
+    JpegParams(uint8_t    *uSrc,
+               int         srcSize,
+               uint8_t *uDst,
+               int         dstSize,
+               int         quality,
+               int         inWidth,
+               int         inHeight,
+               int         outWidth,
+               int         outHeight,
+               const char *format)
         : src(uSrc), src_size(srcSize), dst(uDst), dst_size(dstSize),
           quality(quality), in_width(inWidth), in_height(inHeight),
           out_width(outWidth), out_height(outHeight), format(format),
           jpeg_size(0)
     {}
 
-    uint8_t* src;
-    int src_size;
-    uint8_t* dst;
-    int dst_size;
-    int quality;
-    int in_width;
-    int in_height;
-    int out_width;
-    int out_height;
-    const char* format;
-    size_t jpeg_size;
- };
-
-
-class JpegBuilder : public LightRefBase<JpegBuilder>
-{
+    uint8_t    *src;
+    int         src_size;
+    uint8_t    *dst;
+    int         dst_size;
+    int         quality;
+    int         in_width;
+    int         in_height;
+    int         out_width;
+    int         out_height;
+    const char *format;
+    size_t      jpeg_size;
+};
+
+
+class JpegBuilder : public LightRefBase<JpegBuilder>{
 public:
     JpegBuilder();
     ~JpegBuilder();
 
-    status_t getSupportedPictureFormat(int* pFormat, int len);
-    void prepareImage(const CameraParameters& params);
-    void setParameters(const CameraParameters &params);
+    status_t getSupportedPictureFormat(int *pFormat,
+                                       int  len);
+    void     prepareImage(const CameraParameters& params);
+    void     setParameters(const CameraParameters& params);
 
-    status_t encodeImage(JpegParams* mainJpeg, JpegParams* thumbNail);
-    size_t getImageSize();
-    status_t buildImage(camera_request_memory get_memory, camera_memory_t** image);
-    void reset();
+    status_t encodeImage(JpegParams *mainJpeg,
+                         JpegParams *thumbNail);
+    size_t   getImageSize();
+    status_t buildImage(camera_request_memory get_memory,
+                        camera_memory_t     **image);
+    void     reset();
 
 private:
-    status_t insertElement(const char* tag, const char* value);
-    void insertExifToJpeg(unsigned char* jpeg, size_t jpeg_size);
-    status_t insertExifThumbnailImage(const char*, int);
-    void saveJpeg(unsigned char* picture, size_t jpeg_size);
+    status_t insertElement(const char *tag,
+                           const char *value);
+    void     insertExifToJpeg(unsigned char *jpeg,
+                              size_t         jpeg_size);
+    status_t insertExifThumbnailImage(const char *,
+                                      int);
+    void     saveJpeg(unsigned char *picture,
+                      size_t         jpeg_size);
 
 private:
-    status_t encodeJpeg(JpegParams* input);
-    const char* degreesToExifOrientation(const char*);
-    void stringToRational(const char*, unsigned int*, unsigned int*);
-    bool isAsciiTag(const char* tag);
-    status_t convertGPSCoord(double coord, int &deg, int &min, int &sec, int &secDivisor);
+    status_t    encodeJpeg(JpegParams *input);
+    const char* degreesToExifOrientation(const char *);
+    void        stringToRational(const    char *,
+                                 unsigned int *,
+                                 unsigned int *);
+    bool        isAsciiTag(const char *tag);
+    status_t    convertGPSCoord(double coord,
+                                int  & deg,
+                                int  & min,
+                                int  & sec,
+                                int  & secDivisor);
 
 private:
-    JpegParams* mMainInput;
-    JpegParams* mThumbnailInput;
+    JpegParams *mMainInput;
+    JpegParams *mThumbnailInput;
 
     bool mCancelEncoding;
     CameraFrame::FrameType mType;
@@ -163,13 +181,12 @@ private:
 
 private:
     ExifElement_t table[MAX_EXIF_TAGS_SUPPORTED];
-    unsigned int gps_tag_count;
-    unsigned int exif_tag_count;
-    unsigned int position;
+    unsigned int  gps_tag_count;
+    unsigned int  exif_tag_count;
+    unsigned int  position;
     bool jpeg_opened;
     bool has_datetime_tag;
 };
-
 };
 
-#endif
+#endif // ifndef _JPEG_BUILDER_H_
diff --git a/mx6/libcamera/OvDevice.cpp b/mx6/libcamera/OvDevice.cpp
old mode 100755
new mode 100644
index 39e01d2..d1242c7
--- a/mx6/libcamera/OvDevice.cpp
+++ b/mx6/libcamera/OvDevice.cpp
@@ -18,23 +18,34 @@
 #include "CameraUtil.h"
 #include "OvDevice.h"
 
-PixelFormat OvDevice::getMatchFormat(int* sfmt, int slen, int* dfmt, int dlen)
+PixelFormat OvDevice::getMatchFormat(int *sfmt,
+                                     int  slen,
+                                     int *dfmt,
+                                     int  dlen)
 {
-    if(sfmt == NULL || slen == 0 || dfmt == NULL || dlen == 0) {
+    if ((sfmt == NULL) || (slen == 0) || (dfmt == NULL) || (dlen == 0)) {
         FLOGE("setSupportedPreviewFormats invalid parameters");
         return 0;
     }
 
     PixelFormat matchFormat = 0;
-    bool live = true;
-    for(int i=0; i<slen && live; i++) {
-        for(int j=0; j<dlen; j++) {
-            FLOG_RUNTIME("sfmt[%d]=%c%c%c%c, dfmt[%d]=%c%c%c%c", i, sfmt[i]&0xFF,
-                (sfmt[i]>>8)&0xFF, (sfmt[i]>>16)&0xFF, (sfmt[i]>>24)&0xFF, j,
-                dfmt[j]&0xFF, (dfmt[j]>>8)&0xFF, (dfmt[j]>>16)&0xFF, (dfmt[j]>>24)&0xFF);
-            if(sfmt[i] == dfmt[j]) {
+    bool live               = true;
+    for (int i = 0; i < slen && live; i++) {
+        for (int j = 0; j < dlen; j++) {
+            FLOG_RUNTIME("sfmt[%d]=%c%c%c%c, dfmt[%d]=%c%c%c%c",
+                         i,
+                         sfmt[i] & 0xFF,
+                         (sfmt[i] >> 8) & 0xFF,
+                         (sfmt[i] >> 16) & 0xFF,
+                         (sfmt[i] >> 24) & 0xFF,
+                         j,
+                         dfmt[j] & 0xFF,
+                         (dfmt[j] >> 8) & 0xFF,
+                         (dfmt[j] >> 16) & 0xFF,
+                         (dfmt[j] >> 24) & 0xFF);
+            if (sfmt[i] == dfmt[j]) {
                 matchFormat = convertV4L2FormatToPixelFormat(dfmt[j]);
-                live = false;
+                live        = false;
                 break;
             }
         }
@@ -43,28 +54,31 @@ PixelFormat OvDevice::getMatchFormat(int* sfmt, int slen, int* dfmt, int dlen)
     return matchFormat;
 }
 
-status_t OvDevice::setSupportedPreviewFormats(int* sfmt, int slen, int* dfmt, int dlen)
+status_t OvDevice::setSupportedPreviewFormats(int *sfmt,
+                                              int  slen,
+                                              int *dfmt,
+                                              int  dlen)
 {
-    if(sfmt == NULL || slen == 0 || dfmt == NULL || dlen == 0) {
+    if ((sfmt == NULL) || (slen == 0) || (dfmt == NULL) || (dlen == 0)) {
         FLOGE("setSupportedPreviewFormats invalid parameters");
         return BAD_VALUE;
     }
 
     char fmtStr[FORMAT_STRING_LEN];
     memset(fmtStr, 0, FORMAT_STRING_LEN);
-    for(int i = 0; i < slen; i++) {
+    for (int i = 0; i < slen; i++) {
         for (int j = 0; j < dlen; j++) {
-            //should report VPU support format.
-            if(sfmt[i] == dfmt[j]) {
-                if(sfmt[i] == v4l2_fourcc('Y','U','1','2')) {
+            // should report VPU support format.
+            if (sfmt[i] == dfmt[j]) {
+                if (sfmt[i] == v4l2_fourcc('Y', 'U', '1', '2')) {
                     strcat(fmtStr, "yuv420p");
                     strcat(fmtStr, ",");
                 }
-                else if(sfmt[i] == v4l2_fourcc('N','V','1','2')) {
+                else if (sfmt[i] == v4l2_fourcc('N', 'V', '1', '2')) {
                     strcat(fmtStr, "yuv420sp");
                     strcat(fmtStr, ",");
                 }
-                else if(sfmt[i] == v4l2_fourcc('Y','U','Y','V')) {
+                else if (sfmt[i] == v4l2_fourcc('Y', 'U', 'Y', 'V')) {
                     strcat(fmtStr, "yuv422i-yuyv");
                     strcat(fmtStr, ",");
                 }
@@ -78,14 +92,15 @@ status_t OvDevice::setSupportedPreviewFormats(int* sfmt, int slen, int* dfmt, in
 
 status_t OvDevice::setPreviewStringFormat(PixelFormat format)
 {
-    const char* pformat = NULL;
-    if(format == HAL_PIXEL_FORMAT_YCbCr_420_P) {
+    const char *pformat = NULL;
+
+    if (format == HAL_PIXEL_FORMAT_YCbCr_420_P) {
         pformat = "yuv420p";
     }
-    else if(format == HAL_PIXEL_FORMAT_YCbCr_420_SP) {
+    else if (format == HAL_PIXEL_FORMAT_YCbCr_420_SP) {
         pformat = "yuv420sp";
     }
-    else if(format == HAL_PIXEL_FORMAT_YCbCr_422_I) {
+    else if (format == HAL_PIXEL_FORMAT_YCbCr_422_I) {
         pformat = "yuv422i-yuyv";
     }
     else {
@@ -98,116 +113,158 @@ status_t OvDevice::setPreviewStringFormat(PixelFormat format)
     return NO_ERROR;
 }
 
-status_t OvDevice::initParameters(CameraParameters& params, int* supportRecordingFormat, int rfmtLen,
-                        int* supportPictureFormat, int pfmtLen)
+status_t OvDevice::initParameters(CameraParameters& params,
+                                  int              *supportRecordingFormat,
+                                  int               rfmtLen,
+                                  int              *supportPictureFormat,
+                                  int               pfmtLen)
 {
-    if(mCameraHandle < 0) {
+    if (mCameraHandle < 0) {
         FLOGE("OvDevice: initParameters sensor has not been opened");
         return BAD_VALUE;
     }
-    if(supportRecordingFormat == NULL || rfmtLen == 0 ||
-            supportPictureFormat == NULL || pfmtLen == 0) {
+    if ((supportRecordingFormat == NULL) || (rfmtLen == 0) ||
+        (supportPictureFormat == NULL) || (pfmtLen == 0)) {
         FLOGE("OvDevice: initParameters invalid parameters");
         return BAD_VALUE;
     }
 
-    //first read sensor format.
+    // first read sensor format.
     int ret = 0, index = 0;
     int sensorFormat[MAX_SENSOR_FORMAT];
 #if 0
     struct v4l2_fmtdesc vid_fmtdesc;
-    while(ret == 0) {
+    while (ret == 0) {
         vid_fmtdesc.index = index;
-        vid_fmtdesc.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-        ret = ioctl(mCameraHandle, VIDIOC_ENUM_FMT, &vid_fmtdesc);
-        FLOG_RUNTIME("index:%d,ret:%d, format:%c%c%c%c", index, ret, 
-             vid_fmtdesc.pixelformat&0xFF, (vid_fmtdesc.pixelformat>>8)&0xFF,
-            (vid_fmtdesc.pixelformat>>16)&0xFF, (vid_fmtdesc.pixelformat>>24)&0xFF);
-        if(ret == 0) {
+        vid_fmtdesc.type  = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        ret               = ioctl(mCameraHandle, VIDIOC_ENUM_FMT, &vid_fmtdesc);
+        FLOG_RUNTIME("index:%d,ret:%d, format:%c%c%c%c", index, ret,
+                     vid_fmtdesc.pixelformat & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 8) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 16) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0) {
             sensorFormat[index++] = vid_fmtdesc.pixelformat;
         }
     }
-#endif
-    //v4l2 does not support enum format, now hard code here.
-    sensorFormat[0] = v4l2_fourcc('N','V','1','2');
-    sensorFormat[1] = v4l2_fourcc('Y','U','1','2');
-    sensorFormat[2] = v4l2_fourcc('Y','U','Y','V');
-    index = 3;
-    //second check match sensor format with vpu support format and picture format.
-    mPreviewPixelFormat = getMatchFormat(supportRecordingFormat, rfmtLen, sensorFormat, index);
-    mPicturePixelFormat = getMatchFormat(supportPictureFormat, pfmtLen, sensorFormat, index);
+#endif // if 0
+
+    // v4l2 does not support enum format, now hard code here.
+    sensorFormat[0] = v4l2_fourcc('N', 'V', '1', '2');
+    sensorFormat[1] = v4l2_fourcc('Y', 'U', '1', '2');
+    sensorFormat[2] = v4l2_fourcc('Y', 'U', 'Y', 'V');
+    index           = 3;
+
+    // second check match sensor format with vpu support format and picture
+    // format.
+    mPreviewPixelFormat = getMatchFormat(supportRecordingFormat,
+                                         rfmtLen,
+                                         sensorFormat,
+                                         index);
+    mPicturePixelFormat = getMatchFormat(supportPictureFormat,
+                                         pfmtLen,
+                                         sensorFormat,
+                                         index);
     setPreviewStringFormat(mPreviewPixelFormat);
-    ret = setSupportedPreviewFormats(supportRecordingFormat, rfmtLen, sensorFormat, index);
-    if(ret) {
+    ret = setSupportedPreviewFormats(supportRecordingFormat,
+                                     rfmtLen,
+                                     sensorFormat,
+                                     index);
+    if (ret) {
         FLOGE("setSupportedPreviewFormats failed");
         return ret;
     }
 
     index = 0;
     char TmpStr[20];
-    int  previewCnt= 0, pictureCnt = 0;
+    int  previewCnt = 0, pictureCnt = 0;
     struct v4l2_frmsizeenum vid_frmsize;
     struct v4l2_frmivalenum vid_frmval;
-    while(ret == 0) {
+    while (ret == 0) {
         memset(TmpStr, 0, 20);
         memset(&vid_frmsize, 0, sizeof(struct v4l2_frmsizeenum));
-        vid_frmsize.index = index ++;
-        vid_frmsize.pixel_format = v4l2_fourcc('N','V','1','2');
-        ret = ioctl(mCameraHandle, VIDIOC_ENUM_FRAMESIZES, &vid_frmsize);
-        if(ret == 0) {
+        vid_frmsize.index        = index++;
+        vid_frmsize.pixel_format = v4l2_fourcc('N', 'V', '1', '2');
+        ret                      = ioctl(mCameraHandle,
+                                         VIDIOC_ENUM_FRAMESIZES,
+                                         &vid_frmsize);
+        if (ret == 0) {
             FLOG_RUNTIME("enum frame size w:%d, h:%d",
-                vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+                         vid_frmsize.discrete.width, vid_frmsize.discrete.height);
             memset(&vid_frmval, 0, sizeof(struct v4l2_frmivalenum));
-            vid_frmval.index = 0;
+            vid_frmval.index        = 0;
             vid_frmval.pixel_format = vid_frmsize.pixel_format;
-            vid_frmval.width = vid_frmsize.discrete.width;
-            vid_frmval.height= vid_frmsize.discrete.height;
+            vid_frmval.width        = vid_frmsize.discrete.width;
+            vid_frmval.height       = vid_frmsize.discrete.height;
 
-            //ret = ioctl(mCameraHandle, VIDIOC_ENUM_FRAMEINTERVALS, &vid_frmval);
-            //v4l2 does not support, now hard code here.
-            if(ret == 0) {
+            // ret = ioctl(mCameraHandle, VIDIOC_ENUM_FRAMEINTERVALS,
+            // &vid_frmval);
+            // v4l2 does not support, now hard code here.
+            if (ret == 0) {
                 FLOG_RUNTIME("vid_frmval denominator:%d, numeraton:%d",
-                   vid_frmval.discrete.denominator, vid_frmval.discrete.numerator);
-                if(vid_frmsize.discrete.width > 1280 || vid_frmsize.discrete.height >720) {
+                             vid_frmval.discrete.denominator,
+                             vid_frmval.discrete.numerator);
+                if ((vid_frmsize.discrete.width > 1280) ||
+                    (vid_frmsize.discrete.height > 720)) {
                     vid_frmval.discrete.denominator = 15;
-                    vid_frmval.discrete.numerator = 1;
+                    vid_frmval.discrete.numerator   = 1;
                 }
                 else {
                     vid_frmval.discrete.denominator = 30;
-                    vid_frmval.discrete.numerator = 1;
+                    vid_frmval.discrete.numerator   = 1;
                 }
 
-                sprintf(TmpStr, "%dx%d", vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+                sprintf(TmpStr,
+                        "%dx%d",
+                        vid_frmsize.discrete.width,
+                        vid_frmsize.discrete.height);
                 if (pictureCnt == 0)
-                    strncpy((char*) mSupportedPictureSizes, TmpStr, CAMER_PARAM_BUFFER_SIZE);
-                else{
-                    strncat(mSupportedPictureSizes,  PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-                    strncat(mSupportedPictureSizes, TmpStr, CAMER_PARAM_BUFFER_SIZE);
+                    strncpy((char *)mSupportedPictureSizes,
+                            TmpStr,
+                            CAMER_PARAM_BUFFER_SIZE);
+                else {
+                    strncat(mSupportedPictureSizes,
+                            PARAMS_DELIMITER,
+                            CAMER_PARAM_BUFFER_SIZE);
+                    strncat(mSupportedPictureSizes,
+                            TmpStr,
+                            CAMER_PARAM_BUFFER_SIZE);
                 }
-                pictureCnt ++;
+                pictureCnt++;
 
-                if (vid_frmval.discrete.denominator/vid_frmval.discrete.numerator >= 15){
+                if (vid_frmval.discrete.denominator /
+                    vid_frmval.discrete.numerator >= 15) {
                     if (previewCnt == 0)
-                        strncpy((char*) mSupportedPreviewSizes, TmpStr, CAMER_PARAM_BUFFER_SIZE);
-                    else{
-                        strncat(mSupportedPreviewSizes,  PARAMS_DELIMITER, CAMER_PARAM_BUFFER_SIZE);
-                        strncat(mSupportedPreviewSizes, TmpStr, CAMER_PARAM_BUFFER_SIZE);
+                        strncpy((char *)mSupportedPreviewSizes,
+                                TmpStr,
+                                CAMER_PARAM_BUFFER_SIZE);
+                    else {
+                        strncat(mSupportedPreviewSizes,
+                                PARAMS_DELIMITER,
+                                CAMER_PARAM_BUFFER_SIZE);
+                        strncat(mSupportedPreviewSizes,
+                                TmpStr,
+                                CAMER_PARAM_BUFFER_SIZE);
                     }
-                    previewCnt ++;
+                    previewCnt++;
                 }
             }
         }
-    }//end while
+    } // end while
 
     strcpy(mSupportedFPS, "15,30");
     FLOGI("SupportedPictureSizes is %s", mSupportedPictureSizes);
     FLOGI("SupportedPreviewSizes is %s", mSupportedPreviewSizes);
     FLOGI("SupportedFPS is %s", mSupportedFPS);
 
-    mParams.set(CameraParameters::KEY_SUPPORTED_PICTURE_SIZES, mSupportedPictureSizes);
-    mParams.set(CameraParameters::KEY_SUPPORTED_PREVIEW_SIZES, mSupportedPreviewSizes);
-    mParams.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES, mSupportedFPS);
-    mParams.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FPS_RANGE, "(12000,17000),(25000,33000)");
+    mParams.set(CameraParameters::KEY_SUPPORTED_PICTURE_SIZES,
+                mSupportedPictureSizes);
+    mParams.set(CameraParameters::KEY_SUPPORTED_PREVIEW_SIZES,
+                mSupportedPreviewSizes);
+    mParams.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES,
+                mSupportedFPS);
+    mParams.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FPS_RANGE,
+                "(12000,17000),(25000,33000)");
     mParams.set(CameraParameters::KEY_PREVIEW_FPS_RANGE, "25000,33000");
 
     mParams.setPreviewSize(DEFAULT_PREVIEW_W, DEFAULT_PREVIEW_H);
@@ -220,23 +277,24 @@ status_t OvDevice::initParameters(CameraParameters& params, int* supportRecordin
 
 status_t OvDevice::setParameters(CameraParameters& params)
 {
-    int w, h;
-    int framerate, local_framerate;
-    int max_zoom,zoom, max_fps, min_fps;
+    int  w, h;
+    int  framerate, local_framerate;
+    int  max_zoom, zoom, max_fps, min_fps;
     char tmp[128];
 
     Mutex::Autolock lock(mLock);
 
     max_zoom = params.getInt(CameraParameters::KEY_MAX_ZOOM);
-    zoom = params.getInt(CameraParameters::KEY_ZOOM);
-    if(zoom > max_zoom){
-        FLOGE("Invalid zoom setting, zoom %d, max zoom %d",zoom,max_zoom);
+    zoom     = params.getInt(CameraParameters::KEY_ZOOM);
+    if (zoom > max_zoom) {
+        FLOGE("Invalid zoom setting, zoom %d, max zoom %d", zoom, max_zoom);
         return BAD_VALUE;
     }
     if (!((strcmp(params.getPreviewFormat(), "yuv420sp") == 0) ||
-            (strcmp(params.getPreviewFormat(), "yuv420p") == 0) ||
-            (strcmp(params.getPreviewFormat(), "yuv422i-yuyv") == 0))) {
-        FLOGE("Only yuv420sp or yuv420pis supported, but input format is %s", params.getPreviewFormat());
+          (strcmp(params.getPreviewFormat(), "yuv420p") == 0) ||
+          (strcmp(params.getPreviewFormat(), "yuv422i-yuyv") == 0))) {
+        FLOGE("Only yuv420sp or yuv420pis supported, but input format is %s",
+              params.getPreviewFormat());
         return BAD_VALUE;
     }
 
@@ -248,7 +306,7 @@ status_t OvDevice::setParameters(CameraParameters& params)
     params.getPreviewSize(&w, &h);
     sprintf(tmp, "%dx%d", w, h);
     FLOGI("Set preview size: %s", tmp);
-    if (strstr(mSupportedPreviewSizes, tmp) == NULL){
+    if (strstr(mSupportedPreviewSizes, tmp) == NULL) {
         FLOGE("The preview size w %d, h %d is not corrected", w, h);
         return BAD_VALUE;
     }
@@ -256,26 +314,26 @@ status_t OvDevice::setParameters(CameraParameters& params)
     params.getPictureSize(&w, &h);
     sprintf(tmp, "%dx%d", w, h);
     FLOGI("Set picture size: %s", tmp);
-    if (strstr(mSupportedPictureSizes, tmp) == NULL){
+    if (strstr(mSupportedPictureSizes, tmp) == NULL) {
         FLOGE("The picture size w %d, h %d is not corrected", w, h);
         return BAD_VALUE;
     }
 
     local_framerate = params.getPreviewFrameRate();
     FLOGI("get local frame rate:%d FPS", local_framerate);
-    if ((local_framerate > 30) || (local_framerate < 0) ){
+    if ((local_framerate > 30) || (local_framerate < 0)) {
         FLOGE("The framerate is not corrected");
         local_framerate = 15;
     }
 
     framerate = params.getPreviewFrameRate();
     FLOGI("Set frame rate:%d FPS", framerate);
-    if ((framerate > 30) || (framerate < 0) ){
+    if ((framerate > 30) || (framerate < 0)) {
         FLOGE("The framerate is not corrected");
         return BAD_VALUE;
     }
-    else if(local_framerate != framerate) {
-        if(framerate == 15) {
+    else if (local_framerate != framerate) {
+        if (framerate == 15) {
             params.set(CameraParameters::KEY_PREVIEW_FPS_RANGE, "12000,17000");
         }
         else if (framerate == 30) {
@@ -285,15 +343,17 @@ status_t OvDevice::setParameters(CameraParameters& params)
 
     int actual_fps = 15;
     params.getPreviewFpsRange(&min_fps, &max_fps);
-    FLOGI("FPS range: %d - %d",min_fps, max_fps);
-    if (max_fps < 1000 || min_fps < 1000 || max_fps > 33000 || min_fps > 33000){
+    FLOGI("FPS range: %d - %d", min_fps, max_fps);
+    if ((max_fps < 1000) || (min_fps < 1000) || (max_fps > 33000) ||
+        (min_fps > 33000)) {
         FLOGE("The fps range from %d to %d is error", min_fps, max_fps);
         return BAD_VALUE;
     }
-    actual_fps = min_fps > 15000? 30:15;
+    actual_fps = min_fps > 15000 ? 30 : 15;
     FLOGI("setParameters: actual_fps=%d", actual_fps);
     params.setPreviewFrameRate(actual_fps);
 
     mParams = params;
     return NO_ERROR;
 }
+
diff --git a/mx6/libcamera/OvDevice.h b/mx6/libcamera/OvDevice.h
old mode 100755
new mode 100644
index a4f44fc..eee3454
--- a/mx6/libcamera/OvDevice.h
+++ b/mx6/libcamera/OvDevice.h
@@ -29,16 +29,24 @@
 #define MAX_SENSOR_FORMAT 20
 #define FORMAT_STRING_LEN 64
 
-class OvDevice : public DeviceAdapter
-{
+class OvDevice : public DeviceAdapter {
 public:
-    virtual status_t initParameters(CameraParameters& params, int* supportRecordingFormat, int rfmtLen,
-                        int* supportPictureFormat, int pfmtLen);
+    virtual status_t initParameters(CameraParameters& params,
+                                    int              *supportRecordingFormat,
+                                    int               rfmtLen,
+                                    int              *supportPictureFormat,
+                                    int               pfmtLen);
     virtual status_t setParameters(CameraParameters& params);
 
 private:
-    PixelFormat getMatchFormat(int* sfmt, int slen, int* dfmt, int dlen);
-    status_t setSupportedPreviewFormats(int* sfmt, int slen, int* dfmt, int dlen);
+    PixelFormat      getMatchFormat(int *sfmt,
+                                    int  slen,
+                                    int *dfmt,
+                                    int  dlen);
+    status_t setSupportedPreviewFormats(int *sfmt,
+                                        int  slen,
+                                        int *dfmt,
+                                        int  dlen);
     status_t setPreviewStringFormat(PixelFormat format);
 
 private:
@@ -47,4 +55,4 @@ private:
     char mSupportedPreviewSizes[CAMER_PARAM_BUFFER_SIZE];
 };
 
-#endif
+#endif // ifndef _OV_DEVICE_H_
diff --git a/mx6/libcamera/PhysMemAdapter.cpp b/mx6/libcamera/PhysMemAdapter.cpp
index 2b492a7..a99d13e 100644
--- a/mx6/libcamera/PhysMemAdapter.cpp
+++ b/mx6/libcamera/PhysMemAdapter.cpp
@@ -34,33 +34,42 @@ PhysMemAdapter::~PhysMemAdapter()
     ion_close(mIonFd);
 }
 
-int PhysMemAdapter::allocatePreviewBuffer(int width, int height, int format, int numBufs)
+int PhysMemAdapter::allocatePreviewBuffer(int width,
+                                          int height,
+                                          int format,
+                                          int numBufs)
 {
     return BAD_VALUE;
 }
 
-int PhysMemAdapter::allocatePictureBuffer(int width, int height, int format, int numBufs)
+int PhysMemAdapter::allocatePictureBuffer(int width,
+                                          int height,
+                                          int format,
+                                          int numBufs)
 {
-    if(mIonFd <= 0) {
+    if (mIonFd <= 0) {
         FLOGE("try to allocate buffer from ion in preview or ion invalid");
         return BAD_VALUE;
     }
 
     int size = 0;
-    if(width == 0 || height == 0) {
+    if ((width == 0) || (height == 0)) {
         FLOGE("allocateBufferFromIon: width or height = 0");
         return BAD_VALUE;
     }
-    switch(format) {
+    switch (format) {
         case HAL_PIXEL_FORMAT_YCbCr_420_SP:
-            size = width * ((height + 16)&(~15)) * 3/2;
+            size = width * ((height + 16) & (~15)) * 3 / 2;
             break;
+
         case HAL_PIXEL_FORMAT_YCbCr_420_P:
-            size = width * height * 3/2;
+            size = width * height * 3 / 2;
             break;
+
         case HAL_PIXEL_FORMAT_YCbCr_422_I:
             size = width * height * 2;
             break;
+
         default:
             FLOGE("Error: format not supported int ion alloc");
             return BAD_VALUE;
@@ -69,64 +78,74 @@ int PhysMemAdapter::allocatePictureBuffer(int width, int height, int format, int
     unsigned char *ptr = NULL;
     int sharedFd;
     int phyAddr;
-    struct ion_handle * ionHandle;
-    size = (size + PAGE_SIZE)&(~(PAGE_SIZE-1));
+    struct ion_handle *ionHandle;
+    size = (size + PAGE_SIZE) & (~(PAGE_SIZE - 1));
 
     FLOGI("allocateBufferFromIon buffer num:%d", numBufs);
-    for(int i = 0; i < numBufs; i++) {
+    for (int i = 0; i < numBufs; i++) {
         ionHandle = NULL;
         int err = ion_alloc(mIonFd, size, 8, 1, &ionHandle);
-        if(err) {
+        if (err) {
             FLOGE("ion_alloc failed.");
             return BAD_VALUE;
         }
 
-        err = ion_map(mIonFd, ionHandle, size, PROT_READ|PROT_WRITE, MAP_SHARED, 0, &ptr, &sharedFd);
-        if(err) {
+        err = ion_map(mIonFd,
+                      ionHandle,
+                      size,
+                      PROT_READ | PROT_WRITE,
+                      MAP_SHARED,
+                      0,
+                      &ptr,
+                      &sharedFd);
+        if (err) {
             FLOGE("ion_map failed.");
             return BAD_VALUE;
         }
         phyAddr = ion_phys(mIonFd, ionHandle);
-        if(phyAddr == 0) {
+        if (phyAddr == 0) {
             FLOGE("ion_phys failed.");
             return BAD_VALUE;
         }
-        FLOG_RUNTIME("phyalloc ptr:0x%x, phy:0x%x, size:%d", (int)ptr, phyAddr, size);
+        FLOG_RUNTIME("phyalloc ptr:0x%x, phy:0x%x, size:%d",
+                     (int)ptr,
+                     phyAddr,
+                     size);
         mCameraBuffer[i].reset();
-        mCameraBuffer[i].mIndex = i;
-        mCameraBuffer[i].mWidth = width;
-        mCameraBuffer[i].mHeight = height;
-        mCameraBuffer[i].mFormat = format;
-        mCameraBuffer[i].mVirtAddr = ptr;
-        mCameraBuffer[i].mPhyAddr = phyAddr;
-        mCameraBuffer[i].mSize =  size;
-        mCameraBuffer[i].mBufHandle = (buffer_handle_t*)ionHandle;
+        mCameraBuffer[i].mIndex     = i;
+        mCameraBuffer[i].mWidth     = width;
+        mCameraBuffer[i].mHeight    = height;
+        mCameraBuffer[i].mFormat    = format;
+        mCameraBuffer[i].mVirtAddr  = ptr;
+        mCameraBuffer[i].mPhyAddr   = phyAddr;
+        mCameraBuffer[i].mSize      =  size;
+        mCameraBuffer[i].mBufHandle = (buffer_handle_t *)ionHandle;
         close(sharedFd);
     }
 
-    mBufferCount = numBufs;
+    mBufferCount    = numBufs;
     mQueueableCount = numBufs;
-    mFormat = format;
-    mBufferSize = mCameraBuffer[0].mSize;
-    mFrameWidth = width;
-    mFrameHeight = height;
+    mFormat         = format;
+    mBufferSize     = mCameraBuffer[0].mSize;
+    mFrameWidth     = width;
+    mFrameHeight    = height;
 
     dispatchBuffers(&mCameraBuffer[0], numBufs, BUFFER_CREATE);
 
     return NO_ERROR;
-
 }
 
 int PhysMemAdapter::freeBuffer()
 {
-    if(mIonFd <= 0) {
+    if (mIonFd <= 0) {
         FLOGE("try to free buffer from ion in preview or ion invalid");
         return BAD_VALUE;
     }
 
     FLOGI("freeBufferToIon buffer num:%d", mBufferCount);
-    for(int i = 0; i < mBufferCount; i++) {
-        struct ion_handle * ionHandle = (struct ion_handle *)mCameraBuffer[i].mBufHandle;
+    for (int i = 0; i < mBufferCount; i++) {
+        struct ion_handle *ionHandle =
+            (struct ion_handle *)mCameraBuffer[i].mBufHandle;
         ion_free(mIonFd, ionHandle);
         munmap(mCameraBuffer[i].mVirtAddr, mCameraBuffer[i].mSize);
     }
@@ -134,7 +153,6 @@ int PhysMemAdapter::freeBuffer()
     memset(mCameraBuffer, 0, sizeof(mCameraBuffer));
     dispatchBuffers(NULL, 0, BUFFER_DESTROY);
     return NO_ERROR;
-
 }
 
 int PhysMemAdapter::maxQueueableBuffers()
diff --git a/mx6/libcamera/PhysMemAdapter.h b/mx6/libcamera/PhysMemAdapter.h
index 4907675..9ae794e 100644
--- a/mx6/libcamera/PhysMemAdapter.h
+++ b/mx6/libcamera/PhysMemAdapter.h
@@ -22,22 +22,27 @@
 
 using namespace android;
 
-class PhysMemAdapter : public CameraBufferProvider
-{
+class PhysMemAdapter : public CameraBufferProvider {
 public:
     PhysMemAdapter();
     virtual ~PhysMemAdapter();
 
-    virtual int allocatePreviewBuffer(int width, int height, int format, int numBufs);
-    virtual int allocatePictureBuffer(int width, int height, int format, int numBufs);
+    virtual int allocatePreviewBuffer(int width,
+                                      int height,
+                                      int format,
+                                      int numBufs);
+    virtual int allocatePictureBuffer(int width,
+                                      int height,
+                                      int format,
+                                      int numBufs);
     virtual int freeBuffer();
     virtual int maxQueueableBuffers();
 
-    //void setErrorListener(CameraErrorListener* listener);
+    // void setErrorListener(CameraErrorListener* listener);
 
 protected:
     int mIonFd;
-    CameraErrorListener* mErrorListener;
+    CameraErrorListener *mErrorListener;
 
     CameraFrame mCameraBuffer[MAX_PREVIEW_BUFFER];
 
@@ -49,4 +54,4 @@ protected:
     int mQueueableCount;
 };
 
-#endif
+#endif // ifndef _PHYS_MEM_ADAPTER_H_
diff --git a/mx6/libcamera/SurfaceAdapter.cpp b/mx6/libcamera/SurfaceAdapter.cpp
old mode 100755
new mode 100644
index 64f6cdc..66aa82c
--- a/mx6/libcamera/SurfaceAdapter.cpp
+++ b/mx6/libcamera/SurfaceAdapter.cpp
@@ -30,11 +30,14 @@ SurfaceAdapter::~SurfaceAdapter()
     clearBufferListeners();
 }
 
-int SurfaceAdapter::setNativeWindowAttribute(int width, int height, int format, int numBufs)
+int SurfaceAdapter::setNativeWindowAttribute(int width,
+                                             int height,
+                                             int format,
+                                             int numBufs)
 {
     status_t err = NO_ERROR;
 
-    if(NULL == mNativeWindow) {
+    if (NULL == mNativeWindow) {
         FLOGE("SurfaceAdapter: allocateBuffer invalid parameters");
         return BAD_VALUE;
     }
@@ -43,7 +46,7 @@ int SurfaceAdapter::setNativeWindowAttribute(int width, int height, int format,
     err = mNativeWindow->set_usage(mNativeWindow, CAMERA_GRALLOC_USAGE);
     if (err != 0) {
         FLOGE("native_window_set_usage failed: %s (%d)", strerror(-err), -err);
-        if(ENODEV == err) {
+        if (ENODEV == err) {
             FLOGE("Preview surface abandoned!");
             mNativeWindow = NULL;
         }
@@ -52,10 +55,12 @@ int SurfaceAdapter::setNativeWindowAttribute(int width, int height, int format,
     }
 
     FLOGI("Number of buffers set to NativeWindow %d", numBufs);
-    ///Set the number of buffers needed for camera preview
+
+    // /Set the number of buffers needed for camera preview
     err = mNativeWindow->set_buffer_count(mNativeWindow, numBufs);
-    if(err != 0) {
-        FLOGE("native_window_set_buffer_count failed: %s (%d)", strerror(-err), -err);
+    if (err != 0) {
+        FLOGE("native_window_set_buffer_count failed: %s (%d)", strerror(
+                  -err), -err);
         if (ENODEV == err) {
             FLOGE("Preview surface abandoned!");
             mNativeWindow = NULL;
@@ -66,11 +71,12 @@ int SurfaceAdapter::setNativeWindowAttribute(int width, int height, int format,
 
     // Set window geometry
     err = mNativeWindow->set_buffers_geometry(mNativeWindow,
-            width, height, format);
+                                              width, height, format);
 
-    if(err != 0) {
-        FLOGE("native_window_set_buffers_geometry failed: %s (%d)", strerror(-err), -err);
-        if(ENODEV == err) {
+    if (err != 0) {
+        FLOGE("native_window_set_buffers_geometry failed: %s (%d)", strerror(
+                  -err), -err);
+        if (ENODEV == err) {
             FLOGE("Preview surface abandoned!");
             mNativeWindow = NULL;
         }
@@ -82,18 +88,21 @@ int SurfaceAdapter::setNativeWindowAttribute(int width, int height, int format,
     return err;
 }
 
-int SurfaceAdapter::allocatePreviewBuffer(int width, int height, int format, int numBufs)
+int SurfaceAdapter::allocatePreviewBuffer(int width,
+                                          int height,
+                                          int format,
+                                          int numBufs)
 {
-    status_t err = NO_ERROR;
+    status_t err   = NO_ERROR;
     int undequeued = 0;
 
-    if(NULL == mNativeWindow || numBufs == 0) {
+    if ((NULL == mNativeWindow) || (numBufs == 0)) {
         FLOGE("allocatePreviewBuffer invalid parameters");
         return BAD_VALUE;
     }
 
     err = setNativeWindowAttribute(width, height, format, numBufs);
-    if(err) {
+    if (err) {
         FLOGE("setNativeWindowAttribute failed.");
         return err;
     }
@@ -106,59 +115,68 @@ int SurfaceAdapter::allocatePreviewBuffer(int width, int height, int format, int
     return err;
 }
 
-int SurfaceAdapter::allocatePictureBuffer(int width, int height, int format, int numBufs)
+int SurfaceAdapter::allocatePictureBuffer(int width,
+                                          int height,
+                                          int format,
+                                          int numBufs)
 {
     status_t err = NO_ERROR;
 
-    if(NULL == mNativeWindow || numBufs == 0) {
+    if ((NULL == mNativeWindow) || (numBufs == 0)) {
         FLOGE("allocatePictureBuffer invalid parameters");
         return BAD_VALUE;
     }
 
     err = setNativeWindowAttribute(width, height, format, numBufs);
-    if(err) {
+    if (err) {
         FLOGE("setNativeWindowAttribute failed.");
         return err;
     }
 
-    mBufferCount = numBufs;
+    mBufferCount    = numBufs;
     mQueueableCount = numBufs;
 
     err = allocateBuffer(width, height, format, numBufs, mQueueableCount);
     return err;
 }
 
-int SurfaceAdapter::allocateBuffer(int width, int height, int format, int numBufs, int maxQCount)
+int SurfaceAdapter::allocateBuffer(int width,
+                                   int height,
+                                   int format,
+                                   int numBufs,
+                                   int maxQCount)
 {
     status_t err;
-    int i = -1;
-    GraphicBufferMapper &mapper = GraphicBufferMapper::get();
+    int i                       = -1;
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
     Rect bounds;
 
-    if(NULL == mNativeWindow || numBufs == 0) {
+    if ((NULL == mNativeWindow) || (numBufs == 0)) {
         FLOGE("allocateBuffer invalid parameters");
         return BAD_VALUE;
     }
 
     memset(mCameraBuffer, 0, sizeof(mCameraBuffer));
-   // lock the initial queueable buffers
-    bounds.left = 0;
-    bounds.top = 0;
-    bounds.right = width;
+
+    // lock the initial queueable buffers
+    bounds.left   = 0;
+    bounds.top    = 0;
+    bounds.right  = width;
     bounds.bottom = height;
     void *pVaddr = NULL;
-    int stride = 0;
+    int   stride = 0;
 
-    for(i=0; i < numBufs; i++) {
-        buffer_handle_t* buf_h = NULL;
+    for (i = 0; i < numBufs; i++) {
+        buffer_handle_t *buf_h = NULL;
         stride = 0;
         pVaddr = NULL;
+
         // TODO(XXX): Do we need to keep stride information in camera hal?
 
         err = mNativeWindow->dequeue_buffer(mNativeWindow, &buf_h, &stride);
-        if(err != 0) {
+        if (err != 0) {
             FLOGE("dequeueBuffer failed: %s (%d)", strerror(-err), -err);
-            if(ENODEV == err) {
+            if (ENODEV == err) {
                 FLOGE("Preview surface abandoned!");
                 mNativeWindow = NULL;
             }
@@ -167,20 +185,21 @@ int SurfaceAdapter::allocateBuffer(int width, int height, int format, int numBuf
 
         mapper.lock(*buf_h, CAMERA_GRALLOC_USAGE, bounds, &pVaddr);
         mCameraBuffer[i].initialize(buf_h, i);
-        mCameraBuffer[i].mWidth = width;
+        mCameraBuffer[i].mWidth  = width;
         mCameraBuffer[i].mHeight = height;
     }
 
-    for(i = 0; i < maxQCount; i++) {
+    for (i = 0; i < maxQCount; i++) {
         mNativeWindow->lock_buffer(mNativeWindow, mCameraBuffer[i].mBufHandle);
     }
 
     // return the rest of the buffers back to ANativeWindow
-    for(i = maxQCount; i >= 0 && i < numBufs; i++) {
-        err = mNativeWindow->cancel_buffer(mNativeWindow, mCameraBuffer[i].mBufHandle);
-        if(err != 0) {
+    for (i = maxQCount; i >= 0 && i < numBufs; i++) {
+        err = mNativeWindow->cancel_buffer(mNativeWindow,
+                                           mCameraBuffer[i].mBufHandle);
+        if (err != 0) {
             FLOGE("cancel_buffer failed: %s (%d)", strerror(-err), -err);
-            if(ENODEV == err) {
+            if (ENODEV == err) {
                 FLOGE("Preview surface abandoned!");
                 mNativeWindow = NULL;
             }
@@ -188,24 +207,27 @@ int SurfaceAdapter::allocateBuffer(int width, int height, int format, int numBuf
             goto fail;
         }
         mapper.unlock(*mCameraBuffer[i].mBufHandle);
-        //the frame held in SurfaceAdapter.
+
+        // the frame held in SurfaceAdapter.
         mCameraBuffer[i].addReference();
     }
 
     dispatchBuffers(&mCameraBuffer[0], numBufs, BUFFER_CREATE);
 
-    mFormat = format;
-    mBufferSize = mCameraBuffer[0].mSize;
-    mFrameWidth = width;
+    mFormat      = format;
+    mBufferSize  = mCameraBuffer[0].mSize;
+    mFrameWidth  = width;
     mFrameHeight = height;
 
     return NO_ERROR;
 
 fail:
+
     // need to cancel buffers if any were dequeued
     for (int start = 0; start < i && i > 0; start++) {
-        int err = mNativeWindow->cancel_buffer(mNativeWindow, mCameraBuffer[start].mBufHandle);
-        if(err != 0) {
+        int err = mNativeWindow->cancel_buffer(mNativeWindow,
+                                               mCameraBuffer[start].mBufHandle);
+        if (err != 0) {
             FLOGE("cancelBuffer failed w/ error 0x%08x", err);
             break;
         }
@@ -225,19 +247,21 @@ int SurfaceAdapter::freeBuffer()
 {
     status_t ret = NO_ERROR;
 
-     GraphicBufferMapper &mapper = GraphicBufferMapper::get();
-    //Give the buffers back to display here -  sort of free it
-    if(mNativeWindow) {
-        for(int i = 0; i < mBufferCount; i++) {
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+
+    // Give the buffers back to display here -  sort of free it
+    if (mNativeWindow) {
+        for (int i = 0; i < mBufferCount; i++) {
             mapper.unlock(*mCameraBuffer[i].mBufHandle);
-            ret = mNativeWindow->cancel_buffer(mNativeWindow, mCameraBuffer[i].mBufHandle);
-            if(ENODEV == ret) {
-                 FLOGE("Preview surface abandoned!");
-                 mNativeWindow = NULL;
-                 return -ret;
+            ret = mNativeWindow->cancel_buffer(mNativeWindow,
+                                               mCameraBuffer[i].mBufHandle);
+            if (ENODEV == ret) {
+                FLOGE("Preview surface abandoned!");
+                mNativeWindow = NULL;
+                return -ret;
             }
-            else if(NO_ERROR != ret) {
-                 FLOGE("cancel_buffer() failed: %s (%d)", strerror(-ret), -ret);
+            else if (NO_ERROR != ret) {
+                FLOGE("cancel_buffer() failed: %s (%d)", strerror(-ret), -ret);
                 return -ret;
             }
         }
@@ -248,29 +272,29 @@ int SurfaceAdapter::freeBuffer()
 
     memset(mCameraBuffer, 0, sizeof(mCameraBuffer));
 
-    ///Clear the frames with camera adapter map
+    // /Clear the frames with camera adapter map
     dispatchBuffers(NULL, 0, BUFFER_DESTROY);
 
     return ret;
 }
 
-void SurfaceAdapter::setErrorListener(CameraErrorListener* listener)
+void SurfaceAdapter::setErrorListener(CameraErrorListener *listener)
 {
     mErrorListener = listener;
 }
 
-int SurfaceAdapter::setPreviewWindow(preview_stream_ops_t* window)
+int SurfaceAdapter::setPreviewWindow(preview_stream_ops_t *window)
 {
-    ///Note that Display Adapter cannot work without a valid window object
-    if(!window) {
+    // /Note that Display Adapter cannot work without a valid window object
+    if (!window) {
         FLOGE("NULL window object passed to DisplayAdapter");
         return BAD_VALUE;
     }
 
-    ///Destroy the existing window object, if it exists
+    // /Destroy the existing window object, if it exists
     destroy();
 
-    ///Move to new window obj
+    // /Move to new window obj
     mNativeWindow = window;
 
     return NO_ERROR;
@@ -279,8 +303,8 @@ int SurfaceAdapter::setPreviewWindow(preview_stream_ops_t* window)
 void SurfaceAdapter::destroy()
 {
     mNativeWindow = NULL;
-    mBufferCount = 0;
-    mBufferSize = 0;
+    mBufferCount  = 0;
+    mBufferSize   = 0;
 }
 
 int SurfaceAdapter::maxQueueableBuffers()
@@ -288,11 +312,12 @@ int SurfaceAdapter::maxQueueableBuffers()
     return mQueueableCount;
 }
 
-void SurfaceAdapter::renderBuffer(buffer_handle_t* bufHandle)
+void SurfaceAdapter::renderBuffer(buffer_handle_t *bufHandle)
 {
     status_t ret = NO_ERROR;
 
-    GraphicBufferMapper &mapper = GraphicBufferMapper::get();
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+
     // unlock buffer before sending to display
     mapper.unlock(*bufHandle);
 
@@ -302,36 +327,37 @@ void SurfaceAdapter::renderBuffer(buffer_handle_t* bufHandle)
     }
 }
 
-void SurfaceAdapter::cancelBuffer(buffer_handle_t* bufHandle)
+void SurfaceAdapter::cancelBuffer(buffer_handle_t *bufHandle)
 {
     status_t ret = NO_ERROR;
 
-    GraphicBufferMapper &mapper = GraphicBufferMapper::get();
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+
     mapper.unlock(*bufHandle);
 
     ret = mNativeWindow->cancel_buffer(mNativeWindow, bufHandle);
-    if(ret != 0) {
+    if (ret != 0) {
         FLOGE("Surface::queueBuffer returned error %d", ret);
     }
 }
 
-CameraFrame* SurfaceAdapter::requestBuffer()
+CameraFrame * SurfaceAdapter::requestBuffer()
 {
     status_t err;
-    buffer_handle_t* buf;
+    buffer_handle_t *buf;
     int i = 0;
-    int stride;  // dummy variable to get stride
-    GraphicBufferMapper &mapper = GraphicBufferMapper::get();
-    Rect bounds;
+    int stride; // dummy variable to get stride
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+    Rect  bounds;
     void *pVaddr;
 
-    if(NULL == mNativeWindow) {
+    if (NULL == mNativeWindow) {
         FLOGE("mNativeWindow is null");
         return NULL;
     }
 
     err = mNativeWindow->dequeue_buffer(mNativeWindow, &buf, &stride);
-    if(err != 0) {
+    if (err != 0) {
         FLOGE("dequeueBuffer failed: %s (%d)", strerror(-err), -err);
         if (ENODEV == err) {
             FLOGE("Preview surface abandoned!");
@@ -342,7 +368,7 @@ CameraFrame* SurfaceAdapter::requestBuffer()
     }
 
     err = mNativeWindow->lock_buffer(mNativeWindow, buf);
-    if(err != 0) {
+    if (err != 0) {
         FLOGE("lockbuffer failed: %s (%d)", strerror(-err), -err);
         if (ENODEV == err) {
             FLOGE("Preview surface abandoned!");
@@ -352,18 +378,21 @@ CameraFrame* SurfaceAdapter::requestBuffer()
         return NULL;
     }
 
-    for(i=0; i < mBufferCount; i++) {
-        if(mCameraBuffer[i].mBufHandle == buf)
+    for (i = 0; i < mBufferCount; i++) {
+        if (mCameraBuffer[i].mBufHandle == buf)
             break;
     }
 
     // lock buffer before sending to FrameProvider for filling
-    bounds.left = 0;
-    bounds.top = 0;
-    bounds.right = mFrameWidth;
+    bounds.left   = 0;
+    bounds.top    = 0;
+    bounds.right  = mFrameWidth;
     bounds.bottom = mFrameHeight;
 
-    mapper.lock(*mCameraBuffer[i].mBufHandle, CAMERA_GRALLOC_USAGE, bounds, &pVaddr);
+    mapper.lock(*mCameraBuffer[i].mBufHandle,
+                CAMERA_GRALLOC_USAGE,
+                bounds,
+                &pVaddr);
 
     return &mCameraBuffer[i];
 }
diff --git a/mx6/libcamera/SurfaceAdapter.h b/mx6/libcamera/SurfaceAdapter.h
old mode 100755
new mode 100644
index aa7e4b2..005c68a
--- a/mx6/libcamera/SurfaceAdapter.h
+++ b/mx6/libcamera/SurfaceAdapter.h
@@ -22,33 +22,46 @@
 
 using namespace android;
 
-class SurfaceAdapter : public CameraBufferProvider, public LightRefBase<SurfaceAdapter>
-{
+class SurfaceAdapter : public CameraBufferProvider,
+                       public LightRefBase<SurfaceAdapter>{
 public:
     SurfaceAdapter();
     virtual ~SurfaceAdapter();
 
-    virtual int allocatePreviewBuffer(int width, int height, int format, int numBufs);
-    virtual int allocatePictureBuffer(int width, int height, int format, int numBufs);
-    virtual int freeBuffer();
-    virtual int maxQueueableBuffers();
-    virtual int setPreviewWindow(struct preview_stream_ops *window);
+    virtual int allocatePreviewBuffer(int width,
+                                      int height,
+                                      int format,
+                                      int numBufs);
+    virtual int allocatePictureBuffer(int width,
+                                      int height,
+                                      int format,
+                                      int numBufs);
+    virtual int  freeBuffer();
+    virtual int  maxQueueableBuffers();
+    virtual int  setPreviewWindow(struct preview_stream_ops *window);
 
-    void setErrorListener(CameraErrorListener* listener);
+    void         setErrorListener(CameraErrorListener *listener);
 
 protected:
-    void destroy();
-    void renderBuffer(buffer_handle_t* bufHandle);
-    void cancelBuffer(buffer_handle_t* bufHandle);
+    void         destroy();
+    void         renderBuffer(buffer_handle_t *bufHandle);
+    void         cancelBuffer(buffer_handle_t *bufHandle);
     CameraFrame* requestBuffer();
 
 private:
-    int setNativeWindowAttribute(int width, int height, int format, int numBufs);
-    int allocateBuffer(int width, int height, int format, int numBufs, int maxQCount);
+    int          setNativeWindowAttribute(int width,
+                                          int height,
+                                          int format,
+                                          int numBufs);
+    int allocateBuffer(int width,
+                       int height,
+                       int format,
+                       int numBufs,
+                       int maxQCount);
 
 protected:
-    CameraErrorListener* mErrorListener;
-    preview_stream_ops_t* mNativeWindow;
+    CameraErrorListener  *mErrorListener;
+    preview_stream_ops_t *mNativeWindow;
 
     CameraFrame mCameraBuffer[MAX_PREVIEW_BUFFER];
 
@@ -60,4 +73,4 @@ protected:
     int mQueueableCount;
 };
 
-#endif
+#endif // ifndef _SURFACE_ADAPTER_H_
diff --git a/mx6/libcamera/UvcDevice.h b/mx6/libcamera/UvcDevice.h
old mode 100755
new mode 100644
index ed6c234..7f40063
--- a/mx6/libcamera/UvcDevice.h
+++ b/mx6/libcamera/UvcDevice.h
@@ -29,17 +29,38 @@
 #define FORMAT_STRING_LEN 64
 
 
-class UvcDevice : public DeviceAdapter
-{
+class UvcDevice : public DeviceAdapter {
 public:
-    virtual status_t initParameters(CameraParameters& params, int* supportRecordingFormat, int rfmtLen,
-                        int* supportPictureFormat, int pfmtLen) {return 0;}
-    virtual status_t setParameters(CameraParameters& params) {return 0;}
+    virtual status_t initParameters(CameraParameters& params,
+                                    int              *supportRecordingFormat,
+                                    int               rfmtLen,
+                                    int              *supportPictureFormat,
+                                    int               pfmtLen) {
+        return 0;
+    }
+
+    virtual status_t setParameters(CameraParameters& params) {
+        return 0;
+    }
 
 private:
-    PixelFormat getMatchFormat(int* sfmt, int slen, int* dfmt, int dlen) {return 0;}
-    status_t setSupportedPreviewFormats(int* sfmt, int slen, int* dfmt, int dlen) {return 0;}
-    status_t setPreviewStringFormat(PixelFormat format) {return 0;}
+    PixelFormat getMatchFormat(int *sfmt,
+                               int  slen,
+                               int *dfmt,
+                               int  dlen) {
+        return 0;
+    }
+
+    status_t setSupportedPreviewFormats(int *sfmt,
+                                        int  slen,
+                                        int *dfmt,
+                                        int  dlen) {
+        return 0;
+    }
+
+    status_t setPreviewStringFormat(PixelFormat format) {
+        return 0;
+    }
 
 private:
     char mSupportedFPS[MAX_SENSOR_FORMAT];
@@ -47,5 +68,5 @@ private:
     char mSupportedPreviewSizes[CAMER_PARAM_BUFFER_SIZE];
 };
 
-#endif
+#endif // ifndef _UVC_DEVICE_H
 
diff --git a/mx6/libcamera/YuvToJpegEncoder.cpp b/mx6/libcamera/YuvToJpegEncoder.cpp
old mode 100755
new mode 100644
index 876eb9d..b15e8d7
--- a/mx6/libcamera/YuvToJpegEncoder.cpp
+++ b/mx6/libcamera/YuvToJpegEncoder.cpp
@@ -20,7 +20,7 @@
 #include <hardware/hardware.h>
 #include "NV12_resize.h"
 
-YuvToJpegEncoder* YuvToJpegEncoder::create(int format) {
+YuvToJpegEncoder * YuvToJpegEncoder::create(int format) {
     // Only ImageFormat.NV21 and ImageFormat.YUY2 are supported
     // for now.
     if (format == HAL_PIXEL_FORMAT_YCbCr_420_SP) {
@@ -33,12 +33,13 @@ YuvToJpegEncoder* YuvToJpegEncoder::create(int format) {
     }
 }
 
-int YuvToJpegEncoder::getSupportedPictureFormat(int* pFormat, int len)
+int YuvToJpegEncoder::getSupportedPictureFormat(int *pFormat,
+                                                int  len)
 {
-    if(pFormat != NULL && len > 0) {
-        pFormat[0] = v4l2_fourcc('N','V','1','2');
-        if(len > 1) {
-            pFormat[1] = v4l2_fourcc('Y','U','Y','V');
+    if ((pFormat != NULL) && (len > 0)) {
+        pFormat[0] = v4l2_fourcc('N', 'V', '1', '2');
+        if (len > 1) {
+            pFormat[1] = v4l2_fourcc('Y', 'U', 'Y', 'V');
         }
 
         return NO_ERROR;
@@ -47,19 +48,29 @@ int YuvToJpegEncoder::getSupportedPictureFormat(int* pFormat, int len)
 }
 
 YuvToJpegEncoder::YuvToJpegEncoder()
-{
-}
-
-int YuvToJpegEncoder::encode(void* inYuv, int inWidth, int inHeight, int quality,
-                    void* outBuf, int outSize, int outWidth, int outHeight) {
-    jpeg_compress_struct    cinfo;
-    jpegBuilder_error_mgr        sk_err;
-    uint8_t* resize_src = NULL;
-    jpegBuilder_destination_mgr dest_mgr((uint8_t*)outBuf, outSize);
-
-    if(inWidth != outWidth || inHeight != outHeight) {
-        resize_src = (uint8_t*)malloc(outSize);
-        yuvResize((uint8_t*)inYuv, inWidth, inHeight, resize_src, outWidth, outHeight);
+{}
+
+int YuvToJpegEncoder::encode(void *inYuv,
+                             int   inWidth,
+                             int   inHeight,
+                             int   quality,
+                             void *outBuf,
+                             int   outSize,
+                             int   outWidth,
+                             int   outHeight) {
+    jpeg_compress_struct  cinfo;
+    jpegBuilder_error_mgr sk_err;
+    uint8_t *resize_src = NULL;
+    jpegBuilder_destination_mgr dest_mgr((uint8_t *)outBuf, outSize);
+
+    if ((inWidth != outWidth) || (inHeight != outHeight)) {
+        resize_src = (uint8_t *)malloc(outSize);
+        yuvResize((uint8_t *)inYuv,
+                  inWidth,
+                  inHeight,
+                  resize_src,
+                  outWidth,
+                  outHeight);
         inYuv = resize_src;
     }
 
@@ -72,56 +83,60 @@ int YuvToJpegEncoder::encode(void* inYuv, int inWidth, int inHeight, int quality
 
     jpeg_start_compress(&cinfo, TRUE);
 
-    compress(&cinfo, (uint8_t*) inYuv);
+    compress(&cinfo, (uint8_t *)inYuv);
 
     jpeg_finish_compress(&cinfo);
 
-    if(resize_src != NULL) {
+    if (resize_src != NULL) {
         free(resize_src);
     }
     return dest_mgr.jpegsize;
 }
 
-void YuvToJpegEncoder::setJpegCompressStruct(jpeg_compress_struct* cinfo,
-        int width, int height, int quality) {
-    cinfo->image_width = width;
-    cinfo->image_height = height;
+void YuvToJpegEncoder::setJpegCompressStruct(jpeg_compress_struct *cinfo,
+                                             int                   width,
+                                             int                   height,
+                                             int                   quality) {
+    cinfo->image_width      = width;
+    cinfo->image_height     = height;
     cinfo->input_components = 3;
-    cinfo->in_color_space = JCS_YCbCr;
+    cinfo->in_color_space   = JCS_YCbCr;
     jpeg_set_defaults(cinfo);
 
     jpeg_set_quality(cinfo, quality, TRUE);
     jpeg_set_colorspace(cinfo, JCS_YCbCr);
     cinfo->raw_data_in = TRUE;
-    cinfo->dct_method = JDCT_IFAST;
+    cinfo->dct_method  = JDCT_IFAST;
     configSamplingFactors(cinfo);
 }
 
-///////////////////////////////////////////////////////////////////
+// /////////////////////////////////////////////////////////////////
 Yuv420SpToJpegEncoder::Yuv420SpToJpegEncoder() :
-        YuvToJpegEncoder() {
+    YuvToJpegEncoder() {
     fNumPlanes = 2;
 }
 
-void Yuv420SpToJpegEncoder::compress(jpeg_compress_struct* cinfo,
-        uint8_t* yuv) {
-    JSAMPROW y[16];
-    JSAMPROW cb[8];
-    JSAMPROW cr[8];
+void Yuv420SpToJpegEncoder::compress(jpeg_compress_struct *cinfo,
+                                     uint8_t              *yuv) {
+    JSAMPROW   y[16];
+    JSAMPROW   cb[8];
+    JSAMPROW   cr[8];
     JSAMPARRAY planes[3];
+
     planes[0] = y;
     planes[1] = cb;
     planes[2] = cr;
 
-    int width = cinfo->image_width;
-    int height = cinfo->image_height;
-    uint8_t* yPlanar = yuv;
-    uint8_t* vuPlanar = yuv + width * height;
-    uint8_t* uRows = new uint8_t [8 * (width >> 1)];
-    uint8_t* vRows = new uint8_t [8 * (width >> 1)];
+    int width         = cinfo->image_width;
+    int height        = cinfo->image_height;
+    uint8_t *yPlanar  = yuv;
+    uint8_t *vuPlanar = yuv + width * height;
+    uint8_t *uRows    = new uint8_t[8 * (width >> 1)];
+    uint8_t *vRows    = new uint8_t[8 * (width >> 1)];
+
     // process 16 lines of Y and 8 lines of U/V each time.
     while (cinfo->next_scanline < cinfo->image_height) {
-        //deitnerleave u and v
+        // deitnerleave u and v
         deinterleave(vuPlanar, uRows, vRows, cinfo->next_scanline, width);
 
         for (int i = 0; i < 16; i++) {
@@ -132,33 +147,36 @@ void Yuv420SpToJpegEncoder::compress(jpeg_compress_struct* cinfo,
             if ((i & 1) == 0) {
                 // height and width are both halved because of downsampling
                 int offset = (i >> 1) * (width >> 1);
-                cb[i/2] = uRows + offset;
-                cr[i/2] = vRows + offset;
+                cb[i / 2] = uRows + offset;
+                cr[i / 2] = vRows + offset;
             }
-          }
+        }
         jpeg_write_raw_data(cinfo, planes, 16);
     }
-    delete [] uRows;
-    delete [] vRows;
-
+    delete[] uRows;
+    delete[] vRows;
 }
 
-void Yuv420SpToJpegEncoder::deinterleave(uint8_t* vuPlanar, uint8_t* uRows,
-        uint8_t* vRows, int rowIndex, int width) {
+void Yuv420SpToJpegEncoder::deinterleave(uint8_t *vuPlanar,
+                                         uint8_t *uRows,
+                                         uint8_t *vRows,
+                                         int      rowIndex,
+                                         int      width) {
     for (int row = 0; row < 8; ++row) {
-        int offset = ((rowIndex >> 1) + row) * width;
-        uint8_t* vu = vuPlanar + offset;
+        int offset  = ((rowIndex >> 1) + row) * width;
+        uint8_t *vu = vuPlanar + offset;
         for (int i = 0; i < (width >> 1); ++i) {
             int index = row * (width >> 1) + i;
             uRows[index] = vu[0];
             vRows[index] = vu[1];
-            vu += 2;
+            vu          += 2;
         }
     }
 }
 
-void Yuv420SpToJpegEncoder::configSamplingFactors(jpeg_compress_struct* cinfo) {
-    // cb and cr are horizontally downsampled and vertically downsampled as well.
+void Yuv420SpToJpegEncoder::configSamplingFactors(jpeg_compress_struct *cinfo) {
+    // cb and cr are horizontally downsampled and vertically downsampled as
+    // well.
     cinfo->comp_info[0].h_samp_factor = 2;
     cinfo->comp_info[0].v_samp_factor = 2;
     cinfo->comp_info[1].h_samp_factor = 1;
@@ -167,61 +185,74 @@ void Yuv420SpToJpegEncoder::configSamplingFactors(jpeg_compress_struct* cinfo) {
     cinfo->comp_info[2].v_samp_factor = 1;
 }
 
-int Yuv420SpToJpegEncoder::yuvResize(uint8_t* srcBuf, int srcWidth, int srcHeight,
-                uint8_t* dstBuf, int dstWidth, int dstHeight)
+int Yuv420SpToJpegEncoder::yuvResize(uint8_t *srcBuf,
+                                     int      srcWidth,
+                                     int      srcHeight,
+                                     uint8_t *dstBuf,
+                                     int      dstWidth,
+                                     int      dstHeight)
 {
-    if(!srcBuf || !dstBuf) {
+    if (!srcBuf || !dstBuf) {
         return -1;
     }
 
     structConvImage o_img_ptr, i_img_ptr;
-    //input
-    i_img_ptr.uWidth =  srcWidth;
+
+    // input
+    i_img_ptr.uWidth  =  srcWidth;
     i_img_ptr.uStride =  i_img_ptr.uWidth;
     i_img_ptr.uHeight =  srcHeight;
     i_img_ptr.eFormat = IC_FORMAT_YCbCr420_lp;
-    i_img_ptr.imgPtr = srcBuf;
-    i_img_ptr.clrPtr = i_img_ptr.imgPtr + (i_img_ptr.uWidth * i_img_ptr.uHeight);
+    i_img_ptr.imgPtr  = srcBuf;
+    i_img_ptr.clrPtr  = i_img_ptr.imgPtr + (i_img_ptr.uWidth * i_img_ptr.uHeight);
 
-    //ouput
-    o_img_ptr.uWidth = dstWidth;
+    // ouput
+    o_img_ptr.uWidth  = dstWidth;
     o_img_ptr.uStride = o_img_ptr.uWidth;
     o_img_ptr.uHeight = dstHeight;
     o_img_ptr.eFormat = IC_FORMAT_YCbCr420_lp;
-    o_img_ptr.imgPtr = dstBuf;
-    o_img_ptr.clrPtr = o_img_ptr.imgPtr + (o_img_ptr.uWidth * o_img_ptr.uHeight);
+    o_img_ptr.imgPtr  = dstBuf;
+    o_img_ptr.clrPtr  = o_img_ptr.imgPtr + (o_img_ptr.uWidth * o_img_ptr.uHeight);
 
     VT_resizeFrame_Video_opt2_lp(&i_img_ptr, &o_img_ptr, NULL, 0);
 
     return 0;
 }
-///////////////////////////////////////////////////////////////////////////////
+
+// /////////////////////////////////////////////////////////////////////////////
 Yuv422IToJpegEncoder::Yuv422IToJpegEncoder() :
-        YuvToJpegEncoder() {
+    YuvToJpegEncoder() {
     fNumPlanes = 1;
 }
 
-void Yuv422IToJpegEncoder::compress(jpeg_compress_struct* cinfo,
-        uint8_t* yuv) {
-    JSAMPROW y[16];
-    JSAMPROW cb[16];
-    JSAMPROW cr[16];
+void Yuv422IToJpegEncoder::compress(jpeg_compress_struct *cinfo,
+                                    uint8_t              *yuv) {
+    JSAMPROW   y[16];
+    JSAMPROW   cb[16];
+    JSAMPROW   cr[16];
     JSAMPARRAY planes[3];
+
     planes[0] = y;
     planes[1] = cb;
     planes[2] = cr;
 
-    int width = cinfo->image_width;
-    int height = cinfo->image_height;
-    uint8_t* yRows = new uint8_t [16 * width];
-    uint8_t* uRows = new uint8_t [16 * (width >> 1)];
-    uint8_t* vRows = new uint8_t [16 * (width >> 1)];
+    int width      = cinfo->image_width;
+    int height     = cinfo->image_height;
+    uint8_t *yRows = new uint8_t[16 * width];
+    uint8_t *uRows = new uint8_t[16 * (width >> 1)];
+    uint8_t *vRows = new uint8_t[16 * (width >> 1)];
 
-    uint8_t* yuvOffset = yuv;
+    uint8_t *yuvOffset = yuv;
 
     // process 16 lines of Y and 16 lines of U/V each time.
     while (cinfo->next_scanline < cinfo->image_height) {
-        deinterleave(yuvOffset, yRows, uRows, vRows, cinfo->next_scanline, width, height);
+        deinterleave(yuvOffset,
+                     yRows,
+                     uRows,
+                     vRows,
+                     cinfo->next_scanline,
+                     width,
+                     height);
 
         for (int i = 0; i < 16; i++) {
             // y row
@@ -236,30 +267,35 @@ void Yuv422IToJpegEncoder::compress(jpeg_compress_struct* cinfo,
 
         jpeg_write_raw_data(cinfo, planes, 16);
     }
-    delete [] yRows;
-    delete [] uRows;
-    delete [] vRows;
+    delete[] yRows;
+    delete[] uRows;
+    delete[] vRows;
 }
 
-
-void Yuv422IToJpegEncoder::deinterleave(uint8_t* yuv, uint8_t* yRows, uint8_t* uRows,
-        uint8_t* vRows, int rowIndex, int width, int height) {
+void Yuv422IToJpegEncoder::deinterleave(uint8_t *yuv,
+                                        uint8_t *yRows,
+                                        uint8_t *uRows,
+                                        uint8_t *vRows,
+                                        int      rowIndex,
+                                        int      width,
+                                        int      height) {
     for (int row = 0; row < 16; ++row) {
-        uint8_t* yuvSeg = yuv + (rowIndex + row) * width * 2;
+        uint8_t *yuvSeg = yuv + (rowIndex + row) * width * 2;
         for (int i = 0; i < (width >> 1); ++i) {
             int indexY = row * width + (i << 1);
             int indexU = row * (width >> 1) + i;
-            yRows[indexY] = yuvSeg[0];
+            yRows[indexY]     = yuvSeg[0];
             yRows[indexY + 1] = yuvSeg[2];
-            uRows[indexU] = yuvSeg[1];
-            vRows[indexU] = yuvSeg[3];
-            yuvSeg += 4;
+            uRows[indexU]     = yuvSeg[1];
+            vRows[indexU]     = yuvSeg[3];
+            yuvSeg           += 4;
         }
     }
 }
 
-void Yuv422IToJpegEncoder::configSamplingFactors(jpeg_compress_struct* cinfo) {
-    // cb and cr are horizontally downsampled and vertically downsampled as well.
+void Yuv422IToJpegEncoder::configSamplingFactors(jpeg_compress_struct *cinfo) {
+    // cb and cr are horizontally downsampled and vertically downsampled as
+    // well.
     cinfo->comp_info[0].h_samp_factor = 2;
     cinfo->comp_info[0].v_samp_factor = 2;
     cinfo->comp_info[1].h_samp_factor = 1;
@@ -268,13 +304,17 @@ void Yuv422IToJpegEncoder::configSamplingFactors(jpeg_compress_struct* cinfo) {
     cinfo->comp_info[2].v_samp_factor = 2;
 }
 
-int Yuv422IToJpegEncoder::yuvResize(uint8_t* srcBuf, int srcWidth, int srcHeight,
-                uint8_t* dstBuf, int dstWidth, int dstHeight)
+int Yuv422IToJpegEncoder::yuvResize(uint8_t *srcBuf,
+                                    int      srcWidth,
+                                    int      srcHeight,
+                                    uint8_t *dstBuf,
+                                    int      dstWidth,
+                                    int      dstHeight)
 {
-    int i,j,s;
+    int i, j, s;
     int h_offset;
     int v_offset;
-    unsigned char *ptr,cc;
+    unsigned char *ptr, cc;
     int h_scale_ratio;
     int v_scale_ratio;
 
@@ -282,41 +322,42 @@ int Yuv422IToJpegEncoder::yuvResize(uint8_t* srcBuf, int srcWidth, int srcHeight
 
 _resize_begin:
 
-    if(!dstWidth) return -1;
-    if(!dstHeight) return -1;
+    if (!dstWidth) return -1;
+
+    if (!dstHeight) return -1;
 
     h_scale_ratio = srcWidth / dstWidth;
-    if(!h_scale_ratio) return -1;
+    if (!h_scale_ratio) return -1;
 
     v_scale_ratio = srcHeight / dstHeight;
-    if(!v_scale_ratio) return -1;
+    if (!v_scale_ratio) return -1;
 
     h_offset = (srcWidth - dstWidth * h_scale_ratio) / 2;
     v_offset = (srcHeight - dstHeight * v_scale_ratio) / 2;
 
-    for(i = 0; i < dstHeight * v_scale_ratio; i += v_scale_ratio)
+    for (i = 0; i < dstHeight * v_scale_ratio; i += v_scale_ratio)
     {
-        for(j = 0; j < dstWidth * h_scale_ratio; j += h_scale_ratio)
+        for (j = 0; j < dstWidth * h_scale_ratio; j += h_scale_ratio)
         {
             ptr = srcBuf + i * srcWidth + j + v_offset * srcWidth + h_offset;
-            cc = ptr[0];
+            cc  = ptr[0];
 
-            ptr = dstBuf + (i / v_scale_ratio) * dstWidth + (j / h_scale_ratio);
+            ptr    = dstBuf + (i / v_scale_ratio) * dstWidth + (j / h_scale_ratio);
             ptr[0] = cc;
         }
     }
 
-    srcBuf += srcWidth*srcHeight;
-    dstBuf += dstWidth*dstHeight;
+    srcBuf += srcWidth * srcHeight;
+    dstBuf += dstWidth * dstHeight;
 
-    if(s < 2)
+    if (s < 2)
     {
-        if(!s++)
+        if (!s++)
         {
-            srcWidth >>= 1;
+            srcWidth  >>= 1;
             srcHeight >>= 1;
 
-            dstWidth >>= 1;
+            dstWidth  >>= 1;
             dstHeight >>= 1;
         }
 
@@ -326,12 +367,11 @@ _resize_begin:
     return 0;
 }
 
-
 void jpegBuilder_error_exit(j_common_ptr cinfo)
 {
-    jpegBuilder_error_mgr* error = (jpegBuilder_error_mgr*)cinfo->err;
+    jpegBuilder_error_mgr *error = (jpegBuilder_error_mgr *)cinfo->err;
 
-    (*error->output_message) (cinfo);
+    (*error->output_message)(cinfo);
 
     /* Let the memory manager delete any temp files before we die */
     jpeg_destroy(cinfo);
@@ -339,37 +379,40 @@ void jpegBuilder_error_exit(j_common_ptr cinfo)
     longjmp(error->fJmpBuf, -1);
 }
 
-
-static void jpegBuilder_init_destination (j_compress_ptr cinfo) {
-    jpegBuilder_destination_mgr* dest = (jpegBuilder_destination_mgr*)cinfo->dest;
+static void jpegBuilder_init_destination(j_compress_ptr cinfo) {
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
 
     dest->next_output_byte = dest->buf;
-    dest->free_in_buffer = dest->bufsize;
-    dest->jpegsize = 0;
+    dest->free_in_buffer   = dest->bufsize;
+    dest->jpegsize         = 0;
 }
 
 static boolean jpegBuilder_empty_output_buffer(j_compress_ptr cinfo) {
-    jpegBuilder_destination_mgr* dest = (jpegBuilder_destination_mgr*)cinfo->dest;
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
 
     dest->next_output_byte = dest->buf;
-    dest->free_in_buffer = dest->bufsize;
+    dest->free_in_buffer   = dest->bufsize;
     return TRUE; // ?
 }
 
-static void jpegBuilder_term_destination (j_compress_ptr cinfo) {
-    jpegBuilder_destination_mgr* dest = (jpegBuilder_destination_mgr*)cinfo->dest;
+static void jpegBuilder_term_destination(j_compress_ptr cinfo) {
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
+
     dest->jpegsize = dest->bufsize - dest->free_in_buffer;
 }
 
-jpegBuilder_destination_mgr::jpegBuilder_destination_mgr(uint8_t* input, int size) {
-    this->init_destination = jpegBuilder_init_destination;
+jpegBuilder_destination_mgr::jpegBuilder_destination_mgr(uint8_t *input,
+                                                         int      size) {
+    this->init_destination    = jpegBuilder_init_destination;
     this->empty_output_buffer = jpegBuilder_empty_output_buffer;
-    this->term_destination = jpegBuilder_term_destination;
+    this->term_destination    = jpegBuilder_term_destination;
 
-    this->buf = input;
+    this->buf     = input;
     this->bufsize = size;
 
     jpegsize = 0;
 }
 
-
diff --git a/mx6/libcamera/YuvToJpegEncoder.h b/mx6/libcamera/YuvToJpegEncoder.h
old mode 100755
new mode 100644
index 863ef28..bc61c1a
--- a/mx6/libcamera/YuvToJpegEncoder.h
+++ b/mx6/libcamera/YuvToJpegEncoder.h
@@ -45,39 +45,66 @@ public:
 
     YuvToJpegEncoder();
 
-    static int getSupportedPictureFormat(int* pFormat, int len);
+    static int getSupportedPictureFormat(int *pFormat,
+                                         int  len);
+
     /** Encode YUV data to jpeg,  which is output to a stream.
      */
-    int encode(void* inYuv, int inWidth, int inHeight, int quality,
-                    void* outBuf, int outSize, int outWidth, int outHeight);
+    int encode(void *inYuv,
+               int   inWidth,
+               int   inHeight,
+               int   quality,
+               void *outBuf,
+               int   outSize,
+               int   outWidth,
+               int   outHeight);
 
     virtual ~YuvToJpegEncoder() {}
 
 protected:
     int fNumPlanes;
 
-    void setJpegCompressStruct(jpeg_compress_struct* cinfo, int width,
-            int height, int quality);
-    virtual void configSamplingFactors(jpeg_compress_struct* cinfo) = 0;
-    virtual void compress(jpeg_compress_struct* cinfo, uint8_t* yuv) = 0;
-    virtual int yuvResize(uint8_t* srcBuf, int srcWidth, int srcHeight,
-                uint8_t* dstBuf, int dstWidth, int dstHeight) = 0;
+    void setJpegCompressStruct(jpeg_compress_struct *cinfo,
+                               int                   width,
+                               int                   height,
+                               int                   quality);
+    virtual void configSamplingFactors(jpeg_compress_struct *cinfo) = 0;
+    virtual void compress(jpeg_compress_struct *cinfo,
+                          uint8_t              *yuv)                = 0;
+    virtual int  yuvResize(uint8_t *srcBuf,
+                           int      srcWidth,
+                           int      srcHeight,
+                           uint8_t *dstBuf,
+                           int      dstWidth,
+                           int      dstHeight) = 0;
 };
 
 class Yuv420SpToJpegEncoder : public YuvToJpegEncoder {
 public:
-     Yuv420SpToJpegEncoder();
-     virtual ~Yuv420SpToJpegEncoder() {}
+    Yuv420SpToJpegEncoder();
+    virtual ~Yuv420SpToJpegEncoder() {}
 
 private:
-     void configSamplingFactors(jpeg_compress_struct* cinfo);
-     void deinterleaveYuv(uint8_t* yuv, int width, int height,
-            uint8_t*& yPlanar, uint8_t*& uPlanar, uint8_t*& vPlanar);
-     void deinterleave(uint8_t* vuPlanar, uint8_t* uRows, uint8_t* vRows,
-             int rowIndex, int width);
-     void compress(jpeg_compress_struct* cinfo, uint8_t* yuv);
-     virtual int yuvResize(uint8_t* srcBuf, int srcWidth, int srcHeight,
-                uint8_t* dstBuf, int dstWidth, int dstHeight);
+    void configSamplingFactors(jpeg_compress_struct *cinfo);
+    void deinterleaveYuv(uint8_t   *yuv,
+                         int        width,
+                         int        height,
+                         uint8_t *& yPlanar,
+                         uint8_t *& uPlanar,
+                         uint8_t *& vPlanar);
+    void deinterleave(uint8_t *vuPlanar,
+                      uint8_t *uRows,
+                      uint8_t *vRows,
+                      int      rowIndex,
+                      int      width);
+    void        compress(jpeg_compress_struct *cinfo,
+                         uint8_t              *yuv);
+    virtual int yuvResize(uint8_t *srcBuf,
+                          int      srcWidth,
+                          int      srcHeight,
+                          uint8_t *dstBuf,
+                          int      dstWidth,
+                          int      dstHeight);
 };
 
 class Yuv422IToJpegEncoder : public YuvToJpegEncoder {
@@ -86,20 +113,31 @@ public:
     virtual ~Yuv422IToJpegEncoder() {}
 
 private:
-    void configSamplingFactors(jpeg_compress_struct* cinfo);
-    void compress(jpeg_compress_struct* cinfo, uint8_t* yuv);
-    void deinterleave(uint8_t* yuv, uint8_t* yRows, uint8_t* uRows,
-            uint8_t* vRows, int rowIndex, int width, int height);
-    virtual int yuvResize(uint8_t* srcBuf, int srcWidth, int srcHeight,
-                uint8_t* dstBuf, int dstWidth, int dstHeight);
+    void configSamplingFactors(jpeg_compress_struct *cinfo);
+    void compress(jpeg_compress_struct *cinfo,
+                  uint8_t              *yuv);
+    void deinterleave(uint8_t *yuv,
+                      uint8_t *yRows,
+                      uint8_t *uRows,
+                      uint8_t *vRows,
+                      int      rowIndex,
+                      int      width,
+                      int      height);
+    virtual int yuvResize(uint8_t *srcBuf,
+                          int      srcWidth,
+                          int      srcHeight,
+                          uint8_t *dstBuf,
+                          int      dstWidth,
+                          int      dstHeight);
 };
 
 struct jpegBuilder_destination_mgr : jpeg_destination_mgr {
-    jpegBuilder_destination_mgr(uint8_t* input, int size);
+    jpegBuilder_destination_mgr(uint8_t *input,
+                                int size);
 
-    uint8_t* buf;
-    int bufsize;
-    size_t jpegsize;
+    uint8_t *buf;
+    int      bufsize;
+    size_t   jpegsize;
 };
 
 
@@ -109,4 +147,4 @@ struct jpegBuilder_error_mgr : jpeg_error_mgr {
 
 void jpegBuilder_error_exit(j_common_ptr cinfo);
 
-#endif
+#endif // ifndef YuvToJpegEncoder_DEFINED
diff --git a/mx6/libcamera/messageQueue.cpp b/mx6/libcamera/messageQueue.cpp
old mode 100755
new mode 100644
index 1dffe07..c5cf781
--- a/mx6/libcamera/messageQueue.cpp
+++ b/mx6/libcamera/messageQueue.cpp
@@ -28,11 +28,10 @@
 #include "messageQueue.h"
 
 namespace android {
-
 void CMessageList::insert(const sp<CMessage>& node)
 {
     mList.push_back(node);
-};
+}
 
 void CMessageList::remove(CMessageList::LIST::iterator pos)
 {
@@ -47,90 +46,100 @@ void CMessageList::clear()
 CMessageQueue::CMessageQueue()
 {
     Mutex::Autolock _l(mLock);
+
     mMessages.clear();
 }
 
 CMessageQueue::~CMessageQueue()
 {
     Mutex::Autolock _l(mLock);
+
     mMessages.clear();
 }
 
-sp<CMessage> CMessageQueue::waitMessage(nsecs_t timeout)
+sp<CMessage>CMessageQueue::waitMessage(nsecs_t timeout)
 {
-    sp<CMessage> result;
+    sp<CMessage>    result;
     sp<SyncMessage> syncResult;
     nsecs_t timeoutTime = systemTime() + timeout;
-    while(true) {
+    while (true) {
         Mutex::Autolock _l(mLock);
         nsecs_t now = systemTime();
-        //handle sync message firstly.
+
+        // handle sync message firstly.
         LIST::iterator scur(mSyncMessages.begin());
-        if(scur != mSyncMessages.end()) {
-            syncResult = (SyncMessage*)(*scur).get();
+        if (scur != mSyncMessages.end()) {
+            syncResult = (SyncMessage *)(*scur).get();
         }
 
-        if(syncResult != 0) {
-            result = (CMessage*)syncResult.get();
+        if (syncResult != 0) {
+            result = (CMessage *)syncResult.get();
             mSyncMessages.remove(scur);
             break;
         }
 
-        //handle sync message secondly.
+        // handle sync message secondly.
         LIST::iterator cur(mMessages.begin());
-        if(cur != mMessages.end()) {
+        if (cur != mMessages.end()) {
             result = *cur;
         }
 
-        if(result != 0) {
+        if (result != 0) {
             mMessages.remove(cur);
             break;
         }
 
-        if(timeout >= 0) {
-            if(timeoutTime < now) {
+        if (timeout >= 0) {
+            if (timeoutTime < now) {
                 result = 0;
                 break;
             }
             nsecs_t relTime = timeoutTime - systemTime();
             mCondition.waitRelative(mLock, relTime);
-        }else {
+        } else {
             mCondition.wait(mLock);
         }
     }
 
-    if(syncResult != NULL) {
+    if (syncResult != NULL) {
         syncResult->notify();
     }
 
     return result;
 }
 
-status_t CMessageQueue::postMessage(const sp<CMessage>& message, int32_t flags)
+status_t CMessageQueue::postMessage(const sp<CMessage>& message,
+                                    int32_t             flags)
 {
     return queueMessage(message, flags);
 }
 
-status_t CMessageQueue::postSyncMessage(const sp<SyncMessage>& message, int32_t flags)
+status_t CMessageQueue::postSyncMessage(const sp<SyncMessage>& message,
+                                        int32_t                flags)
 {
     status_t res = queueSyncMessage(message, flags);
+
     if (res == NO_ERROR) {
         message->wait();
     }
     return res;
 }
 
-status_t CMessageQueue::queueMessage(const sp<CMessage>& message, int32_t flags)
+status_t CMessageQueue::queueMessage(const sp<CMessage>& message,
+                                     int32_t             flags)
 {
     Mutex::Autolock _l(mLock);
+
     mMessages.insert(message);
     mCondition.signal();
     return NO_ERROR;
 }
 
-status_t CMessageQueue::queueSyncMessage(const sp<SyncMessage>& message, int32_t flags)
+status_t CMessageQueue::queueSyncMessage(const sp<SyncMessage>& message,
+                                         int32_t                flags)
 {
     Mutex::Autolock _l(mLock);
+
     mSyncMessages.insert(message.get());
     mCondition.signal();
     return NO_ERROR;
diff --git a/mx6/libcamera/messageQueue.h b/mx6/libcamera/messageQueue.h
old mode 100755
new mode 100644
index 154ff47..9d1c836
--- a/mx6/libcamera/messageQueue.h
+++ b/mx6/libcamera/messageQueue.h
@@ -28,31 +28,45 @@
 #include <semaphore.h>
 
 namespace android {
-
 class CMessage;
 
-class CMessageList
-{
+class CMessageList {
     List< sp<CMessage> > mList;
     typedef List< sp<CMessage> > LIST;
+
 public:
-    inline LIST::iterator begin() {return mList.begin();}
-    inline LIST::const_iterator begin() const {return mList.begin();}
-    inline LIST::iterator end() {return mList.end();}
-    inline LIST::const_iterator end() const {return mList.end();}
-    inline bool isEmpty() const {return mList.empty();}
-    void insert(const sp<CMessage> &node);
+    inline LIST::iterator begin() {
+        return mList.begin();
+    }
+
+    inline LIST::const_iterator begin() const {
+        return mList.begin();
+    }
+
+    inline LIST::iterator end() {
+        return mList.end();
+    }
+
+    inline LIST::const_iterator end() const {
+        return mList.end();
+    }
+
+    inline bool isEmpty() const {
+        return mList.empty();
+    }
+
+    void insert(const sp<CMessage>& node);
     void remove(LIST::iterator pos);
     void clear();
 };
 
-class CMessage : public LightRefBase<CMessage>
-{
+class CMessage : public LightRefBase<CMessage>{
 public:
     int32_t what;
     int32_t arg0;
 
-    CMessage(int32_t what, int32_t arg0=0)
+    CMessage(int32_t what,
+             int32_t arg0 = 0)
         : what(what), arg0(arg0) {}
 
     virtual ~CMessage() {}
@@ -61,10 +75,10 @@ private:
     friend class LightRefBase<CMessage>;
 };
 
-class SyncMessage : public CMessage
-{
+class SyncMessage : public CMessage {
 public:
-    SyncMessage(int32_t what, int32_t arg0=0)
+    SyncMessage(int32_t what,
+                int32_t arg0 = 0)
         : CMessage(what, arg0)
     {
         sem_init(&mSem, 0, 0);
@@ -89,28 +103,30 @@ private:
     sem_t mSem;
 };
 
-class CMessageQueue
-{
+class CMessageQueue {
     typedef List< sp<CMessage> > LIST;
+
 public:
     CMessageQueue();
     ~CMessageQueue();
 
-    sp<CMessage> waitMessage(nsecs_t timeout=-1);
-    status_t postMessage(const sp<CMessage>& message, int32_t flags=0);
-    status_t postSyncMessage(const sp<SyncMessage>& message, int32_t flags=0);
+    sp<CMessage> waitMessage(nsecs_t timeout = -1);
+    status_t     postMessage(const sp<CMessage>& message,
+                             int32_t             flags = 0);
+    status_t     postSyncMessage(const sp<SyncMessage>& message,
+                                 int32_t                flags = 0);
 
 private:
-    status_t queueMessage(const sp<CMessage>& message, int32_t flags);
-    status_t queueSyncMessage(const sp<SyncMessage>& message, int32_t flags);
+    status_t queueMessage(const sp<CMessage>& message,
+                          int32_t             flags);
+    status_t queueSyncMessage(const sp<SyncMessage>& message,
+                              int32_t                flags);
 
     Mutex mLock;
     Condition mCondition;
     CMessageList mMessages;
     CMessageList mSyncMessages;
 };
-
-
 };
 
-#endif
+#endif // ifndef CAMERA_HAL_MESSAGE_QUEUE_H
-- 
1.8.0

