From be65ab7185362866bcea2119182fab06c2b0dd48 Mon Sep 17 00:00:00 2001
From: Xiaowen Liu <b37945@freescale.com>
Date: Tue, 8 Jan 2013 13:37:35 +0800
Subject: [PATCH 400/635] ENGR00215174 add camera hal v2 implementation for
 android 4.2.

add camera hal v2 implementation for android 4.2.

Signed-off-by: Xiaowen Liu <b37945@freescale.com>
---
 mx6/libcamera2/Android.mk           |  93 ++++
 mx6/libcamera2/CameraHal.cpp        | 191 ++++++++
 mx6/libcamera2/CameraHal.h          |  87 ++++
 mx6/libcamera2/CameraModule.cpp     | 563 ++++++++++++++++++++++
 mx6/libcamera2/CameraUtil.cpp       | 365 +++++++++++++++
 mx6/libcamera2/CameraUtil.h         | 326 +++++++++++++
 mx6/libcamera2/CaptureStream.cpp    | 315 +++++++++++++
 mx6/libcamera2/DeviceAdapter.cpp    | 645 ++++++++++++++++++++++++++
 mx6/libcamera2/DeviceAdapter.h      | 165 +++++++
 mx6/libcamera2/JpegBuilder.cpp      | 667 ++++++++++++++++++++++++++
 mx6/libcamera2/JpegBuilder.h        | 190 ++++++++
 mx6/libcamera2/MetadaManager.cpp    | 901 ++++++++++++++++++++++++++++++++++++
 mx6/libcamera2/MetadaManager.h      |  76 +++
 mx6/libcamera2/NV12_resize.c        | 303 ++++++++++++
 mx6/libcamera2/NV12_resize.h        | 148 ++++++
 mx6/libcamera2/Ov5640.cpp           | 136 ++++++
 mx6/libcamera2/Ov5640.h             |  27 ++
 mx6/libcamera2/Ov5642.cpp           | 135 ++++++
 mx6/libcamera2/Ov5642.h             |  27 ++
 mx6/libcamera2/OvDevice.cpp         | 252 ++++++++++
 mx6/libcamera2/OvDevice.h           |  41 ++
 mx6/libcamera2/PhysMemAdapter.cpp   | 145 ++++++
 mx6/libcamera2/PhysMemAdapter.h     |  54 +++
 mx6/libcamera2/PreviewStream.cpp    | 240 ++++++++++
 mx6/libcamera2/RequestManager.cpp   | 427 +++++++++++++++++
 mx6/libcamera2/RequestManager.h     | 107 +++++
 mx6/libcamera2/StreamAdapter.cpp    | 299 ++++++++++++
 mx6/libcamera2/StreamAdapter.h      | 175 +++++++
 mx6/libcamera2/UvcDevice.h          |  39 ++
 mx6/libcamera2/YuvToJpegEncoder.cpp | 404 ++++++++++++++++
 mx6/libcamera2/YuvToJpegEncoder.h   | 147 ++++++
 mx6/libcamera2/messageQueue.cpp     | 147 ++++++
 mx6/libcamera2/messageQueue.h       | 131 ++++++
 33 files changed, 7968 insertions(+)
 create mode 100755 mx6/libcamera2/Android.mk
 create mode 100755 mx6/libcamera2/CameraHal.cpp
 create mode 100755 mx6/libcamera2/CameraHal.h
 create mode 100755 mx6/libcamera2/CameraModule.cpp
 create mode 100755 mx6/libcamera2/CameraUtil.cpp
 create mode 100755 mx6/libcamera2/CameraUtil.h
 create mode 100755 mx6/libcamera2/CaptureStream.cpp
 create mode 100755 mx6/libcamera2/DeviceAdapter.cpp
 create mode 100755 mx6/libcamera2/DeviceAdapter.h
 create mode 100755 mx6/libcamera2/JpegBuilder.cpp
 create mode 100755 mx6/libcamera2/JpegBuilder.h
 create mode 100755 mx6/libcamera2/MetadaManager.cpp
 create mode 100755 mx6/libcamera2/MetadaManager.h
 create mode 100755 mx6/libcamera2/NV12_resize.c
 create mode 100755 mx6/libcamera2/NV12_resize.h
 create mode 100755 mx6/libcamera2/Ov5640.cpp
 create mode 100755 mx6/libcamera2/Ov5640.h
 create mode 100755 mx6/libcamera2/Ov5642.cpp
 create mode 100755 mx6/libcamera2/Ov5642.h
 create mode 100755 mx6/libcamera2/OvDevice.cpp
 create mode 100755 mx6/libcamera2/OvDevice.h
 create mode 100755 mx6/libcamera2/PhysMemAdapter.cpp
 create mode 100755 mx6/libcamera2/PhysMemAdapter.h
 create mode 100755 mx6/libcamera2/PreviewStream.cpp
 create mode 100755 mx6/libcamera2/RequestManager.cpp
 create mode 100755 mx6/libcamera2/RequestManager.h
 create mode 100755 mx6/libcamera2/StreamAdapter.cpp
 create mode 100755 mx6/libcamera2/StreamAdapter.h
 create mode 100755 mx6/libcamera2/UvcDevice.h
 create mode 100755 mx6/libcamera2/YuvToJpegEncoder.cpp
 create mode 100755 mx6/libcamera2/YuvToJpegEncoder.h
 create mode 100755 mx6/libcamera2/messageQueue.cpp
 create mode 100755 mx6/libcamera2/messageQueue.h

diff --git a/mx6/libcamera2/Android.mk b/mx6/libcamera2/Android.mk
new file mode 100755
index 0000000..05a6813
--- /dev/null
+++ b/mx6/libcamera2/Android.mk
@@ -0,0 +1,93 @@
+# Copyright (C) 2008 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+ifeq ($(BOARD_SOC_CLASS),IMX6)
+LOCAL_PATH:= $(call my-dir)
+
+ifeq ($(BOARD_HAVE_IMX_CAMERA),true)
+
+include $(CLEAR_VARS)
+
+LOCAL_SRC_FILES:=    \
+    CameraHal.cpp    \
+    CameraModule.cpp \
+    CameraUtil.cpp \
+    DeviceAdapter.cpp \
+    RequestManager.cpp \
+    StreamAdapter.cpp \
+    PreviewStream.cpp \
+    CaptureStream.cpp \
+    JpegBuilder.cpp \
+    MetadaManager.cpp \
+    messageQueue.cpp \
+    OvDevice.cpp \
+    Ov5640.cpp \
+    Ov5642.cpp \
+    PhysMemAdapter.cpp \
+    YuvToJpegEncoder.cpp \
+    NV12_resize.c
+
+LOCAL_CPPFLAGS +=
+
+LOCAL_SHARED_LIBRARIES:= \
+    libcamera_client \
+    libui \
+    libutils \
+    libcutils \
+    libbinder \
+    libmedia \
+    libhardware_legacy \
+    libdl \
+    libc \
+    libjpeg \
+    libexif \
+    libion \
+    libcamera_metadata
+
+LOCAL_C_INCLUDES += \
+	frameworks/base/include/binder \
+	frameworks/base/include/ui \
+	frameworks/base/camera/libcameraservice \
+	hardware/imx/mx6/libgralloc_wrapper \
+	system/media/camera/include \
+	external/jpeg \
+	external/jhead
+
+ifeq ($(HAVE_FSL_IMX_CODEC),true)
+    #LOCAL_SHARED_LIBRARIES += libfsl_jpeg_enc_arm11_elinux
+    #LOCAL_CPPFLAGS += -DUSE_FSL_JPEG_ENC
+    #LOCAL_C_INCLUDES += device/fsl-proprietary/codec/ghdr
+endif
+ifeq ($(BOARD_CAMERA_NV12),true)
+    LOCAL_CPPFLAGS += -DRECORDING_FORMAT_NV12
+else
+    LOCAL_CPPFLAGS += -DRECORDING_FORMAT_YUV420
+endif
+
+#Define this for switch the Camera through V4L2 MXC IOCTL
+#LOCAL_CPPFLAGS += -DV4L2_CAMERA_SWITCH
+
+#LOCAL_CPPFLAGS += -Werror
+
+LOCAL_MODULE_PATH := $(TARGET_OUT_SHARED_LIBRARIES)/hw
+LOCAL_MODULE:= camera.$(TARGET_BOARD_PLATFORM)
+
+LOCAL_CFLAGS += -fno-short-enums
+LOCAL_PRELINK_MODULE := false
+LOCAL_MODULE_TAGS := eng
+
+include $(BUILD_SHARED_LIBRARY)
+endif
+
+endif
diff --git a/mx6/libcamera2/CameraHal.cpp b/mx6/libcamera2/CameraHal.cpp
new file mode 100755
index 0000000..a3c6142
--- /dev/null
+++ b/mx6/libcamera2/CameraHal.cpp
@@ -0,0 +1,191 @@
+/*
+ * Copyright (C) 2009-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "CameraHal.h"
+#include "PhysMemAdapter.h"
+
+using namespace android;
+
+CameraHal::CameraHal(int cameraId)
+    : mPowerLock(false), mCameraId(cameraId)
+{
+
+}
+
+CameraHal::~CameraHal()
+{
+    release();
+    mRequestManager.clear();
+}
+
+void CameraHal::handleError(int err)
+{
+    switch (err) {
+        case CAMERA2_MSG_ERROR_HARDWARE:
+            abort();
+            break;
+
+        case CAMERA2_MSG_ERROR_DEVICE:
+            abort();
+            break;
+
+        case CAMERA2_MSG_ERROR_REQUEST:
+            mNotifyCb(CAMERA_MSG_ERROR, 0, 0, 0, mNotifyUserPtr);
+            break;
+
+        case CAMERA2_MSG_ERROR_FRAME:
+            break;
+
+        case CAMERA2_MSG_ERROR_STREAM:
+            break;
+
+        default:
+            break;
+    }
+}
+
+int CameraHal::notify_request_queue_not_empty()
+{
+    FLOGI("%s running", __FUNCTION__);
+    return mRequestManager->dispatchRequest();
+}
+
+int CameraHal::set_request_queue_src_ops(
+    const camera2_request_queue_src_ops_t *request_src_ops)
+{
+    mRequestQueue = request_src_ops;
+    return mRequestManager->setRequestOperation(request_src_ops);
+}
+
+int CameraHal::set_frame_queue_dst_ops(
+                    const camera2_frame_queue_dst_ops_t *frame_dst_ops)
+{
+    mFrameQueue = frame_dst_ops;
+    return 0;
+}
+
+int CameraHal::get_in_progress_count()
+{
+    return mRequestManager->getInProcessCount();
+}
+
+int CameraHal::construct_default_request(
+            int request_template, camera_metadata_t **request)
+{
+    return mRequestManager->CreateDefaultRequest(request_template, request);
+}
+
+int CameraHal::allocate_stream(uint32_t width,
+        uint32_t height, int format,
+        const camera2_stream_ops_t *stream_ops,
+        uint32_t *stream_id,
+        uint32_t *format_actual,
+        uint32_t *usage,
+        uint32_t *max_buffers)
+{
+    return mRequestManager->allocateStream(width, height, format,
+                stream_ops, stream_id, format_actual, usage, max_buffers);
+}
+
+int CameraHal::register_stream_buffers(
+    uint32_t stream_id, int num_buffers,
+    buffer_handle_t *buffers)
+{
+    return mRequestManager->registerStreamBuffers(stream_id, num_buffers, buffers);
+}
+
+int CameraHal::release_stream(uint32_t stream_id)
+{
+    return mRequestManager->releaseStream(stream_id);
+}
+
+int CameraHal::allocate_reprocess_stream(
+    uint32_t width,
+    uint32_t height,
+    uint32_t format,
+    const camera2_stream_in_ops_t *reprocess_stream_ops,
+    uint32_t *stream_id,
+    uint32_t *consumer_usage,
+    uint32_t *max_buffers)
+{
+    return INVALID_OPERATION;
+}
+
+int CameraHal::release_reprocess_stream(uint32_t stream_id)
+{
+    return INVALID_OPERATION;
+}
+
+int CameraHal::get_metadata_vendor_tag_ops(vendor_tag_query_ops_t **ops)
+{
+    *ops = NULL;
+    return NO_ERROR;
+}
+
+int CameraHal::set_notify_callback(camera2_notify_callback notify_cb,
+            void *user)
+{
+    mNotifyCb = notify_cb;
+    mNotifyUserPtr = user;
+    return NO_ERROR;
+}
+
+status_t CameraHal::initialize(CameraInfo& info)
+{
+    status_t ret = NO_ERROR;
+
+    FLOG_RUNTIME("initialize name:%s, path:%s", info.name, info.devPath);
+    mRequestManager = new RequestManager(mCameraId);
+    if (mRequestManager == NULL) {
+        FLOGE("CameraHal: DeviceAdapter create failed");
+        return BAD_VALUE;
+    }
+
+    ret = mRequestManager->initialize(info);
+    if (ret) {
+        FLOGE("CameraHal: DeviceAdapter initialize failed");
+        return ret;
+    }
+
+    return ret;
+}
+
+void CameraHal::release()
+{
+    mRequestManager->release();
+}
+
+void CameraHal::LockWakeLock()
+{
+    if (!mPowerLock) {
+        acquire_wake_lock(PARTIAL_WAKE_LOCK, V4LSTREAM_WAKE_LOCK);
+        mPowerLock = true;
+    }
+}
+
+void CameraHal::UnLockWakeLock()
+{
+    if (mPowerLock) {
+        release_wake_lock(V4LSTREAM_WAKE_LOCK);
+        mPowerLock = false;
+    }
+}
+
+status_t CameraHal::dump(int fd) const
+{
+    return NO_ERROR;
+}
+
diff --git a/mx6/libcamera2/CameraHal.h b/mx6/libcamera2/CameraHal.h
new file mode 100755
index 0000000..226a55c
--- /dev/null
+++ b/mx6/libcamera2/CameraHal.h
@@ -0,0 +1,87 @@
+/*
+ * Copyright (C) 2009-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _CAMERA_HAL_H
+#define _CAMERA_HAL_H
+
+#include "CameraUtil.h"
+#include "DeviceAdapter.h"
+#include "RequestManager.h"
+#include <hardware/camera2.h>
+
+using namespace android;
+
+class PhysMemAdapter;
+
+class CameraHal : public CameraErrorListener
+{
+public:
+    CameraHal(int cameraId);
+    ~CameraHal();
+    status_t initialize(CameraInfo& info);
+    void handleError(int err);
+
+    //camera2 interface.
+    int set_request_queue_src_ops(
+        const camera2_request_queue_src_ops_t *request_src_ops);
+    int notify_request_queue_not_empty();
+    int set_frame_queue_dst_ops(const camera2_frame_queue_dst_ops_t *frame_dst_ops);
+    int get_in_progress_count();
+    int construct_default_request(int request_template, camera_metadata_t **request);
+    int allocate_stream(uint32_t width,
+        uint32_t height, int format,
+        const camera2_stream_ops_t *stream_ops,
+        uint32_t *stream_id,
+        uint32_t *format_actual,
+        uint32_t *usage,
+        uint32_t *max_buffers);
+    int register_stream_buffers(uint32_t stream_id, int num_buffers,
+        buffer_handle_t *buffers);
+    int release_stream(uint32_t stream_id);
+    int allocate_reprocess_stream(
+        uint32_t width,
+        uint32_t height,
+        uint32_t format,
+        const camera2_stream_in_ops_t *reprocess_stream_ops,
+        uint32_t *stream_id,
+        uint32_t *consumer_usage,
+        uint32_t *max_buffers);
+    int release_reprocess_stream(
+        uint32_t stream_id);
+    int get_metadata_vendor_tag_ops(vendor_tag_query_ops_t **ops);
+    int set_notify_callback(camera2_notify_callback notify_cb,
+            void *user);
+
+    void     release();
+    status_t dump(int fd) const;
+
+    void     LockWakeLock();
+    void     UnLockWakeLock();
+
+private:
+    bool mPowerLock;
+    int  mCameraId;
+    mutable Mutex mLock;
+
+private:
+    sp<RequestManager> mRequestManager;
+    const camera2_request_queue_src_ops *mRequestQueue;
+    const camera2_frame_queue_dst_ops *mFrameQueue;
+    camera2_notify_callback mNotifyCb;
+    void *mNotifyUserPtr;
+};
+
+#endif // ifndef _CAMERA_HAL_H
diff --git a/mx6/libcamera2/CameraModule.cpp b/mx6/libcamera2/CameraModule.cpp
new file mode 100755
index 0000000..fa6d162
--- /dev/null
+++ b/mx6/libcamera2/CameraModule.cpp
@@ -0,0 +1,563 @@
+/*
+ * Copyright (C) Freescale - http://www.Freescale.com/
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "CameraHAL"
+#include <linux/videodev2.h>
+#include <linux/mxcfb.h>
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include <dirent.h>
+#include <utils/threads.h>
+#include <cutils/properties.h>
+#include "CameraHal.h"
+#include "CameraUtil.h"
+
+#define MAX_CAMERAS_SUPPORTED 2
+
+static android::Mutex gCameraHalDeviceLock;
+
+static int camera_device_open(const hw_module_t *module,
+                              const char        *name,
+                              hw_device_t      **device);
+static int camera_device_close(hw_device_t *device);
+static int camera_get_number_of_cameras(void);
+static int camera_get_camera_info(int camera_id,
+                                  struct camera_info *info);
+
+static struct hw_module_methods_t camera_module_methods = {
+    open: camera_device_open
+};
+
+camera_module_t HAL_MODULE_INFO_SYM = {
+    common: {
+        tag: HARDWARE_MODULE_TAG,
+        module_api_version: CAMERA_MODULE_API_VERSION_2_0,
+        hal_api_version: HARDWARE_HAL_API_VERSION,
+        id: CAMERA_HARDWARE_MODULE_ID,
+        name: "Freescale CameraHal Module",
+        author: "Freescale",
+        methods: &camera_module_methods,
+        dso: NULL,       /* remove compilation warnings */
+        reserved: { 0 }, /* remove compilation warnings */
+    },
+    get_number_of_cameras: camera_get_number_of_cameras,
+    get_camera_info: camera_get_camera_info,
+};
+
+typedef struct fsl_camera_device {
+    camera2_device_t base;
+    CameraHal *camHal;
+    int cameraid;
+} fsl_camera_device_t;
+
+CameraHal *fsl_get_camerahal(const camera2_device_t *device)
+{
+    CameraHal *camHal = NULL;
+    if (device && device->priv) {
+        fsl_camera_device_t *fslDev = (fsl_camera_device_t *)device->priv;
+        camHal = fslDev->camHal;
+    }
+
+    return camHal;
+}
+
+/*******************************************************************
+* implementation of camera2_device_ops functions
+*******************************************************************/
+int set_request_queue_src_ops(const struct camera2_device *device,
+        const camera2_request_queue_src_ops_t *request_src_ops)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->set_request_queue_src_ops(request_src_ops);
+    }
+    return ret;
+}
+
+int notify_request_queue_not_empty(const struct camera2_device *device)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->notify_request_queue_not_empty();
+    }
+    return ret;
+}
+
+int set_frame_queue_dst_ops(const struct camera2_device *device,
+        const camera2_frame_queue_dst_ops_t *frame_dst_ops)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->set_frame_queue_dst_ops(frame_dst_ops);
+    }
+    return ret;
+}
+
+int get_in_progress_count(const struct camera2_device *device)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->get_in_progress_count();
+    }
+    return ret;
+}
+
+int flush_captures_in_progress(const struct camera2_device *)
+{
+    FLOGE("%s:does not support now",__FUNCTION__);
+    return INVALID_OPERATION;
+}
+
+int construct_default_request(const struct camera2_device *device,
+    int request_template,
+    camera_metadata_t **request)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->construct_default_request(request_template, request);
+    }
+    return ret;
+}
+
+int allocate_stream(const struct camera2_device *device,
+        uint32_t width,
+        uint32_t height,
+        int      format,
+        const camera2_stream_ops_t *stream_ops,
+        uint32_t *stream_id,
+        uint32_t *format_actual,
+        uint32_t *usage,
+        uint32_t *max_buffers)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->allocate_stream(width, height, format, stream_ops,
+            stream_id, format_actual, usage, max_buffers);
+    }
+    return ret;
+}
+
+int register_stream_buffers(
+        const struct camera2_device *device,
+        uint32_t stream_id,
+        int num_buffers,
+        buffer_handle_t *buffers)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->register_stream_buffers(stream_id, num_buffers, buffers);
+    }
+    return ret;
+}
+
+int release_stream(
+        const struct camera2_device *device,
+        uint32_t stream_id)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->release_stream(stream_id);
+    }
+    return ret;
+}
+
+int allocate_reprocess_stream(const struct camera2_device *,
+        uint32_t width,
+        uint32_t height,
+        uint32_t format,
+        const camera2_stream_in_ops_t *reprocess_stream_ops,
+        uint32_t *stream_id,
+        uint32_t *consumer_usage,
+        uint32_t *max_buffers)
+{
+    return INVALID_OPERATION;
+}
+
+int allocate_reprocess_stream_from_stream(const struct camera2_device *,
+        uint32_t output_stream_id,
+        const camera2_stream_in_ops_t *reprocess_stream_ops,
+        uint32_t *stream_id)
+{
+    return INVALID_OPERATION;
+}
+
+int release_reprocess_stream(
+        const struct camera2_device *,
+        uint32_t stream_id)
+{
+    return INVALID_OPERATION;
+}
+
+int trigger_action(const struct camera2_device *,
+        uint32_t trigger_id,
+        int32_t ext1,
+        int32_t ext2)
+{
+    return INVALID_OPERATION;
+}
+
+int set_notify_callback(const struct camera2_device *device,
+        camera2_notify_callback notify_cb,
+        void *user)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->set_notify_callback(notify_cb, user);
+    }
+    return ret;
+}
+
+int get_metadata_vendor_tag_ops(const struct camera2_device *device,
+        vendor_tag_query_ops_t **ops)
+{
+    int ret = INVALID_OPERATION;
+    CameraHal *camHal = fsl_get_camerahal(device);
+
+    if (camHal != NULL) {
+        ret = camHal->get_metadata_vendor_tag_ops(ops);
+    }
+    return ret;
+}
+
+int camera_dump(const struct camera2_device *, int fd)
+{
+    return INVALID_OPERATION;
+}
+
+camera2_device_ops_t fsl_camera_ops = {
+    set_request_queue_src_ops:           set_request_queue_src_ops,
+    notify_request_queue_not_empty:      notify_request_queue_not_empty,
+    set_frame_queue_dst_ops:             set_frame_queue_dst_ops,
+    get_in_progress_count:               get_in_progress_count,
+    flush_captures_in_progress:          flush_captures_in_progress,
+    construct_default_request:           construct_default_request,
+
+    allocate_stream:                     allocate_stream,
+    register_stream_buffers:             register_stream_buffers,
+    release_stream:                      release_stream,
+
+    allocate_reprocess_stream:           allocate_reprocess_stream,
+    allocate_reprocess_stream_from_stream: allocate_reprocess_stream_from_stream,
+    release_reprocess_stream:            release_reprocess_stream,
+
+    trigger_action:                      trigger_action,
+    set_notify_callback:                 set_notify_callback,
+    get_metadata_vendor_tag_ops:         get_metadata_vendor_tag_ops,
+    dump:                                camera_dump,
+};
+
+int camera_device_close(hw_device_t *device)
+{
+    int ret = 0;
+    fsl_camera_device_t *fsl_dev = NULL;
+    CameraHal *camHal = NULL;
+
+    ALOGV("%s", __FUNCTION__);
+
+    android::Mutex::Autolock lock(gCameraHalDeviceLock);
+
+    if (!device) {
+        return -EINVAL;
+    }
+
+    camera2_device_t *camDev = (camera2_device_t *)device;
+    camHal = fsl_get_camerahal(camDev);
+    fsl_dev = (fsl_camera_device_t *)camDev->priv;
+
+    if (camHal) {
+        delete camHal;
+    }
+
+    if (fsl_dev) {
+        free(fsl_dev);
+    }
+
+
+    return ret;
+}
+
+#define FACE_BACK_CAMERA_NAME "back_camera_name"
+#define FACE_FRONT_CAMERA_NAME "front_camera_name"
+#define FACE_BACK_CAMERA_ORIENT "back_camera_orient"
+#define FACE_FRONT_CAMERA_ORIENT "front_camera_orient"
+#define DEFAULT_ERROR_NAME '0'
+#define DEFAULT_ERROR_NAME_str "0"
+#define UVC_NAME "uvc"
+static struct CameraInfo sCameraInfo[2];
+static int gCameraNum = 0;
+
+/*******************************************************************
+* implementation of camera_module functions
+*******************************************************************/
+
+/* open device handle to one of the cameras
+ *
+ * assume camera service will keep singleton of each camera
+ * so this function will always only be called once per camera instance
+ */
+int camera_device_open(const hw_module_t *module,
+                       const char        *name,
+                       hw_device_t      **device)
+{
+    int rv          = 0;
+    int num_cameras = 0;
+    int cameraid;
+    fsl_camera_device_t *camera_device = NULL;
+    CameraHal *camera                  = NULL;
+    char *SelectedCameraName;
+
+    android::Mutex::Autolock lock(gCameraHalDeviceLock);
+
+    ALOGI("camera_device open: %s", name);
+
+    if (name != NULL) {
+        cameraid    = atoi(name);
+        num_cameras = camera_get_number_of_cameras();
+
+        if (cameraid > num_cameras)
+        {
+            ALOGE("camera service provided cameraid out of bounds, "
+                  "cameraid = %d, num supported = %d",
+                  cameraid, num_cameras);
+            rv = -EINVAL;
+            goto fail;
+        }
+
+        camera_device = (fsl_camera_device_t *)malloc(sizeof(*camera_device));
+        if (!camera_device)
+        {
+            ALOGE("camera_device allocation fail");
+            rv = -ENOMEM;
+            goto fail;
+        }
+
+        memset(camera_device, 0, sizeof(*camera_device));
+
+        camera_device->base.common.tag     = HARDWARE_DEVICE_TAG;
+        camera_device->base.common.version = CAMERA_DEVICE_API_VERSION_2_0;
+        camera_device->base.common.module  = (hw_module_t *)(module);
+        camera_device->base.common.close   = camera_device_close;
+        camera_device->base.ops            = &fsl_camera_ops;
+        camera_device->base.priv           = camera_device;
+
+        *device = &camera_device->base.common;
+
+        camera_device->cameraid = cameraid;
+
+        camera = new CameraHal(cameraid);
+
+        if (!camera)
+        {
+            ALOGE("Couldn't create instance of CameraHal class");
+            rv = -ENOMEM;
+            goto fail;
+        }
+
+        camera_device->camHal = camera;
+        if (camera->initialize(sCameraInfo[cameraid]) < 0) {
+            rv = -EINVAL;
+            goto fail;
+        }
+    }
+
+    return rv;
+
+fail:
+    if (camera_device) {
+        free(camera_device);
+        camera_device = NULL;
+    }
+    if (camera) {
+        delete camera;
+        camera = NULL;
+    }
+    *device = NULL;
+    return rv;
+}
+
+static int GetDevPath(const char  *pCameraName,
+                      char        *pCameraDevPath,
+                      unsigned int pathLen)
+{
+    int  retCode = -1;
+    int  fd      = 0;
+    char dev_node[CAMAERA_FILENAME_LENGTH];
+    DIR *v4l_dir = NULL;
+    struct dirent *dir_entry;
+    struct v4l2_capability v4l2_cap;
+    struct v4l2_dbg_chip_ident vid_chip;
+
+    v4l_dir = opendir("/sys/class/video4linux");
+    if (v4l_dir) {
+        while ((dir_entry = readdir(v4l_dir))) {
+            memset((void *)dev_node, 0, CAMAERA_FILENAME_LENGTH);
+            if (strncmp(dir_entry->d_name, "video", 5))
+                continue;
+            sprintf(dev_node, "/dev/%s", dir_entry->d_name);
+            if ((fd = open(dev_node, O_RDWR, O_NONBLOCK)) < 0)
+                continue;
+            if (ioctl(fd, VIDIOC_QUERYCAP, &v4l2_cap) < 0) {
+                close(fd);
+                fd = 0;
+                continue;
+            } else if (v4l2_cap.capabilities & V4L2_CAP_VIDEO_CAPTURE) {
+                if (ioctl(fd, VIDIOC_DBG_G_CHIP_IDENT, &vid_chip) < 0) {
+                    close(fd);
+                    fd = 0;
+                    continue;
+                }
+                if (strstr(vid_chip.match.name, pCameraName)) {
+                    // fsl csi/mipi camera name and path match
+                    if (pathLen > strlen(dev_node)) {
+                        strcpy(pCameraDevPath, dev_node);
+                        ALOGI("Get sensor %s's dev path %s",
+                              pCameraName,
+                              pCameraDevPath);
+                        retCode = 0;
+                    }
+                    close(fd);
+                    fd = 0;
+                    break;
+                }
+            }
+            close(fd);
+            fd = 0;
+        }
+        closedir(v4l_dir);
+    }
+
+    return retCode;
+}
+
+static void GetCameraPropery(char *pFaceBackCameraName,
+                             char *pFaceFrontCameraName,
+                             int  *pFaceBackOrient,
+                             int  *pFaceFrontOrient)
+{
+    char orientStr[10];
+
+    property_get(FACE_BACK_CAMERA_NAME,
+                 pFaceBackCameraName,
+                 DEFAULT_ERROR_NAME_str);
+    property_get(FACE_BACK_CAMERA_ORIENT, orientStr, DEFAULT_ERROR_NAME_str);
+
+    if (orientStr[0] == DEFAULT_ERROR_NAME)
+        *pFaceBackOrient = 0;
+    else
+        *pFaceBackOrient = atoi(orientStr);
+
+    ALOGI("Face Back Camera is %s, orient is %d",
+          pFaceBackCameraName,
+          *pFaceBackOrient);
+
+    property_get(FACE_FRONT_CAMERA_NAME,
+                 pFaceFrontCameraName,
+                 DEFAULT_ERROR_NAME_str);
+
+    property_get(FACE_FRONT_CAMERA_ORIENT, orientStr, DEFAULT_ERROR_NAME_str);
+
+
+    if (orientStr[0] == DEFAULT_ERROR_NAME)
+        *pFaceFrontOrient = 0;
+    else
+        *pFaceFrontOrient = atoi(orientStr);
+
+    ALOGI("Face Front Camera is %s, orient is %d",
+          pFaceFrontCameraName,
+          *pFaceFrontOrient);
+}
+
+int camera_get_number_of_cameras()
+{
+    int back_orient = 0,  front_orient = 0;
+
+    if (gCameraNum == 0) {
+        char name_back[CAMERA_SENSOR_LENGTH];
+        char name_front[CAMERA_SENSOR_LENGTH];
+        GetCameraPropery(name_back,
+                         name_front,
+                         &back_orient,
+                         &front_orient);
+        if (name_back[0] != DEFAULT_ERROR_NAME) {
+            strncpy(sCameraInfo[gCameraNum].name,
+                    name_back,
+                    CAMERA_SENSOR_LENGTH);
+            sCameraInfo[gCameraNum].facing      = CAMERA_FACING_BACK;
+            sCameraInfo[gCameraNum].orientation = back_orient;
+            memset(sCameraInfo[gCameraNum].devPath, 0, CAMAERA_FILENAME_LENGTH);
+            GetDevPath(sCameraInfo[gCameraNum].name,
+                       sCameraInfo[gCameraNum].devPath,
+                       CAMAERA_FILENAME_LENGTH);
+            ALOGI("Camera ID %d: name %s, Facing %d, orientation %d, dev path %s",
+                    gCameraNum,
+                    sCameraInfo[gCameraNum].name,
+                    sCameraInfo[gCameraNum].facing,
+                    sCameraInfo[gCameraNum].orientation,
+                    sCameraInfo[gCameraNum].devPath);
+            gCameraNum++;
+        }
+        if (name_front[0] != DEFAULT_ERROR_NAME) {
+            strncpy(sCameraInfo[gCameraNum].name,
+                    name_front,
+                    CAMERA_SENSOR_LENGTH);
+            sCameraInfo[gCameraNum].facing      = CAMERA_FACING_FRONT;
+            sCameraInfo[gCameraNum].orientation = front_orient;
+            memset(sCameraInfo[gCameraNum].devPath, 0, CAMAERA_FILENAME_LENGTH);
+            GetDevPath(sCameraInfo[gCameraNum].name,
+                       sCameraInfo[gCameraNum].devPath,
+                       CAMAERA_FILENAME_LENGTH);
+            ALOGI("Camera ID %d: name %s, Facing %d, orientation %d, dev path %s",
+                    gCameraNum,
+                    sCameraInfo[gCameraNum].name,
+                    sCameraInfo[gCameraNum].facing,
+                    sCameraInfo[gCameraNum].orientation,
+                    sCameraInfo[gCameraNum].devPath);
+            gCameraNum++;
+        }
+    }
+    return gCameraNum;
+}
+
+int camera_get_camera_info(int                 cameraId,
+                           struct camera_info *cameraInfo)
+{
+    //MetadaManager::createStaticInfo(cameraId, &sCameraInfo[cameraId]);
+    sCameraInfo[cameraId].device_version = HARDWARE_DEVICE_API_VERSION(2, 0);
+    memcpy(cameraInfo, &sCameraInfo[cameraId], sizeof(camera_info));
+    return 0;
+}
+
diff --git a/mx6/libcamera2/CameraUtil.cpp b/mx6/libcamera2/CameraUtil.cpp
new file mode 100755
index 0000000..d0e0c60
--- /dev/null
+++ b/mx6/libcamera2/CameraUtil.cpp
@@ -0,0 +1,365 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "CameraUtil.h"
+#include <sys/atomics.h>
+
+int convertPixelFormatToV4L2Format(PixelFormat format)
+{
+    int nFormat = 0;
+
+    switch (format) {
+        case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+        case HAL_PIXEL_FORMAT_YCrCb_420_SP:
+            nFormat = v4l2_fourcc('N', 'V', '1', '2');
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_420_P:
+            nFormat = v4l2_fourcc('Y', 'U', '1', '2');
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_422_I:
+            nFormat = v4l2_fourcc('Y', 'U', 'Y', 'V');
+            break;
+
+        default:
+            FLOGE("Error: format:0x%x not supported!", format);
+            break;
+    }
+    FLOGI("pixel format: 0x%x", nFormat);
+    return nFormat;
+}
+
+PixelFormat convertV4L2FormatToPixelFormat(unsigned int format)
+{
+    PixelFormat nFormat = 0;
+
+    switch (format) {
+        case v4l2_fourcc('N', 'V', '1', '2'):
+            nFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+            break;
+
+        case v4l2_fourcc('Y', 'U', '1', '2'):
+            nFormat = HAL_PIXEL_FORMAT_YCbCr_420_P;
+            break;
+
+        case v4l2_fourcc('Y', 'U', 'Y', 'V'):
+            nFormat = HAL_PIXEL_FORMAT_YCbCr_422_I;
+            break;
+
+        default:
+            FLOGE("Error: format:0x%x not supported!", format);
+            break;
+    }
+    FLOGI("pixel format: 0x%x", nFormat);
+    return nFormat;
+}
+
+int convertStringToPixelFormat(const char *pFormat)
+{
+    if (pFormat == NULL) {
+        return 0;
+    }
+
+    if (!strcmp(pFormat, "yuv420p")) {
+        return HAL_PIXEL_FORMAT_YCbCr_420_P;
+    }
+    else if (!strcmp(pFormat, "yuv420sp")) {
+        return HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    }
+    else if (!strcmp(pFormat, "yuv422i-yuyv")) {
+        return HAL_PIXEL_FORMAT_YCbCr_422_I;
+    }
+    else {
+        FLOGE("format %s is not supported", pFormat);
+        return BAD_VALUE;
+    }
+}
+
+int convertStringToV4L2Format(const char *pFormat)
+{
+    if (pFormat == NULL) {
+        return 0;
+    }
+
+    if (!strcmp(pFormat, "yuv420p")) {
+        return v4l2_fourcc('Y', 'U', '1', '2');
+    }
+    else if (!strcmp(pFormat, "yuv420sp")) {
+        return v4l2_fourcc('N', 'V', '1', '2');
+    }
+    else if (!strcmp(pFormat, "yuv422i-yuyv")) {
+        return v4l2_fourcc('Y', 'U', 'Y', 'V');
+    }
+    else {
+        FLOGE("format %s is not supported", pFormat);
+        return BAD_VALUE;
+    }
+}
+
+CameraFrame::~CameraFrame()
+{
+    reset();
+}
+
+void CameraFrame::initialize(buffer_handle_t  buf_h,
+                             int              index)
+{
+    fAssert(buf_h != NULL);
+    private_handle_t *handle = (private_handle_t *)buf_h;
+    mBufHandle = buf_h;
+    mVirtAddr  =  (void *)handle->base;
+    mPhyAddr   =   handle->phys;
+    mSize      =   handle->size;
+    mWidth     =  handle->width;
+    mHeight    = handle->height;
+    mFormat    = handle->format;
+
+    mObserver  = NULL;
+    mRefCount  = 0;
+    mBufState  = BUFS_CREATE;
+    mFrameType = INVALID_FRAME;
+    mIndex     = index;
+}
+
+void CameraFrame::addState(CAMERA_BUFS_STATE state)
+{
+    mBufState |= state;
+}
+
+void CameraFrame::setState(CAMERA_BUFS_STATE state)
+{
+    mBufState = state;
+}
+
+int CameraFrame::getState()
+{
+    return mBufState;
+}
+
+void CameraFrame::removeState(CAMERA_BUFS_STATE state)
+{
+    mBufState &= ~state;
+}
+
+void CameraFrame::addReference()
+{
+    __atomic_inc(&mRefCount);
+}
+
+void CameraFrame::release()
+{
+    fAssert(mRefCount > 0);
+
+    int prevCount = __atomic_dec(&mRefCount);
+    if ((prevCount == 1) && (mObserver != NULL)) {
+        mObserver->handleFrameRelease(this);
+    }
+}
+
+void CameraFrame::setObserver(CameraFrameObserver *observer)
+{
+    mObserver = observer;
+}
+
+void CameraFrame::reset()
+{
+    mBufHandle = NULL;
+    mVirtAddr  = NULL;
+    mPhyAddr   = 0;
+    mObserver  = NULL;
+    mRefCount  = 0;
+    mBufState  = BUFS_CREATE;
+    mFrameType = INVALID_FRAME;
+}
+
+// //////////CameraBufferProvider////////////////////
+CameraBufferProvider::CameraBufferProvider()
+{
+    mBufferListeners.clear();
+}
+
+CameraBufferProvider::~CameraBufferProvider()
+{
+    mBufferListeners.clear();
+}
+
+void CameraBufferProvider::addBufferListener(CameraBufferListener *listener)
+{
+    CameraBufferListener *pNtf = NULL;
+    size_t nSize               = mBufferListeners.size();
+
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraBufferListener *)mBufferListeners[i];
+        if (pNtf == listener) {
+            return;
+        }
+    }
+
+    mBufferListeners.push((int)listener);
+}
+
+void CameraBufferProvider::removeBufferListener(CameraBufferListener *listener)
+{
+    CameraBufferListener *pNtf;
+    size_t nSize = mBufferListeners.size();
+
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraBufferListener *)mBufferListeners[i];
+        if (pNtf == listener) {
+            mBufferListeners.removeAt(i);
+
+            // break;
+        }
+    }
+}
+
+void CameraBufferProvider::clearBufferListeners()
+{
+    mBufferListeners.clear();
+}
+
+void CameraBufferProvider::dispatchBuffers(CameraFrame *pBuffer,
+                                           int          num,
+                                           BufferState  bufState)
+{
+    CameraBufferListener *listener;
+    size_t nSize = mBufferListeners.size();
+
+    for (size_t i = 0; i < nSize; i++) {
+        listener = (CameraBufferListener *)mBufferListeners[i];
+        switch (bufState) {
+            case BUFFER_CREATE:
+                fAssert(pBuffer != NULL);
+                listener->onBufferCreat(pBuffer, num);
+                break;
+
+            case BUFFER_DESTROY:
+                listener->onBufferDestroy();
+                break;
+        } // end switch
+    }     // end for
+}
+
+// //////////CameraFrameProvider////////////////////
+CameraFrameProvider::CameraFrameProvider()
+{
+    mFrameListeners.clear();
+}
+
+CameraFrameProvider::~CameraFrameProvider()
+{
+    mFrameListeners.clear();
+}
+
+void CameraFrameProvider::addFrameListener(CameraFrameListener *listener)
+{
+    CameraFrameListener *pNtf;
+    size_t nSize = mFrameListeners.size();
+
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraFrameListener *)mFrameListeners[i];
+        if (pNtf == listener) {
+            return;
+        }
+    }
+
+    mFrameListeners.push((int)listener);
+}
+
+void CameraFrameProvider::removeFrameListener(CameraFrameListener *listener)
+{
+    CameraFrameListener *pNtf;
+    size_t nSize = mFrameListeners.size();
+
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraFrameListener *)mFrameListeners[i];
+        if (pNtf == listener) {
+            mFrameListeners.removeAt(i);
+
+            // break;
+        }
+    }
+}
+
+void CameraFrameProvider::clearFrameListeners()
+{
+    mFrameListeners.clear();
+}
+
+void CameraFrameProvider::dispatchCameraFrame(CameraFrame *frame)
+{
+    fAssert(frame != NULL);
+    CameraFrameListener *listener;
+    size_t nSize = mFrameListeners.size();
+
+    // add reference here to avoid frame release too early.
+    frame->addReference();
+    for (size_t i = 0; i < nSize; i++) {
+        listener = (CameraFrameListener *)mFrameListeners[i];
+        listener->handleCameraFrame(frame);
+    }
+    frame->release();
+}
+
+// ----------------CameraEventProvider----------
+void CameraEventProvider::addEventListener(CameraEventListener *listener)
+{
+    CameraEventListener *pNtf;
+    size_t nSize = mEventListeners.size();
+
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraEventListener *)mEventListeners[i];
+        if (pNtf == listener) {
+            return;
+        }
+    }
+
+    mEventListeners.push((int)listener);
+}
+
+void CameraEventProvider::removeEventListener(CameraEventListener *listener)
+{
+    CameraEventListener *pNtf;
+    size_t nSize = mEventListeners.size();
+
+    for (size_t i = 0; i < nSize; i++) {
+        pNtf = (CameraEventListener *)mEventListeners[i];
+        if (pNtf == listener) {
+            mEventListeners.removeAt(i);
+
+            // break;
+        }
+    }
+}
+
+void CameraEventProvider::clearEventListeners()
+{
+    mEventListeners.clear();
+}
+
+void CameraEventProvider::dispatchEvent(sp<CameraEvent>& event)
+{
+    fAssert(event != NULL);
+    CameraEventListener *listener;
+    size_t nSize = mEventListeners.size();
+
+    for (size_t i = 0; i < nSize; i++) {
+        listener = (CameraEventListener *)mEventListeners[i];
+        listener->handleEvent(event);
+    }
+}
+
diff --git a/mx6/libcamera2/CameraUtil.h b/mx6/libcamera2/CameraUtil.h
new file mode 100755
index 0000000..6771121
--- /dev/null
+++ b/mx6/libcamera2/CameraUtil.h
@@ -0,0 +1,326 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _CAMERA_UTILS_H
+#define _CAMERA_UTILS_H
+
+#undef LOG_TAG
+#define LOG_TAG "FslCameraHAL"
+#include <utils/Log.h>
+
+#include <string.h>
+#include <unistd.h>
+#include <time.h>
+#include <dlfcn.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <linux/time.h>
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include <utils/threads.h>
+#include <utils/RefBase.h>
+#include <binder/MemoryBase.h>
+#include <binder/MemoryHeapBase.h>
+#include <camera/CameraParameters.h>
+#include <utils/Vector.h>
+#include <utils/KeyedVector.h>
+#include <cutils/properties.h>
+#include <hardware_legacy/power.h>
+#include <ui/GraphicBufferMapper.h>
+#include <ui/Rect.h>
+#include <ui/PixelFormat.h>
+#include <system/window.h>
+#include <system/camera.h>
+#include "gralloc_priv.h"
+#include <linux/videodev2.h>
+#include <hardware/camera2.h>
+#include "MetadaManager.h"
+
+using namespace android;
+
+//#define CAMERA_HAL_DEBUG
+#ifdef CAMERA_HAL_DEBUG
+# define FLOG_RUNTIME(format, ...) ALOGI((format), ## __VA_ARGS__)
+//# define FLOG_TRACE(format, ...) ALOGI((format), ## __VA_ARGS__)
+#else // ifdef CAMERA_HAL_DEBUG
+# define FLOG_RUNTIME(format, ...)
+//# define FLOG_TRACE(format, ...)
+#endif // ifdef CAMERA_HAL_DEBUG
+
+#define FLOG_TRACE(format, ...) ALOGI((format), ## __VA_ARGS__)
+#define FLOGI(format, ...) ALOGI((format), ## __VA_ARGS__)
+#define FLOGW(format, ...) ALOGW((format), ## __VA_ARGS__)
+#define FLOGE(format, ...) ALOGE((format), ## __VA_ARGS__)
+
+#define fAssert(e) ((e) ? (void)0 : __assert2(__FILE__, __LINE__, __func__, #e))
+
+#define UVC_SENSOR_NAME "uvc"
+#define OV5640_SENSOR_NAME "ov5640"
+#define OV5642_SENSOR_NAME "ov5642"
+#define V4LSTREAM_WAKE_LOCK "V4LCapture"
+
+#define MAX_PREVIEW_BUFFER      6
+#define MAX_CAPTURE_BUFFER      3
+#define NUM_PREVIEW_BUFFER      4
+#define NUM_CAPTURE_BUFFER      2
+
+#define CAMAERA_FILENAME_LENGTH 256
+#define CAMERA_SENSOR_LENGTH    32
+#define CAMERA_FORMAT_LENGTH    32
+#define CAMER_PARAM_BUFFER_SIZE 512
+#define PARAMS_DELIMITER ","
+#define THREAD_WAIT_TIMEOUT 5000 * 1000 * 1000LL
+
+#define MAX_RESOLUTION_SIZE   64
+#define MAX_FPS_RANGE   4
+#define MAX_SENSOR_FORMAT 20
+
+#define CAMERA_GRALLOC_USAGE GRALLOC_USAGE_HW_TEXTURE | \
+    GRALLOC_USAGE_HW_RENDER |                           \
+    GRALLOC_USAGE_SW_READ_RARELY |                      \
+    GRALLOC_USAGE_SW_WRITE_NEVER |                      \
+    GRALLOC_USAGE_FORCE_CONTIGUOUS
+
+#define ARRAY_SIZE(x) (sizeof(x)/sizeof((x)[0]))
+
+#define CAMERA_MAX(x, y) (x) > (y) ? (x) : (y)
+
+int         convertPixelFormatToV4L2Format(PixelFormat format);
+PixelFormat convertV4L2FormatToPixelFormat(unsigned int format);
+int         convertStringToPixelFormat(const char *pFormat);
+int         convertStringToV4L2Format(const char *pFormat);
+
+struct VideoMetadataBuffer
+{
+    size_t phyOffset;
+    size_t length;
+};
+
+struct CameraInfo : public camera_info
+{
+    char name[CAMERA_SENSOR_LENGTH];
+    char devPath[CAMAERA_FILENAME_LENGTH];
+};
+
+struct SensorInfo
+{
+    int mPreviewResolutions[MAX_RESOLUTION_SIZE];
+    int mPictureResolutions[MAX_RESOLUTION_SIZE];
+    int mAvailableFormats[MAX_SENSOR_FORMAT];
+    nsecs_t mMinFrameDuration;
+    nsecs_t mMaxFrameDuration;
+    int mTargetFpsRange[MAX_FPS_RANGE];
+    int mMaxWidth;
+    int mMaxHeight;
+    float mFocalLength;
+};
+
+struct VideoInfo
+{
+    struct v4l2_capability     cap;
+    struct v4l2_format         format;
+    struct v4l2_streamparm     param;
+    struct v4l2_buffer         buf;
+    struct v4l2_requestbuffers rb;
+    bool                       isStreamOn;
+    int                        width;
+    int                        height;
+    int                        formatIn;
+    int                        framesizeIn;
+};
+
+class CameraFrame;
+
+class CameraFrameObserver {
+public:
+    CameraFrameObserver() {}
+
+    virtual ~CameraFrameObserver() {}
+
+    virtual void handleFrameRelease(CameraFrame *buffer) = 0;
+
+private:
+    CameraFrameObserver(const CameraFrameObserver&);
+    CameraFrameObserver& operator=(const CameraFrameObserver&);
+};
+
+struct StreamBuffer {
+    int mWidth;
+    int mHeight;
+    int mFormat;
+    void *mVirtAddr;
+    int mPhyAddr;
+    size_t mSize;
+    buffer_handle_t mBufHandle;
+    nsecs_t mTimeStamp;
+};
+
+class CameraFrame : public StreamBuffer {
+public:
+    enum CAMERA_BUFS_STATE {
+        BUFS_CREATE      = -1,
+        BUFS_FREE        = 0,
+        BUFS_IN_CAPTURE  = 1,
+        BUFS_IN_RECORDER = 2,
+        BUFS_IN_PREIVIEW = 4,
+        BUFS_IN_DRIVER   = 8,
+        BUFS_IN_SERVICE  = 0x10
+    };
+    enum FrameType {
+        INVALID_FRAME = 0,
+        IMAGE_FRAME   = 1,
+        PREVIEW_FRAME = 2,
+    };
+
+    CameraFrame() {}
+
+    ~CameraFrame();
+
+    void initialize(buffer_handle_t  buf_h,
+                    int              index);
+    void addState(CAMERA_BUFS_STATE state);
+    void setState(CAMERA_BUFS_STATE state);
+    int getState();
+    void removeState(CAMERA_BUFS_STATE state);
+    void release();
+    void addReference();
+    void setObserver(CameraFrameObserver *observer);
+    void reset();
+
+private:
+    CameraFrame(const CameraFrame&);
+    CameraFrame& operator=(const CameraFrame&);
+
+public:
+    FrameType mFrameType;
+    int mIndex;
+
+private:
+    int mRefCount;
+    int mBufState;
+    CameraFrameObserver *mObserver;
+};
+
+enum CAMERA_ERROR {
+    ERROR_FATAL = 1,
+    ERROR_TINY  = 2,
+};
+
+class CameraErrorListener {
+public:
+    virtual void handleError(int err) = 0;
+    virtual ~CameraErrorListener() {}
+};
+
+class CameraBufferListener {
+public:
+    virtual void onBufferCreat(CameraFrame *pBuffer, int num) = 0;
+    virtual void onBufferDestroy() = 0;
+    virtual ~CameraBufferListener() {}
+};
+
+class CameraBufferProvider {
+public:
+    enum BufferState {
+        BUFFER_CREATE  = 1,
+        BUFFER_DESTROY = 2,
+    };
+    CameraBufferProvider();
+    virtual ~CameraBufferProvider();
+
+    virtual int allocateBuffers(int width, int height,
+                               int format, int numBufs) = 0;
+    virtual int freeBuffers() = 0;
+
+    void addBufferListener(CameraBufferListener *listener);
+    void removeBufferListener(CameraBufferListener *listener);
+    void clearBufferListeners();
+
+    void dispatchBuffers(CameraFrame *pBuffer, int num, BufferState bufState);
+
+private:
+    Vector<int> mBufferListeners;
+};
+
+class CameraFrameListener {
+public:
+    virtual void handleCameraFrame(CameraFrame *frame) = 0;
+    virtual ~CameraFrameListener() {}
+};
+
+class CameraFrameProvider {
+public:
+    CameraFrameProvider();
+    virtual ~CameraFrameProvider();
+
+    virtual int getFrameSize()  = 0;
+    virtual int getFrameCount() = 0;
+    void addFrameListener(CameraFrameListener *listener);
+    void removeFrameListener(CameraFrameListener *listener);
+    void clearFrameListeners();
+
+    void dispatchCameraFrame(CameraFrame *frame);
+
+private:
+    Vector<int> mFrameListeners;
+};
+
+class CameraEvent : public LightRefBase<CameraEvent>{
+public:
+    enum CameraEventType {
+        EVENT_INVALID = 0x0,
+        EVENT_SHUTTER = 0x1,
+        EVENT_FOCUS   = 0x2,
+        EVENT_ZOOM    = 0x4,
+        EVENT_FACE    = 0x8
+    };
+
+    CameraEvent()
+        : mData(NULL), mEventType(EVENT_INVALID)
+    {}
+
+    void *mData;
+    CameraEventType mEventType;
+};
+
+class CameraEventListener {
+public:
+    virtual void handleEvent(sp<CameraEvent>& event) = 0;
+    virtual ~CameraEventListener() {}
+};
+
+class CameraEventProvider {
+public:
+    CameraEventProvider() {
+        mEventListeners.clear();
+    }
+
+    void addEventListener(CameraEventListener *listerner);
+    void removeEventListener(CameraEventListener *listerner);
+    void clearEventListeners();
+    void dispatchEvent(sp<CameraEvent>& event);
+
+    virtual ~CameraEventProvider() {
+        mEventListeners.clear();
+    }
+
+private:
+    Vector<int> mEventListeners;
+};
+
+#endif // ifndef _CAMERA_UTILS_H
diff --git a/mx6/libcamera2/CaptureStream.cpp b/mx6/libcamera2/CaptureStream.cpp
new file mode 100755
index 0000000..600b1e8
--- /dev/null
+++ b/mx6/libcamera2/CaptureStream.cpp
@@ -0,0 +1,315 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <utils/StrongPointer.h>
+#include <binder/MemoryBase.h>
+#include <binder/MemoryHeapBase.h>
+#include "StreamAdapter.h"
+#include "PhysMemAdapter.h"
+#include "CameraUtil.h"
+
+CaptureStream::CaptureStream(int id)
+    : StreamAdapter(id)
+{
+    mActualFormat = 0;
+    mVideoSnapShot = false;
+    mPhysMemAdapter = new PhysMemAdapter();
+    sem_init(&mRespondSem, 0, 0);
+}
+
+CaptureStream::~CaptureStream()
+{
+    delete mPhysMemAdapter;
+}
+
+int CaptureStream::initialize(int width, int height, int format,
+                              int usage, int bufferNum)
+{
+    StreamAdapter::initialize(width, height, format, usage, bufferNum);
+
+    mJpegBuilder = new JpegBuilder();
+    if (mJpegBuilder == NULL) {
+        FLOGE("Couldn't create JpegBuilder");
+        return NO_MEMORY;
+    }
+
+    return NO_ERROR;
+}
+
+int CaptureStream::configure(int fps, bool videoSnapshot)
+{
+    FLOG_TRACE("CaptureStream::configure");
+    int stride = 0;
+    int index = -1;
+    int ret = NO_ERROR;
+    int errCode = 0;
+
+    mJpegBuilder->reset();
+    mJpegBuilder->setMetadaManager(mMetadaManager);
+
+    mVideoSnapShot = videoSnapshot;
+    if (mVideoSnapShot) {
+        FLOGE("%s video Snapshot", __FUNCTION__);
+        mPrepared = true;
+        return ret;
+    }
+
+    fAssert(mDeviceAdapter.get() != NULL);
+
+    if (mFormat == HAL_PIXEL_FORMAT_BLOB) {
+        mActualFormat = mDeviceAdapter->getPicturePixelFormat();
+        //fmt = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    }
+    else {
+        mActualFormat = mFormat;
+    }
+
+    ret = mDeviceAdapter->setDeviceConfig(mWidth, mHeight, mActualFormat, fps);
+    if (ret != NO_ERROR) {
+        FLOGE("%s setDeviceConfig failed", __FUNCTION__);
+        errCode = CAMERA2_MSG_ERROR_DEVICE;
+        goto fail;
+    }
+
+    fAssert(mPhysMemAdapter != NULL);
+    mDeviceAdapter->setCameraBufferProvide(mPhysMemAdapter);
+
+    ret = mPhysMemAdapter->allocateBuffers(mWidth, mHeight,
+                        mActualFormat, 2/*MAX_CAPTURE_BUFFER*/);
+    if (ret != NO_ERROR) {
+        FLOGE("%s allocateBuffers failed", __FUNCTION__);
+        errCode = CAMERA2_MSG_ERROR_DEVICE;
+        goto fail;
+    }
+
+    mPrepared = true;
+    return NO_ERROR;
+
+fail:
+    mPhysMemAdapter->freeBuffers();
+    FLOGE("Error occurred, performing cleanup");
+
+    if (NULL != mErrorListener) {
+        mErrorListener->handleError(errCode);
+    }
+
+    return BAD_VALUE;
+}
+
+int CaptureStream::start()
+{
+    FLOG_TRACE("CaptureStream::start");
+    int ret = 0;
+    StreamAdapter::start();
+
+    if (mVideoSnapShot) {
+        FLOGE("%s video Snapshot", __FUNCTION__);
+        return ret;
+    }
+
+    fAssert(mDeviceAdapter.get() != NULL);
+    ret = mDeviceAdapter->startImageCapture();
+    if (ret != NO_ERROR) {
+        FLOGE("Couldn't start preview for DeviceAdapter");
+        return ret;
+    }
+    return NO_ERROR;
+}
+
+int CaptureStream::stop()
+{
+    FLOG_TRACE("CaptureStream::stop");
+    StreamAdapter::stop();
+
+    if (mVideoSnapShot) {
+        FLOGE("%s video Snapshot", __FUNCTION__);
+        return NO_ERROR;
+    }
+
+    if (mDeviceAdapter.get() != NULL) {
+        mDeviceAdapter->stopImageCapture();
+    }
+    return NO_ERROR;
+}
+
+int CaptureStream::release()
+{
+    FLOG_TRACE("CaptureStream::release");
+    StreamAdapter::release();
+    if (mVideoSnapShot) {
+        FLOGE("%s video Snapshot", __FUNCTION__);
+        return NO_ERROR;
+    }
+
+    return mPhysMemAdapter->freeBuffers();
+}
+
+void CaptureStream::applyRequest()
+{
+    sem_wait(&mRespondSem);
+}
+
+int CaptureStream::processFrame(CameraFrame *frame)
+{
+    status_t ret = NO_ERROR;
+
+    StreamBuffer buffer;
+    ret = requestBuffer(&buffer);
+    if (ret != NO_ERROR) {
+        FLOGE("%s requestBuffer failed", __FUNCTION__);
+        return ret;
+    }
+
+    ret = makeJpegImage(&buffer, frame);
+    if (ret != NO_ERROR) {
+        FLOGE("%s makeJpegImage failed", __FUNCTION__);
+        return ret;
+    }
+
+    buffer.mTimeStamp = frame->mTimeStamp;
+    ret = renderBuffer(&buffer);
+    if (ret != NO_ERROR) {
+        FLOGE("%s renderBuffer failed", __FUNCTION__);
+        return ret;
+    }
+
+    sem_post(&mRespondSem);
+
+    return ret;
+}
+
+
+status_t CaptureStream::makeJpegImage(StreamBuffer *dstBuf, StreamBuffer *srcBuf)
+{
+    status_t ret = NO_ERROR;
+    int encodeQuality = 100, thumbQuality = 100;
+    int thumbWidth, thumbHeight;
+    JpegParams *mainJpeg = NULL, *thumbJpeg = NULL;
+    void *rawBuf = NULL, *thumbBuf = NULL;
+    size_t imageSize = 0;
+
+    if (dstBuf == NULL || srcBuf == NULL) {
+        FLOGE("%s invalid param", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    sp<MemoryHeapBase> rawFrame(
+                    new MemoryHeapBase(srcBuf->mSize, 0, "rawFrame"));
+    rawBuf = rawFrame->getBase();
+    if (rawBuf == MAP_FAILED) {
+        FLOGE("%s new MemoryHeapBase failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    sp<MemoryHeapBase> thumbFrame(
+                new MemoryHeapBase(srcBuf->mSize, 0, "thumbFrame"));
+    thumbBuf = thumbFrame->getBase();
+    if (thumbBuf == MAP_FAILED) {
+        FLOGE("%s new MemoryHeapBase failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    ret = mMetadaManager->getJpegQuality(encodeQuality);
+    if (ret != NO_ERROR) {
+        FLOGE("%s getJpegQuality failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    if ((encodeQuality < 0) || (encodeQuality > 100)) {
+        encodeQuality = 100;
+    }
+
+    ret = mMetadaManager->getJpegThumbQuality(thumbQuality);
+    if (ret != NO_ERROR) {
+        FLOGE("%s getJpegThumbQuality failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    if ((thumbQuality < 0) || (thumbQuality > 100)) {
+        thumbQuality = 100;
+    }
+
+    mainJpeg = new JpegParams((uint8_t *)srcBuf->mVirtAddr,
+                       srcBuf->mSize, (uint8_t *)rawBuf,
+                       srcBuf->mSize, encodeQuality,
+                       srcBuf->mWidth, srcBuf->mHeight,
+                       srcBuf->mWidth, srcBuf->mHeight,
+                       mActualFormat);
+
+    ret = mMetadaManager->getJpegThumbSize(thumbWidth, thumbHeight);
+    if (ret != NO_ERROR) {
+        FLOGE("%s getJpegThumbSize failed", __FUNCTION__);
+        goto err_out;
+    }
+
+    if ((thumbWidth > 0) && (thumbHeight > 0)) {
+        int thumbSize   = 0;
+        int thumbFormat = convertPixelFormatToV4L2Format(mActualFormat);
+        switch (thumbFormat) {
+            case v4l2_fourcc('N', 'V', '1', '2'):
+                thumbSize = thumbWidth * thumbHeight * 3 / 2;
+                break;
+
+            case v4l2_fourcc('Y', 'U', '1', '2'):
+                thumbSize = thumbWidth * thumbHeight * 3 / 2;
+                break;
+
+            case v4l2_fourcc('Y', 'U', 'Y', 'V'):
+                thumbSize = thumbWidth * thumbHeight * 2;
+                break;
+
+            default:
+                FLOGE("Error: %s format not supported", __FUNCTION__);
+                goto err_out;
+        }
+        thumbSize = srcBuf->mSize;
+        thumbJpeg = new JpegParams((uint8_t *)srcBuf->mVirtAddr,
+                           srcBuf->mSize,
+                           (uint8_t *)thumbBuf,
+                           thumbSize,
+                           thumbQuality,
+                           srcBuf->mWidth,
+                           srcBuf->mHeight,
+                           thumbWidth,
+                           thumbHeight,
+                           mActualFormat);
+    }
+
+    mJpegBuilder->prepareImage(dstBuf);
+    ret = mJpegBuilder->encodeImage(mainJpeg, thumbJpeg);
+    if (ret != NO_ERROR) {
+        FLOGE("%s encodeImage failed", __FUNCTION__);
+        goto err_out;
+    }
+
+    imageSize = mJpegBuilder->getImageSize();
+    ret = mJpegBuilder->buildImage(dstBuf);
+    if (ret != NO_ERROR) {
+        FLOGE("%s buildImage failed", __FUNCTION__);
+        goto err_out;
+    }
+
+err_out:
+    if (mainJpeg) {
+        delete mainJpeg;
+    }
+
+    if (thumbJpeg) {
+        delete thumbJpeg;
+    }
+
+    return ret;
+}
diff --git a/mx6/libcamera2/DeviceAdapter.cpp b/mx6/libcamera2/DeviceAdapter.cpp
new file mode 100755
index 0000000..060d731
--- /dev/null
+++ b/mx6/libcamera2/DeviceAdapter.cpp
@@ -0,0 +1,645 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "DeviceAdapter.h"
+#include "UvcDevice.h"
+#include "Ov5640.h"
+#include "Ov5642.h"
+
+sp<DeviceAdapter>DeviceAdapter::Create(const CameraInfo& info)
+{
+    sp<DeviceAdapter> devAdapter;
+    if (strstr(info.name, UVC_SENSOR_NAME)) {
+        FLOGI("DeviceAdapter: Create uvc device");
+        devAdapter = new UvcDevice();
+    }
+    else if (strstr(info.name, OV5640_SENSOR_NAME)) {
+        FLOGI("DeviceAdapter: Create ov5640 device");
+        devAdapter = new Ov5640();
+    }
+    else if (strstr(info.name, OV5642_SENSOR_NAME)) {
+        FLOGI("DeviceAdapter: Create ov5642 device");
+        devAdapter = new Ov5642();
+    }
+    else {
+        devAdapter = new OvDevice();
+        FLOGI("sensor %s does not support well now!", info.name);
+    }
+
+    return devAdapter;
+}
+
+DeviceAdapter::DeviceAdapter()
+    : mCameraHandle(-1), mQueued(0), mDequeued(0)
+{}
+
+DeviceAdapter::~DeviceAdapter()
+{
+    // Close the camera handle and free the video info structure
+    close(mCameraHandle);
+
+    if (mVideoInfo) {
+        delete mVideoInfo;
+        mVideoInfo = NULL;
+    }
+}
+
+void DeviceAdapter::setMetadaManager(sp<MetadaManager> &metadaManager)
+{
+    mMetadaManager = metadaManager;
+}
+
+PixelFormat DeviceAdapter::getMatchFormat(int *sfmt, int  slen,
+                                         int *dfmt, int  dlen)
+{
+    if ((sfmt == NULL) || (slen == 0) || (dfmt == NULL) || (dlen == 0)) {
+        FLOGE("getMatchFormat invalid parameters");
+        return 0;
+    }
+
+    PixelFormat matchFormat = 0;
+    bool live = true;
+    for (int i = 0; i < slen && live; i++) {
+        for (int j = 0; j < dlen; j++) {
+            if (sfmt[i] == dfmt[j]) {
+                matchFormat = dfmt[j];
+                live        = false;
+                break;
+            }
+        }
+    }
+
+    return matchFormat;
+}
+
+void DeviceAdapter::setPreviewPixelFormat()
+{
+    int vpuFormats[MAX_VPU_SUPPORT_FORMAT];
+    memset(vpuFormats, 0, sizeof(vpuFormats));
+    int ret = mMetadaManager->getSupportedRecordingFormat(&vpuFormats[0],
+                                    MAX_VPU_SUPPORT_FORMAT);
+    if (ret != NO_ERROR) {
+        FLOGE("getSupportedRecordingFormat failed");
+        mPreviewPixelFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+        return;
+    }
+
+    mPreviewPixelFormat = getMatchFormat(vpuFormats, MAX_VPU_SUPPORT_FORMAT,
+                          mAvailableFormats, MAX_SENSOR_FORMAT);
+}
+
+void DeviceAdapter::setPicturePixelFormat()
+{
+    int picFormats[MAX_PICTURE_SUPPORT_FORMAT];
+    memset(picFormats, 0, sizeof(picFormats));
+    int ret = mMetadaManager->getSupportedPictureFormat(picFormats,
+                                MAX_PICTURE_SUPPORT_FORMAT);
+    if (ret != NO_ERROR) {
+        FLOGE("getSupportedPictureFormat failed");
+        mPicturePixelFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+        return;
+    }
+    mPicturePixelFormat = getMatchFormat(picFormats, MAX_PICTURE_SUPPORT_FORMAT,
+                            mAvailableFormats, MAX_SENSOR_FORMAT);
+}
+
+status_t DeviceAdapter::initialize(const CameraInfo& info)
+{
+    if (info.name == NULL) {
+        FLOGE("invalid camera sensor name in initialize");
+        return BAD_VALUE;
+    }
+    if (info.devPath == NULL) {
+        FLOGE("invalid camera devpath in initialize");
+        return BAD_VALUE;
+    }
+
+    mCameraHandle = open(info.devPath, O_RDWR);
+    if (mCameraHandle < 0) {
+        FLOGE("can not open camera devpath:%s", info.devPath);
+        return BAD_VALUE;
+    }
+    mVideoInfo = new VideoInfo();
+    if (mVideoInfo == NULL) {
+        close(mCameraHandle);
+        FLOGE("new VideoInfo failed");
+        return NO_MEMORY;
+    }
+
+    int ret = NO_ERROR;
+    ret = ioctl(mCameraHandle, VIDIOC_QUERYCAP, &mVideoInfo->cap);
+    if (ret < 0) {
+        close(mCameraHandle);
+        delete mVideoInfo;
+        FLOGE("query v4l2 capability failed");
+        return BAD_VALUE;
+    }
+    if ((mVideoInfo->cap.capabilities & V4L2_CAP_VIDEO_CAPTURE) == 0)
+    {
+        close(mCameraHandle);
+        delete mVideoInfo;
+        FLOGE("v4l2 capability does not support capture");
+        return BAD_VALUE;
+    }
+
+    initSensorInfo();
+    setPreviewPixelFormat();
+    setPicturePixelFormat();
+    // Initialize flags
+    mPreviewing            = false;
+    mVideoInfo->isStreamOn = false;
+    mImageCapture          = false;
+
+    return NO_ERROR;
+}
+
+status_t DeviceAdapter::setDeviceConfig(int         width,
+                                        int         height,
+                                        PixelFormat format,
+                                        int         fps)
+{
+    if (mCameraHandle <= 0) {
+        FLOGE("setDeviceConfig: DeviceAdapter uninitialized");
+        return BAD_VALUE;
+    }
+    if ((width == 0) || (height == 0)) {
+        FLOGE("setDeviceConfig: invalid parameters");
+        return BAD_VALUE;
+    }
+
+    status_t ret = NO_ERROR;
+    int input    = 1;
+    ret = ioctl(mCameraHandle, VIDIOC_S_INPUT, &input);
+    if (ret < 0) {
+        FLOGE("Open: VIDIOC_S_INPUT Failed: %s", strerror(errno));
+        return ret;
+    }
+
+    int vformat;
+    vformat = convertPixelFormatToV4L2Format(format);
+
+    if ((width > 1920) || (height > 1080)) {
+        fps = 15;
+    }
+    FLOGI("Width * Height %d x %d format %d, fps: %d",
+          width, height, vformat, fps);
+
+    mVideoInfo->width       = width;
+    mVideoInfo->height      = height;
+    mVideoInfo->framesizeIn = (width * height << 1);
+    mVideoInfo->formatIn    = vformat;
+
+    mVideoInfo->param.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    mVideoInfo->param.parm.capture.timeperframe.numerator   = 1;
+    mVideoInfo->param.parm.capture.timeperframe.denominator = fps;
+    mVideoInfo->param.parm.capture.capturemode = getCaptureMode(width, height);
+    ret = ioctl(mCameraHandle, VIDIOC_S_PARM, &mVideoInfo->param);
+    if (ret < 0) {
+        FLOGE("Open: VIDIOC_S_PARM Failed: %s", strerror(errno));
+        return ret;
+    }
+
+    mVideoInfo->format.type                 = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    mVideoInfo->format.fmt.pix.width        = width & 0xFFFFFFF8;
+    mVideoInfo->format.fmt.pix.height       = height & 0xFFFFFFF8;
+    mVideoInfo->format.fmt.pix.pixelformat  = vformat;
+    mVideoInfo->format.fmt.pix.priv         = 0;
+    mVideoInfo->format.fmt.pix.sizeimage    = 0;
+    mVideoInfo->format.fmt.pix.bytesperline = 0;
+
+    // Special stride alignment for YU12
+    if (vformat == v4l2_fourcc('Y', 'U', '1', '2')){
+        // Goolge define the the stride and c_stride for YUV420 format
+        // y_size = stride * height
+        // c_stride = ALIGN(stride/2, 16)
+        // c_size = c_stride * height/2
+        // size = y_size + c_size * 2
+        // cr_offset = y_size
+        // cb_offset = y_size + c_size
+        // int stride = (width+15)/16*16;
+        // int c_stride = (stride/2+16)/16*16;
+        // y_size = stride * height
+        // c_stride = ALIGN(stride/2, 16)
+        // c_size = c_stride * height/2
+        // size = y_size + c_size * 2
+        // cr_offset = y_size
+        // cb_offset = y_size + c_size
+
+        // GPU and IPU take below stride calculation
+        // GPU has the Y stride to be 32 alignment, and UV stride to be
+        // 16 alignment.
+        // IPU have the Y stride to be 2x of the UV stride alignment
+        int stride = (width+31)/32*32;
+        int c_stride = (stride/2+15)/16*16;
+        mVideoInfo->format.fmt.pix.bytesperline = stride;
+        mVideoInfo->format.fmt.pix.sizeimage    = stride*height+c_stride * height;
+        FLOGI("Special handling for YV12 on Stride %d, size %d",
+            mVideoInfo->format.fmt.pix.bytesperline,
+            mVideoInfo->format.fmt.pix.sizeimage);
+    }
+
+    ret = ioctl(mCameraHandle, VIDIOC_S_FMT, &mVideoInfo->format);
+    if (ret < 0) {
+        FLOGE("Open: VIDIOC_S_FMT Failed: %s", strerror(errno));
+        return ret;
+    }
+
+    return ret;
+}
+
+int DeviceAdapter::getFrameSize()
+{
+    return mBufferSize;
+}
+
+int DeviceAdapter::getFrameCount()
+{
+    return mBufferCount;
+}
+
+status_t DeviceAdapter::registerCameraBuffers(CameraFrame *pBuffer,
+                                             int        & num)
+{
+    status_t ret = NO_ERROR;
+
+    if ((pBuffer == NULL) || (num <= 0)) {
+        FLOGE("requestCameraBuffers invalid pBuffer");
+        return BAD_VALUE;
+    }
+
+    mVideoInfo->rb.type   = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    mVideoInfo->rb.memory = V4L2_MEMORY_USERPTR;
+    mVideoInfo->rb.count  = num;
+
+    ret = ioctl(mCameraHandle, VIDIOC_REQBUFS, &mVideoInfo->rb);
+    if (ret < 0) {
+        FLOGE("VIDIOC_REQBUFS failed: %s", strerror(errno));
+        return ret;
+    }
+
+    for (int i = 0; i < num; i++) {
+        CameraFrame *buffer = pBuffer + i;
+        memset(&mVideoInfo->buf, 0, sizeof(struct v4l2_buffer));
+        mVideoInfo->buf.index    = i;
+        mVideoInfo->buf.type     = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        mVideoInfo->buf.memory   = V4L2_MEMORY_USERPTR;
+        mVideoInfo->buf.m.offset = buffer->mPhyAddr;
+        mVideoInfo->buf.length   = buffer->mSize;
+
+        ret = ioctl(mCameraHandle, VIDIOC_QUERYBUF, &mVideoInfo->buf);
+        if (ret < 0) {
+            FLOGE("Unable to query buffer (%s)", strerror(errno));
+            return ret;
+        }
+
+        // Associate each Camera buffer
+        buffer->setObserver(this);
+        mDeviceBufs[i] = buffer;
+    }
+
+    mBufferSize  = pBuffer->mSize;
+    mBufferCount = num;
+
+    return ret;
+}
+
+status_t DeviceAdapter::fillCameraFrame(CameraFrame *frame)
+{
+    status_t ret = NO_ERROR;
+
+    if (!mVideoInfo->isStreamOn) {
+        return NO_ERROR;
+    }
+
+    int i = frame->mIndex;
+    if (i < 0) {
+        return BAD_VALUE;
+    }
+
+    struct v4l2_buffer cfilledbuffer;
+    memset(&cfilledbuffer, 0, sizeof (struct v4l2_buffer));
+    cfilledbuffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    cfilledbuffer.memory = V4L2_MEMORY_USERPTR;
+    cfilledbuffer.index    = i;
+    cfilledbuffer.m.offset = frame->mPhyAddr;
+
+    ret = ioctl(mCameraHandle, VIDIOC_QBUF, &cfilledbuffer);
+    if (ret < 0) {
+        FLOGE("fillCameraFrame: VIDIOC_QBUF Failed");
+        return BAD_VALUE;
+    }
+    mQueued++;
+
+    return ret;
+}
+
+status_t DeviceAdapter::startDeviceLocked()
+{
+    status_t ret = NO_ERROR;
+
+    fAssert(mBufferProvider != NULL);
+
+    int state;
+    for (int i = 0; i < mBufferCount; i++) {
+        CameraFrame* frame = mDeviceBufs[i];
+        state = frame->getState();
+        if (state != CameraFrame::BUFS_FREE) {
+            continue;
+        }
+        frame->setState(CameraFrame::BUFS_IN_DRIVER);
+
+        mVideoInfo->buf.index    = i;
+        mVideoInfo->buf.type     = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        mVideoInfo->buf.memory   = V4L2_MEMORY_USERPTR;
+        mVideoInfo->buf.m.offset = frame->mPhyAddr;
+
+        ret = ioctl(mCameraHandle, VIDIOC_QBUF, &mVideoInfo->buf);
+        if (ret < 0) {
+            FLOGE("VIDIOC_QBUF Failed");
+            return BAD_VALUE;
+        }
+
+        mQueued++;
+    }
+
+    enum v4l2_buf_type bufType;
+    if (!mVideoInfo->isStreamOn) {
+        bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+
+        ret = ioctl(mCameraHandle, VIDIOC_STREAMON, &bufType);
+        if (ret < 0) {
+            FLOGE("VIDIOC_STREAMON failed: %s", strerror(errno));
+            return ret;
+        }
+
+        mVideoInfo->isStreamOn = true;
+    }
+
+    mDeviceThread = new DeviceThread(this);
+
+    FLOGI("Created device thread");
+    return ret;
+}
+
+status_t DeviceAdapter::stopDeviceLocked()
+{
+    status_t ret = NO_ERROR;
+    enum v4l2_buf_type bufType;
+
+    mDeviceThread->requestExitAndWait();
+    mDeviceThread.clear();
+
+    if (mVideoInfo->isStreamOn) {
+        bufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+
+        ret = ioctl(mCameraHandle, VIDIOC_STREAMOFF, &bufType);
+        if (ret < 0) {
+            FLOGE("StopStreaming: Unable to stop capture: %s", strerror(errno));
+            return ret;
+        }
+
+        mVideoInfo->isStreamOn = false;
+    }
+
+    mQueued   = 0;
+    mDequeued = 0;
+    memset(mDeviceBufs, 0, sizeof(mDeviceBufs));
+
+    return ret;
+}
+
+status_t DeviceAdapter::startPreview()
+{
+    status_t ret = NO_ERROR;
+
+    if (mPreviewing) {
+        FLOGE("DeviceAdapter: startPreview but preview running");
+        return BAD_VALUE;
+    }
+
+    Mutex::Autolock lock(mBufsLock);
+    ret = startDeviceLocked();
+
+    mPreviewing = true;
+
+    return ret;
+}
+
+status_t DeviceAdapter::stopPreview()
+{
+    int ret = NO_ERROR;
+
+    if (!mPreviewing) {
+        FLOGE("DeviceAdapter: stopPreview but preview not running");
+        return NO_INIT;
+    }
+
+    Mutex::Autolock lock(mBufsLock);
+    mPreviewing = false;
+    ret         = stopDeviceLocked();
+
+    return ret;
+}
+
+status_t DeviceAdapter::startImageCapture()
+{
+    status_t ret = NO_ERROR;
+
+    if (mImageCapture) {
+        FLOGE("DeviceAdapter: startPreview but preview running");
+        return BAD_VALUE;
+    }
+
+    Mutex::Autolock lock(mBufsLock);
+    mImageCapture = true;
+    ret           = startDeviceLocked();
+
+    return ret;
+}
+
+status_t DeviceAdapter::stopImageCapture()
+{
+    int ret = NO_ERROR;
+
+    if (!mImageCapture) {
+        FLOGE("DeviceAdapter: stopPreview but preview not running");
+        return NO_INIT;
+    }
+
+    Mutex::Autolock lock(mBufsLock);
+    mImageCapture = false;
+    ret           = stopDeviceLocked();
+
+    return ret;
+}
+
+CameraFrame * DeviceAdapter::acquireCameraFrame()
+{
+    int ret;
+
+    struct v4l2_buffer cfilledbuffer;
+    memset(&cfilledbuffer, 0, sizeof (cfilledbuffer));
+    cfilledbuffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    cfilledbuffer.memory = V4L2_MEMORY_USERPTR;
+
+    /* DQ */
+    ret = ioctl(mCameraHandle, VIDIOC_DQBUF, &cfilledbuffer);
+    if (ret < 0) {
+        FLOGE("GetFrame: VIDIOC_DQBUF Failed");
+        return NULL;
+    }
+    mDequeued++;
+
+    int index = cfilledbuffer.index;
+    fAssert(index >= 0 && index < mBufferCount);
+    mDeviceBufs[index]->mTimeStamp = systemTime();
+
+    return mDeviceBufs[index];
+}
+
+// #define FSL_CAMERAHAL_DUMP
+static void bufferDump(CameraFrame *frame)
+{
+#ifdef FSL_CAMERAHAL_DUMP
+
+    // for test code
+    char value[100];
+    memset(value, 0, sizeof(value));
+    static int vflg = 0;
+    property_get("rw.camera.test", value, "");
+    if (strcmp(value, "1") == 0)
+        vflg = 1;
+    if (vflg) {
+        FILE *pf = NULL;
+        pf = fopen("/sdcard/camera_tst.data", "wb");
+        if (pf == NULL) {
+            FLOGI("open /sdcard/camera_tst.data failed");
+        }
+        else {
+            FLOGI("-----write-----");
+            fwrite(frame->mVirtAddr, frame->mSize, 1, pf);
+            fclose(pf);
+        }
+        vflg = 0;
+    }
+#endif // ifdef FSL_CAMERAHAL_DUMP
+}
+
+int DeviceAdapter::deviceThread()
+{
+    CameraFrame *frame = NULL;
+
+    frame = acquireCameraFrame();
+    if (!frame) {
+        if (mQueued - mDequeued <= 0) {
+            // if stop preview, then exit.
+            if (!mPreviewing) {
+                FLOGI("preview stop, so exit device thread");
+                return BAD_VALUE;
+            }
+            else {
+                // to check buffer in another cycle.
+                FLOGI("no buffer in v4l driver, check it next time");
+                return NO_ERROR;
+            }
+        }
+        FLOGE("device thread exit with frame = null, %d buffers still in v4l",
+              mQueued - mDequeued);
+        if (mErrorListener != NULL) {
+            mErrorListener->handleError(CAMERA2_MSG_ERROR_DEVICE);
+        }
+        return BAD_VALUE;
+    }
+
+    if (mImageCapture) {
+        sp<CameraEvent> cameraEvt = new CameraEvent();
+        cameraEvt->mEventType = CameraEvent::EVENT_SHUTTER;
+        dispatchEvent(cameraEvt);
+
+        frame->mFrameType = CameraFrame::IMAGE_FRAME;
+    }
+    else {
+        frame->mFrameType = CameraFrame::PREVIEW_FRAME;
+    }
+
+    dispatchCameraFrame(frame);
+    if (mImageCapture || !mPreviewing) {
+        FLOGI("device thread exit...");
+        return ALREADY_EXISTS;
+    }
+
+    return NO_ERROR;
+}
+
+status_t DeviceAdapter::autoFocus()
+{
+    if (mAutoFocusThread != NULL) {
+        mAutoFocusThread.clear();
+    }
+
+    mAutoFocusThread = new AutoFocusThread(this);
+    if (mAutoFocusThread == NULL) {
+        return UNKNOWN_ERROR;
+    }
+    return NO_ERROR;
+}
+
+status_t DeviceAdapter::cancelAutoFocus()
+{
+    return NO_ERROR;
+}
+
+int DeviceAdapter::autoFocusThread()
+{
+    sp<CameraEvent> cameraEvt = new CameraEvent();
+    cameraEvt->mEventType = CameraEvent::EVENT_FOCUS;
+    dispatchEvent(cameraEvt);
+
+    // exit the thread.
+    return UNKNOWN_ERROR;
+}
+
+void DeviceAdapter::handleFrameRelease(CameraFrame *buffer)
+{
+    if (mPreviewing) {
+        fillCameraFrame(buffer);
+    }
+}
+
+void DeviceAdapter::setErrorListener(CameraErrorListener *listener)
+{
+    mErrorListener = listener;
+}
+
+void DeviceAdapter::setCameraBufferProvide(CameraBufferProvider *bufferProvider)
+{
+    if (bufferProvider != NULL) {
+        bufferProvider->addBufferListener(this);
+    }
+    mBufferProvider = bufferProvider;
+}
+
+void DeviceAdapter::onBufferCreat(CameraFrame *pBuffer,
+                                  int          num)
+{
+    registerCameraBuffers(pBuffer, num);
+}
+
+void DeviceAdapter::onBufferDestroy()
+{
+    memset(mDeviceBufs, 0, sizeof(mDeviceBufs));
+}
+
diff --git a/mx6/libcamera2/DeviceAdapter.h b/mx6/libcamera2/DeviceAdapter.h
new file mode 100755
index 0000000..d2ec8a8
--- /dev/null
+++ b/mx6/libcamera2/DeviceAdapter.h
@@ -0,0 +1,165 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _DEVICE_ADAPTER_H_
+#define _DEVICE_ADAPTER_H_
+
+#include "CameraUtil.h"
+
+using namespace android;
+
+class DeviceAdapter : public CameraFrameProvider,
+                      public CameraBufferListener,
+                      public CameraEventProvider,
+                      public CameraFrameObserver,
+                      public SensorInfo,
+                      public LightRefBase<DeviceAdapter>
+{
+public:
+    static sp<DeviceAdapter> Create(const CameraInfo& info);
+    DeviceAdapter();
+    ~DeviceAdapter();
+
+public:
+    virtual int      getFrameSize();
+    virtual int      getFrameCount();
+
+    void             setErrorListener(CameraErrorListener *listener);
+    void             setCameraBufferProvide(CameraBufferProvider *bufferProvider);
+    virtual status_t initialize(const CameraInfo& info);
+    status_t         setDeviceConfig(int         width,
+                                     int         height,
+                                     PixelFormat format,
+                                     int         fps);
+    PixelFormat getPreviewPixelFormat() {
+        return mPreviewPixelFormat;
+    }
+
+    PixelFormat getPicturePixelFormat() {
+        return mPicturePixelFormat;
+    }
+
+    virtual status_t initSensorInfo() = 0;
+    virtual int getCaptureMode(int width, int height) {return 0;}
+    PixelFormat getMatchFormat(int *sfmt, int  slen,
+                               int *dfmt, int  dlen);
+    void setMetadaManager(sp<MetadaManager> &metadaManager);
+    void setPreviewPixelFormat();
+    void setPicturePixelFormat();
+
+    status_t         autoFocus();
+    status_t         cancelAutoFocus();
+
+    virtual status_t startPreview();
+    virtual status_t stopPreview();
+
+    virtual status_t startImageCapture();
+    virtual status_t stopImageCapture();
+
+protected:
+    void             onBufferCreat(CameraFrame *pBuffer,
+                                   int          num);
+    void             onBufferDestroy();
+    virtual status_t registerCameraBuffers(CameraFrame *pBuffer,
+                                          int        & num);
+    virtual void     handleFrameRelease(CameraFrame *buffer);
+
+private:
+    class AutoFocusThread : public Thread {
+    public:
+        AutoFocusThread(DeviceAdapter *hw) :
+            Thread(false), mAdapter(hw) {}
+
+        virtual void onFirstRef() {
+            run("AutoFocusThread", PRIORITY_URGENT_DISPLAY);
+        }
+
+        virtual bool threadLoop() {
+            int ret = 0;
+
+            ret = mAdapter->autoFocusThread();
+            if (ret != 0) {
+                return false;
+            }
+
+            // loop until we need to quit
+            return true;
+        }
+
+    private:
+        DeviceAdapter *mAdapter;
+    };
+
+    class DeviceThread : public Thread {
+    public:
+        DeviceThread(DeviceAdapter *hw) :
+            Thread(false), mAdapter(hw) {}
+
+        virtual void onFirstRef() {
+            run("DeviceThread", PRIORITY_URGENT_DISPLAY);
+        }
+
+        virtual bool threadLoop() {
+            int ret = 0;
+
+            ret = mAdapter->deviceThread();
+            if (ret != 0) {
+                return false;
+            }
+
+            // loop until we need to quit
+            return true;
+        }
+
+    private:
+        DeviceAdapter *mAdapter;
+    };
+
+private:
+    status_t     fillCameraFrame(CameraFrame *frame);
+    CameraFrame* acquireCameraFrame();
+
+    status_t     startDeviceLocked();
+    status_t     stopDeviceLocked();
+    int          deviceThread();
+    int          autoFocusThread();
+
+protected:
+    CameraBufferProvider *mBufferProvider;
+    CameraErrorListener  *mErrorListener;
+    int mBufferCount;
+    int mBufferSize;
+    CameraFrame* mDeviceBufs[MAX_PREVIEW_BUFFER];
+    mutable Mutex mBufsLock;
+
+    mutable Mutex mLock;
+    CameraParameters mParams;
+    bool mPreviewing;
+    bool mImageCapture;
+    sp<DeviceThread> mDeviceThread;
+    sp<AutoFocusThread> mAutoFocusThread;
+
+    struct VideoInfo *mVideoInfo;
+    int mCameraHandle;
+    int mQueued;
+    int mDequeued;
+
+    PixelFormat mPicturePixelFormat;
+    PixelFormat mPreviewPixelFormat;
+    sp<MetadaManager> mMetadaManager;
+};
+
+#endif // ifndef _DEVICE_ADAPTER_H_
diff --git a/mx6/libcamera2/JpegBuilder.cpp b/mx6/libcamera2/JpegBuilder.cpp
new file mode 100755
index 0000000..d89243f
--- /dev/null
+++ b/mx6/libcamera2/JpegBuilder.cpp
@@ -0,0 +1,667 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "CameraHAL"
+
+#include <stdlib.h>
+#include <unistd.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <stdio.h>
+#include <errno.h>
+#include <math.h>
+
+#include "JpegBuilder.h"
+
+extern "C" {
+    #include "jpeglib.h"
+    #include "jerror.h"
+}
+
+namespace android {
+struct string_pair {
+    const char *string1;
+    const char *string2;
+};
+
+static string_pair degress_to_exif_lut[] = {
+    // degrees, exif_orientation
+    { "0",   "1"     },
+    { "90",  "6"     },
+    { "180", "3"     },
+    { "270", "8"     },
+};
+
+/* public static functions */
+const char * JpegBuilder::degreesToExifOrientation(const char *degrees) {
+    for (unsigned int i = 0; i < ARRAY_SIZE(degress_to_exif_lut); i++) {
+        if (!strcmp(degrees, degress_to_exif_lut[i].string1)) {
+            return degress_to_exif_lut[i].string2;
+        }
+    }
+    return NULL;
+}
+
+void JpegBuilder::stringToRational(const char   *str,
+                                   unsigned int *num,
+                                   unsigned int *den) {
+    int   len;
+    char *tempVal = NULL;
+
+    if (str != NULL) {
+        len     = strlen(str);
+        tempVal = (char *)malloc(sizeof(char) * (len + 1));
+    }
+
+    if (tempVal != NULL) {
+        // convert the decimal string into a rational
+        size_t den_len;
+        char  *ctx;
+        unsigned int numerator   = 0;
+        unsigned int denominator = 0;
+        char *temp               = NULL;
+
+        memset(tempVal, '\0', len + 1);
+        strncpy(tempVal, str, len);
+        temp = strtok_r(tempVal, ".", &ctx);
+
+        if (temp != NULL)
+            numerator = atoi(temp);
+
+        if (!numerator)
+            numerator = 1;
+
+        temp = strtok_r(NULL, ".", &ctx);
+        if (temp != NULL) {
+            den_len = strlen(temp);
+            if (HUGE_VAL == den_len) {
+                den_len = 0;
+            }
+
+            denominator = static_cast<unsigned int>(pow(10, den_len));
+            numerator   = numerator * denominator + atoi(temp);
+        }
+        else {
+            denominator = 1;
+        }
+
+        free(tempVal);
+
+        *num = numerator;
+        *den = denominator;
+    }
+}
+
+bool JpegBuilder::isAsciiTag(const char *tag) {
+    // TODO(XXX): Add tags as necessary
+    return (strcmp(tag, TAG_GPS_PROCESSING_METHOD) == 0);
+}
+
+void JpegBuilder::insertExifToJpeg(unsigned char *jpeg,
+                                   size_t         jpeg_size) {
+    ReadMode_t read_mode = (ReadMode_t)(READ_METADATA | READ_IMAGE);
+
+    ResetJpgfile();
+    if (ReadJpegSectionsFromBuffer(jpeg, jpeg_size, read_mode)) {
+        jpeg_opened = true;
+        create_EXIF(table, exif_tag_count, gps_tag_count, has_datetime_tag);
+    }
+}
+
+status_t JpegBuilder::insertExifThumbnailImage(const char *thumb,
+                                               int         len) {
+    status_t ret = NO_ERROR;
+
+    if ((len > 0) && jpeg_opened) {
+        ret = ReplaceThumbnailFromBuffer(thumb, len);
+        FLOGI("insertExifThumbnailImage. ReplaceThumbnail(). ret=%d", ret);
+    }
+
+    return ret;
+}
+
+void JpegBuilder::saveJpeg(unsigned char *jpeg,
+                           size_t         jpeg_size) {
+    if (jpeg_opened) {
+        WriteJpegToBuffer(jpeg, jpeg_size);
+        DiscardData();
+        jpeg_opened = false;
+    }
+}
+
+status_t JpegBuilder::insertElement(const char *tag,
+                                    const char *value) {
+    int value_length = 0;
+    status_t ret     = NO_ERROR;
+
+    if (!value || !tag) {
+        return -EINVAL;
+    }
+
+    if (position >= MAX_EXIF_TAGS_SUPPORTED) {
+        FLOGE("Max number of EXIF elements already inserted");
+        return NO_MEMORY;
+    }
+
+    if (isAsciiTag(tag)) {
+        value_length = sizeof(ExifAsciiPrefix) +
+                       strlen(value + sizeof(ExifAsciiPrefix));
+    }
+    else {
+        value_length = strlen(value);
+    }
+
+    if (IsGpsTag(tag)) {
+        table[position].GpsTag = TRUE;
+        table[position].Tag    = GpsTagNameToValue(tag);
+        gps_tag_count++;
+    }
+    else {
+        table[position].GpsTag = FALSE;
+        table[position].Tag    = TagNameToValue(tag);
+        exif_tag_count++;
+
+        if (strcmp(tag, TAG_DATETIME) == 0) {
+            has_datetime_tag = true;
+        }
+    }
+
+    table[position].DataLength = 0;
+    table[position].Value      = (char *)malloc(sizeof(char) * (value_length + 1));
+
+    if (table[position].Value) {
+        memcpy(table[position].Value, value, value_length + 1);
+        table[position].DataLength = value_length + 1;
+    }
+
+    position++;
+    return ret;
+}
+
+JpegBuilder::JpegBuilder()
+    : gps_tag_count(0), exif_tag_count(0), position(0),
+      jpeg_opened(false), has_datetime_tag(false)
+{
+    reset();
+}
+
+void JpegBuilder::reset()
+{
+    gps_tag_count    = 0;
+    exif_tag_count   = 0;
+    position         = 0;
+    jpeg_opened      = false;
+    has_datetime_tag = false;
+    mMainInput       = NULL;
+    mThumbnailInput  = NULL;
+    mCancelEncoding  = false;
+    memset(&mEXIFData, 0, sizeof(mEXIFData));
+    memset(&table, 0, sizeof(table));
+}
+
+JpegBuilder::~JpegBuilder()
+{
+    int num_elements = gps_tag_count + exif_tag_count;
+
+    for (int i = 0; i < num_elements; i++) {
+        if (table[i].Value) {
+            free(table[i].Value);
+        }
+    }
+
+    if (jpeg_opened) {
+        DiscardData();
+    }
+}
+
+status_t JpegBuilder::prepareImage(const StreamBuffer *streamBuf)
+{
+    status_t ret = NO_ERROR;
+    int eError   = 0;
+    struct timeval sTv;
+    struct tm     *pTime;
+
+    if ((NO_ERROR == ret) && (mEXIFData.mModelValid)) {
+        ret = insertElement(TAG_MODEL, EXIF_MODEL);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mMakeValid)) {
+        ret = insertElement(TAG_MAKE, EXIF_MAKENOTE);
+    }
+
+    float focalLength;
+    ret = mMetadaManager->getFocalLength(focalLength);
+    if ((NO_ERROR == ret)) {
+        char str[16];  // 14 should be enough. We overestimate to be safe.
+        snprintf(str, sizeof(str), "%g", focalLength);
+        unsigned int numerator = 0, denominator = 0;
+        JpegBuilder::stringToRational(str, &numerator, &denominator);
+        if (numerator || denominator) {
+            char temp_value[256]; // arbitrarily long string
+            snprintf(temp_value,
+                     sizeof(temp_value) / sizeof(char),
+                     "%u/%u", numerator, denominator);
+            ret = insertElement(TAG_FOCALLENGTH, temp_value);
+        }
+    }
+
+    if ((NO_ERROR == ret)) {
+        int status = gettimeofday(&sTv, NULL);
+        pTime = gmtime(&sTv.tv_sec);
+        char temp_value[EXIF_DATE_TIME_SIZE + 1];
+        if ((0 == status) && (NULL != pTime)) {
+            snprintf(temp_value, EXIF_DATE_TIME_SIZE,
+                     "%04d:%02d:%02d %02d:%02d:%02d",
+                     pTime->tm_year + 1900,
+                     pTime->tm_mon + 1,
+                     pTime->tm_mday,
+                     pTime->tm_hour,
+                     pTime->tm_min,
+                     pTime->tm_sec);
+
+            ret = insertElement(TAG_DATETIME, temp_value);
+        }
+    }
+
+    int width, height;
+    fAssert(streamBuf != NULL);
+    width = streamBuf->mWidth;
+    height = streamBuf->mHeight;
+    if ((NO_ERROR == ret)) {
+        char temp_value[5];
+        snprintf(temp_value, sizeof(temp_value) / sizeof(char), "%lu",
+                 (unsigned long)width);
+        ret = insertElement(TAG_IMAGE_WIDTH, temp_value);
+    }
+
+    if ((NO_ERROR == ret)) {
+        char temp_value[5];
+        snprintf(temp_value, sizeof(temp_value) / sizeof(char), "%lu",
+                 (unsigned long)height);
+        ret = insertElement(TAG_IMAGE_LENGTH, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLatValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d/%d,%d/%d,%d/%d",
+                 abs(mEXIFData.mGPSData.mLatDeg), 1,
+                 abs(mEXIFData.mGPSData.mLatMin), 1,
+                 abs(mEXIFData.mGPSData.mLatSec),
+                 abs(mEXIFData.mGPSData.mLatSecDiv));
+        ret = insertElement(TAG_GPS_LAT, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLatValid)) {
+        ret = insertElement(TAG_GPS_LAT_REF, mEXIFData.mGPSData.mLatRef);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLongValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d/%d,%d/%d,%d/%d",
+                 abs(mEXIFData.mGPSData.mLongDeg), 1,
+                 abs(mEXIFData.mGPSData.mLongMin), 1,
+                 abs(mEXIFData.mGPSData.mLongSec),
+                 abs(mEXIFData.mGPSData.mLongSecDiv));
+        ret = insertElement(TAG_GPS_LONG, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mLongValid)) {
+        ret = insertElement(TAG_GPS_LONG_REF, mEXIFData.mGPSData.mLongRef);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mAltitudeValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d/%d",
+                 abs(mEXIFData.mGPSData.mAltitude), 1);
+        ret = insertElement(TAG_GPS_ALT, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mAltitudeValid)) {
+        char temp_value[5];
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d", mEXIFData.mGPSData.mAltitudeRef);
+        ret = insertElement(TAG_GPS_ALT_REF, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mMapDatumValid)) {
+        ret = insertElement(TAG_GPS_MAP_DATUM, mEXIFData.mGPSData.mMapDatum);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mProcMethodValid)) {
+        char temp_value[GPS_PROCESSING_SIZE];
+        memcpy(temp_value, ExifAsciiPrefix, sizeof(ExifAsciiPrefix));
+        memcpy(temp_value + sizeof(ExifAsciiPrefix),
+               mEXIFData.mGPSData.mProcMethod,
+               (GPS_PROCESSING_SIZE - sizeof(ExifAsciiPrefix)));
+        ret = insertElement(TAG_GPS_PROCESSING_METHOD, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mVersionIdValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d,%d,%d,%d",
+                 mEXIFData.mGPSData.mVersionId[0],
+                 mEXIFData.mGPSData.mVersionId[1],
+                 mEXIFData.mGPSData.mVersionId[2],
+                 mEXIFData.mGPSData.mVersionId[3]);
+        ret = insertElement(TAG_GPS_VERSION_ID, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mTimeStampValid)) {
+        char temp_value[256]; // arbitrarily long string
+        snprintf(temp_value,
+                 sizeof(temp_value) / sizeof(char) - 1,
+                 "%d/%d,%d/%d,%d/%d",
+                 mEXIFData.mGPSData.mTimeStampHour, 1,
+                 mEXIFData.mGPSData.mTimeStampMin, 1,
+                 mEXIFData.mGPSData.mTimeStampSec, 1);
+        ret = insertElement(TAG_GPS_TIMESTAMP, temp_value);
+    }
+
+    if ((NO_ERROR == ret) && (mEXIFData.mGPSData.mDatestampValid)) {
+        ret = insertElement(TAG_GPS_DATESTAMP, mEXIFData.mGPSData.mDatestamp);
+    }
+
+    int32_t jpegRotation;
+    ret = mMetadaManager->getJpegRotation(jpegRotation);
+    if (NO_ERROR == ret) {
+        char str[16];
+        snprintf(str, sizeof(str), "%d", jpegRotation);
+        const char *exif_orient =
+            JpegBuilder::degreesToExifOrientation(str);
+
+        if (exif_orient) {
+            ret = insertElement(TAG_ORIENTATION, exif_orient);
+        }
+    }
+
+    return ret;
+}
+
+void JpegBuilder::setMetadaManager(sp<MetadaManager> &metadaManager)
+{
+    mMetadaManager = metadaManager;
+    if (metadaManager.get() == NULL) {
+        return;
+    }
+
+    status_t ret = NO_ERROR;
+
+    double gpsCoordinates[3];
+    ret = mMetadaManager->getGpsCoordinates(gpsCoordinates, 3);
+    if (ret == 0) {
+        double gpsPos = gpsCoordinates[0];
+        if (convertGPSCoord(gpsPos,
+                            mEXIFData.mGPSData.mLatDeg,
+                            mEXIFData.mGPSData.mLatMin,
+                            mEXIFData.mGPSData.mLatSec,
+                            mEXIFData.mGPSData.mLatSecDiv) == NO_ERROR) {
+            if (0 < gpsPos) {
+                strncpy(mEXIFData.mGPSData.mLatRef, GPS_NORTH_REF, GPS_REF_SIZE);
+            }
+            else {
+                strncpy(mEXIFData.mGPSData.mLatRef, GPS_SOUTH_REF, GPS_REF_SIZE);
+            }
+
+            mEXIFData.mGPSData.mLatValid = true;
+        }
+        else {
+            mEXIFData.mGPSData.mLatValid = false;
+        }
+
+        gpsPos = gpsCoordinates[1];
+        if (convertGPSCoord(gpsPos,
+                            mEXIFData.mGPSData.mLongDeg,
+                            mEXIFData.mGPSData.mLongMin,
+                            mEXIFData.mGPSData.mLongSec,
+                            mEXIFData.mGPSData.mLongSecDiv) == NO_ERROR) {
+            if (0 < gpsPos) {
+                strncpy(mEXIFData.mGPSData.mLongRef, GPS_EAST_REF, GPS_REF_SIZE);
+            }
+            else {
+                strncpy(mEXIFData.mGPSData.mLongRef, GPS_WEST_REF, GPS_REF_SIZE);
+            }
+
+            mEXIFData.mGPSData.mLongValid = true;
+        }
+        else {
+            mEXIFData.mGPSData.mLongValid = false;
+        }
+
+        gpsPos = gpsCoordinates[2];
+        mEXIFData.mGPSData.mAltitude = floor(fabs(gpsPos));
+        if (gpsPos < 0) {
+            mEXIFData.mGPSData.mAltitudeRef = 1;
+        }
+        else {
+            mEXIFData.mGPSData.mAltitudeRef = 0;
+        }
+        mEXIFData.mGPSData.mAltitudeValid = true;
+    }
+    else {
+        mEXIFData.mGPSData.mLatValid = false;
+        mEXIFData.mGPSData.mLongValid = false;
+        mEXIFData.mGPSData.mAltitudeValid = false;
+    }
+
+    int64_t gpsTimestamp;
+    ret = mMetadaManager->getGpsTimeStamp(gpsTimestamp);
+    if (ret == 0) {
+        struct tm *timeinfo = gmtime((time_t *)&(gpsTimestamp));
+        if (NULL != timeinfo) {
+            mEXIFData.mGPSData.mTimeStampHour  = timeinfo->tm_hour;
+            mEXIFData.mGPSData.mTimeStampMin   = timeinfo->tm_min;
+            mEXIFData.mGPSData.mTimeStampSec   = timeinfo->tm_sec;
+            mEXIFData.mGPSData.mTimeStampValid = true;
+        }
+        else {
+            mEXIFData.mGPSData.mTimeStampValid = false;
+        }
+
+        long gpsDatestamp = gpsTimestamp;
+        timeinfo = gmtime((time_t *)&(gpsDatestamp));
+        if (NULL != timeinfo) {
+            strftime(mEXIFData.mGPSData.mDatestamp,
+                     GPS_DATESTAMP_SIZE,
+                     "%Y:%m:%d",
+                     timeinfo);
+            mEXIFData.mGPSData.mDatestampValid = true;
+        }
+        else {
+            mEXIFData.mGPSData.mDatestampValid = false;
+        }
+    }
+    else {
+        mEXIFData.mGPSData.mTimeStampValid = false;
+        mEXIFData.mGPSData.mDatestampValid = false;
+    }
+
+    uint8_t gpsProcessingMethod[GPS_PROCESSING_SIZE];
+    ret = mMetadaManager->getGpsProcessingMethod(gpsProcessingMethod, GPS_PROCESSING_SIZE);
+    if (ret == 0) {
+        memset(mEXIFData.mGPSData.mProcMethod, 0, GPS_PROCESSING_SIZE);
+        strncpy(mEXIFData.mGPSData.mProcMethod, (const char*)gpsProcessingMethod, GPS_PROCESSING_SIZE - 1);
+        mEXIFData.mGPSData.mProcMethodValid = true;
+    }
+    else {
+        mEXIFData.mGPSData.mProcMethodValid = false;
+    }
+
+    mEXIFData.mGPSData.mMapDatumValid  = false;
+    mEXIFData.mGPSData.mVersionIdValid = false;
+    mEXIFData.mModelValid              = true;
+    mEXIFData.mMakeValid               = true;
+}
+
+status_t JpegBuilder::encodeImage(JpegParams *mainJpeg,
+                                  JpegParams *thumbNail)
+{
+    status_t ret = NO_ERROR;
+
+    mMainInput      = mainJpeg;
+    mThumbnailInput = thumbNail;
+    if (thumbNail) {
+        ret = encodeJpeg(thumbNail);
+    }
+
+    if (ret != NO_ERROR) {
+        FLOGE("%s encodeJpeg failed", __FUNCTION__);
+        return ret;
+    }
+
+    return encodeJpeg(mainJpeg);
+}
+
+status_t JpegBuilder::encodeJpeg(JpegParams *input)
+{
+    PixelFormat format = input->format;
+    YuvToJpegEncoder *encoder = YuvToJpegEncoder::create(format);
+
+    if (encoder == NULL) {
+        FLOGE("%s YuvToJpegEncoder::create failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    int res = 0;
+    res = encoder->encode(input->src,
+                          input->in_width,
+                          input->in_height,
+                          input->quality,
+                          input->dst,
+                          input->dst_size,
+                          input->out_width,
+                          input->out_height);
+
+    delete encoder;
+    if (res) {
+        input->jpeg_size = res;
+        return NO_ERROR;
+    }
+    else {
+        return BAD_VALUE;
+    }
+}
+
+size_t JpegBuilder::getImageSize()
+{
+    size_t jpeg_size, image_size;
+    Section_t *exif_section = NULL;
+
+    jpeg_size = mMainInput->jpeg_size;
+
+    exif_section = FindSection(M_EXIF);
+    if (exif_section != NULL) {
+        image_size = jpeg_size + exif_section->Size;
+    }
+    else {
+        image_size = jpeg_size;
+    }
+    return image_size;
+}
+
+status_t JpegBuilder::buildImage(const StreamBuffer *streamBuf)
+{
+    size_t   jpeg_size;
+    uint8_t *src  = NULL;
+
+    if (!streamBuf || !mMainInput || !streamBuf->mVirtAddr) {
+        FLOGE("%s invalid param", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    jpeg_size = mMainInput->jpeg_size;
+    src       = mMainInput->src;
+
+    if (mMainInput->dst && (jpeg_size > 0)) {
+        if (position > 0) {
+            Section_t *exif_section = NULL;
+
+            insertExifToJpeg((unsigned char *)mMainInput->dst, jpeg_size);
+
+            if (mThumbnailInput) {
+                insertExifThumbnailImage((const char *)mThumbnailInput->dst,
+                                         (int)mThumbnailInput->jpeg_size);
+            }
+
+            exif_section = FindSection(M_EXIF);
+            if (exif_section) {
+                size_t imageSize = jpeg_size + exif_section->Size;
+                if (streamBuf->mSize < imageSize) {
+                    FLOGE("%s buf size %d small than %d", __FUNCTION__,
+                                    streamBuf->mSize, imageSize);
+                    return BAD_VALUE;
+                }
+
+                saveJpeg((unsigned char *)streamBuf->mVirtAddr,
+                         jpeg_size + exif_section->Size);
+            }
+        } else {
+            size_t imageSize = jpeg_size;
+            if (streamBuf->mSize < imageSize) {
+                FLOGE("%s buf size %d small than %d", __FUNCTION__,
+                                    streamBuf->mSize, imageSize);
+                return BAD_VALUE;
+            }
+            memcpy(streamBuf->mVirtAddr, mMainInput->dst, jpeg_size);
+        }
+    }
+
+    return NO_ERROR;
+}
+
+status_t JpegBuilder::convertGPSCoord(double coord,
+                                      int  & deg,
+                                      int  & min,
+                                      int  & sec,
+                                      int  & secDivisor)
+{
+    double tmp;
+
+    if (coord == 0) {
+        FLOGE("Invalid GPS coordinate");
+
+        return -EINVAL;
+    }
+
+    deg        = (int)floor(fabs(coord));
+    tmp        = (fabs(coord) - floor(fabs(coord))) * GPS_MIN_DIV;
+    min        = (int)floor(tmp);
+    tmp        = (tmp - floor(tmp)) * (GPS_SEC_DIV * GPS_SEC_ACCURACY);
+    sec        = (int)floor(tmp);
+    secDivisor = GPS_SEC_ACCURACY;
+
+    if (sec >= (GPS_SEC_DIV * GPS_SEC_ACCURACY)) {
+        sec  = 0;
+        min += 1;
+    }
+
+    if (min >= 60) {
+        min  = 0;
+        deg += 1;
+    }
+
+    return NO_ERROR;
+}
+};
diff --git a/mx6/libcamera2/JpegBuilder.h b/mx6/libcamera2/JpegBuilder.h
new file mode 100755
index 0000000..058083b
--- /dev/null
+++ b/mx6/libcamera2/JpegBuilder.h
@@ -0,0 +1,190 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _JPEG_BUILDER_H_
+#define _JPEG_BUILDER_H_
+
+#include "CameraUtil.h"
+#include <utils/RefBase.h>
+#include "YuvToJpegEncoder.h"
+
+extern "C" {
+#include "jhead.h"
+}
+
+namespace android {
+#define EXIF_MAKENOTE "fsl_makernote"
+#define EXIF_MODEL    "fsl_model"
+
+#define MAX_EXIF_TAGS_SUPPORTED 30
+
+static const char TAG_MODEL[]                 = "Model";
+static const char TAG_MAKE[]                  = "Make";
+static const char TAG_FOCALLENGTH[]           = "FocalLength";
+static const char TAG_DATETIME[]              = "DateTime";
+static const char TAG_IMAGE_WIDTH[]           = "ImageWidth";
+static const char TAG_IMAGE_LENGTH[]          = "ImageLength";
+static const char TAG_GPS_LAT[]               = "GPSLatitude";
+static const char TAG_GPS_LAT_REF[]           = "GPSLatitudeRef";
+static const char TAG_GPS_LONG[]              = "GPSLongitude";
+static const char TAG_GPS_LONG_REF[]          = "GPSLongitudeRef";
+static const char TAG_GPS_ALT[]               = "GPSAltitude";
+static const char TAG_GPS_ALT_REF[]           = "GPSAltitudeRef";
+static const char TAG_GPS_MAP_DATUM[]         = "GPSMapDatum";
+static const char TAG_GPS_PROCESSING_METHOD[] = "GPSProcessingMethod";
+static const char TAG_GPS_VERSION_ID[]        = "GPSVersionID";
+static const char TAG_GPS_TIMESTAMP[]         = "GPSTimeStamp";
+static const char TAG_GPS_DATESTAMP[]         = "GPSDateStamp";
+static const char TAG_ORIENTATION[]           = "Orientation";
+
+#define GPS_MIN_DIV                 60
+#define GPS_SEC_DIV                 60
+#define GPS_SEC_ACCURACY            1000
+
+#define GPS_NORTH_REF               "N"
+#define GPS_SOUTH_REF               "S"
+#define GPS_EAST_REF                "E"
+#define GPS_WEST_REF                "W"
+
+#define EXIF_DATE_TIME_SIZE         20
+
+#define GPS_DATESTAMP_SIZE          11
+#define GPS_REF_SIZE                2
+#define GPS_MAPDATUM_SIZE           100
+#define GPS_PROCESSING_SIZE         100
+#define GPS_VERSION_SIZE            4
+
+struct GPSData
+{
+    int           mLongDeg, mLongMin, mLongSec, mLongSecDiv;
+    char          mLongRef[GPS_REF_SIZE];
+    bool          mLongValid;
+    int           mLatDeg, mLatMin, mLatSec, mLatSecDiv;
+    char          mLatRef[GPS_REF_SIZE];
+    bool          mLatValid;
+    int           mAltitude;
+    unsigned char mAltitudeRef;
+    bool          mAltitudeValid;
+    char          mMapDatum[GPS_MAPDATUM_SIZE];
+    bool          mMapDatumValid;
+    char          mVersionId[GPS_VERSION_SIZE];
+    bool          mVersionIdValid;
+    char          mProcMethod[GPS_PROCESSING_SIZE];
+    bool          mProcMethodValid;
+    char          mDatestamp[GPS_DATESTAMP_SIZE];
+    bool          mDatestampValid;
+    uint32_t      mTimeStampHour;
+    uint32_t      mTimeStampMin;
+    uint32_t      mTimeStampSec;
+    bool          mTimeStampValid;
+};
+
+struct EXIFData
+{
+    GPSData mGPSData;
+    bool    mMakeValid;
+    bool    mModelValid;
+};
+
+struct JpegParams {
+    JpegParams(uint8_t *uSrc,
+               int     srcSize,
+               uint8_t *uDst,
+               int     dstSize,
+               int     quality,
+               int     inWidth,
+               int     inHeight,
+               int     outWidth,
+               int     outHeight,
+               int     format)
+        : src(uSrc), src_size(srcSize), dst(uDst), dst_size(dstSize),
+          quality(quality), in_width(inWidth), in_height(inHeight),
+          out_width(outWidth), out_height(outHeight), format(format),
+          jpeg_size(0)
+    {}
+
+    uint8_t    *src;
+    int         src_size;
+    uint8_t    *dst;
+    int         dst_size;
+    int         quality;
+    int         in_width;
+    int         in_height;
+    int         out_width;
+    int         out_height;
+    int         format;
+    size_t      jpeg_size;
+};
+
+
+class JpegBuilder : public LightRefBase<JpegBuilder>{
+public:
+    JpegBuilder();
+    ~JpegBuilder();
+
+    status_t prepareImage(const StreamBuffer *streamBuf);
+
+    status_t encodeImage(JpegParams *mainJpeg,
+                         JpegParams *thumbNail);
+    size_t   getImageSize();
+    status_t buildImage(const StreamBuffer *streamBuf);
+    void     reset();
+    void setMetadaManager(sp<MetadaManager> &metadaManager);
+
+private:
+    status_t insertElement(const char *tag,
+                           const char *value);
+    void     insertExifToJpeg(unsigned char *jpeg,
+                              size_t         jpeg_size);
+    status_t insertExifThumbnailImage(const char *,
+                                      int);
+    void     saveJpeg(unsigned char *picture,
+                      size_t         jpeg_size);
+
+private:
+    status_t    encodeJpeg(JpegParams *input);
+    const char* degreesToExifOrientation(const char *);
+    void        stringToRational(const    char *,
+                                 unsigned int *,
+                                 unsigned int *);
+    bool        isAsciiTag(const char *tag);
+    status_t    convertGPSCoord(double coord,
+                                int  & deg,
+                                int  & min,
+                                int  & sec,
+                                int  & secDivisor);
+
+private:
+    JpegParams *mMainInput;
+    JpegParams *mThumbnailInput;
+
+    bool mCancelEncoding;
+    CameraFrame::FrameType mType;
+    EXIFData mEXIFData;
+
+private:
+    ExifElement_t table[MAX_EXIF_TAGS_SUPPORTED];
+    unsigned int  gps_tag_count;
+    unsigned int  exif_tag_count;
+    unsigned int  position;
+    bool jpeg_opened;
+    bool has_datetime_tag;
+
+    sp<MetadaManager> mMetadaManager;
+};
+};
+
+#endif // ifndef _JPEG_BUILDER_H_
diff --git a/mx6/libcamera2/MetadaManager.cpp b/mx6/libcamera2/MetadaManager.cpp
new file mode 100755
index 0000000..e98d590
--- /dev/null
+++ b/mx6/libcamera2/MetadaManager.cpp
@@ -0,0 +1,901 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "MetadaManager.h"
+#include "RequestManager.h"
+
+MetadaManager::MetadaManager(SensorInfo *dev, int cameraId)
+      : mCurrentRequest(NULL), mSensorInfo(dev), mCameraId(cameraId)
+{
+    mVpuSupportFmt[0] = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    mVpuSupportFmt[1] = HAL_PIXEL_FORMAT_YCbCr_420_P;
+
+    mPictureSupportFmt[0] = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    mPictureSupportFmt[1] = HAL_PIXEL_FORMAT_YCbCr_422_I;
+}
+
+MetadaManager::~MetadaManager()
+{
+    if (mCurrentRequest != NULL) {
+        free_camera_metadata(mCurrentRequest);
+    }
+}
+
+status_t MetadaManager::getSupportedRecordingFormat(int *src, int len)
+{
+    if (src == NULL || len == 0) {
+        return BAD_VALUE;
+    }
+
+    for (int i=0; i<MAX_VPU_SUPPORT_FORMAT && i<len; i++) {
+        src[i] = mVpuSupportFmt[i];
+    }
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getSupportedPictureFormat(int *src, int len)
+{
+    if (src == NULL || len == 0) {
+        return BAD_VALUE;
+    }
+
+    for (int i=0; i<MAX_PICTURE_SUPPORT_FORMAT && i<len; i++) {
+        src[i] = mPictureSupportFmt[i];
+    }
+    return NO_ERROR;
+}
+
+status_t  MetadaManager::addOrSize(camera_metadata_t *request,
+        bool sizeRequest,
+        size_t *entryCount,
+        size_t *dataCount,
+        uint32_t tag,
+        const void *entryData,
+        size_t entryDataCount) {
+    status_t res;
+    if (!sizeRequest) {
+        return add_camera_metadata_entry(request, tag, entryData,
+                entryDataCount);
+    } else {
+        int type = get_camera_metadata_tag_type(tag);
+        if (type < 0 ) return BAD_VALUE;
+        (*entryCount)++;
+        (*dataCount) += calculate_camera_metadata_entry_data_size(type,
+                entryDataCount);
+        return OK;
+    }
+}
+
+status_t MetadaManager::createDefaultRequest(
+        int request_template,
+        camera_metadata_t **request,
+        bool sizeRequest) {
+
+    size_t entryCount = 0;
+    size_t dataCount = 0;
+    status_t ret;
+
+#define ADD_OR_SIZE( tag, data, count ) \
+    if ( ( ret = addOrSize(*request, sizeRequest, &entryCount, &dataCount, \
+            tag, data, count) ) != OK ) return ret
+
+    static const int64_t USEC = 1000LL;
+    static const int64_t MSEC = USEC * 1000LL;
+    static const int64_t SEC = MSEC * 1000LL;
+
+    /** android.request */
+
+    static const uint8_t metadataMode = ANDROID_REQUEST_METADATA_NONE;
+    ADD_OR_SIZE(ANDROID_REQUEST_METADATA_MODE, &metadataMode, 1);
+
+    static const int32_t id = 0;
+    ADD_OR_SIZE(ANDROID_REQUEST_ID, &id, 1);
+
+    static const int32_t frameCount = 0;
+    ADD_OR_SIZE(ANDROID_REQUEST_FRAME_COUNT, &frameCount, 1);
+
+    // OUTPUT_STREAMS set by user
+    entryCount += 1;
+    dataCount += 5; // TODO: Should be maximum stream number
+
+    /** android.lens */
+
+    static const float focusDistance = 0;
+    ADD_OR_SIZE(ANDROID_LENS_FOCUS_DISTANCE, &focusDistance, 1);
+
+    static float aperture = 2.8;
+    ADD_OR_SIZE(ANDROID_LENS_APERTURE, &aperture, 1);
+
+    static float focalLength = 0.0;
+    ADD_OR_SIZE(ANDROID_LENS_FOCAL_LENGTH, &focalLength, 1);
+
+    static const float filterDensity = 0;
+    ADD_OR_SIZE(ANDROID_LENS_FILTER_DENSITY, &filterDensity, 1);
+
+    static const uint8_t opticalStabilizationMode =
+            ANDROID_LENS_OPTICAL_STABILIZATION_OFF;
+    ADD_OR_SIZE(ANDROID_LENS_OPTICAL_STABILIZATION_MODE,
+            &opticalStabilizationMode, 1);
+
+
+    /** android.sensor */
+
+
+    static const int64_t frameDuration = 33333333L; // 1/30 s
+    ADD_OR_SIZE(ANDROID_SENSOR_FRAME_DURATION, &frameDuration, 1);
+
+
+    /** android.flash */
+
+    static const uint8_t flashMode = ANDROID_FLASH_OFF;
+    ADD_OR_SIZE(ANDROID_FLASH_MODE, &flashMode, 1);
+
+    static const uint8_t flashPower = 10;
+    ADD_OR_SIZE(ANDROID_FLASH_FIRING_POWER, &flashPower, 1);
+
+    static const int64_t firingTime = 0;
+    ADD_OR_SIZE(ANDROID_FLASH_FIRING_TIME, &firingTime, 1);
+
+    /** Processing block modes */
+    uint8_t hotPixelMode = 0;
+    uint8_t demosaicMode = 0;
+    uint8_t noiseMode = 0;
+    uint8_t shadingMode = 0;
+    uint8_t geometricMode = 0;
+    uint8_t colorMode = 0;
+    uint8_t tonemapMode = 0;
+    uint8_t edgeMode = 0;
+    uint8_t vstabMode = 0;
+
+    switch (request_template) {
+      case CAMERA2_TEMPLATE_PREVIEW:
+        hotPixelMode = ANDROID_PROCESSING_FAST;
+        demosaicMode = ANDROID_PROCESSING_FAST;
+        noiseMode = ANDROID_PROCESSING_FAST;
+        shadingMode = ANDROID_PROCESSING_FAST;
+        geometricMode = ANDROID_PROCESSING_FAST;
+        colorMode = ANDROID_PROCESSING_FAST;
+        tonemapMode = ANDROID_PROCESSING_FAST;
+        edgeMode = ANDROID_PROCESSING_FAST;
+        vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_OFF;
+        break;
+      case CAMERA2_TEMPLATE_STILL_CAPTURE:
+        hotPixelMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        demosaicMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        noiseMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        shadingMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        geometricMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        colorMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        tonemapMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        edgeMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_OFF;
+        break;
+      case CAMERA2_TEMPLATE_VIDEO_RECORD:
+        hotPixelMode = ANDROID_PROCESSING_FAST;
+        demosaicMode = ANDROID_PROCESSING_FAST;
+        noiseMode = ANDROID_PROCESSING_FAST;
+        shadingMode = ANDROID_PROCESSING_FAST;
+        geometricMode = ANDROID_PROCESSING_FAST;
+        colorMode = ANDROID_PROCESSING_FAST;
+        tonemapMode = ANDROID_PROCESSING_FAST;
+        edgeMode = ANDROID_PROCESSING_FAST;
+        vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_ON;
+        break;
+      case CAMERA2_TEMPLATE_VIDEO_SNAPSHOT:
+        hotPixelMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        demosaicMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        noiseMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        shadingMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        geometricMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        colorMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        tonemapMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        edgeMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_ON;
+        break;
+      case CAMERA2_TEMPLATE_ZERO_SHUTTER_LAG:
+        hotPixelMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        demosaicMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        noiseMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        shadingMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        geometricMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        colorMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        tonemapMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        edgeMode = ANDROID_PROCESSING_HIGH_QUALITY;
+        vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_OFF;
+        break;
+      default:
+        hotPixelMode = ANDROID_PROCESSING_FAST;
+        demosaicMode = ANDROID_PROCESSING_FAST;
+        noiseMode = ANDROID_PROCESSING_FAST;
+        shadingMode = ANDROID_PROCESSING_FAST;
+        geometricMode = ANDROID_PROCESSING_FAST;
+        colorMode = ANDROID_PROCESSING_FAST;
+        tonemapMode = ANDROID_PROCESSING_FAST;
+        edgeMode = ANDROID_PROCESSING_FAST;
+        vstabMode = ANDROID_CONTROL_VIDEO_STABILIZATION_OFF;
+        break;
+    }
+    ADD_OR_SIZE(ANDROID_HOT_PIXEL_MODE, &hotPixelMode, 1);
+    ADD_OR_SIZE(ANDROID_DEMOSAIC_MODE, &demosaicMode, 1);
+    ADD_OR_SIZE(ANDROID_NOISE_MODE, &noiseMode, 1);
+    ADD_OR_SIZE(ANDROID_SHADING_MODE, &shadingMode, 1);
+    ADD_OR_SIZE(ANDROID_GEOMETRIC_MODE, &geometricMode, 1);
+    ADD_OR_SIZE(ANDROID_COLOR_MODE, &colorMode, 1);
+    ADD_OR_SIZE(ANDROID_TONEMAP_MODE, &tonemapMode, 1);
+    ADD_OR_SIZE(ANDROID_EDGE_MODE, &edgeMode, 1);
+    ADD_OR_SIZE(ANDROID_CONTROL_VIDEO_STABILIZATION_MODE, &vstabMode, 1);
+
+    /** android.noise */
+    static const uint8_t noiseStrength = 5;
+    ADD_OR_SIZE(ANDROID_NOISE_STRENGTH, &noiseStrength, 1);
+
+    /** android.color */
+    static const float colorTransform[9] = {
+        1.0f, 0.f, 0.f,
+        0.f, 1.f, 0.f,
+        0.f, 0.f, 1.f
+    };
+    ADD_OR_SIZE(ANDROID_COLOR_TRANSFORM, colorTransform, 9);
+
+    /** android.tonemap */
+    static const float tonemapCurve[4] = {
+        0.f, 0.f,
+        1.f, 1.f
+    };
+    ADD_OR_SIZE(ANDROID_TONEMAP_CURVE_RED, tonemapCurve, 32); // sungjoong
+    ADD_OR_SIZE(ANDROID_TONEMAP_CURVE_GREEN, tonemapCurve, 32);
+    ADD_OR_SIZE(ANDROID_TONEMAP_CURVE_BLUE, tonemapCurve, 32);
+
+    /** android.edge */
+    static const uint8_t edgeStrength = 5;
+    ADD_OR_SIZE(ANDROID_EDGE_STRENGTH, &edgeStrength, 1);
+
+    /** android.scaler */
+    int32_t cropRegion[3] = {
+        0, 0, /*mSensorInfo->mMaxWidth*/
+    };
+    ADD_OR_SIZE(ANDROID_SCALER_CROP_REGION, cropRegion, 3);
+
+    /** android.jpeg */
+    static const int32_t jpegQuality = 100;
+    ADD_OR_SIZE(ANDROID_JPEG_QUALITY, &jpegQuality, 1);
+
+    static const int32_t thumbnailSize[2] = {
+        160, 120
+    };
+    ADD_OR_SIZE(ANDROID_JPEG_THUMBNAIL_SIZE, thumbnailSize, 2);
+
+    static const int32_t thumbnailQuality = 100;
+    ADD_OR_SIZE(ANDROID_JPEG_THUMBNAIL_QUALITY, &thumbnailQuality, 1);
+
+    static const double gpsCoordinates[3] = {
+        0, 0, 0
+    };
+    ADD_OR_SIZE(ANDROID_JPEG_GPS_COORDINATES, gpsCoordinates, 3);
+
+    static const uint8_t gpsProcessingMethod[32] = "None";
+    ADD_OR_SIZE(ANDROID_JPEG_GPS_PROCESSING_METHOD, gpsProcessingMethod, 32);
+
+    static const int64_t gpsTimestamp = 0;
+    ADD_OR_SIZE(ANDROID_JPEG_GPS_TIMESTAMP, &gpsTimestamp, 1);
+
+    static const int32_t jpegOrientation = 0;
+    ADD_OR_SIZE(ANDROID_JPEG_ORIENTATION, &jpegOrientation, 1);
+
+    /** android.stats */
+
+    static const uint8_t faceDetectMode = ANDROID_STATS_FACE_DETECTION_FULL;
+    ADD_OR_SIZE(ANDROID_STATS_FACE_DETECT_MODE, &faceDetectMode, 1);
+
+    static const uint8_t histogramMode = ANDROID_STATS_OFF;
+    ADD_OR_SIZE(ANDROID_STATS_HISTOGRAM_MODE, &histogramMode, 1);
+
+    static const uint8_t sharpnessMapMode = ANDROID_STATS_OFF;
+    ADD_OR_SIZE(ANDROID_STATS_SHARPNESS_MAP_MODE, &sharpnessMapMode, 1);
+
+
+    /** android.control */
+
+    uint8_t controlIntent = 0;
+    switch (request_template) {
+      case CAMERA2_TEMPLATE_PREVIEW:
+        controlIntent = ANDROID_CONTROL_INTENT_PREVIEW;
+        break;
+      case CAMERA2_TEMPLATE_STILL_CAPTURE:
+        controlIntent = ANDROID_CONTROL_INTENT_STILL_CAPTURE;
+        break;
+      case CAMERA2_TEMPLATE_VIDEO_RECORD:
+        controlIntent = ANDROID_CONTROL_INTENT_VIDEO_RECORD;
+        break;
+      case CAMERA2_TEMPLATE_VIDEO_SNAPSHOT:
+        controlIntent = ANDROID_CONTROL_INTENT_VIDEO_SNAPSHOT;
+        break;
+      case CAMERA2_TEMPLATE_ZERO_SHUTTER_LAG:
+        controlIntent = ANDROID_CONTROL_INTENT_ZERO_SHUTTER_LAG;
+        break;
+      default:
+        controlIntent = ANDROID_CONTROL_INTENT_CUSTOM;
+        break;
+    }
+    ADD_OR_SIZE(ANDROID_CONTROL_CAPTURE_INTENT, &controlIntent, 1);
+
+    static const uint8_t controlMode = ANDROID_CONTROL_AUTO;
+    ADD_OR_SIZE(ANDROID_CONTROL_MODE, &controlMode, 1);
+
+    static const uint8_t effectMode = ANDROID_CONTROL_EFFECT_OFF;
+    ADD_OR_SIZE(ANDROID_CONTROL_EFFECT_MODE, &effectMode, 1);
+
+    static const uint8_t sceneMode = ANDROID_CONTROL_SCENE_MODE_UNSUPPORTED;
+    ADD_OR_SIZE(ANDROID_CONTROL_SCENE_MODE, &sceneMode, 1);
+
+    static const uint8_t aeMode = ANDROID_CONTROL_AE_ON;
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_MODE, &aeMode, 1);
+
+    int32_t controlRegions[5] = {
+        0, 0, mSensorInfo->mMaxWidth, mSensorInfo->mMaxHeight, 1000
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_REGIONS, controlRegions, 5);
+
+    static const int32_t aeExpCompensation = 0;
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_EXP_COMPENSATION, &aeExpCompensation, 1);
+
+    static const int32_t aeTargetFpsRange[2] = {
+        15, 30
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_TARGET_FPS_RANGE, aeTargetFpsRange, 2);
+
+    static const uint8_t aeAntibandingMode =
+            ANDROID_CONTROL_AE_ANTIBANDING_AUTO;
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_ANTIBANDING_MODE, &aeAntibandingMode, 1);
+
+    static const uint8_t awbMode =
+            ANDROID_CONTROL_AWB_AUTO;
+    ADD_OR_SIZE(ANDROID_CONTROL_AWB_MODE, &awbMode, 1);
+
+    ADD_OR_SIZE(ANDROID_CONTROL_AWB_REGIONS, controlRegions, 5);
+
+    uint8_t afMode = 0;
+    switch (request_template) {
+      case CAMERA2_TEMPLATE_PREVIEW:
+        afMode = ANDROID_CONTROL_AF_CONTINUOUS_PICTURE;
+        break;
+      case CAMERA2_TEMPLATE_STILL_CAPTURE:
+        afMode = ANDROID_CONTROL_AF_CONTINUOUS_PICTURE;
+        break;
+      case CAMERA2_TEMPLATE_VIDEO_RECORD:
+        afMode = ANDROID_CONTROL_AF_CONTINUOUS_VIDEO;
+        break;
+      case CAMERA2_TEMPLATE_VIDEO_SNAPSHOT:
+        afMode = ANDROID_CONTROL_AF_CONTINUOUS_VIDEO;
+        break;
+      case CAMERA2_TEMPLATE_ZERO_SHUTTER_LAG:
+        afMode = ANDROID_CONTROL_AF_CONTINUOUS_PICTURE;
+        break;
+      default:
+        afMode = ANDROID_CONTROL_AF_AUTO;
+        break;
+    }
+    ADD_OR_SIZE(ANDROID_CONTROL_AF_MODE, &afMode, 1);
+
+    ADD_OR_SIZE(ANDROID_CONTROL_AF_REGIONS, controlRegions, 5);
+
+    if (sizeRequest) {
+        ALOGV("Allocating %d entries, %d extra bytes for "
+                "request template type %d",
+                entryCount, dataCount, request_template);
+        *request = allocate_camera_metadata(entryCount, dataCount);
+        if (*request == NULL) {
+            ALOGE("Unable to allocate new request template type %d "
+                    "(%d entries, %d bytes extra data)", request_template,
+                    entryCount, dataCount);
+            return NO_MEMORY;
+        }
+    }
+    return OK;
+#undef ADD_OR_SIZE
+}
+
+status_t MetadaManager::setCurrentRequest(camera_metadata_t* request)
+{
+    if (request == NULL) {
+        return BAD_VALUE;
+    }
+
+    if (mCurrentRequest != NULL) {
+        free_camera_metadata(mCurrentRequest);
+    }
+
+    mCurrentRequest = clone_camera_metadata(request);
+    if (mCurrentRequest == NULL) {
+        return BAD_VALUE;
+    }
+
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getFrameRate(int *value)
+{
+    camera_metadata_entry_t streams;
+    int res = find_camera_metadata_entry(mCurrentRequest,
+            ANDROID_CONTROL_AE_TARGET_FPS_RANGE, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading fps range tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    int v[2];
+    for (uint32_t i = 0; i < streams.count && i < 2; i++) {
+        v[i] = streams.data.i32[i];
+    }
+
+    if (v[0] > 15 && v[1] > 15) {
+        *value = 30;
+    }
+    else {
+        *value = 15;
+    }
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getGpsCoordinates(double *pCoords, int count)
+{
+    camera_metadata_entry_t streams;
+    int res = find_camera_metadata_entry(mCurrentRequest,
+                ANDROID_JPEG_GPS_COORDINATES, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading jpeg Coordinates tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    for (int i=0; i<(int)streams.count && i<count; i++) {
+        pCoords[i] = streams.data.d[i];
+    }
+
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getGpsTimeStamp(int64_t &timeStamp)
+{
+    camera_metadata_entry_t streams;
+    int res = find_camera_metadata_entry(mCurrentRequest,
+                ANDROID_JPEG_GPS_TIMESTAMP, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading jpeg TimeStamp tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    timeStamp = streams.data.i64[0];
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getGpsProcessingMethod(uint8_t* src, int count)
+{
+    camera_metadata_entry_t streams;
+    int res = find_camera_metadata_entry(mCurrentRequest,
+                ANDROID_JPEG_GPS_PROCESSING_METHOD, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading jpeg ProcessingMethod tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    for (int i=0; i<(int)streams.count && i<count; i++) {
+        src[i] = streams.data.u8[i];
+    }
+
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getJpegRotation(int32_t &jpegRotation)
+{
+    camera_metadata_entry_t streams;
+    int res = find_camera_metadata_entry(mCurrentRequest,
+                ANDROID_JPEG_ORIENTATION, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading jpeg Rotation tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    jpegRotation = streams.data.i32[0];
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getJpegQuality(int32_t &quality)
+{
+    camera_metadata_entry_t streams;
+    int res = find_camera_metadata_entry(mCurrentRequest,
+                ANDROID_JPEG_QUALITY, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading jpeg quality tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    quality = streams.data.i32[0];
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getJpegThumbQuality(int32_t &thumb)
+{
+    camera_metadata_entry_t streams;
+    int res = find_camera_metadata_entry(mCurrentRequest,
+                ANDROID_JPEG_THUMBNAIL_QUALITY, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading jpeg thumbnail quality tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    thumb = streams.data.i32[0];
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getJpegThumbSize(int &width, int &height)
+{
+    camera_metadata_entry_t streams;
+    int res = find_camera_metadata_entry(mCurrentRequest,
+                ANDROID_JPEG_THUMBNAIL_SIZE, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading jpeg thumbnail size tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    width = streams.data.i32[0];
+    height = streams.data.i32[1];
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getRequestType(int *reqType)
+{
+    if (mCurrentRequest == NULL) {
+        FLOGE("mCurrentRequest is invalid");
+        return BAD_VALUE;
+    }
+
+    int requestType;
+    camera_metadata_entry_t streams;
+    int res;
+
+    res = find_camera_metadata_entry(mCurrentRequest,
+            ANDROID_REQUEST_ID, &streams);
+    if (res != NO_ERROR) {
+        ALOGE("%s: error reading output stream tag", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    int requestId = streams.data.i32[0];
+    if (requestId >= PreviewRequestIdStart && requestId < PreviewRequestIdEnd) {
+        requestType = REQUEST_TYPE_PREVIEW;
+        FLOG_RUNTIME("%s request type preview", __FUNCTION__);
+    }
+    else if (requestId >= RecordingRequestIdStart && requestId < RecordingRequestIdEnd) {
+        requestType = REQUEST_TYPE_RECORD;
+        FLOG_RUNTIME("%s request type record", __FUNCTION__);
+    }
+    else if (requestId >= CaptureRequestIdStart && requestId < CaptureRequestIdEnd) {
+        requestType = REQUEST_TYPE_CAPTURE;
+        FLOG_RUNTIME("%s request type capture", __FUNCTION__);
+    }
+    else {
+        FLOGE("%s invalid request type id:%d", __FUNCTION__, requestId);
+        return BAD_VALUE;
+    }
+
+    *reqType = requestType;
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getFocalLength(float &focalLength)
+{
+    focalLength = mSensorInfo->mFocalLength;
+    return NO_ERROR;
+}
+
+status_t MetadaManager::getRequestStreams(camera_metadata_entry_t *reqStreams)
+{
+    if (reqStreams == NULL) {
+        FLOGE("%s invalid param", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    return find_camera_metadata_entry(mCurrentRequest,
+                ANDROID_REQUEST_OUTPUT_STREAMS, reqStreams);
+}
+
+status_t MetadaManager::createStaticInfo(camera_metadata_t **info, bool sizeRequest)
+{
+    size_t entryCount = 0;
+    size_t dataCount = 0;
+    status_t ret;
+
+    fAssert(mSensorInfo != NULL);
+
+#define ADD_OR_SIZE( tag, data, count ) \
+    if ( ( ret = addOrSize(*info, sizeRequest, &entryCount, &dataCount, \
+            tag, data, count) ) != OK ) return ret
+
+    // android.lens
+    static float minFocusDistance = 0;
+    ADD_OR_SIZE(ANDROID_LENS_MINIMUM_FOCUS_DISTANCE,
+            &minFocusDistance, 1);
+    ADD_OR_SIZE(ANDROID_LENS_HYPERFOCAL_DISTANCE,
+            &minFocusDistance, 1);
+
+    static float focalLength = 0.0;
+    ADD_OR_SIZE(ANDROID_LENS_AVAILABLE_FOCAL_LENGTHS,
+            &focalLength, 1);
+
+    static float aperture = 2.8;
+    ADD_OR_SIZE(ANDROID_LENS_AVAILABLE_APERTURES,
+            &aperture, 1);
+
+    static const float filterDensity = 0;
+    ADD_OR_SIZE(ANDROID_LENS_AVAILABLE_FILTER_DENSITY,
+            &filterDensity, 1);
+    static const uint8_t availableOpticalStabilization =
+            ANDROID_LENS_OPTICAL_STABILIZATION_OFF;
+    ADD_OR_SIZE(ANDROID_LENS_AVAILABLE_OPTICAL_STABILIZATION,
+            &availableOpticalStabilization, 1);
+
+    static const int32_t lensShadingMapSize[] = {1, 1};
+    ADD_OR_SIZE(ANDROID_LENS_SHADING_MAP_SIZE, lensShadingMapSize,
+            sizeof(lensShadingMapSize)/sizeof(int32_t));
+
+    static const float lensShadingMap[3 * 1 * 1 ] =
+            { 1.f, 1.f, 1.f };
+    ADD_OR_SIZE(ANDROID_LENS_SHADING_MAP, lensShadingMap,
+            sizeof(lensShadingMap)/sizeof(float));
+
+    int32_t lensFacing = mCameraId ?
+            ANDROID_LENS_FACING_FRONT : ANDROID_LENS_FACING_BACK;
+    ADD_OR_SIZE(ANDROID_LENS_FACING, &lensFacing, 1);
+#if 0
+    nsecs_t kExposureTimeRange[2] =
+            {1000L, 30000000000L};
+    // android.sensor
+    ADD_OR_SIZE(ANDROID_SENSOR_EXPOSURE_TIME_RANGE,
+            kExposureTimeRange, 2);
+
+    ADD_OR_SIZE(ANDROID_SENSOR_MAX_FRAME_DURATION,
+            &mSensorInfo->mMaxFrameDuration, 1);
+
+    uint32_t kAvailableSensitivities[5] =
+             {100, 200, 400, 800, 1600};
+    ADD_OR_SIZE(ANDROID_SENSOR_AVAILABLE_SENSITIVITIES,
+            kAvailableSensitivities,
+            sizeof(kAvailableSensitivities)
+            /sizeof(uint32_t));
+
+    uint8_t kColorFilterArrangement = ANDROID_SENSOR_RGGB;
+    ADD_OR_SIZE(ANDROID_SENSOR_COLOR_FILTER_ARRANGEMENT,
+            &kColorFilterArrangement, 1);
+#endif
+    static const float sensorPhysicalSize[2] = {3.20f, 2.40f}; // mm
+    ADD_OR_SIZE(ANDROID_SENSOR_PHYSICAL_SIZE,
+            sensorPhysicalSize, 2);
+
+    int32_t pixelArraySize[2] = {
+        mSensorInfo->mMaxWidth, mSensorInfo->mMaxHeight
+    };
+    ADD_OR_SIZE(ANDROID_SENSOR_PIXEL_ARRAY_SIZE, pixelArraySize, 2);
+    ADD_OR_SIZE(ANDROID_SENSOR_ACTIVE_ARRAY_SIZE, pixelArraySize,2);
+
+#if 0
+    uint32_t kMaxRawValue = 4000;
+    ADD_OR_SIZE(ANDROID_SENSOR_WHITE_LEVEL,
+            &kMaxRawValue, 1);
+
+    uint32_t kBlackLevel = 1000;
+    static const int32_t blackLevelPattern[4] = {
+            kBlackLevel, kBlackLevel,
+            kBlackLevel, kBlackLevel
+    };
+    ADD_OR_SIZE(ANDROID_SENSOR_BLACK_LEVEL_PATTERN,
+            blackLevelPattern, sizeof(blackLevelPattern)/sizeof(int32_t));
+#endif
+    //TODO: sensor color calibration fields
+
+    // android.flash
+    uint8_t flashAvailable = 0;
+    ADD_OR_SIZE(ANDROID_FLASH_AVAILABLE, &flashAvailable, 1);
+
+    static const int64_t flashChargeDuration = 0;
+    ADD_OR_SIZE(ANDROID_FLASH_CHARGE_DURATION, &flashChargeDuration, 1);
+
+    // android.tonemap
+
+    static const int32_t tonemapCurvePoints = 128;
+    ADD_OR_SIZE(ANDROID_TONEMAP_MAX_CURVE_POINTS, &tonemapCurvePoints, 1);
+
+    // android.scaler
+
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_FORMATS,
+            mSensorInfo->mAvailableFormats,
+            sizeof(mSensorInfo->mAvailableFormats)/sizeof(uint32_t));
+#if 0
+    const uint32_t kAvailableFormats[3] = {
+        HAL_PIXEL_FORMAT_RAW_SENSOR,
+        HAL_PIXEL_FORMAT_BLOB,
+        HAL_PIXEL_FORMAT_YCrCb_420_SP
+    };
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_FORMATS,
+            kAvailableFormats,
+            sizeof(kAvailableFormats)/sizeof(uint32_t));
+#endif
+    int32_t availableRawSizes[2] = {
+        mSensorInfo->mMaxWidth, mSensorInfo->mMaxHeight
+    };
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_RAW_SIZES,
+            availableRawSizes, 2);
+
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_RAW_MIN_DURATIONS,
+            &mSensorInfo->mMinFrameDuration, 1);
+
+
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_PROCESSED_SIZES,
+        mSensorInfo->mPreviewResolutions,
+        ARRAY_SIZE(mSensorInfo->mPreviewResolutions));
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_JPEG_SIZES,
+        mSensorInfo->mPictureResolutions,
+        ARRAY_SIZE(mSensorInfo->mPictureResolutions));
+
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_PROCESSED_MIN_DURATIONS,
+            &mSensorInfo->mMinFrameDuration,
+            sizeof(mSensorInfo->mMinFrameDuration)/sizeof(uint64_t));
+
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_JPEG_MIN_DURATIONS,
+            &mSensorInfo->mMinFrameDuration,
+            sizeof(mSensorInfo->mMinFrameDuration)/sizeof(uint64_t));
+
+    static const float maxZoom = 4;
+    ADD_OR_SIZE(ANDROID_SCALER_AVAILABLE_MAX_ZOOM, &maxZoom, 1);
+
+    // android.jpeg
+
+    static const int32_t jpegThumbnailSizes[] = {
+            160, 120,
+            160, 160,
+            96, 96,
+            144, 96
+    };
+
+    ADD_OR_SIZE(ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES,
+            jpegThumbnailSizes, sizeof(jpegThumbnailSizes)/sizeof(int32_t));
+
+    static const int32_t jpegMaxSize = 8 * 1024 * 1024;
+    ADD_OR_SIZE(ANDROID_JPEG_MAX_SIZE, &jpegMaxSize, 1);
+
+    // android.stats
+
+    static const uint8_t availableFaceDetectModes[] = {
+            ANDROID_STATS_FACE_DETECTION_OFF
+    };
+    ADD_OR_SIZE(ANDROID_STATS_AVAILABLE_FACE_DETECT_MODES,
+            availableFaceDetectModes,
+            sizeof(availableFaceDetectModes));
+
+    static const int32_t maxFaceCount = 0;
+    ADD_OR_SIZE(ANDROID_STATS_MAX_FACE_COUNT,
+            &maxFaceCount, 1);
+
+    static const int32_t histogramSize = 64;
+    ADD_OR_SIZE(ANDROID_STATS_HISTOGRAM_BUCKET_COUNT,
+            &histogramSize, 1);
+
+    static const int32_t maxHistogramCount = 1000;
+    ADD_OR_SIZE(ANDROID_STATS_MAX_HISTOGRAM_COUNT,
+            &maxHistogramCount, 1);
+
+    static const int32_t sharpnessMapSize[2] = {64, 64};
+    ADD_OR_SIZE(ANDROID_STATS_SHARPNESS_MAP_SIZE,
+            sharpnessMapSize, sizeof(sharpnessMapSize)/sizeof(int32_t));
+
+    static const int32_t maxSharpnessMapValue = 1000;
+    ADD_OR_SIZE(ANDROID_STATS_MAX_SHARPNESS_MAP_VALUE,
+            &maxSharpnessMapValue, 1);
+
+    // android.control
+
+    static const uint8_t availableSceneModes[] = {
+            ANDROID_CONTROL_SCENE_MODE_UNSUPPORTED
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AVAILABLE_SCENE_MODES,
+            availableSceneModes, sizeof(availableSceneModes));
+
+    static const uint8_t availableEffects[] = {
+            ANDROID_CONTROL_EFFECT_OFF
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AVAILABLE_EFFECTS,
+            availableEffects, sizeof(availableEffects));
+
+    int32_t max3aRegions = 0;
+    ADD_OR_SIZE(ANDROID_CONTROL_MAX_REGIONS,
+            &max3aRegions, 1);
+
+    static const uint8_t availableAeModes[] = {
+            ANDROID_CONTROL_AE_OFF,
+            ANDROID_CONTROL_AE_ON
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_AVAILABLE_MODES,
+            availableAeModes, sizeof(availableAeModes));
+
+    static const camera_metadata_rational exposureCompensationStep = {
+            1, 1
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_EXP_COMPENSATION_STEP,
+            &exposureCompensationStep, 1);
+
+    int32_t exposureCompensationRange[] = {-3, 3};
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_EXP_COMPENSATION_RANGE,
+            exposureCompensationRange,
+            sizeof(exposureCompensationRange)/sizeof(int32_t));
+
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES,
+            mSensorInfo->mTargetFpsRange,
+            sizeof(mSensorInfo->mTargetFpsRange)/sizeof(int32_t));
+
+    static const uint8_t availableAntibandingModes[] = {
+            ANDROID_CONTROL_AE_ANTIBANDING_OFF,
+            ANDROID_CONTROL_AE_ANTIBANDING_AUTO
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AE_AVAILABLE_ANTIBANDING_MODES,
+            availableAntibandingModes, sizeof(availableAntibandingModes));
+
+    static const uint8_t availableAwbModes[] = {
+            ANDROID_CONTROL_AWB_OFF
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AWB_AVAILABLE_MODES,
+            availableAwbModes, sizeof(availableAwbModes));
+
+    static const uint8_t availableAfModes[] = {
+            ANDROID_CONTROL_AF_OFF
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AF_AVAILABLE_MODES,
+                availableAfModes, sizeof(availableAfModes));
+
+    static const uint8_t availableVstabModes[] = {
+            ANDROID_CONTROL_VIDEO_STABILIZATION_OFF
+    };
+    ADD_OR_SIZE(ANDROID_CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES,
+            availableVstabModes, sizeof(availableVstabModes));
+
+    static const uint8_t quirkTriggerAuto = 1;
+    ADD_OR_SIZE(ANDROID_QUIRKS_TRIGGER_AF_WITH_AUTO,
+            &quirkTriggerAuto, 1);
+
+    static const uint8_t quirkUseZslFormat = 1;
+    ADD_OR_SIZE(ANDROID_QUIRKS_USE_ZSL_FORMAT,
+            &quirkUseZslFormat, 1);
+
+    static const uint8_t quirkMeteringCropRegion = 1;
+    ADD_OR_SIZE(ANDROID_QUIRKS_METERING_CROP_REGION,
+            &quirkMeteringCropRegion, 1);
+
+
+#undef ADD_OR_SIZE
+    /** Allocate metadata if sizing */
+    if (sizeRequest) {
+        ALOGV("Allocating %d entries, %d extra bytes for "
+                "static camera info",
+                entryCount, dataCount);
+        *info = allocate_camera_metadata(entryCount, dataCount);
+        if (*info == NULL) {
+            ALOGE("Unable to allocate camera static info"
+                    "(%d entries, %d bytes extra data)",
+                    entryCount, dataCount);
+            return NO_MEMORY;
+        }
+    }
+    return OK;
+}
+
diff --git a/mx6/libcamera2/MetadaManager.h b/mx6/libcamera2/MetadaManager.h
new file mode 100755
index 0000000..f009ebf
--- /dev/null
+++ b/mx6/libcamera2/MetadaManager.h
@@ -0,0 +1,76 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _METADA_MANAGER_H_
+#define _METADA_MANAGER_H_
+
+#include "CameraUtil.h"
+
+#define MAX_VPU_SUPPORT_FORMAT 2
+#define MAX_PICTURE_SUPPORT_FORMAT 2
+
+using namespace android;
+
+struct SensorInfo;
+
+class MetadaManager : public LightRefBase<MetadaManager>
+{
+public:
+    MetadaManager(SensorInfo *dev, int cameraId);
+    ~MetadaManager();
+
+    status_t addOrSize(camera_metadata_t *request,
+        bool sizeRequest,
+        size_t *entryCount,
+        size_t *dataCount,
+        uint32_t tag,
+        const void *entryData,
+        size_t entryDataCount);
+
+    status_t createStaticInfo(camera_metadata_t **info, bool sizeRequest);
+
+    status_t createDefaultRequest(
+        int request_template,
+        camera_metadata_t **request,
+        bool sizeRequest);
+
+    status_t setCurrentRequest(camera_metadata_t* request);
+    status_t getRequestType(int *reqType);
+    status_t getRequestStreams(camera_metadata_entry_t *reqStreams);
+    status_t getFrameRate(int *value);
+
+    status_t getGpsCoordinates(double *pCoords, int count);
+    status_t getGpsTimeStamp(int64_t &timeStamp);
+    status_t getGpsProcessingMethod(uint8_t* src, int count);
+    status_t getFocalLength(float &focalLength);
+    status_t getJpegRotation(int32_t &jpegRotation);
+    status_t getJpegQuality(int32_t &quality);
+    status_t getJpegThumbQuality(int32_t &thumb);
+    status_t getJpegThumbSize(int &width, int &height);
+
+    status_t getSupportedRecordingFormat(int *src, int len);
+    status_t getSupportedPictureFormat(int *src, int len);
+
+private:
+    camera_metadata_t* mCurrentRequest;
+    SensorInfo *mSensorInfo;
+
+    int mVpuSupportFmt[MAX_VPU_SUPPORT_FORMAT];
+    int mPictureSupportFmt[MAX_PICTURE_SUPPORT_FORMAT];
+    int mCameraId;
+};
+
+#endif
diff --git a/mx6/libcamera2/NV12_resize.c b/mx6/libcamera2/NV12_resize.c
new file mode 100755
index 0000000..cdd11bc
--- /dev/null
+++ b/mx6/libcamera2/NV12_resize.c
@@ -0,0 +1,303 @@
+#include "NV12_resize.h"
+
+//#define LOG_NDEBUG 0
+#define LOG_NIDEBUG 0
+#define LOG_NDDEBUG 0
+
+#define LOG_TAG "NV12_resize"
+#define STRIDE 4096
+#include <utils/Log.h>
+
+/*==========================================================================
+* Function Name  : VT_resizeFrame_Video_opt2_lp
+*
+* Description    : Resize a yuv frame.
+*
+* Input(s)       : input_img_ptr        -> Input Image Structure
+*                : output_img_ptr       -> Output Image Structure
+*                : cropout             -> crop structure
+*
+* Value Returned : mmBool               -> FALSE on error TRUE on success
+* NOTE:
+*            Not tested for crop funtionallity.
+*            faster version.
+============================================================================*/
+mmBool
+VT_resizeFrame_Video_opt2_lp
+(
+ structConvImage* i_img_ptr,        /* Points to the input image           */
+ structConvImage* o_img_ptr,        /* Points to the output image          */
+ IC_rect_type*  cropout,          /* how much to resize to in final image */
+ mmUint16 dummy                         /* Transparent pixel value              */
+ )
+{
+  ALOGV("VT_resizeFrame_Video_opt2_lp+");
+
+  mmUint16 row,col;
+  mmUint32 resizeFactorX;
+  mmUint32 resizeFactorY;
+
+
+  mmUint16 x, y;
+
+  mmUchar* ptr8;
+  mmUchar *ptr8Cb, *ptr8Cr;
+
+
+  mmUint16 xf, yf;
+  mmUchar* inImgPtrY;
+  mmUchar* inImgPtrU;
+  mmUchar* inImgPtrV;
+  mmUint32 cox, coy, codx, cody;
+  mmUint16 idx,idy, idxC;
+
+  if(i_img_ptr->uWidth == o_img_ptr->uWidth)
+	{
+		if(i_img_ptr->uHeight == o_img_ptr->uHeight)
+			{
+				ALOGV("************************f(i_img_ptr->uHeight == o_img_ptr->uHeight) are same *********************\n");
+				ALOGV("************************(i_img_ptr->width == %d" , i_img_ptr->uWidth );
+				ALOGV("************************(i_img_ptr->uHeight == %d" , i_img_ptr->uHeight );
+				ALOGV("************************(o_img_ptr->width == %d" ,o_img_ptr->uWidth );
+				ALOGV("************************(o_img_ptr->uHeight == %d" , o_img_ptr->uHeight );
+			}
+	}
+
+  if (!i_img_ptr || !i_img_ptr->imgPtr ||
+    !o_img_ptr || !o_img_ptr->imgPtr)
+  {
+	ALOGE("Image Point NULL");
+	ALOGV("VT_resizeFrame_Video_opt2_lp-");
+	return FALSE;
+  }
+  inImgPtrY = (mmUchar *) i_img_ptr->imgPtr + i_img_ptr->uOffset;
+  inImgPtrU = (mmUchar *) i_img_ptr->clrPtr + i_img_ptr->uOffset/2;
+  inImgPtrV = (mmUchar*)inImgPtrU + 1;
+
+  if (cropout == NULL)
+  {
+    cox = 0;
+    coy = 0;
+    codx = o_img_ptr->uWidth;
+    cody = o_img_ptr->uHeight;
+  }
+  else
+  {
+    cox = cropout->x;
+    coy = cropout->y;
+    codx = cropout->uWidth;
+    cody = cropout->uHeight;
+  }
+  idx = i_img_ptr->uWidth;
+  idy = i_img_ptr->uHeight;
+
+  /* make sure valid input size */
+  if (idx < 1 || idy < 1 || i_img_ptr->uStride < 1)
+	{
+	ALOGE("idx or idy less then 1 idx = %d idy = %d stride = %d", idx, idy, i_img_ptr->uStride);
+	ALOGV("VT_resizeFrame_Video_opt2_lp-");
+	return FALSE;
+	}
+
+  resizeFactorX = ((idx-1)<<9) / codx;
+  resizeFactorY = ((idy-1)<<9) / cody;
+
+  if(i_img_ptr->eFormat == IC_FORMAT_YCbCr420_lp &&
+    o_img_ptr->eFormat == IC_FORMAT_YCbCr420_lp)
+  {
+    ptr8 = (mmUchar*)o_img_ptr->imgPtr + cox + coy*o_img_ptr->uWidth;
+
+
+    ////////////////////////////for Y//////////////////////////
+    for (row=0; row < cody; row++)
+    {
+        mmUchar *pu8Yrow1 = NULL;
+        mmUchar *pu8Yrow2 = NULL;
+        y  = (mmUint16) ((mmUint32) (row*resizeFactorY) >> 9);
+        yf = (mmUchar)  ((mmUint32)((row*resizeFactorY) >> 6) & 0x7);
+        pu8Yrow1 = inImgPtrY + (y) * i_img_ptr->uStride;
+        pu8Yrow2 = pu8Yrow1 + i_img_ptr->uStride;
+
+        for (col=0; col < codx; col++)
+        {
+            mmUchar in11, in12, in21, in22;
+            mmUchar *pu8ptr1 = NULL;
+            mmUchar *pu8ptr2 = NULL;
+            mmUchar w;
+            mmUint16 accum_1;
+            //mmUint32 accum_W;
+
+
+
+            x  = (mmUint16) ((mmUint32)  (col*resizeFactorX) >> 9);
+            xf = (mmUchar)  ((mmUint32) ((col*resizeFactorX) >> 6) & 0x7);
+
+
+            //accum_W = 0;
+            accum_1 =  0;
+
+            pu8ptr1 = pu8Yrow1 + (x);
+            pu8ptr2 = pu8Yrow2 + (x);
+
+            /* A pixel */
+            //in = *(inImgPtrY + (y)*idx + (x));
+            in11 = *(pu8ptr1);
+
+            w = bWeights[xf][yf][0];
+            accum_1 = (w * in11);
+            //accum_W += (w);
+
+            /* B pixel */
+            //in = *(inImgPtrY + (y)*idx + (x+1));
+            in12 = *(pu8ptr1+1);
+            w = bWeights[xf][yf][1];
+            accum_1 += (w * in12);
+            //accum_W += (w);
+
+            /* C pixel */
+            //in = *(inImgPtrY + (y+1)*idx + (x));
+            in21 = *(pu8ptr2);
+            w = bWeights[xf][yf][3];
+            accum_1 += (w * in21);
+            //accum_W += (w);
+
+            /* D pixel */
+            //in = *(inImgPtrY + (y+1)*idx + (x+1));
+            in22 = *(pu8ptr2+1);
+            w = bWeights[xf][yf][2];
+            accum_1 += (w * in22);
+            //accum_W += (w);
+
+            /* divide by sum of the weights */
+            //accum_1 /= (accum_W);
+            //accum_1 = (accum_1/64);
+            accum_1 = (accum_1>>6);
+            *ptr8 = (mmUchar)accum_1 ;
+
+
+            ptr8++;
+        }
+        ptr8 = ptr8 + (o_img_ptr->uStride - codx);
+    }
+    ////////////////////////////for Y//////////////////////////
+
+    ///////////////////////////////for Cb-Cr//////////////////////
+
+    ptr8Cb = (mmUchar*)o_img_ptr->clrPtr + cox + coy*o_img_ptr->uWidth;
+
+    ptr8Cr = (mmUchar*)(ptr8Cb+1);
+
+    idxC = (idx>>1);
+    for (row=0; row < (((cody)>>1)); row++)
+    {
+        mmUchar *pu8Cbr1 = NULL;
+        mmUchar *pu8Cbr2 = NULL;
+        mmUchar *pu8Crr1 = NULL;
+        mmUchar *pu8Crr2 = NULL;
+
+        y  = (mmUint16) ((mmUint32) (row*resizeFactorY) >> 9);
+        yf = (mmUchar)  ((mmUint32)((row*resizeFactorY) >> 6) & 0x7);
+
+        pu8Cbr1 = inImgPtrU + (y) * i_img_ptr->uStride;
+        pu8Cbr2 = pu8Cbr1 + i_img_ptr->uStride;
+        pu8Crr1 = inImgPtrV + (y) * i_img_ptr->uStride;
+        pu8Crr2 = pu8Crr1 + i_img_ptr->uStride;
+
+        for (col=0; col < (((codx)>>1)); col++)
+        {
+            mmUchar in11, in12, in21, in22;
+            mmUchar *pu8Cbc1 = NULL;
+            mmUchar *pu8Cbc2 = NULL;
+            mmUchar *pu8Crc1 = NULL;
+            mmUchar *pu8Crc2 = NULL;
+
+            mmUchar w;
+            mmUint16 accum_1Cb, accum_1Cr;
+            //mmUint32 accum_WCb, accum_WCr;
+
+
+            x  = (mmUint16) ((mmUint32)  (col*resizeFactorX) >> 9);
+            xf = (mmUchar)  ((mmUint32) ((col*resizeFactorX) >> 6) & 0x7);
+
+
+            //accum_WCb = accum_WCr =  0;
+            accum_1Cb = accum_1Cr =  0;
+
+            pu8Cbc1 = pu8Cbr1 + (x*2);
+            pu8Cbc2 = pu8Cbr2 + (x*2);
+	    pu8Crc1 = pu8Crr1 + (x*2);
+            pu8Crc2 = pu8Crr2 + (x*2);
+
+            /* A pixel */
+            w = bWeights[xf][yf][0];
+
+            in11 = *(pu8Cbc1);
+            accum_1Cb = (w * in11);
+            //    accum_WCb += (w);
+
+			in11 = *(pu8Crc1);
+            accum_1Cr = (w * in11);
+            //accum_WCr += (w);
+
+            /* B pixel */
+            w = bWeights[xf][yf][1];
+
+            in12 = *(pu8Cbc1+2);
+            accum_1Cb += (w * in12);
+            //accum_WCb += (w);
+
+            in12 = *(pu8Crc1+2);
+            accum_1Cr += (w * in12);
+            //accum_WCr += (w);
+
+            /* C pixel */
+            w = bWeights[xf][yf][3];
+
+            in21 = *(pu8Cbc2);
+            accum_1Cb += (w * in21);
+            //accum_WCb += (w);
+
+			in21 = *(pu8Crc2);
+            accum_1Cr += (w * in21);
+            //accum_WCr += (w);
+
+            /* D pixel */
+            w = bWeights[xf][yf][2];
+
+            in22 = *(pu8Cbc2+2);
+            accum_1Cb += (w * in22);
+            //accum_WCb += (w);
+
+            in22 = *(pu8Crc2+2);
+            accum_1Cr += (w * in22);
+            //accum_WCr += (w);
+
+            /* divide by sum of the weights */
+            //accum_1Cb /= (accum_WCb);
+            accum_1Cb = (accum_1Cb>>6);
+            *ptr8Cb = (mmUchar)accum_1Cb ;
+
+            accum_1Cr = (accum_1Cr >> 6);
+            *ptr8Cr = (mmUchar)accum_1Cr ;
+
+            ptr8Cb++;
+            ptr8Cr++;
+
+            ptr8Cb++;
+            ptr8Cr++;
+        }
+        ptr8Cb = ptr8Cb + (o_img_ptr->uStride-codx);
+        ptr8Cr = ptr8Cr + (o_img_ptr->uStride-codx);
+    }
+    ///////////////////For Cb- Cr////////////////////////////////////////
+  }
+  else
+  {
+	ALOGE("eFormat not supported");
+	ALOGV("VT_resizeFrame_Video_opt2_lp-");
+	return FALSE;
+  }
+  ALOGV("success");
+  ALOGV("VT_resizeFrame_Video_opt2_lp-");
+  return TRUE;
+}
diff --git a/mx6/libcamera2/NV12_resize.h b/mx6/libcamera2/NV12_resize.h
new file mode 100755
index 0000000..927faf8
--- /dev/null
+++ b/mx6/libcamera2/NV12_resize.h
@@ -0,0 +1,148 @@
+#ifndef NV12_RESIZE_H_
+#define NV12_RESIZE_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+typedef unsigned char       mmBool;
+typedef unsigned char       mmUchar;
+typedef unsigned char       mmUint8;
+typedef unsigned char       mmByte;
+typedef unsigned short      mmUint16;
+typedef unsigned int        mmUint32;
+typedef unsigned long       mmUint64;
+typedef signed char         mmInt8;
+typedef char		        mmChar;
+typedef signed short        mmInt16;
+typedef signed int          mmInt32;
+typedef signed long         mmLong;
+typedef signed int          mmHandle;
+typedef float        mmFloat;
+typedef double       mmDouble;
+typedef int 		    HObj;
+typedef HObj		    HFile;
+typedef int 		    HDir;
+typedef void* mmMutexHandle;
+typedef struct _fstat
+{
+      mmInt32 fileSize;
+}VE_FileAttribute;
+
+typedef struct
+{
+	mmInt32		second;
+	mmInt32 	millisecond;
+}tsVE_Time;
+
+typedef struct
+{
+	mmInt32 	year;
+	mmInt32 	month;
+	mmInt32 	day;
+	mmInt32 	hour;
+	mmInt32 	minute;
+	mmInt32 	second;
+} TmDateTime;
+
+/*----------------------------------------------------------------------------
+    Define : TRUE/FALSE for boolean operations
+----------------------------------------------------------------------------*/
+
+#ifndef TRUE
+    #define TRUE    1
+#endif
+
+#ifndef FALSE
+    #define FALSE   0
+#endif
+
+#ifndef NULL
+   #define NULL        0
+#endif
+
+const mmUint8 bWeights[8][8][4] = {
+  {{64, 0, 0, 0}, {56, 0, 0, 8}, {48, 0, 0,16}, {40, 0, 0,24},
+   {32, 0, 0,32}, {24, 0, 0,40}, {16, 0, 0,48}, { 8, 0, 0,56}},
+
+  {{56, 8, 0, 0}, {49, 7, 1, 7}, {42, 6, 2,14}, {35, 5, 3,21},
+   {28, 4, 4,28}, {21, 3, 5,35}, {14, 2, 6,42}, { 7, 1, 7,49}},
+
+  {{48,16, 0, 0}, {42,14, 2, 6}, {36,12,4 ,12}, {30,10,6 ,18},
+   {24, 8, 8,24}, {18, 6,10,30}, {12,4 ,12,36}, { 6, 2,14,42}},
+
+  {{40,24,0 ,0 }, {35,21, 3, 5}, {30,18, 6,10}, {25,15, 9,15},
+   {20,12,12,20}, {15, 9,15,25}, {10, 6,18,30}, { 5, 3,21,35}},
+
+  {{32,32, 0,0 }, {28,28, 4, 4}, {24,24, 8, 8}, {20,20,12,12},
+   {16,16,16,16}, {12,12,20,20}, { 8, 8,24,24}, { 4, 4,28,28}},
+
+  {{24,40,0 ,0 }, {21,35, 5, 3}, {18,30,10, 6}, {15,25,15, 9},
+   {12,20,20,12}, { 9,15,25,15}, { 6,10,30,18}, { 3, 5,35,21}},
+
+  {{16,48, 0,0 }, {14,42, 6, 2}, {12,36,12, 4}, {10,30,18, 6},
+   {8 ,24,24,8 }, { 6,18,30,10}, { 4,12,36,12}, { 2, 6,42,14}},
+
+  {{ 8,56, 0,0 }, { 7,49, 7, 1}, { 6,42,14, 2}, { 5,35,21, 3},
+   { 4,28,28,4 }, { 3,21,35, 5}, { 2,14,42, 6}, { 1,7 ,49, 7}}
+};
+
+typedef enum
+{
+    IC_FORMAT_NONE,
+    IC_FORMAT_RGB565,
+    IC_FORMAT_RGB888,
+    IC_FORMAT_YCbCr420_lp,
+    IC_FORMAT_YCbCr,
+    IC_FORMAT_YCbCr420_FRAME_PK,
+    IC_FORMAT_MAX
+}enumImageFormat;
+
+/* This structure defines the format of an image */
+typedef struct
+{
+  mmInt32                       uWidth;
+  mmInt32                       uHeight;
+  mmInt32                       uStride;
+  enumImageFormat               eFormat;
+  mmByte                        *imgPtr;
+  mmByte                        *clrPtr;
+  mmInt32                       uOffset;
+} structConvImage;
+
+typedef struct IC_crop_struct
+{
+  mmUint32 x;             /* x pos of rectangle                              */
+  mmUint32 y;             /* y pos of rectangle                              */
+  mmUint32 uWidth;        /* dx of rectangle                                 */
+  mmUint32 uHeight;       /* dy of rectangle                                 */
+} IC_rect_type;
+
+/*==========================================================================
+* Function Name  : VT_resizeFrame_Video_opt2_lp
+*
+* Description    : Resize a yuv frame.
+*
+* Input(s)       : input_img_ptr        -> Input Image Structure
+*                : output_img_ptr       -> Output Image Structure
+*                : cropout             -> crop structure
+*
+* Value Returned : mmBool               -> FALSE on error TRUE on success
+* NOTE:
+*            Not tested for crop funtionallity.
+*            faster version.
+============================================================================*/
+mmBool
+VT_resizeFrame_Video_opt2_lp
+(
+ structConvImage* i_img_ptr,        /* Points to the input image           */
+ structConvImage* o_img_ptr,        /* Points to the output image          */
+ IC_rect_type*  cropout,          /* how much to resize to in final image */
+ mmUint16 dummy                         /* Transparent pixel value              */
+ );
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif //#define NV12_RESIZE_H_
diff --git a/mx6/libcamera2/Ov5640.cpp b/mx6/libcamera2/Ov5640.cpp
new file mode 100755
index 0000000..2a62360
--- /dev/null
+++ b/mx6/libcamera2/Ov5640.cpp
@@ -0,0 +1,136 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "Ov5640.h"
+
+
+status_t Ov5640::initSensorInfo()
+{
+    if (mCameraHandle < 0) {
+        FLOGE("OvDevice: initParameters sensor has not been opened");
+        return BAD_VALUE;
+    }
+
+    // first read sensor format.
+    int ret = 0, index = 0;
+    int sensorFormats[MAX_SENSOR_FORMAT];
+    memset(mAvailableFormats, 0, sizeof(mAvailableFormats));
+    memset(sensorFormats, 0, sizeof(sensorFormats));
+#if 0
+    struct v4l2_fmtdesc vid_fmtdesc;
+    while (ret == 0) {
+        vid_fmtdesc.index = index;
+        vid_fmtdesc.type  = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        ret               = ioctl(mCameraHandle, VIDIOC_ENUM_FMT, &vid_fmtdesc);
+        FLOG_RUNTIME("index:%d,ret:%d, format:%c%c%c%c", index, ret,
+                     vid_fmtdesc.pixelformat & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 8) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 16) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0) {
+            sensorFormats[index++] = vid_fmtdesc.pixelformat;
+        }
+    }
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+#endif
+
+    // v4l2 does not support enum format, now hard code here.
+    sensorFormats[index++] = v4l2_fourcc('N', 'V', '1', '2');
+    sensorFormats[index++] = v4l2_fourcc('Y', 'V', '1', '2');
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+    //mAvailableFormats[2] = v4l2_fourcc('Y', 'U', 'Y', 'V');
+    index = 4;
+
+    changeSensorFormats(sensorFormats, index);
+
+    index = 0;
+    char TmpStr[20];
+    int  previewCnt = 0, pictureCnt = 0;
+    struct v4l2_frmsizeenum vid_frmsize;
+    struct v4l2_frmivalenum vid_frmval;
+    while (ret == 0) {
+        memset(TmpStr, 0, 20);
+        memset(&vid_frmsize, 0, sizeof(struct v4l2_frmsizeenum));
+        vid_frmsize.index        = index++;
+        vid_frmsize.pixel_format = v4l2_fourcc('N', 'V', '1', '2');
+        ret = ioctl(mCameraHandle,
+                    VIDIOC_ENUM_FRAMESIZES, &vid_frmsize);
+        if (ret == 0) {
+            FLOG_RUNTIME("enum frame size w:%d, h:%d",
+                         vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+            memset(&vid_frmval, 0, sizeof(struct v4l2_frmivalenum));
+            vid_frmval.index        = 0;
+            vid_frmval.pixel_format = vid_frmsize.pixel_format;
+            vid_frmval.width        = vid_frmsize.discrete.width;
+            vid_frmval.height       = vid_frmsize.discrete.height;
+
+            // ret = ioctl(mCameraHandle, VIDIOC_ENUM_FRAMEINTERVALS,
+            // &vid_frmval);
+            // v4l2 does not support, now hard code here.
+            if (ret == 0) {
+                FLOG_RUNTIME("vid_frmval denominator:%d, numeraton:%d",
+                             vid_frmval.discrete.denominator,
+                             vid_frmval.discrete.numerator);
+                if ((vid_frmsize.discrete.width > 1920) ||
+                    (vid_frmsize.discrete.height > 1080)) {
+                    vid_frmval.discrete.denominator = 15;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+                else {
+                    vid_frmval.discrete.denominator = 30;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+
+                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.width;
+                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.height;
+
+                if (vid_frmval.discrete.denominator /
+                    vid_frmval.discrete.numerator > 15) {
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.width;
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.height;;
+                }
+            }
+        }
+    } // end while
+
+    mMinFrameDuration = 33331760L;
+    mMaxFrameDuration = 30000000000L;
+    int i;
+    for (i=0; i<MAX_RESOLUTION_SIZE  && i<pictureCnt; i+=2) {
+        FLOGI("SupportedPictureSizes: %d x %d", mPictureResolutions[i], mPictureResolutions[i+1]);
+    }
+
+    adjustPreviewResolutions();
+    for (i=0; i<MAX_RESOLUTION_SIZE  && i<previewCnt; i+=2) {
+        FLOGI("SupportedPreviewSizes: %d x %d", mPreviewResolutions[i], mPreviewResolutions[i+1]);
+    }
+    FLOGI("FrameDuration is %lld, %lld", mMinFrameDuration, mMaxFrameDuration);
+
+    i = 0;
+    mTargetFpsRange[i++] = 12;
+    mTargetFpsRange[i++] = 15;
+    mTargetFpsRange[i++] = 27;
+    mTargetFpsRange[i++] = 30;
+
+    setMaxPictureResolutions();
+    FLOGI("mMaxWidth:%d, mMaxHeight:%d", mMaxWidth, mMaxHeight);
+
+    return NO_ERROR;
+}
+
+
diff --git a/mx6/libcamera2/Ov5640.h b/mx6/libcamera2/Ov5640.h
new file mode 100755
index 0000000..ec8897b
--- /dev/null
+++ b/mx6/libcamera2/Ov5640.h
@@ -0,0 +1,27 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _OV5640_H_
+#define _OV5640_H_
+
+#include "OvDevice.h"
+
+class Ov5640 : public OvDevice {
+public:
+    virtual status_t initSensorInfo();
+};
+
+#endif // ifndef _OV_DEVICE_H_
diff --git a/mx6/libcamera2/Ov5642.cpp b/mx6/libcamera2/Ov5642.cpp
new file mode 100755
index 0000000..24255c5
--- /dev/null
+++ b/mx6/libcamera2/Ov5642.cpp
@@ -0,0 +1,135 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "Ov5642.h"
+
+status_t Ov5642::initSensorInfo()
+{
+    if (mCameraHandle < 0) {
+        FLOGE("OvDevice: initParameters sensor has not been opened");
+        return BAD_VALUE;
+    }
+
+    // first read sensor format.
+    int ret = 0, index = 0;
+    int sensorFormats[MAX_SENSOR_FORMAT];
+    memset(mAvailableFormats, 0, sizeof(mAvailableFormats));
+    memset(sensorFormats, 0, sizeof(sensorFormats));
+#if 0
+    struct v4l2_fmtdesc vid_fmtdesc;
+    while (ret == 0) {
+        vid_fmtdesc.index = index;
+        vid_fmtdesc.type  = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        ret               = ioctl(mCameraHandle, VIDIOC_ENUM_FMT, &vid_fmtdesc);
+        FLOG_RUNTIME("index:%d,ret:%d, format:%c%c%c%c", index, ret,
+                     vid_fmtdesc.pixelformat & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 8) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 16) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0) {
+            sensorFormats[index++] = vid_fmtdesc.pixelformat;
+        }
+    }
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+#endif
+
+    // v4l2 does not support enum format, now hard code here.
+    sensorFormats[index++] = v4l2_fourcc('N', 'V', '1', '2');
+    sensorFormats[index++] = v4l2_fourcc('Y', 'V', '1', '2');
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+    //mAvailableFormats[2] = v4l2_fourcc('Y', 'U', 'Y', 'V');
+    index = 4;
+
+    changeSensorFormats(sensorFormats, index);
+
+    index = 0;
+    char TmpStr[20];
+    int  previewCnt = 0, pictureCnt = 0;
+    struct v4l2_frmsizeenum vid_frmsize;
+    struct v4l2_frmivalenum vid_frmval;
+    while (ret == 0) {
+        memset(TmpStr, 0, 20);
+        memset(&vid_frmsize, 0, sizeof(struct v4l2_frmsizeenum));
+        vid_frmsize.index        = index++;
+        vid_frmsize.pixel_format = v4l2_fourcc('N', 'V', '1', '2');
+        ret = ioctl(mCameraHandle,
+                    VIDIOC_ENUM_FRAMESIZES, &vid_frmsize);
+        if (ret == 0) {
+            FLOG_RUNTIME("enum frame size w:%d, h:%d",
+                         vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+            memset(&vid_frmval, 0, sizeof(struct v4l2_frmivalenum));
+            vid_frmval.index        = 0;
+            vid_frmval.pixel_format = vid_frmsize.pixel_format;
+            vid_frmval.width        = vid_frmsize.discrete.width;
+            vid_frmval.height       = vid_frmsize.discrete.height;
+
+            // ret = ioctl(mCameraHandle, VIDIOC_ENUM_FRAMEINTERVALS,
+            // &vid_frmval);
+            // v4l2 does not support, now hard code here.
+            if (ret == 0) {
+                FLOG_RUNTIME("vid_frmval denominator:%d, numeraton:%d",
+                             vid_frmval.discrete.denominator,
+                             vid_frmval.discrete.numerator);
+                if ((vid_frmsize.discrete.width > 1280) ||
+                    (vid_frmsize.discrete.height > 800)) {
+                    vid_frmval.discrete.denominator = 15;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+                else {
+                    vid_frmval.discrete.denominator = 30;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+
+                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.width;
+                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.height;
+
+                if (vid_frmval.discrete.denominator /
+                    vid_frmval.discrete.numerator > 15) {
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.width;
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.height;;
+                }
+            }
+        }
+    } // end while
+
+    mMinFrameDuration = 33331760L;
+    mMaxFrameDuration = 30000000000L;
+    int i;
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<pictureCnt; i+=2) {
+        FLOGI("SupportedPictureSizes: %d x %d", mPictureResolutions[i], mPictureResolutions[i+1]);
+    }
+
+    adjustPreviewResolutions();
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<previewCnt; i+=2) {
+        FLOGI("SupportedPreviewSizes: %d x %d", mPreviewResolutions[i], mPreviewResolutions[i+1]);
+    }
+    FLOGI("FrameDuration is %lld, %lld", mMinFrameDuration, mMaxFrameDuration);
+
+    i = 0;
+    mTargetFpsRange[i++] = 12;
+    mTargetFpsRange[i++] = 15;
+    mTargetFpsRange[i++] = 27;
+    mTargetFpsRange[i++] = 30;
+
+    setMaxPictureResolutions();
+    FLOGI("mMaxWidth:%d, mMaxHeight:%d", mMaxWidth, mMaxHeight);
+
+    return NO_ERROR;
+}
+
+
diff --git a/mx6/libcamera2/Ov5642.h b/mx6/libcamera2/Ov5642.h
new file mode 100755
index 0000000..c198c9c
--- /dev/null
+++ b/mx6/libcamera2/Ov5642.h
@@ -0,0 +1,27 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _OV5642_H_
+#define _OV5642_H_
+
+#include "OvDevice.h"
+
+class Ov5642 : public OvDevice {
+public:
+    virtual status_t initSensorInfo();
+};
+
+#endif // ifndef _OV_DEVICE_H_
diff --git a/mx6/libcamera2/OvDevice.cpp b/mx6/libcamera2/OvDevice.cpp
new file mode 100755
index 0000000..cb73543
--- /dev/null
+++ b/mx6/libcamera2/OvDevice.cpp
@@ -0,0 +1,252 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "CameraUtil.h"
+#include "OvDevice.h"
+
+status_t OvDevice::changeSensorFormats(int *src, int len)
+{
+    if (src == NULL || len == 0) {
+        return 0;
+    }
+
+    int k = 0;
+    for (int i=0; i<len && i<MAX_SENSOR_FORMAT; i++) {
+        switch (src[i]) {
+            case v4l2_fourcc('N', 'V', '1', '2'):
+                mAvailableFormats[k++] = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+                break;
+
+            case v4l2_fourcc('Y', 'V', '1', '2'):
+                mAvailableFormats[k++] = HAL_PIXEL_FORMAT_YCbCr_420_P;
+                break;
+
+            case v4l2_fourcc('Y', 'U', 'Y', 'V'):
+                mAvailableFormats[k++] = HAL_PIXEL_FORMAT_YCbCr_422_I;
+                break;
+
+            case v4l2_fourcc('B', 'L', 'O', 'B'):
+                mAvailableFormats[k++] = HAL_PIXEL_FORMAT_BLOB;
+                break;
+
+            case v4l2_fourcc('R', 'A', 'W', 'S'):
+                mAvailableFormats[k++] = HAL_PIXEL_FORMAT_RAW_SENSOR;
+                break;
+
+            default:
+                FLOGE("Error: format 0x%x not supported!", src[i]);
+                break;
+        }
+    }
+
+    return 0;
+}
+
+status_t OvDevice::initSensorInfo()
+{
+    if (mCameraHandle < 0) {
+        FLOGE("OvDevice: initParameters sensor has not been opened");
+        return BAD_VALUE;
+    }
+
+    // first read sensor format.
+    int ret = 0, index = 0;
+    int sensorFormats[MAX_SENSOR_FORMAT];
+    memset(mAvailableFormats, 0, sizeof(mAvailableFormats));
+    memset(sensorFormats, 0, sizeof(sensorFormats));
+#if 0
+    struct v4l2_fmtdesc vid_fmtdesc;
+    while (ret == 0) {
+        vid_fmtdesc.index = index;
+        vid_fmtdesc.type  = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        ret               = ioctl(mCameraHandle, VIDIOC_ENUM_FMT, &vid_fmtdesc);
+        FLOG_RUNTIME("index:%d,ret:%d, format:%c%c%c%c", index, ret,
+                     vid_fmtdesc.pixelformat & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 8) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 16) & 0xFF,
+                     (vid_fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0) {
+            sensorFormats[index++] = vid_fmtdesc.pixelformat;
+        }
+    }
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+#endif
+
+    // v4l2 does not support enum format, now hard code here.
+    sensorFormats[index++] = v4l2_fourcc('N', 'V', '1', '2');
+    sensorFormats[index++] = v4l2_fourcc('Y', 'V', '1', '2');
+    sensorFormats[index++] = v4l2_fourcc('B', 'L', 'O', 'B');
+    sensorFormats[index++] = v4l2_fourcc('R', 'A', 'W', 'S');
+    //mAvailableFormats[2] = v4l2_fourcc('Y', 'U', 'Y', 'V');
+    index = 4;
+
+    changeSensorFormats(sensorFormats, index);
+
+    index = 0;
+    char TmpStr[20];
+    int  previewCnt = 0, pictureCnt = 0;
+    struct v4l2_frmsizeenum vid_frmsize;
+    struct v4l2_frmivalenum vid_frmval;
+    while (ret == 0) {
+        memset(TmpStr, 0, 20);
+        memset(&vid_frmsize, 0, sizeof(struct v4l2_frmsizeenum));
+        vid_frmsize.index        = index++;
+        vid_frmsize.pixel_format = v4l2_fourcc('N', 'V', '1', '2');
+        ret = ioctl(mCameraHandle,
+                    VIDIOC_ENUM_FRAMESIZES, &vid_frmsize);
+        if (ret == 0) {
+            FLOG_RUNTIME("enum frame size w:%d, h:%d",
+                         vid_frmsize.discrete.width, vid_frmsize.discrete.height);
+            memset(&vid_frmval, 0, sizeof(struct v4l2_frmivalenum));
+            vid_frmval.index        = 0;
+            vid_frmval.pixel_format = vid_frmsize.pixel_format;
+            vid_frmval.width        = vid_frmsize.discrete.width;
+            vid_frmval.height       = vid_frmsize.discrete.height;
+
+            // ret = ioctl(mCameraHandle, VIDIOC_ENUM_FRAMEINTERVALS,
+            // &vid_frmval);
+            // v4l2 does not support, now hard code here.
+            if (ret == 0) {
+                FLOG_RUNTIME("vid_frmval denominator:%d, numeraton:%d",
+                             vid_frmval.discrete.denominator,
+                             vid_frmval.discrete.numerator);
+                if ((vid_frmsize.discrete.width > 1920) ||
+                    (vid_frmsize.discrete.height > 1080)) {
+                    vid_frmval.discrete.denominator = 15;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+                else {
+                    vid_frmval.discrete.denominator = 30;
+                    vid_frmval.discrete.numerator   = 1;
+                }
+
+                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.width;
+                mPictureResolutions[pictureCnt++] = vid_frmsize.discrete.height;
+
+                if (vid_frmval.discrete.denominator /
+                    vid_frmval.discrete.numerator > 15) {
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.width;
+                    mPreviewResolutions[previewCnt++] = vid_frmsize.discrete.height;;
+                }
+            }
+        }
+    } // end while
+
+    mMinFrameDuration = 33331760L;
+    mMaxFrameDuration = 30000000000L;
+    int i;
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<pictureCnt; i+=2) {
+        FLOGI("SupportedPictureSizes: %d x %d", mPictureResolutions[i], mPictureResolutions[i+1]);
+    }
+
+    adjustPreviewResolutions();
+    for (i=0; i<MAX_RESOLUTION_SIZE && i<previewCnt; i+=2) {
+        FLOGI("SupportedPreviewSizes: %d x %d", mPreviewResolutions[i], mPreviewResolutions[i+1]);
+    }
+    FLOGI("FrameDuration is %lld, %lld", mMinFrameDuration, mMaxFrameDuration);
+
+    i = 0;
+    mTargetFpsRange[i++] = 12;
+    mTargetFpsRange[i++] = 15;
+    mTargetFpsRange[i++] = 27;
+    mTargetFpsRange[i++] = 30;
+
+    setMaxPictureResolutions();
+    FLOGI("mMaxWidth:%d, mMaxHeight:%d", mMaxWidth, mMaxHeight);
+    mFocalLength = 0.0f;
+
+    return NO_ERROR;
+}
+
+int OvDevice::getCaptureMode(int width, int height)
+{
+    int capturemode = 0;
+
+    if ((width == 640) && (height == 480)) {
+        capturemode = 0;
+    }
+    else if ((width == 320) && (height == 240)) {
+        capturemode = 1;
+    }
+    else if ((width == 720) && (height == 480)) {
+        capturemode = 2;
+    }
+    else if ((width == 720) && (height == 576)) {
+        capturemode = 3;
+    }
+    else if ((width == 1280) && (height == 720)) {
+        capturemode = 4;
+    }
+    else if ((width == 1920) && (height == 1080)) {
+        capturemode = 5;
+    }
+    else if ((width == 2592) && (height == 1944)) {
+        capturemode = 6;
+    }
+    else if ((width == 176) && (height == 144)) {
+        capturemode = 7;
+    }
+    else if ((width == 1024) && (height == 768)) {
+        capturemode = 8;
+    }
+    else {
+        FLOGE("width:%d height:%d is not supported.", width, height);
+    }
+    return capturemode;
+}
+
+status_t OvDevice::adjustPreviewResolutions()
+{
+    int xTmp, yTmp, xMax, yMax, idx;
+    idx = 0;
+    xTmp = xMax = mPreviewResolutions[0];
+    yTmp = yMax = mPreviewResolutions[1];
+    for (int i=0; i<MAX_RESOLUTION_SIZE; i+=2) {
+        if (mPreviewResolutions[i] > xMax) {
+            xMax = mPreviewResolutions[i];
+            yMax = mPreviewResolutions[i+1];
+            idx = i;
+        }
+    }
+
+    mPreviewResolutions[0] = xMax;
+    mPreviewResolutions[1] = yMax;
+    mPreviewResolutions[idx] = xTmp;
+    mPreviewResolutions[idx+1] = yTmp;
+
+    return 0;
+}
+
+status_t OvDevice::setMaxPictureResolutions()
+{
+    int xMax, yMax;
+    xMax = mPictureResolutions[0];
+    yMax = mPictureResolutions[1];
+
+    for (int i=0; i<MAX_RESOLUTION_SIZE; i+=2) {
+        if (mPictureResolutions[i] > xMax || mPictureResolutions[i+1] > yMax) {
+            xMax = mPictureResolutions[i];
+            yMax = mPictureResolutions[i+1];
+        }
+    }
+
+    mMaxWidth = xMax;
+    mMaxHeight = yMax;
+
+    return 0;
+}
+
diff --git a/mx6/libcamera2/OvDevice.h b/mx6/libcamera2/OvDevice.h
new file mode 100755
index 0000000..20ee6dd
--- /dev/null
+++ b/mx6/libcamera2/OvDevice.h
@@ -0,0 +1,41 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _OV_DEVICE_H_
+#define _OV_DEVICE_H_
+
+#include "CameraUtil.h"
+#include "DeviceAdapter.h"
+
+#define DEFAULT_PREVIEW_FPS (15)
+#define DEFAULT_PREVIEW_W   (640)
+#define DEFAULT_PREVIEW_H   (480)
+#define DEFAULT_PICTURE_W   (640)
+#define DEFAULT_PICTURE_H   (480)
+#define FORMAT_STRING_LEN 64
+
+class OvDevice : public DeviceAdapter {
+public:
+    virtual status_t initSensorInfo();
+    virtual int getCaptureMode(int width, int height);
+
+protected:
+    status_t changeSensorFormats(int *src, int len);
+    status_t adjustPreviewResolutions();
+    status_t setMaxPictureResolutions();
+};
+
+#endif // ifndef _OV_DEVICE_H_
diff --git a/mx6/libcamera2/PhysMemAdapter.cpp b/mx6/libcamera2/PhysMemAdapter.cpp
new file mode 100755
index 0000000..e0fde2c
--- /dev/null
+++ b/mx6/libcamera2/PhysMemAdapter.cpp
@@ -0,0 +1,145 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+#include "PhysMemAdapter.h"
+#include <ion/ion.h>
+
+PhysMemAdapter::PhysMemAdapter()
+    : mIonFd(-1), mFrameWidth(0), mFrameHeight(0),
+      mBufferCount(0), mBufferSize(0), mFormat(0)
+{
+    memset(mCameraBuffer, 0, sizeof(mCameraBuffer));
+    mIonFd = ion_open();
+}
+
+PhysMemAdapter::~PhysMemAdapter()
+{
+    memset(mCameraBuffer, 0, sizeof(mCameraBuffer));
+    clearBufferListeners();
+    ion_close(mIonFd);
+}
+
+int PhysMemAdapter::allocateBuffers(int width,int height,
+                                   int format, int numBufs)
+{
+    if (mIonFd <= 0) {
+        FLOGE("try to allocate buffer from ion in preview or ion invalid");
+        return BAD_VALUE;
+    }
+
+    int size = 0;
+    if ((width == 0) || (height == 0)) {
+        FLOGE("allocateBufferFromIon: width or height = 0");
+        return BAD_VALUE;
+    }
+    switch (format) {
+        case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+            size = width * ((height + 16) & (~15)) * 3 / 2;
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_420_P:
+            size = width * height * 3 / 2;
+            break;
+
+        case HAL_PIXEL_FORMAT_YCbCr_422_I:
+            size = width * height * 2;
+            break;
+
+        default:
+            FLOGE("Error: format not supported int ion alloc");
+            return BAD_VALUE;
+    }
+
+    unsigned char *ptr = NULL;
+    int sharedFd;
+    int phyAddr;
+    struct ion_handle *ionHandle;
+    size = (size + PAGE_SIZE) & (~(PAGE_SIZE - 1));
+
+    FLOGI("allocateBufferFromIon buffer num:%d", numBufs);
+    for (int i = 0; i < numBufs; i++) {
+        ionHandle = NULL;
+        int err = ion_alloc(mIonFd, size, 8, 1, &ionHandle);
+        if (err) {
+            FLOGE("ion_alloc failed.");
+            return BAD_VALUE;
+        }
+
+        err = ion_map(mIonFd,
+                      ionHandle,
+                      size,
+                      PROT_READ | PROT_WRITE,
+                      MAP_SHARED,
+                      0,
+                      &ptr,
+                      &sharedFd);
+        if (err) {
+            FLOGE("ion_map failed.");
+            return BAD_VALUE;
+        }
+        phyAddr = ion_phys(mIonFd, ionHandle);
+        if (phyAddr == 0) {
+            FLOGE("ion_phys failed.");
+            return BAD_VALUE;
+        }
+        FLOG_RUNTIME("phyalloc ptr:0x%x, phy:0x%x, size:%d",
+                     (int)ptr,
+                     phyAddr,
+                     size);
+        mCameraBuffer[i].reset();
+        mCameraBuffer[i].mIndex     = i;
+        mCameraBuffer[i].mWidth     = width;
+        mCameraBuffer[i].mHeight    = height;
+        mCameraBuffer[i].mFormat    = format;
+        mCameraBuffer[i].mVirtAddr  = ptr;
+        mCameraBuffer[i].mPhyAddr   = phyAddr;
+        mCameraBuffer[i].mSize      =  size;
+        mCameraBuffer[i].mBufHandle = (buffer_handle_t)ionHandle;
+        mCameraBuffer[i].setState(CameraFrame::BUFS_FREE);
+        close(sharedFd);
+    }
+
+    mBufferCount    = numBufs;
+    mFormat         = format;
+    mBufferSize     = mCameraBuffer[0].mSize;
+    mFrameWidth     = width;
+    mFrameHeight    = height;
+
+    dispatchBuffers(&mCameraBuffer[0], numBufs, BUFFER_CREATE);
+
+    return NO_ERROR;
+}
+
+int PhysMemAdapter::freeBuffers()
+{
+    if (mIonFd <= 0) {
+        FLOGE("try to free buffer from ion in preview or ion invalid");
+        return BAD_VALUE;
+    }
+
+    FLOGI("freeBufferToIon buffer num:%d", mBufferCount);
+    for (int i = 0; i < mBufferCount; i++) {
+        struct ion_handle *ionHandle =
+            (struct ion_handle *)mCameraBuffer[i].mBufHandle;
+        ion_free(mIonFd, ionHandle);
+        munmap(mCameraBuffer[i].mVirtAddr, mCameraBuffer[i].mSize);
+    }
+
+    memset(mCameraBuffer, 0, sizeof(mCameraBuffer));
+    dispatchBuffers(NULL, 0, BUFFER_DESTROY);
+    return NO_ERROR;
+}
diff --git a/mx6/libcamera2/PhysMemAdapter.h b/mx6/libcamera2/PhysMemAdapter.h
new file mode 100755
index 0000000..c403ea6
--- /dev/null
+++ b/mx6/libcamera2/PhysMemAdapter.h
@@ -0,0 +1,54 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _PHYS_MEM_ADAPTER_H_
+#define _PHYS_MEM_ADAPTER_H_
+
+#include "CameraUtil.h"
+
+using namespace android;
+
+class PhysMemAdapter : public CameraBufferProvider {
+public:
+    PhysMemAdapter();
+    virtual ~PhysMemAdapter();
+
+//    virtual int allocatePreviewBuffer(int width,
+//                                      int height,
+//                                      int format,
+//                                      int numBufs);
+    virtual int allocateBuffers(int width, int height,
+                               int format, int numBufs);
+    virtual int freeBuffers();
+    //virtual int maxQueueableBuffers();
+
+    // void setErrorListener(CameraErrorListener* listener);
+
+protected:
+    int mIonFd;
+    CameraErrorListener *mErrorListener;
+
+    CameraFrame mCameraBuffer[MAX_CAPTURE_BUFFER];
+
+    uint32_t mFrameWidth;
+    uint32_t mFrameHeight;
+    int mBufferCount;
+    int mBufferSize;
+    PixelFormat mFormat;
+    //int mQueueableCount;
+};
+
+#endif // ifndef _PHYS_MEM_ADAPTER_H_
diff --git a/mx6/libcamera2/PreviewStream.cpp b/mx6/libcamera2/PreviewStream.cpp
new file mode 100755
index 0000000..ec0b94e
--- /dev/null
+++ b/mx6/libcamera2/PreviewStream.cpp
@@ -0,0 +1,240 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "StreamAdapter.h"
+
+
+int PreviewStream::configure(int fps, bool videoSnapshot)
+{
+    FLOG_TRACE("PreviewStream %s running", __FUNCTION__);
+    int ret = NO_ERROR;
+    int errCode = 0;
+
+    fAssert(mDeviceAdapter.get() != NULL);
+    ret = mDeviceAdapter->setDeviceConfig(mWidth, mHeight, mFormat, fps);
+    if (ret != NO_ERROR) {
+        FLOGE("%s setDeviceConfig failed", __FUNCTION__);
+        errCode = CAMERA2_MSG_ERROR_DEVICE;
+        goto fail;
+    }
+
+    mDeviceAdapter->setCameraBufferProvide(this);
+    ret = allocateBuffers(mWidth, mHeight, mFormat, mMaxProducerBuffers);
+    if (ret != NO_ERROR) {
+        FLOGE("%s allocateBuffers failed", __FUNCTION__);
+        errCode = CAMERA2_MSG_ERROR_REQUEST;
+        goto fail;
+    }
+
+    mPrepared = true;
+    return NO_ERROR;
+
+fail:
+    freeBuffers();
+    FLOGE("Error occurred, performing cleanup");
+
+    if (NULL != mErrorListener) {
+        mErrorListener->handleError(errCode);
+    }
+
+    return BAD_VALUE;
+}
+
+int PreviewStream::allocateBuffers(int width, int height,
+                        int format, int numBufs)
+{
+    int index = -1;
+    int ret = NO_ERROR;
+
+    for (int i = 0; i < mMaxProducerBuffers; i++) {
+        buffer_handle_t *buf_h = NULL;
+        ret = mNativeWindow->dequeue_buffer(mNativeWindow, &buf_h);
+        if (ret != 0) {
+            FLOGE("dequeueBuffer failed: %s (%d)", strerror(-ret), -ret);
+            if (ENODEV == ret) {
+                FLOGE("Preview surface abandoned!");
+                mNativeWindow = NULL;
+            }
+            return ret;
+        }
+
+        index = getBufferIdx(buf_h);
+        if (index < 0 || index >= mTotalBuffers) {
+            FLOGE("%s dequeue invalid buffer", __FUNCTION__);
+            return BAD_VALUE;
+        }
+        mCameraBuffer[index].setState(CameraFrame::BUFS_FREE);
+    }
+
+    for (int i = 0; i < mTotalBuffers; i++) {
+        int state = mCameraBuffer[i].getState();
+        if (state == CameraFrame::BUFS_IN_SERVICE) {
+            //the frame held in service.
+            mCameraBuffer[i].addReference();
+        }
+    }
+
+    dispatchBuffers(&mCameraBuffer[0], mTotalBuffers, BUFFER_CREATE);
+
+    return ret;
+}
+
+int PreviewStream::freeBuffers()
+{
+    status_t ret = NO_ERROR;
+
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+
+    // Give the buffers back to display here -  sort of free it
+    if (mNativeWindow) {
+        for (int i = 0; i < mTotalBuffers; i++) {
+            mapper.unlock(mCameraBuffer[i].mBufHandle);
+            ret = mNativeWindow->cancel_buffer(mNativeWindow,
+                                               &mCameraBuffer[i].mBufHandle);
+            if (ENODEV == ret) {
+                FLOGE("Preview surface abandoned!");
+                mNativeWindow = NULL;
+                return -ret;
+            }
+            else if (NO_ERROR != ret) {
+                FLOGE("cancel_buffer() failed: %s (%d)", strerror(-ret), -ret);
+                return -ret;
+            }
+        }
+    }
+    else {
+        FLOGE("mNativeWindow is NULL");
+    }
+
+    // /Clear the frames with camera adapter map
+    dispatchBuffers(NULL, 0, BUFFER_DESTROY);
+
+    return ret;
+}
+
+int PreviewStream::getBufferIdx(buffer_handle_t *buf)
+{
+    if (buf == NULL) {
+        FLOGE("%s invalid param", __FUNCTION__);
+        return -1;
+    }
+
+    int index = -1;
+    for (int i=0; i < mTotalBuffers; i++) {
+        if (mCameraBuffer[i].mBufHandle == *buf) {
+            index = i;
+            break;
+        }
+    }
+
+    return index;
+}
+
+int PreviewStream::registerBuffers(int num_buffers, buffer_handle_t *buffers)
+{
+    if (buffers == NULL || num_buffers > MAX_PREVIEW_BUFFER) {
+        FLOGE("%s buffer num %d too large", __FUNCTION__, num_buffers);
+        return BAD_VALUE;
+    }
+
+    mTotalBuffers = num_buffers;
+    FLOGI("%s total %d buffer", __FUNCTION__, num_buffers);
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+    Rect bounds;
+    memset(mCameraBuffer, 0, sizeof(mCameraBuffer));
+
+    bounds.left   = 0;
+    bounds.top    = 0;
+    bounds.right  = mWidth;
+    bounds.bottom = mHeight;
+    void *pVaddr = NULL;
+
+    for (int i=0; i < num_buffers; i++) {
+        mapper.lock(buffers[i], mUsage, bounds, &pVaddr);
+        mCameraBuffer[i].initialize(buffers[i], i);
+        mCameraBuffer[i].mWidth  = mWidth;
+        mCameraBuffer[i].mHeight = mHeight;
+        mCameraBuffer[i].setState(CameraFrame::BUFS_IN_SERVICE);
+    }
+
+    return 0;
+}
+
+int PreviewStream::start()
+{
+    FLOG_TRACE("PreviewStream %s running", __FUNCTION__);
+    int ret = 0;
+    StreamAdapter::start();
+
+    fAssert(mDeviceAdapter.get() != NULL);
+    ret = mDeviceAdapter->startPreview();
+    if (ret != NO_ERROR) {
+        FLOGE("Couldn't start preview for DeviceAdapter");
+        return ret;
+    }
+    return NO_ERROR;
+}
+
+int PreviewStream::stop()
+{
+    FLOG_TRACE("PreviewStream %s running", __FUNCTION__);
+    StreamAdapter::stop();
+
+    if (mDeviceAdapter.get() != NULL) {
+        mDeviceAdapter->stopPreview();
+    }
+    return NO_ERROR;
+}
+
+int PreviewStream::release()
+{
+    FLOG_TRACE("PreviewStream %s running", __FUNCTION__);
+    StreamAdapter::release();
+    return freeBuffers();
+}
+
+int PreviewStream::processFrame(CameraFrame *frame)
+{
+    status_t ret = NO_ERROR;
+
+    ret = renderBuffer(frame);
+    if (ret != NO_ERROR) {
+        FLOGE("%s renderBuffer failed", __FUNCTION__);
+        return ret;
+    }
+    //the frame held in service.
+    frame->addReference();
+
+    StreamBuffer buffer;
+    ret = requestBuffer(&buffer);
+    if (ret != NO_ERROR) {
+        FLOGE("%s requestBuffer failed", __FUNCTION__);
+        return ret;
+    }
+
+    for (int i = 0; i < mTotalBuffers; i++) {
+        if (mCameraBuffer[i].mBufHandle == buffer.mBufHandle) {
+            //release frame from service.
+            mCameraBuffer[i].release();
+            break;
+        }
+    }
+
+    mCondRespond.signal();
+
+    return ret;
+}
+
diff --git a/mx6/libcamera2/RequestManager.cpp b/mx6/libcamera2/RequestManager.cpp
new file mode 100755
index 0000000..e5bf798
--- /dev/null
+++ b/mx6/libcamera2/RequestManager.cpp
@@ -0,0 +1,427 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "RequestManager.h"
+
+RequestManager::RequestManager(int cameraId)
+{
+    mRequestOperation = NULL;
+    mPendingRequests = 0;
+    mCameraId = cameraId;
+}
+
+RequestManager::~RequestManager()
+{
+    release();
+}
+
+int RequestManager::initialize(CameraInfo& info)
+{
+    status_t ret = NO_ERROR;
+
+    FLOG_RUNTIME("initialize name:%s, path:%s", info.name, info.devPath);
+    mDeviceAdapter = DeviceAdapter::Create(info);
+    if (mDeviceAdapter == NULL) {
+        FLOGE("CameraHal: DeviceAdapter create failed");
+        return BAD_VALUE;
+    }
+
+    mMetadaManager = new MetadaManager(mDeviceAdapter.get(), mCameraId);
+    mDeviceAdapter->setMetadaManager(mMetadaManager);
+    ret = mDeviceAdapter->initialize(info);
+    if (ret) {
+        FLOGE("CameraHal: DeviceAdapter initialize failed");
+        return ret;
+    }
+
+    ret = mMetadaManager->createStaticInfo(
+               (camera_metadata_t**)&info.static_camera_characteristics, true);
+    if (ret) {
+        FLOGE("CameraHal: createStaticInfo failed");
+        return ret;
+    }
+
+    ret = mMetadaManager->createStaticInfo(
+               (camera_metadata_t**)&info.static_camera_characteristics, false);
+    if (ret) {
+        FLOGE("CameraHal: createStaticInfo 2 failed");
+        return ret;
+    }
+    mPendingRequests=0;
+
+    return ret;
+}
+
+void RequestManager::stopAllStreamsLocked()
+{
+    FLOG_TRACE("%s running", __FUNCTION__);
+    sp<StreamAdapter> cameraStream;
+    for (int id = 0; id < MAX_STREAM_NUM; id++) {
+        cameraStream = mStreamAdapter[id];
+        FLOG_RUNTIME("%s steam id:%d", __FUNCTION__, id);
+        if (cameraStream.get() != NULL) {
+            if (cameraStream->mStarted) {
+                cameraStream->stop();
+            }
+            if (cameraStream->mPrepared) {
+                cameraStream->release();
+            }
+        }
+    }
+    FLOG_TRACE("%s end", __FUNCTION__);
+}
+
+int RequestManager::setRequestOperation(const camera2_request_queue_src_ops_t *request_src_ops)
+{
+    mRequestOperation = request_src_ops;
+    return 0;
+}
+
+int RequestManager::CreateDefaultRequest(int request_template, camera_metadata_t **request)
+{
+    FLOG_TRACE("DEBUG(%s): making template (%d) ", __FUNCTION__, request_template);
+
+    if (request == NULL) return BAD_VALUE;
+    if (request_template < 0 || request_template >= CAMERA2_TEMPLATE_COUNT) {
+        return BAD_VALUE;
+    }
+    status_t res;
+    fAssert(mMetadaManager.get() != NULL);
+    // Pass 1, calculate size and allocate
+    res = mMetadaManager->createDefaultRequest(request_template,
+            request,
+            true);
+    if (res != OK) {
+        return res;
+    }
+    // Pass 2, build request
+    res = mMetadaManager->createDefaultRequest(request_template,
+            request,
+            false);
+    if (res != OK) {
+        FLOGE("Unable to populate new request for template %d",
+                request_template);
+    }
+
+    return res;
+}
+
+int RequestManager::dispatchRequest()
+{
+    FLOG_TRACE("%s running", __FUNCTION__);
+    if (mRequestThread.get() != NULL) {
+        FLOGI("RequestThread is running, request it exit");
+        mRequestThread->requestExit();
+        FLOGI("RequestThread exiting");
+    }
+
+    mRequestThread = new RequestHandleThread(this);
+    mPendingRequests++;
+    mRequestThread->run("RequestHandle", PRIORITY_DEFAULT);
+    return 0;
+}
+
+bool RequestManager::handleRequest()
+{
+    FLOG_TRACE("%s running", __FUNCTION__);
+    int res;
+    camera_metadata_t *request=NULL;
+
+    while(mRequestOperation) {
+        FLOG_RUNTIME("%s:Dequeue request" ,__FUNCTION__);
+        mRequestOperation->dequeue_request(mRequestOperation, &request);
+        if(request == NULL) {
+            FLOGE("%s:No more requests available", __FUNCTION__);
+            break;
+        }
+
+        /* Check the streams that need to be active in the stream request */
+        sort_camera_metadata(request);
+
+        res = mMetadaManager->setCurrentRequest(request);
+        if (res != NO_ERROR) {
+            FLOGE("%s: setCurrentRequest failed", __FUNCTION__);
+            mPendingRequests--;
+            return false;
+        }
+
+        int requestType = 0;
+        mMetadaManager->getRequestType(&requestType);
+        FLOG_RUNTIME("%s:start request %d", __FUNCTION__, requestType);
+
+        res = tryRestartStreams(requestType);
+        if (res != NO_ERROR) {
+            FLOGE("%s: tryRestartStreams failed", __FUNCTION__);
+            mPendingRequests--;
+            return false;
+        }
+
+        /* Free the request buffer */
+        mRequestOperation->free_request(mRequestOperation, request);
+        FLOG_RUNTIME("%s:Completed request %d", __FUNCTION__, requestType);
+    }//end while
+
+    FLOG_TRACE("%s exiting", __FUNCTION__);
+    stopAllStreamsLocked();
+    mRequestThread.clear();
+    mPendingRequests--;
+    FLOG_TRACE("%s end...", __FUNCTION__);
+
+    return false;
+}
+
+bool RequestManager::isStreamValid(int requestType, int streamId)
+{
+    if (requestType == REQUEST_TYPE_CAPTURE && streamId == STREAM_ID_PREVIEW) {
+        return false;
+    }
+    if (requestType == REQUEST_TYPE_PREVIEW && streamId == STREAM_ID_JPEG) {
+        return false;
+    }
+
+    return true;
+}
+
+int RequestManager::tryRestartStreams(int requestType)
+{
+    FLOG_RUNTIME("%s running", __FUNCTION__);
+    int res = 0;
+    int fps = 30;
+    bool needRestart = false;
+    res = mMetadaManager->getFrameRate(&fps);
+    if (res != NO_ERROR) {
+        FLOGE("%s: getFrameRate failed", __FUNCTION__);
+        return res;
+    }
+
+    camera_metadata_entry_t streams;
+    res = mMetadaManager->getRequestStreams(&streams);
+    if (res != NO_ERROR) {
+        FLOGE("%s: getRequestStreams failed", __FUNCTION__);
+        return res;
+    }
+
+    bool streamRecord = false;
+    bool streamPicture = false;
+    bool videoSnapshot = false;
+    for (uint32_t i = 0; i < streams.count; i++) {
+        int streamId = streams.data.u8[i];
+        if (streamId == STREAM_ID_RECORD) {
+            streamRecord = true;
+        }
+        else if (streamId == STREAM_ID_JPEG) {
+            streamPicture = true;
+        }
+    }
+
+    if (streamRecord && streamPicture) {
+        videoSnapshot = true;
+    }
+
+    for (uint32_t i = 0; i < streams.count; i++) {
+        int streamId = streams.data.u8[i];
+        if (!isStreamValid(requestType, streamId)) {
+            continue;
+        }
+        sp<StreamAdapter> stream = mStreamAdapter[streamId];
+        if (stream.get() == NULL) {
+            continue;
+        }
+        if (!stream->mPrepared) {
+            FLOGI("stream id:%d need restart", streamId);
+            needRestart = true;
+            break;
+        }
+    }
+
+    if (needRestart) {
+        stopAllStreamsLocked();
+    }
+
+    for (uint32_t i = 0; i < streams.count; i++) {
+        int streamId = streams.data.u8[i];
+        if (!isStreamValid(requestType, streamId)) {
+            continue;
+        }
+        sp<StreamAdapter> stream = mStreamAdapter[streamId];
+        if (stream.get() == NULL) {
+            continue;
+        }
+
+        if (!stream->mPrepared) {
+            res = stream->configure(fps, videoSnapshot);
+            if (res != NO_ERROR) {
+                FLOGE("error configure stream %d", res);
+                return res;
+            }
+        }
+
+        if (!stream->mStarted) {
+            res = stream->start();
+            if (res != NO_ERROR) {
+                FLOGE("error start stream %d", res);
+                return res;
+            }
+        }
+    }
+
+    for (uint32_t i = 0; i < streams.count; i++) {
+        int streamId = streams.data.u8[i];
+        if (!isStreamValid(requestType, streamId)) {
+            continue;
+        }
+
+        sp<StreamAdapter> stream = mStreamAdapter[streamId];
+        if (stream.get() == NULL) {
+            continue;
+        }
+
+        if (!stream->mPrepared || !stream->mStarted) {
+            continue;
+        }
+
+        stream->applyRequest();
+    }
+
+    return res;
+}
+
+int RequestManager::getInProcessCount()
+{
+    return mPendingRequests;
+}
+
+int RequestManager::allocateStream(uint32_t width,
+        uint32_t height, int format,
+        const camera2_stream_ops_t *stream_ops,
+        uint32_t *stream_id,
+        uint32_t *format_actual,
+        uint32_t *usage,
+        uint32_t *max_buffers)
+{
+    int sid = -1;
+    sp<StreamAdapter> cameraStream;
+    *usage = CAMERA_GRALLOC_USAGE;
+
+    FLOG_TRACE("RequestManager %s...", __FUNCTION__);
+    if (format == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
+        if(mStreamAdapter[STREAM_ID_PREVIEW].get() != NULL) {
+            FLOGI("%s record stream, w:%d, h:%d, fmt:0x%x", __FUNCTION__,
+                          width, height, format);
+            sid = STREAM_ID_RECORD;
+            cameraStream = new StreamAdapter(sid);
+        }
+        else {
+            FLOGI("%s preview stream, w:%d, h:%d, fmt:0x%x", __FUNCTION__,
+                          width, height, format);
+            sid = STREAM_ID_PREVIEW;
+            cameraStream = new PreviewStream(sid);
+        }
+
+        //*format_actual = HAL_PIXEL_FORMAT_YCrCb_420_SP;
+        *format_actual = mDeviceAdapter->getPreviewPixelFormat();
+        FLOGI("actual format 0x%x", *format_actual);
+        *max_buffers = NUM_PREVIEW_BUFFER;
+    }
+    else if (format == HAL_PIXEL_FORMAT_BLOB) {
+        FLOGI("%s jpeg stream, w:%d, h:%d, fmt:0x%x", __FUNCTION__,
+                      width, height, format);
+        //*format_actual = HAL_PIXEL_FORMAT_BLOB;
+        *format_actual = mDeviceAdapter->getPicturePixelFormat();
+        FLOGI("actual format 0x%x", *format_actual);
+        sid = STREAM_ID_JPEG;
+        *max_buffers = NUM_CAPTURE_BUFFER;
+
+        cameraStream = new CaptureStream(sid);
+    }
+    else if (format == HAL_PIXEL_FORMAT_YCbCr_420_SP ||
+                         format == HAL_PIXEL_FORMAT_YCbCr_420_P) {
+        FLOGI("%s callback stream, w:%d, h:%d, fmt:0x%x", __FUNCTION__,
+                      width, height, format);
+        *format_actual = format;
+        sid = STREAM_ID_PRVCB;
+        *max_buffers = NUM_PREVIEW_BUFFER;
+
+        cameraStream = new StreamAdapter(sid);
+    }
+    else if (format == CAMERA2_HAL_PIXEL_FORMAT_ZSL) {
+        FLOGI("%s callback stream, w:%d, h:%d, fmt:0x%x", __FUNCTION__,
+                      width, height, format);
+        *format_actual = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+        sid = STREAM_ID_PRVCB;
+        *max_buffers = NUM_PREVIEW_BUFFER;
+
+        cameraStream = new StreamAdapter(sid);
+    }
+    else {
+        FLOGE("format %d does not support now.", format);
+        return BAD_VALUE;
+    }
+
+    *stream_id = sid;
+    cameraStream->initialize(width, height, *format_actual, *usage, *max_buffers);
+    cameraStream->setPreviewWindow(stream_ops);
+    cameraStream->setDeviceAdapter(mDeviceAdapter);
+    cameraStream->setMetadaManager(mMetadaManager);
+
+    mStreamAdapter[sid] = cameraStream;
+    FLOG_TRACE("RequestManager %s end...", __FUNCTION__);
+
+    return 0;
+}
+
+int RequestManager::registerStreamBuffers(uint32_t stream_id, int num_buffers,
+        buffer_handle_t *buffers)
+{
+    FLOG_TRACE("RequestManager %s stream id:%d", __FUNCTION__, stream_id);
+    fAssert(mStreamAdapter[stream_id].get() != NULL);
+    mStreamAdapter[stream_id]->registerBuffers(num_buffers, buffers);
+    FLOG_TRACE("RequestManager %s end...", __FUNCTION__);
+
+    return 0;
+}
+
+int RequestManager::releaseStream(uint32_t stream_id)
+{
+    FLOG_TRACE("RequestManager %s stream id:%d", __FUNCTION__, stream_id);
+    sp<StreamAdapter> cameraStream = mStreamAdapter[stream_id];
+    if (cameraStream.get() == NULL) {
+        FLOGI("%s release invalid stream %d", __FUNCTION__, stream_id);
+        return 0;
+    }
+
+    if (cameraStream->mStarted) {
+        cameraStream->stop();
+    }
+    if (cameraStream->mPrepared) {
+        cameraStream->release();
+    }
+    mStreamAdapter[stream_id].clear();
+    FLOG_TRACE("RequestManager %s end...", __FUNCTION__);
+
+    return 0;
+}
+
+void RequestManager::release()
+{
+    FLOG_TRACE("RequestManager %s...", __FUNCTION__);
+    for (int id = 0; id < MAX_STREAM_NUM; id++) {
+        if (mStreamAdapter[id].get() != NULL) {
+            releaseStream(id);
+        }
+    }
+    FLOG_TRACE("RequestManager %s end...", __FUNCTION__);
+}
diff --git a/mx6/libcamera2/RequestManager.h b/mx6/libcamera2/RequestManager.h
new file mode 100755
index 0000000..5a2d521
--- /dev/null
+++ b/mx6/libcamera2/RequestManager.h
@@ -0,0 +1,107 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _REQUEST_MANAGER_H
+#define _REQUEST_MANAGER_H
+
+#include "CameraUtil.h"
+#include "StreamAdapter.h"
+
+using namespace android;
+
+#define REQUEST_TYPE_PREVIEW  1
+#define REQUEST_TYPE_RECORD   2
+#define REQUEST_TYPE_CAPTURE  4
+
+#define PreviewRequestIdStart   10000000
+#define PreviewRequestIdEnd     20000000
+#define RecordingRequestIdStart 20000000
+#define RecordingRequestIdEnd   30000000
+#define CaptureRequestIdStart   30000000
+#define CaptureRequestIdEnd     40000000
+
+#define STREAM_ID_PREVIEW           (0)
+#define STREAM_ID_RECORD            (1)
+#define STREAM_ID_PRVCB             (2)
+#define STREAM_ID_JPEG              (3)
+#define STREAM_ID_ZSL               (4)
+#define STREAM_ID_JPEG_REPROCESS    (5)
+#define STREAM_ID_LAST              STREAM_ID_JPEG_REPROCESS
+
+#define MAX_STREAM_NUM  6
+
+class RequestManager : public LightRefBase<RequestManager>
+{
+public:
+    RequestManager(int cameraId);
+    ~RequestManager();
+
+    int initialize(CameraInfo& info);
+    int setRequestOperation(const camera2_request_queue_src_ops_t *request_src_ops);
+    int CreateDefaultRequest(int request_template, camera_metadata_t **request);
+    int allocateStream(uint32_t width,
+                        uint32_t height, int format,
+                        const camera2_stream_ops_t *stream_ops,
+                        uint32_t *stream_id,
+                        uint32_t *format_actual,
+                        uint32_t *usage,
+                        uint32_t *max_buffers);
+    int registerStreamBuffers(uint32_t stream_id, int num_buffers,
+                        buffer_handle_t *buffers);
+    int releaseStream(uint32_t stream_id);
+    int getInProcessCount();
+
+    int dispatchRequest();
+    bool handleRequest();
+    void release();
+
+    class RequestHandleThread : public Thread {
+    public:
+        RequestHandleThread(RequestManager *rm) :
+            Thread(false), mRequestManager(rm) {}
+#if 0
+        virtual void onFirstRef() {
+            run("RequestHandle", PRIORITY_DEFAULT);
+        }
+#endif
+        virtual bool threadLoop() {
+            return mRequestManager->handleRequest();
+        }
+
+    private:
+        RequestManager *mRequestManager;
+    };
+
+private:
+    int tryRestartStreams(int requestType);
+    void stopAllStreamsLocked();
+    bool isStreamValid(int requestType, int streamId);
+
+private:
+    sp<DeviceAdapter>  mDeviceAdapter;
+    sp<RequestHandleThread> mRequestThread;
+    mutable Mutex mThreadLock;
+    const camera2_request_queue_src_ops_t *mRequestOperation;
+    sp<MetadaManager> mMetadaManager;
+
+    sp<StreamAdapter> mStreamAdapter[MAX_STREAM_NUM];
+    mutable Mutex mStreamLock;
+    uint8_t mPendingRequests;
+    int mCameraId;
+    //CameraHal *mCameraHal;
+};
+
+#endif
diff --git a/mx6/libcamera2/StreamAdapter.cpp b/mx6/libcamera2/StreamAdapter.cpp
new file mode 100755
index 0000000..73f40ea
--- /dev/null
+++ b/mx6/libcamera2/StreamAdapter.cpp
@@ -0,0 +1,299 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "StreamAdapter.h"
+
+
+StreamAdapter::StreamAdapter(int id)
+    : mPrepared(false), mStarted(false), mStreamId(id), mWidth(0), mHeight(0), mFormat(0), mUsage(0),
+      mMaxProducerBuffers(0), mNativeWindow(NULL), mStreamState(STREAM_INVALID)
+{
+}
+
+int StreamAdapter::initialize(int width, int height, int format, int usage, int bufferNum)
+{
+    mWidth = width;
+    mHeight = height;
+    mFormat = format;
+    mUsage = usage;
+    mMaxProducerBuffers = bufferNum;
+    return 0;
+}
+
+int StreamAdapter::setPreviewWindow(const camera2_stream_ops_t* window)
+{
+    mNativeWindow = window;
+    return 0;
+}
+
+void StreamAdapter::setDeviceAdapter(sp<DeviceAdapter>& device)
+{
+    mDeviceAdapter = device;
+}
+
+void StreamAdapter::setMetadaManager(sp<MetadaManager>& metaManager)
+{
+    mMetadaManager = metaManager;
+}
+
+int StreamAdapter::start()
+{
+    FLOG_TRACE("StreamAdapter %s running", __FUNCTION__);
+    mStreamThread = new StreamThread(this);
+    mThreadQueue.postSyncMessage(new SyncMessage(STREAM_START, 0));
+
+    fAssert(mDeviceAdapter.get() != NULL);
+    mDeviceAdapter->addFrameListener(this);
+    mStarted = true;
+    return NO_ERROR;
+}
+
+int StreamAdapter::stop()
+{
+    FLOG_TRACE("StreamAdapter %s running", __FUNCTION__);
+    if (mDeviceAdapter.get() != NULL) {
+        mDeviceAdapter->removeFrameListener(this);;
+    }
+
+    if (mStreamThread.get() != NULL) {
+        mThreadQueue.postSyncMessage(new SyncMessage(STREAM_STOP, 0));
+    }
+    FLOG_TRACE("StreamAdapter %s end", __FUNCTION__);
+
+    mStarted = false;
+    return NO_ERROR;
+}
+
+int StreamAdapter::release()
+{
+    FLOG_TRACE("StreamAdapter %s running", __FUNCTION__);
+    if (mStreamThread.get() == NULL) {
+        return NO_ERROR;
+    }
+
+    mThreadQueue.postSyncMessage(new SyncMessage(STREAM_EXIT, 0));
+    mStreamThread->requestExitAndWait();
+    mStreamThread.clear();
+    mStreamState = STREAM_INVALID;
+    mPrepared = false;
+
+    return NO_ERROR;
+}
+
+bool StreamAdapter::handleStream()
+{
+    bool shouldLive = true;
+    int ret = 0;
+    CameraFrame *frame = NULL;
+
+    sp<CMessage> msg = mThreadQueue.waitMessage(THREAD_WAIT_TIMEOUT);
+    if (msg == 0) {
+        if (mStreamState == STREAM_STARTED) {
+            FLOGI("%s: get invalid message", __FUNCTION__);
+        }
+        return shouldLive;
+    }
+
+
+    switch (msg->what) {
+        case STREAM_FRAME:
+            frame = (CameraFrame *)msg->arg0;
+            if (!frame || !frame->mBufHandle) {
+                FLOGI("%s invalid frame", __FUNCTION__);
+                break;
+            }
+
+            if (mStreamState == STREAM_STARTED) {
+                ret = processFrame(frame);
+                if (!ret) {
+                    //the frame release from StreamThread.
+                    frame->release();
+                    break;
+                }
+
+            }
+
+            //the frame release from StreamThread.
+            frame->release();
+            cancelBuffer(frame);
+            if (ret != 0) {
+                mErrorListener->handleError(ret);
+                if (ret <= CAMERA2_MSG_ERROR_DEVICE) {
+                    FLOGI("stream thread dead because of error...");
+                    mStreamState = STREAM_EXITED;
+                }
+            }
+
+            break;
+
+        case STREAM_START:
+            FLOGI("stream thread received STREAM_START command");
+            if (mStreamState == STREAM_EXITED) {
+                FLOGI("can't start stream thread, thread dead...");
+            }
+            else {
+                mStreamState = STREAM_STARTED;
+            }
+
+            break;
+
+        case STREAM_STOP:
+            FLOGI("stream thread received STREAM_STOP command");
+            if (mStreamState == STREAM_EXITED) {
+                FLOGI("can't stop stream thread, thread dead...");
+            }
+            else {
+                mStreamState = STREAM_STOPPED;
+            }
+
+            break;
+
+        case STREAM_EXIT:
+            FLOGI("stream thread exiting...");
+            mStreamState = STREAM_EXITED;
+            shouldLive = false;
+            break;
+
+        default:
+            FLOGE("Invalid stream Thread Command 0x%x.", msg->what);
+            break;
+    } // end switch
+
+    return shouldLive;
+}
+
+void StreamAdapter::handleCameraFrame(CameraFrame *frame)
+{
+    if (!frame || !frame->mBufHandle) {
+        FLOGI("%s invalid frame", __FUNCTION__);
+        return;
+    }
+
+    //the frame processed in StreamThread.
+    frame->addReference();
+    mThreadQueue.postMessage(new CMessage(STREAM_FRAME, (int)frame));
+}
+
+void StreamAdapter::applyRequest()
+{
+    Mutex::Autolock _l(mMutexRespond);
+    mCondRespond.wait(mMutexRespond);
+}
+
+int StreamAdapter::processFrame(CameraFrame *frame)
+{
+    status_t ret = NO_ERROR;
+
+    StreamBuffer buffer;
+    int err = requestBuffer(&buffer);
+    if (ret != NO_ERROR) {
+        FLOGE("%s requestBuffer failed", __FUNCTION__);
+        return ret;
+    }
+
+    memcpy(buffer.mVirtAddr, (void *)frame->mVirtAddr, frame->mSize);
+    buffer.mTimeStamp = frame->mTimeStamp;
+    err = renderBuffer(&buffer);
+    if (ret != NO_ERROR) {
+        FLOGE("%s renderBuffer failed", __FUNCTION__);
+        return ret;
+    }
+
+    mCondRespond.signal();
+
+    return ret;
+}
+
+int StreamAdapter::requestBuffer(StreamBuffer* buffer)
+{
+    buffer_handle_t *buf;
+    int i = 0;
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+    Rect  bounds;
+    void *pVaddr;
+
+    if (NULL == mNativeWindow) {
+        FLOGE("mNativeWindow is null");
+        return BAD_VALUE;
+    }
+
+    int err = mNativeWindow->dequeue_buffer(mNativeWindow, &buf);
+    if (err != 0) {
+        FLOGE("dequeueBuffer failed: %s (%d)", strerror(-err), -err);
+        if (ENODEV == err) {
+            FLOGE("Preview surface abandoned!");
+            mNativeWindow = NULL;
+        }
+
+        return BAD_VALUE;
+    }
+
+    bounds.left   = 0;
+    bounds.top    = 0;
+    bounds.right  = mWidth;
+    bounds.bottom = mHeight;
+
+    // lock buffer before sending to FrameProvider for filling
+    mapper.lock(*buf, mUsage, bounds, &pVaddr);
+
+    private_handle_t *handle = (private_handle_t *)(*buf);
+    buffer->mWidth = mWidth;
+    buffer->mHeight = mHeight;
+    buffer->mFormat = mFormat;
+    buffer->mVirtAddr = pVaddr;
+    buffer->mPhyAddr = handle->phys;
+    buffer->mSize = handle->size;
+    buffer->mBufHandle = *buf;
+
+    return 0;
+}
+
+int StreamAdapter::renderBuffer(StreamBuffer *buffer)
+{
+    status_t ret = NO_ERROR;
+
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+
+    // unlock buffer before sending to stream
+    mapper.unlock(buffer->mBufHandle);
+
+    ret = mNativeWindow->enqueue_buffer(mNativeWindow, buffer->mTimeStamp,
+                                        &buffer->mBufHandle);
+    if (ret != 0) {
+        FLOGE("Surface::queueBuffer returned error %d", ret);
+    }
+
+    return ret;
+}
+
+int StreamAdapter::cancelBuffer(StreamBuffer *buffer)
+{
+    status_t ret = NO_ERROR;
+
+    GraphicBufferMapper& mapper = GraphicBufferMapper::get();
+
+    mapper.unlock(buffer->mBufHandle);
+
+    ret = mNativeWindow->cancel_buffer(mNativeWindow, &buffer->mBufHandle);
+    if (ret != 0) {
+        FLOGE("Surface::queueBuffer returned error %d", ret);
+    }
+
+    return ret;
+}
+
+
+
diff --git a/mx6/libcamera2/StreamAdapter.h b/mx6/libcamera2/StreamAdapter.h
new file mode 100755
index 0000000..116b874
--- /dev/null
+++ b/mx6/libcamera2/StreamAdapter.h
@@ -0,0 +1,175 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _STREAM_ADAPTER_H
+#define _STREAM_ADAPTER_H
+
+#include "CameraUtil.h"
+#include "messageQueue.h"
+#include "PhysMemAdapter.h"
+#include "JpegBuilder.h"
+#include "DeviceAdapter.h"
+
+using namespace android;
+
+class StreamAdapter : public LightRefBase<StreamAdapter>,
+                      public CameraFrameListener
+{
+public:
+    StreamAdapter(int id);
+    virtual ~StreamAdapter() {}
+
+    virtual int initialize(int width, int height, int format,
+                           int usage, int bufferNum);
+    virtual int setPreviewWindow(const camera2_stream_ops_t* window);
+    virtual int registerBuffers(int num_buffers, buffer_handle_t *buffers) {return 0;}
+
+    virtual int configure(int fps, bool videoSnapshot)
+    {
+        FLOG_TRACE("StreamAdapter::configure");
+        mPrepared = true;
+        return 0;
+    }
+    virtual int start();
+    virtual int stop();
+    virtual int release();
+    virtual int processFrame(CameraFrame *frame);
+    virtual void applyRequest();
+
+    void setDeviceAdapter(sp<DeviceAdapter>& device);
+    void setMetadaManager(sp<MetadaManager>& metaManager);
+    int getStreamId() {return mStreamId;}
+    int getMaxBuffers() {return mMaxProducerBuffers;}
+
+    int renderBuffer(StreamBuffer *buffer);
+    int requestBuffer(StreamBuffer* buffer);
+    int cancelBuffer(StreamBuffer *buffer);
+
+    //CameraFrameListener
+    void handleCameraFrame(CameraFrame *frame);
+    void setErrorListener(CameraErrorListener *listener);
+
+    enum StreamCommands {
+        STREAM_START,
+        STREAM_STOP,
+        STREAM_FRAME,
+        STREAM_EXIT
+    };
+
+    enum StreamStates {
+        STREAM_INVALID = 0,
+        STREAM_STARTED,
+        STREAM_STOPPED,
+        STREAM_EXITED
+    };
+
+    virtual bool handleStream();
+
+    class StreamThread : public Thread {
+    public:
+        StreamThread(StreamAdapter *stream) :
+            Thread(false), mStream(stream) {}
+
+        virtual void onFirstRef() {
+            run("RequestHandle", PRIORITY_DEFAULT);
+        }
+
+        virtual bool threadLoop() {
+            return mStream->handleStream();
+        }
+
+    private:
+        StreamAdapter *mStream;
+    };
+
+public:
+    bool mPrepared;
+    bool mStarted;
+
+protected:
+    int mStreamId;
+    int mWidth;
+    int mHeight;
+    int mFormat;
+    int mUsage;
+    int mMaxProducerBuffers;
+    const camera2_stream_ops_t *mNativeWindow;
+
+    sp<DeviceAdapter> mDeviceAdapter;
+    sp<StreamThread> mStreamThread;
+    CMessageQueue mThreadQueue;
+    int mStreamState;
+    CameraErrorListener *mErrorListener;
+
+    sp<MetadaManager> mMetadaManager;
+    mutable Mutex mMutexRespond;
+    mutable Condition mCondRespond;
+};
+
+
+class PreviewStream : public StreamAdapter, public CameraBufferProvider
+{
+public:
+    PreviewStream(int id) : StreamAdapter(id) {}
+    ~PreviewStream() {}
+
+    virtual int configure(int fps, bool videoSnapshot);
+    virtual int allocateBuffers(int width, int height,
+                               int format, int numBufs);
+    virtual int start();
+    virtual int stop();
+    virtual int release();
+    virtual int processFrame(CameraFrame *frame);
+
+    virtual int freeBuffers();
+    virtual int registerBuffers(int num_buffers, buffer_handle_t *buffers);
+
+    int getBufferIdx(buffer_handle_t *buf);
+
+private:
+    int mTotalBuffers;
+    CameraFrame mCameraBuffer[MAX_PREVIEW_BUFFER];
+};
+
+
+class CaptureStream : public StreamAdapter
+{
+public:
+    CaptureStream(int id);
+    ~CaptureStream();
+
+    virtual int initialize(int width, int height, int format,
+                           int usage, int bufferNum);
+    virtual int configure(int fps, bool videoSnapshot);
+
+    virtual int start();
+    virtual int stop();
+    virtual int release();
+    virtual int processFrame(CameraFrame *frame);
+    virtual void applyRequest();
+
+private:
+    status_t makeJpegImage(StreamBuffer *dstBuf, StreamBuffer *srcBuf);
+
+private:
+    int mActualFormat;
+    bool mVideoSnapShot;
+    PhysMemAdapter *mPhysMemAdapter;
+    sp<JpegBuilder> mJpegBuilder;
+    mutable sem_t mRespondSem;
+};
+
+#endif
diff --git a/mx6/libcamera2/UvcDevice.h b/mx6/libcamera2/UvcDevice.h
new file mode 100755
index 0000000..948c7b0
--- /dev/null
+++ b/mx6/libcamera2/UvcDevice.h
@@ -0,0 +1,39 @@
+/*
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef _UVC_DEVICE_H
+#define _UVC_DEVICE_H
+
+#include "CameraUtil.h"
+
+#define DEFAULT_PREVIEW_FPS (15)
+#define DEFAULT_PREVIEW_W   (640)
+#define DEFAULT_PREVIEW_H   (480)
+#define DEFAULT_PICTURE_W   (640)
+#define DEFAULT_PICTURE_H   (480)
+#define FORMAT_STRING_LEN 64
+
+
+class UvcDevice : public DeviceAdapter {
+public:
+    virtual status_t initSensorInfo()
+    {
+        return 0;
+    }
+};
+
+#endif // ifndef _UVC_DEVICE_H
+
diff --git a/mx6/libcamera2/YuvToJpegEncoder.cpp b/mx6/libcamera2/YuvToJpegEncoder.cpp
new file mode 100755
index 0000000..dae3389
--- /dev/null
+++ b/mx6/libcamera2/YuvToJpegEncoder.cpp
@@ -0,0 +1,404 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "YuvToJpegEncoder.h"
+#include <ui/PixelFormat.h>
+#include <hardware/hardware.h>
+#include "NV12_resize.h"
+
+YuvToJpegEncoder * YuvToJpegEncoder::create(int format) {
+    // Only ImageFormat.NV21 and ImageFormat.YUY2 are supported
+    // for now.
+    if (format == HAL_PIXEL_FORMAT_YCbCr_420_SP) {
+        return new Yuv420SpToJpegEncoder();
+    } else if (format == HAL_PIXEL_FORMAT_YCbCr_422_I) {
+        return new Yuv422IToJpegEncoder();
+    } else {
+        FLOGE("YuvToJpegEncoder:create format:%d not support", format);
+        return NULL;
+    }
+}
+
+YuvToJpegEncoder::YuvToJpegEncoder()
+{}
+
+int YuvToJpegEncoder::encode(void *inYuv,
+                             int   inWidth,
+                             int   inHeight,
+                             int   quality,
+                             void *outBuf,
+                             int   outSize,
+                             int   outWidth,
+                             int   outHeight) {
+    jpeg_compress_struct  cinfo;
+    jpegBuilder_error_mgr sk_err;
+    uint8_t *resize_src = NULL;
+    jpegBuilder_destination_mgr dest_mgr((uint8_t *)outBuf, outSize);
+
+    if ((inWidth != outWidth) || (inHeight != outHeight)) {
+        resize_src = (uint8_t *)malloc(outSize);
+        yuvResize((uint8_t *)inYuv,
+                  inWidth,
+                  inHeight,
+                  resize_src,
+                  outWidth,
+                  outHeight);
+        inYuv = resize_src;
+    }
+
+    cinfo.err = jpeg_std_error(&sk_err);
+    jpeg_create_compress(&cinfo);
+
+    cinfo.dest = &dest_mgr;
+
+    setJpegCompressStruct(&cinfo, outWidth, outHeight, quality);
+
+    jpeg_start_compress(&cinfo, TRUE);
+
+    compress(&cinfo, (uint8_t *)inYuv);
+
+    jpeg_finish_compress(&cinfo);
+
+    if (resize_src != NULL) {
+        free(resize_src);
+    }
+    return dest_mgr.jpegsize;
+}
+
+void YuvToJpegEncoder::setJpegCompressStruct(jpeg_compress_struct *cinfo,
+                                             int                   width,
+                                             int                   height,
+                                             int                   quality) {
+    cinfo->image_width      = width;
+    cinfo->image_height     = height;
+    cinfo->input_components = 3;
+    cinfo->in_color_space   = JCS_YCbCr;
+    jpeg_set_defaults(cinfo);
+
+    jpeg_set_quality(cinfo, quality, TRUE);
+    jpeg_set_colorspace(cinfo, JCS_YCbCr);
+    cinfo->raw_data_in = TRUE;
+    cinfo->dct_method  = JDCT_IFAST;
+    configSamplingFactors(cinfo);
+}
+
+// /////////////////////////////////////////////////////////////////
+Yuv420SpToJpegEncoder::Yuv420SpToJpegEncoder() :
+    YuvToJpegEncoder() {
+    fNumPlanes = 2;
+}
+
+void Yuv420SpToJpegEncoder::compress(jpeg_compress_struct *cinfo,
+                                     uint8_t              *yuv) {
+    JSAMPROW   y[16];
+    JSAMPROW   cb[8];
+    JSAMPROW   cr[8];
+    JSAMPARRAY planes[3];
+
+    planes[0] = y;
+    planes[1] = cb;
+    planes[2] = cr;
+
+    int width         = cinfo->image_width;
+    int height        = cinfo->image_height;
+    uint8_t *yPlanar  = yuv;
+    uint8_t *vuPlanar = yuv + width * height;
+    uint8_t *uRows    = new uint8_t[8 * (width >> 1)];
+    uint8_t *vRows    = new uint8_t[8 * (width >> 1)];
+
+    // process 16 lines of Y and 8 lines of U/V each time.
+    while (cinfo->next_scanline < cinfo->image_height) {
+        // deitnerleave u and v
+        deinterleave(vuPlanar, uRows, vRows, cinfo->next_scanline, width);
+
+        for (int i = 0; i < 16; i++) {
+            // y row
+            y[i] = yPlanar + (cinfo->next_scanline + i) * width;
+
+            // construct u row and v row
+            if ((i & 1) == 0) {
+                // height and width are both halved because of downsampling
+                int offset = (i >> 1) * (width >> 1);
+                cb[i / 2] = uRows + offset;
+                cr[i / 2] = vRows + offset;
+            }
+        }
+        jpeg_write_raw_data(cinfo, planes, 16);
+    }
+    delete[] uRows;
+    delete[] vRows;
+}
+
+void Yuv420SpToJpegEncoder::deinterleave(uint8_t *vuPlanar,
+                                         uint8_t *uRows,
+                                         uint8_t *vRows,
+                                         int      rowIndex,
+                                         int      width) {
+    for (int row = 0; row < 8; ++row) {
+        int offset  = ((rowIndex >> 1) + row) * width;
+        uint8_t *vu = vuPlanar + offset;
+        for (int i = 0; i < (width >> 1); ++i) {
+            int index = row * (width >> 1) + i;
+            uRows[index] = vu[0];
+            vRows[index] = vu[1];
+            vu          += 2;
+        }
+    }
+}
+
+void Yuv420SpToJpegEncoder::configSamplingFactors(jpeg_compress_struct *cinfo) {
+    // cb and cr are horizontally downsampled and vertically downsampled as
+    // well.
+    cinfo->comp_info[0].h_samp_factor = 2;
+    cinfo->comp_info[0].v_samp_factor = 2;
+    cinfo->comp_info[1].h_samp_factor = 1;
+    cinfo->comp_info[1].v_samp_factor = 1;
+    cinfo->comp_info[2].h_samp_factor = 1;
+    cinfo->comp_info[2].v_samp_factor = 1;
+}
+
+int Yuv420SpToJpegEncoder::yuvResize(uint8_t *srcBuf,
+                                     int      srcWidth,
+                                     int      srcHeight,
+                                     uint8_t *dstBuf,
+                                     int      dstWidth,
+                                     int      dstHeight)
+{
+    if (!srcBuf || !dstBuf) {
+        return -1;
+    }
+
+    structConvImage o_img_ptr, i_img_ptr;
+
+    // input
+    i_img_ptr.uWidth  =  srcWidth;
+    i_img_ptr.uStride =  i_img_ptr.uWidth;
+    i_img_ptr.uHeight =  srcHeight;
+    i_img_ptr.eFormat = IC_FORMAT_YCbCr420_lp;
+    i_img_ptr.imgPtr  = srcBuf;
+    i_img_ptr.clrPtr  = i_img_ptr.imgPtr + (i_img_ptr.uWidth * i_img_ptr.uHeight);
+
+    // ouput
+    o_img_ptr.uWidth  = dstWidth;
+    o_img_ptr.uStride = o_img_ptr.uWidth;
+    o_img_ptr.uHeight = dstHeight;
+    o_img_ptr.eFormat = IC_FORMAT_YCbCr420_lp;
+    o_img_ptr.imgPtr  = dstBuf;
+    o_img_ptr.clrPtr  = o_img_ptr.imgPtr + (o_img_ptr.uWidth * o_img_ptr.uHeight);
+
+    VT_resizeFrame_Video_opt2_lp(&i_img_ptr, &o_img_ptr, NULL, 0);
+
+    return 0;
+}
+
+// /////////////////////////////////////////////////////////////////////////////
+Yuv422IToJpegEncoder::Yuv422IToJpegEncoder() :
+    YuvToJpegEncoder() {
+    fNumPlanes = 1;
+}
+
+void Yuv422IToJpegEncoder::compress(jpeg_compress_struct *cinfo,
+                                    uint8_t              *yuv) {
+    JSAMPROW   y[16];
+    JSAMPROW   cb[16];
+    JSAMPROW   cr[16];
+    JSAMPARRAY planes[3];
+
+    planes[0] = y;
+    planes[1] = cb;
+    planes[2] = cr;
+
+    int width      = cinfo->image_width;
+    int height     = cinfo->image_height;
+    uint8_t *yRows = new uint8_t[16 * width];
+    uint8_t *uRows = new uint8_t[16 * (width >> 1)];
+    uint8_t *vRows = new uint8_t[16 * (width >> 1)];
+
+    uint8_t *yuvOffset = yuv;
+
+    // process 16 lines of Y and 16 lines of U/V each time.
+    while (cinfo->next_scanline < cinfo->image_height) {
+        deinterleave(yuvOffset,
+                     yRows,
+                     uRows,
+                     vRows,
+                     cinfo->next_scanline,
+                     width,
+                     height);
+
+        for (int i = 0; i < 16; i++) {
+            // y row
+            y[i] = yRows + i * width;
+
+            // construct u row and v row
+            // width is halved because of downsampling
+            int offset = i * (width >> 1);
+            cb[i] = uRows + offset;
+            cr[i] = vRows + offset;
+        }
+
+        jpeg_write_raw_data(cinfo, planes, 16);
+    }
+    delete[] yRows;
+    delete[] uRows;
+    delete[] vRows;
+}
+
+void Yuv422IToJpegEncoder::deinterleave(uint8_t *yuv,
+                                        uint8_t *yRows,
+                                        uint8_t *uRows,
+                                        uint8_t *vRows,
+                                        int      rowIndex,
+                                        int      width,
+                                        int      height) {
+    for (int row = 0; row < 16; ++row) {
+        uint8_t *yuvSeg = yuv + (rowIndex + row) * width * 2;
+        for (int i = 0; i < (width >> 1); ++i) {
+            int indexY = row * width + (i << 1);
+            int indexU = row * (width >> 1) + i;
+            yRows[indexY]     = yuvSeg[0];
+            yRows[indexY + 1] = yuvSeg[2];
+            uRows[indexU]     = yuvSeg[1];
+            vRows[indexU]     = yuvSeg[3];
+            yuvSeg           += 4;
+        }
+    }
+}
+
+void Yuv422IToJpegEncoder::configSamplingFactors(jpeg_compress_struct *cinfo) {
+    // cb and cr are horizontally downsampled and vertically downsampled as
+    // well.
+    cinfo->comp_info[0].h_samp_factor = 2;
+    cinfo->comp_info[0].v_samp_factor = 2;
+    cinfo->comp_info[1].h_samp_factor = 1;
+    cinfo->comp_info[1].v_samp_factor = 2;
+    cinfo->comp_info[2].h_samp_factor = 1;
+    cinfo->comp_info[2].v_samp_factor = 2;
+}
+
+int Yuv422IToJpegEncoder::yuvResize(uint8_t *srcBuf,
+                                    int      srcWidth,
+                                    int      srcHeight,
+                                    uint8_t *dstBuf,
+                                    int      dstWidth,
+                                    int      dstHeight)
+{
+    int i, j, s;
+    int h_offset;
+    int v_offset;
+    unsigned char *ptr, cc;
+    int h_scale_ratio;
+    int v_scale_ratio;
+
+    s = 0;
+
+_resize_begin:
+
+    if (!dstWidth) return -1;
+
+    if (!dstHeight) return -1;
+
+    h_scale_ratio = srcWidth / dstWidth;
+    if (!h_scale_ratio) return -1;
+
+    v_scale_ratio = srcHeight / dstHeight;
+    if (!v_scale_ratio) return -1;
+
+    h_offset = (srcWidth - dstWidth * h_scale_ratio) / 2;
+    v_offset = (srcHeight - dstHeight * v_scale_ratio) / 2;
+
+    for (i = 0; i < dstHeight * v_scale_ratio; i += v_scale_ratio)
+    {
+        for (j = 0; j < dstWidth * h_scale_ratio; j += h_scale_ratio)
+        {
+            ptr = srcBuf + i * srcWidth + j + v_offset * srcWidth + h_offset;
+            cc  = ptr[0];
+
+            ptr    = dstBuf + (i / v_scale_ratio) * dstWidth + (j / h_scale_ratio);
+            ptr[0] = cc;
+        }
+    }
+
+    srcBuf += srcWidth * srcHeight;
+    dstBuf += dstWidth * dstHeight;
+
+    if (s < 2)
+    {
+        if (!s++)
+        {
+            srcWidth  >>= 1;
+            srcHeight >>= 1;
+
+            dstWidth  >>= 1;
+            dstHeight >>= 1;
+        }
+
+        goto _resize_begin;
+    }
+
+    return 0;
+}
+
+void jpegBuilder_error_exit(j_common_ptr cinfo)
+{
+    jpegBuilder_error_mgr *error = (jpegBuilder_error_mgr *)cinfo->err;
+
+    (*error->output_message)(cinfo);
+
+    /* Let the memory manager delete any temp files before we die */
+    jpeg_destroy(cinfo);
+
+    longjmp(error->fJmpBuf, -1);
+}
+
+static void jpegBuilder_init_destination(j_compress_ptr cinfo) {
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
+
+    dest->next_output_byte = dest->buf;
+    dest->free_in_buffer   = dest->bufsize;
+    dest->jpegsize         = 0;
+}
+
+static boolean jpegBuilder_empty_output_buffer(j_compress_ptr cinfo) {
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
+
+    dest->next_output_byte = dest->buf;
+    dest->free_in_buffer   = dest->bufsize;
+    return TRUE; // ?
+}
+
+static void jpegBuilder_term_destination(j_compress_ptr cinfo) {
+    jpegBuilder_destination_mgr *dest =
+        (jpegBuilder_destination_mgr *)cinfo->dest;
+
+    dest->jpegsize = dest->bufsize - dest->free_in_buffer;
+}
+
+jpegBuilder_destination_mgr::jpegBuilder_destination_mgr(uint8_t *input,
+                                                         int      size) {
+    this->init_destination    = jpegBuilder_init_destination;
+    this->empty_output_buffer = jpegBuilder_empty_output_buffer;
+    this->term_destination    = jpegBuilder_term_destination;
+
+    this->buf     = input;
+    this->bufsize = size;
+
+    jpegsize = 0;
+}
+
diff --git a/mx6/libcamera2/YuvToJpegEncoder.h b/mx6/libcamera2/YuvToJpegEncoder.h
new file mode 100755
index 0000000..ad1e7f6
--- /dev/null
+++ b/mx6/libcamera2/YuvToJpegEncoder.h
@@ -0,0 +1,147 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ * Copyright (C) 2012-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef YuvToJpegEncoder_DEFINED
+#define YuvToJpegEncoder_DEFINED
+
+#include <string.h>
+#include <unistd.h>
+#include <time.h>
+#include <dlfcn.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <linux/time.h>
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include "CameraUtil.h"
+
+extern "C" {
+    #include "jpeglib.h"
+    #include "jerror.h"
+}
+#include <setjmp.h>
+
+class YuvToJpegEncoder {
+public:
+    /** Create an encoder based on the YUV format.
+     */
+    static YuvToJpegEncoder* create(int pixelFormat);
+
+    YuvToJpegEncoder();
+
+    /** Encode YUV data to jpeg,  which is output to a stream.
+     */
+    int encode(void *inYuv,
+               int   inWidth,
+               int   inHeight,
+               int   quality,
+               void *outBuf,
+               int   outSize,
+               int   outWidth,
+               int   outHeight);
+
+    virtual ~YuvToJpegEncoder() {}
+
+protected:
+    int fNumPlanes;
+
+    void setJpegCompressStruct(jpeg_compress_struct *cinfo,
+                               int                   width,
+                               int                   height,
+                               int                   quality);
+    virtual void configSamplingFactors(jpeg_compress_struct *cinfo) = 0;
+    virtual void compress(jpeg_compress_struct *cinfo,
+                          uint8_t              *yuv)                = 0;
+    virtual int  yuvResize(uint8_t *srcBuf,
+                           int      srcWidth,
+                           int      srcHeight,
+                           uint8_t *dstBuf,
+                           int      dstWidth,
+                           int      dstHeight) = 0;
+};
+
+class Yuv420SpToJpegEncoder : public YuvToJpegEncoder {
+public:
+    Yuv420SpToJpegEncoder();
+    virtual ~Yuv420SpToJpegEncoder() {}
+
+private:
+    void configSamplingFactors(jpeg_compress_struct *cinfo);
+    void deinterleaveYuv(uint8_t   *yuv,
+                         int        width,
+                         int        height,
+                         uint8_t *& yPlanar,
+                         uint8_t *& uPlanar,
+                         uint8_t *& vPlanar);
+    void deinterleave(uint8_t *vuPlanar,
+                      uint8_t *uRows,
+                      uint8_t *vRows,
+                      int      rowIndex,
+                      int      width);
+    void        compress(jpeg_compress_struct *cinfo,
+                         uint8_t              *yuv);
+    virtual int yuvResize(uint8_t *srcBuf,
+                          int      srcWidth,
+                          int      srcHeight,
+                          uint8_t *dstBuf,
+                          int      dstWidth,
+                          int      dstHeight);
+};
+
+class Yuv422IToJpegEncoder : public YuvToJpegEncoder {
+public:
+    Yuv422IToJpegEncoder();
+    virtual ~Yuv422IToJpegEncoder() {}
+
+private:
+    void configSamplingFactors(jpeg_compress_struct *cinfo);
+    void compress(jpeg_compress_struct *cinfo,
+                  uint8_t              *yuv);
+    void deinterleave(uint8_t *yuv,
+                      uint8_t *yRows,
+                      uint8_t *uRows,
+                      uint8_t *vRows,
+                      int      rowIndex,
+                      int      width,
+                      int      height);
+    virtual int yuvResize(uint8_t *srcBuf,
+                          int      srcWidth,
+                          int      srcHeight,
+                          uint8_t *dstBuf,
+                          int      dstWidth,
+                          int      dstHeight);
+};
+
+struct jpegBuilder_destination_mgr : jpeg_destination_mgr {
+    jpegBuilder_destination_mgr(uint8_t *input,
+                                int size);
+
+    uint8_t *buf;
+    int      bufsize;
+    size_t   jpegsize;
+};
+
+
+struct jpegBuilder_error_mgr : jpeg_error_mgr {
+    jmp_buf fJmpBuf;
+};
+
+void jpegBuilder_error_exit(j_common_ptr cinfo);
+
+#endif // ifndef YuvToJpegEncoder_DEFINED
diff --git a/mx6/libcamera2/messageQueue.cpp b/mx6/libcamera2/messageQueue.cpp
new file mode 100755
index 0000000..662a01a
--- /dev/null
+++ b/mx6/libcamera2/messageQueue.cpp
@@ -0,0 +1,147 @@
+/*
+ * Copyright (C) 2009-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+#include <stdint.h>
+#include <errno.h>
+#include <sys/types.h>
+
+#include <utils/threads.h>
+#include <utils/Timers.h>
+#include <utils/Log.h>
+#include <binder/IPCThreadState.h>
+
+#include "messageQueue.h"
+
+namespace android {
+void CMessageList::insert(const sp<CMessage>& node)
+{
+    mList.push_back(node);
+}
+
+void CMessageList::remove(CMessageList::LIST::iterator pos)
+{
+    mList.erase(pos);
+}
+
+void CMessageList::clear()
+{
+    mList.clear();
+}
+
+CMessageQueue::CMessageQueue()
+{
+    Mutex::Autolock _l(mLock);
+
+    mMessages.clear();
+}
+
+CMessageQueue::~CMessageQueue()
+{
+    Mutex::Autolock _l(mLock);
+
+    mMessages.clear();
+}
+
+sp<CMessage>CMessageQueue::waitMessage(nsecs_t timeout)
+{
+    sp<CMessage>    result;
+    sp<SyncMessage> syncResult;
+    nsecs_t timeoutTime = systemTime() + timeout;
+    while (true) {
+        Mutex::Autolock _l(mLock);
+        nsecs_t now = systemTime();
+
+        // handle sync message firstly.
+        LIST::iterator scur(mSyncMessages.begin());
+        if (scur != mSyncMessages.end()) {
+            syncResult = (SyncMessage *)(*scur).get();
+        }
+
+        if (syncResult != 0) {
+            result = (CMessage *)syncResult.get();
+            mSyncMessages.remove(scur);
+            break;
+        }
+
+        // handle sync message secondly.
+        LIST::iterator cur(mMessages.begin());
+        if (cur != mMessages.end()) {
+            result = *cur;
+        }
+
+        if (result != 0) {
+            mMessages.remove(cur);
+            break;
+        }
+
+        if (timeout >= 0) {
+            if (timeoutTime < now) {
+                result = 0;
+                break;
+            }
+            nsecs_t relTime = timeoutTime - systemTime();
+            mCondition.waitRelative(mLock, relTime);
+        } else {
+            mCondition.wait(mLock);
+        }
+    }
+
+    if (syncResult != NULL) {
+        syncResult->notify();
+    }
+
+    return result;
+}
+
+status_t CMessageQueue::postMessage(const sp<CMessage>& message,
+                                    int32_t             flags)
+{
+    return queueMessage(message, flags);
+}
+
+status_t CMessageQueue::postSyncMessage(const sp<SyncMessage>& message,
+                                        int32_t                flags)
+{
+    status_t res = queueSyncMessage(message, flags);
+
+    if (res == NO_ERROR) {
+        message->wait();
+    }
+    return res;
+}
+
+status_t CMessageQueue::queueMessage(const sp<CMessage>& message,
+                                     int32_t             flags)
+{
+    Mutex::Autolock _l(mLock);
+
+    mMessages.insert(message);
+    mCondition.signal();
+    return NO_ERROR;
+}
+
+status_t CMessageQueue::queueSyncMessage(const sp<SyncMessage>& message,
+                                         int32_t                flags)
+{
+    Mutex::Autolock _l(mLock);
+
+    mSyncMessages.insert(message.get());
+    mCondition.signal();
+    return NO_ERROR;
+}
+};
+
diff --git a/mx6/libcamera2/messageQueue.h b/mx6/libcamera2/messageQueue.h
new file mode 100755
index 0000000..575dcd6
--- /dev/null
+++ b/mx6/libcamera2/messageQueue.h
@@ -0,0 +1,131 @@
+/*
+ * Copyright (C) 2009-2013 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+#ifndef CAMERA_HAL_MESSAGE_QUEUE_H
+#define CAMERA_HAL_MESSAGE_QUEUE_H
+
+#include <stdint.h>
+#include <errno.h>
+#include <sys/types.h>
+#include <utils/threads.h>
+#include <utils/Timers.h>
+#include <utils/List.h>
+#include <semaphore.h>
+
+namespace android {
+class CMessage;
+
+class CMessageList {
+    List< sp<CMessage> > mList;
+    typedef List< sp<CMessage> > LIST;
+
+public:
+    inline LIST::iterator begin() {
+        return mList.begin();
+    }
+
+    inline LIST::const_iterator begin() const {
+        return mList.begin();
+    }
+
+    inline LIST::iterator end() {
+        return mList.end();
+    }
+
+    inline LIST::const_iterator end() const {
+        return mList.end();
+    }
+
+    inline bool isEmpty() const {
+        return mList.empty();
+    }
+
+    void insert(const sp<CMessage>& node);
+    void remove(LIST::iterator pos);
+    void clear();
+};
+
+class CMessage : public LightRefBase<CMessage>{
+public:
+    int32_t what;
+    int32_t arg0;
+
+    CMessage(int32_t what,
+             int32_t arg0 = 0)
+        : what(what), arg0(arg0) {}
+
+    virtual ~CMessage() {}
+
+private:
+    friend class LightRefBase<CMessage>;
+};
+
+class SyncMessage : public CMessage {
+public:
+    SyncMessage(int32_t what,
+                int32_t arg0 = 0)
+        : CMessage(what, arg0)
+    {
+        sem_init(&mSem, 0, 0);
+    }
+
+    void wait()
+    {
+        sem_wait(&mSem);
+    }
+
+    void notify()
+    {
+        sem_post(&mSem);
+    }
+
+    ~SyncMessage()
+    {
+        sem_destroy(&mSem);
+    }
+
+private:
+    sem_t mSem;
+};
+
+class CMessageQueue {
+    typedef List< sp<CMessage> > LIST;
+
+public:
+    CMessageQueue();
+    ~CMessageQueue();
+
+    sp<CMessage> waitMessage(nsecs_t timeout = -1);
+    status_t     postMessage(const sp<CMessage>& message,
+                             int32_t             flags = 0);
+    status_t     postSyncMessage(const sp<SyncMessage>& message,
+                                 int32_t                flags = 0);
+
+private:
+    status_t queueMessage(const sp<CMessage>& message,
+                          int32_t             flags);
+    status_t queueSyncMessage(const sp<SyncMessage>& message,
+                              int32_t                flags);
+
+    Mutex mLock;
+    Condition mCondition;
+    CMessageList mMessages;
+    CMessageList mSyncMessages;
+};
+};
+
+#endif // ifndef CAMERA_HAL_MESSAGE_QUEUE_H
-- 
1.8.0

